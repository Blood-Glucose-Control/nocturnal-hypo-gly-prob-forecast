{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.00 Data Cleaner Examples\n",
    "\n",
    "- **Author**: Christopher Risi\n",
    "- **AI Assitance**: Claude Sonnet 3.7\n",
    "\n",
    "The purpose of this notebook is to show examples of how our data cleaning functions should work when preparing data for modeling. \n",
    "\n",
    "## Requirements\n",
    "### General Requirements\n",
    "1. Install the package locally with `pip install -e .` in your project root directory\n",
    "2. Activate your virtual environment (`.noctprob-venv`) before running any code\n",
    "3. Ensure required Python packages are installed from `requirements.txt`\n",
    "\n",
    "### Dataset-Specific Requirements\n",
    "\n",
    "#### Kaggle BrisT1D\n",
    "1. Set up the Kaggle API on your machine:\n",
    "\n",
    "    - Create a Kaggle account if you don't have one\n",
    "    - Generate and download an API key from your Kaggle account settings\n",
    "    - Place the `kaggle.json` file in `~/.kaggle/ directory`\n",
    "    - Set proper permissions: ```chmod 600 ~/.kaggle/kaggle.json```\n",
    "\n",
    "2. Download the dataset using the provided script:\n",
    "\n",
    "    ```bash scripts/data_downloads/kaggle_data_download.sh```\n",
    "\n",
    "3. Ensure the dataset files are in the correct locations:\n",
    "\n",
    "    - Training data: ```src/data/datasets/kaggle_bris_t1d/raw/train.csv```\n",
    "    - Test data: ```src/data/datasets/kaggle_bris_t1d/raw/test.csv```\n",
    "\n",
    "#### Gluroo Example Dataset\n",
    "1. Ensure the Gluroo JSON data is available at the path you'll specify with the file_path parameter\n",
    "2. Optional: Configure custom cleaning parameters through the config dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Example\n",
    "> [!Note] \n",
    ">\n",
    "> If your data is not yet cached, with the current implementation (2025/07/05) this takes ~25 minutes to run on WATGPU. \n",
    "> \n",
    "> Once the data is cached this ran in ~6 seconds.\n",
    "> \n",
    "> We are working on efficiency improvements for this processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the factory function for creating data loaders\n",
    "from src.data.datasets.data_loader import get_loader\n",
    "\n",
    "# For Bristol T1D dataset (train)\n",
    "bris_loader = get_loader(\n",
    "    data_source_name=\"kaggle_brisT1D\",\n",
    "    dataset_type=\"train\",\n",
    "    use_cached=True,  # Set to False to reprocess raw data\n",
    ")\n",
    "bris_data = bris_loader.processed_data\n",
    "\n",
    "# For Bristol T1D dataset (test)\n",
    "bris_test_loader = get_loader(\n",
    "    data_source_name=\"kaggle_brisT1D\", dataset_type=\"test\", use_cached=True\n",
    ")\n",
    "bris_test_data = bris_test_loader.processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available methods and attributes of bris_loader:\n",
      "- _abc_impl\n",
      "- _get_day_splits\n",
      "- _process_raw_data\n",
      "- _validate_data\n",
      "- cached_path\n",
      "- dataset_name\n",
      "- dataset_type\n",
      "- default_path\n",
      "- file_path\n",
      "- get_validation_day_splits\n",
      "- keep_columns\n",
      "- load_data\n",
      "- load_raw\n",
      "- num_validation_days\n",
      "- processed_data\n",
      "- train_data\n",
      "- use_cached\n",
      "- validation_data\n"
     ]
    }
   ],
   "source": [
    "# Display all methods/attributes available on the bris_loader\n",
    "print(\"Available methods and attributes of bris_loader:\")\n",
    "for item in dir(bris_loader):\n",
    "    if not item.startswith(\"__\"):  # Skip dunder/magic methods\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/u6/cjrisi/nocturnal/src/data/datasets/kaggle_bris_t1d/processed/train_cached.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bris_loader.cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# For Gluroo dataset with custom configuration\u001b[39;00m\n\u001b[32m      2\u001b[39m gluroo_config = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_consecutive_nan_values_per_day\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m36\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcoerse_time_interval\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mpd\u001b[49m.Timedelta(minutes=\u001b[32m5\u001b[39m),\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mday_start_time\u001b[39m\u001b[33m\"\u001b[39m: pd.Timedelta(hours=\u001b[32m4\u001b[39m),\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmin_carbs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmeal_length\u001b[39m\u001b[33m\"\u001b[39m: pd.Timedelta(hours=\u001b[32m2\u001b[39m),\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn_top_carb_meals\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m gluroo_loader = get_loader(\n\u001b[32m     12\u001b[39m     data_source_name=\u001b[33m\"\u001b[39m\u001b[33mgluroo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     file_path=\u001b[33m\"\u001b[39m\u001b[33mpath/to/gluroo_data.csv\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     14\u001b[39m     config=gluroo_config,\n\u001b[32m     15\u001b[39m     use_cached=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m gluroo_data = gluroo_loader.processed_data\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# For Gluroo dataset with custom configuration\n",
    "gluroo_config = {\n",
    "    \"max_consecutive_nan_values_per_day\": 36,\n",
    "    \"coerse_time_interval\": pd.Timedelta(minutes=5),\n",
    "    \"day_start_time\": pd.Timedelta(hours=4),\n",
    "    \"min_carbs\": 5,\n",
    "    \"meal_length\": pd.Timedelta(hours=2),\n",
    "    \"n_top_carb_meals\": 3,\n",
    "}\n",
    "\n",
    "gluroo_loader = get_loader(\n",
    "    data_source_name=\"gluroo\",\n",
    "    file_path=\"path/to/gluroo_data.csv\",\n",
    "    config=gluroo_config,\n",
    "    use_cached=False,\n",
    ")\n",
    "gluroo_data = gluroo_loader.processed_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".noctprob-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
