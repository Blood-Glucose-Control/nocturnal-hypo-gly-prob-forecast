{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cff20a",
   "metadata": {},
   "source": [
    "# Allepo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3353016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets.aleppo import AleppoDataLoader\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data_downloads/aleppo_processed.csv\"\n",
    "keep_columns = [\"p_num\", \"date\", \"bgl\"]\n",
    "aleppo = AleppoDataLoader(file_path=file_path, keep_columns=keep_columns)\n",
    "\n",
    "train_data = aleppo.train_data\n",
    "test_data = aleppo.validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346689db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "p_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bg-0:00",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_start_shift",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "1c6939c5-ad5c-4dd7-a16d-b9e12612024d",
       "rows": [
        [
         "2015-05-22 10:37:40",
         "2",
         "8.0",
         "2015-05-22",
         "2015-05-22 10:37:40"
        ],
        [
         "2015-05-22 10:38:32",
         "2",
         "8.56",
         "2015-05-22",
         "2015-05-22 10:38:32"
        ],
        [
         "2015-05-22 10:41:29",
         "2",
         "7.94",
         "2015-05-22",
         "2015-05-22 10:41:29"
        ],
        [
         "2015-05-22 10:46:29",
         "2",
         "8.39",
         "2015-05-22",
         "2015-05-22 10:46:29"
        ],
        [
         "2015-05-22 10:51:29",
         "2",
         "8.28",
         "2015-05-22",
         "2015-05-22 10:51:29"
        ],
        [
         "2015-05-22 10:56:29",
         "2",
         "7.78",
         "2015-05-22",
         "2015-05-22 10:56:29"
        ],
        [
         "2015-05-22 11:01:29",
         "2",
         "8.28",
         "2015-05-22",
         "2015-05-22 11:01:29"
        ],
        [
         "2015-05-22 11:06:29",
         "2",
         "9.44",
         "2015-05-22",
         "2015-05-22 11:06:29"
        ],
        [
         "2015-05-22 11:11:29",
         "2",
         "10.78",
         "2015-05-22",
         "2015-05-22 11:11:29"
        ],
        [
         "2015-05-22 11:16:29",
         "2",
         "11.44",
         "2015-05-22",
         "2015-05-22 11:16:29"
        ],
        [
         "2015-05-22 11:21:29",
         "2",
         "11.44",
         "2015-05-22",
         "2015-05-22 11:21:29"
        ],
        [
         "2015-05-22 11:26:29",
         "2",
         "11.11",
         "2015-05-22",
         "2015-05-22 11:26:29"
        ],
        [
         "2015-05-22 11:31:29",
         "2",
         "10.83",
         "2015-05-22",
         "2015-05-22 11:31:29"
        ],
        [
         "2015-05-22 11:36:28",
         "2",
         "10.56",
         "2015-05-22",
         "2015-05-22 11:36:28"
        ],
        [
         "2015-05-22 11:41:28",
         "2",
         "10.56",
         "2015-05-22",
         "2015-05-22 11:41:28"
        ],
        [
         "2015-05-22 11:46:28",
         "2",
         "10.11",
         "2015-05-22",
         "2015-05-22 11:46:28"
        ],
        [
         "2015-05-22 11:51:28",
         "2",
         "9.67",
         "2015-05-22",
         "2015-05-22 11:51:28"
        ],
        [
         "2015-05-22 11:56:28",
         "2",
         "9.28",
         "2015-05-22",
         "2015-05-22 11:56:28"
        ],
        [
         "2015-05-22 12:01:28",
         "2",
         "8.83",
         "2015-05-22",
         "2015-05-22 12:01:28"
        ],
        [
         "2015-05-22 12:06:28",
         "2",
         "8.11",
         "2015-05-22",
         "2015-05-22 12:06:28"
        ],
        [
         "2015-05-22 12:11:28",
         "2",
         "7.56",
         "2015-05-22",
         "2015-05-22 12:11:28"
        ],
        [
         "2015-05-22 12:16:28",
         "2",
         "6.67",
         "2015-05-22",
         "2015-05-22 12:16:28"
        ],
        [
         "2015-05-22 12:21:28",
         "2",
         "6.11",
         "2015-05-22",
         "2015-05-22 12:21:28"
        ],
        [
         "2015-05-22 12:26:28",
         "2",
         "6.39",
         "2015-05-22",
         "2015-05-22 12:26:28"
        ],
        [
         "2015-05-22 12:31:28",
         "2",
         "6.28",
         "2015-05-22",
         "2015-05-22 12:31:28"
        ],
        [
         "2015-05-22 12:36:28",
         "2",
         "5.72",
         "2015-05-22",
         "2015-05-22 12:36:28"
        ],
        [
         "2015-05-22 12:41:28",
         "2",
         "4.5",
         "2015-05-22",
         "2015-05-22 12:41:28"
        ],
        [
         "2015-05-22 12:46:28",
         "2",
         "4.33",
         "2015-05-22",
         "2015-05-22 12:46:28"
        ],
        [
         "2015-05-22 12:51:28",
         "2",
         "4.33",
         "2015-05-22",
         "2015-05-22 12:51:28"
        ],
        [
         "2015-05-22 12:56:28",
         "2",
         "4.33",
         "2015-05-22",
         "2015-05-22 12:56:28"
        ],
        [
         "2015-05-22 13:01:28",
         "2",
         "4.94",
         "2015-05-22",
         "2015-05-22 13:01:28"
        ],
        [
         "2015-05-22 13:06:28",
         "2",
         "4.22",
         "2015-05-22",
         "2015-05-22 13:06:28"
        ],
        [
         "2015-05-22 13:11:28",
         "2",
         "3.5",
         "2015-05-22",
         "2015-05-22 13:11:28"
        ],
        [
         "2015-05-22 13:16:28",
         "2",
         "2.89",
         "2015-05-22",
         "2015-05-22 13:16:28"
        ],
        [
         "2015-05-22 13:21:28",
         "2",
         "2.61",
         "2015-05-22",
         "2015-05-22 13:21:28"
        ],
        [
         "2015-05-22 13:26:28",
         "2",
         "3.44",
         "2015-05-22",
         "2015-05-22 13:26:28"
        ],
        [
         "2015-05-22 13:31:28",
         "2",
         "2.39",
         "2015-05-22",
         "2015-05-22 13:31:28"
        ],
        [
         "2015-05-22 13:36:28",
         "2",
         "2.83",
         "2015-05-22",
         "2015-05-22 13:36:28"
        ],
        [
         "2015-05-22 13:41:28",
         "2",
         "3.22",
         "2015-05-22",
         "2015-05-22 13:41:28"
        ],
        [
         "2015-05-22 13:46:28",
         "2",
         "3.94",
         "2015-05-22",
         "2015-05-22 13:46:28"
        ],
        [
         "2015-05-22 13:51:28",
         "2",
         "4.0",
         "2015-05-22",
         "2015-05-22 13:51:28"
        ],
        [
         "2015-05-22 13:56:28",
         "2",
         "4.22",
         "2015-05-22",
         "2015-05-22 13:56:28"
        ],
        [
         "2015-05-22 14:01:28",
         "2",
         "3.44",
         "2015-05-22",
         "2015-05-22 14:01:28"
        ],
        [
         "2015-05-22 14:06:28",
         "2",
         "2.56",
         "2015-05-22",
         "2015-05-22 14:06:28"
        ],
        [
         "2015-05-22 14:11:28",
         "2",
         "2.39",
         "2015-05-22",
         "2015-05-22 14:11:28"
        ],
        [
         "2015-05-22 14:16:28",
         "2",
         "2.44",
         "2015-05-22",
         "2015-05-22 14:16:28"
        ],
        [
         "2015-05-22 14:21:28",
         "2",
         "2.78",
         "2015-05-22",
         "2015-05-22 14:21:28"
        ],
        [
         "2015-05-22 14:26:28",
         "2",
         "4.06",
         "2015-05-22",
         "2015-05-22 14:26:28"
        ],
        [
         "2015-05-22 14:31:28",
         "2",
         "4.67",
         "2015-05-22",
         "2015-05-22 14:31:28"
        ],
        [
         "2015-05-22 14:36:28",
         "2",
         "4.56",
         "2015-05-22",
         "2015-05-22 14:36:28"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 13735857
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_num</th>\n",
       "      <th>bg-0:00</th>\n",
       "      <th>day_start_shift</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-05-22 10:37:40</th>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>2015-05-22 10:37:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-22 10:38:32</th>\n",
       "      <td>2</td>\n",
       "      <td>8.56</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>2015-05-22 10:38:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-22 10:41:29</th>\n",
       "      <td>2</td>\n",
       "      <td>7.94</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>2015-05-22 10:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-22 10:46:29</th>\n",
       "      <td>2</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>2015-05-22 10:46:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-22 10:51:29</th>\n",
       "      <td>2</td>\n",
       "      <td>8.28</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>2015-05-22 10:51:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-10 06:34:34</th>\n",
       "      <td>293</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-11-10 06:34:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-10 06:39:34</th>\n",
       "      <td>293</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-11-10 06:39:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-10 06:44:34</th>\n",
       "      <td>293</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-11-10 06:44:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-10 06:49:34</th>\n",
       "      <td>293</td>\n",
       "      <td>6.56</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-11-10 06:49:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-10 06:54:34</th>\n",
       "      <td>293</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-11-10 06:54:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13735857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p_num  bg-0:00 day_start_shift            datetime\n",
       "date                                                                   \n",
       "2015-05-22 10:37:40      2     8.00      2015-05-22 2015-05-22 10:37:40\n",
       "2015-05-22 10:38:32      2     8.56      2015-05-22 2015-05-22 10:38:32\n",
       "2015-05-22 10:41:29      2     7.94      2015-05-22 2015-05-22 10:41:29\n",
       "2015-05-22 10:46:29      2     8.39      2015-05-22 2015-05-22 10:46:29\n",
       "2015-05-22 10:51:29      2     8.28      2015-05-22 2015-05-22 10:51:29\n",
       "...                    ...      ...             ...                 ...\n",
       "2015-11-10 06:34:34    293     6.67      2015-11-10 2015-11-10 06:34:34\n",
       "2015-11-10 06:39:34    293     6.67      2015-11-10 2015-11-10 06:39:34\n",
       "2015-11-10 06:44:34    293     6.67      2015-11-10 2015-11-10 06:44:34\n",
       "2015-11-10 06:49:34    293     6.56      2015-11-10 2015-11-10 06:49:34\n",
       "2015-11-10 06:54:34    293     6.50      2015-11-10 2015-11-10 06:54:34\n",
       "\n",
       "[13735857 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f46693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "p_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bg-0:00",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_start_shift",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "ee661712-7f5c-4377-969b-cf2591324b46",
       "rows": [
        [
         "2015-12-30 07:01:25",
         "2",
         "4.56",
         "2015-12-30",
         "2015-12-30 07:01:25"
        ],
        [
         "2015-12-30 07:06:25",
         "2",
         "4.5",
         "2015-12-30",
         "2015-12-30 07:06:25"
        ],
        [
         "2015-12-30 07:11:25",
         "2",
         "4.56",
         "2015-12-30",
         "2015-12-30 07:11:25"
        ],
        [
         "2015-12-30 07:16:25",
         "2",
         "4.78",
         "2015-12-30",
         "2015-12-30 07:16:25"
        ],
        [
         "2015-12-30 07:21:25",
         "2",
         "4.89",
         "2015-12-30",
         "2015-12-30 07:21:25"
        ],
        [
         "2015-12-30 07:26:25",
         "2",
         "4.94",
         "2015-12-30",
         "2015-12-30 07:26:25"
        ],
        [
         "2015-12-30 07:31:25",
         "2",
         "4.89",
         "2015-12-30",
         "2015-12-30 07:31:25"
        ],
        [
         "2015-12-30 07:36:25",
         "2",
         "4.89",
         "2015-12-30",
         "2015-12-30 07:36:25"
        ],
        [
         "2015-12-30 07:41:25",
         "2",
         "4.83",
         "2015-12-30",
         "2015-12-30 07:41:25"
        ],
        [
         "2015-12-30 07:46:25",
         "2",
         "4.72",
         "2015-12-30",
         "2015-12-30 07:46:25"
        ],
        [
         "2015-12-30 07:51:25",
         "2",
         "4.61",
         "2015-12-30",
         "2015-12-30 07:51:25"
        ],
        [
         "2015-12-30 07:56:25",
         "2",
         "4.5",
         "2015-12-30",
         "2015-12-30 07:56:25"
        ],
        [
         "2015-12-30 08:01:25",
         "2",
         "4.56",
         "2015-12-30",
         "2015-12-30 08:01:25"
        ],
        [
         "2015-12-30 08:06:25",
         "2",
         "4.72",
         "2015-12-30",
         "2015-12-30 08:06:25"
        ],
        [
         "2015-12-30 08:11:25",
         "2",
         "4.83",
         "2015-12-30",
         "2015-12-30 08:11:25"
        ],
        [
         "2015-12-30 08:16:25",
         "2",
         "4.39",
         "2015-12-30",
         "2015-12-30 08:16:25"
        ],
        [
         "2015-12-30 08:21:25",
         "2",
         "4.11",
         "2015-12-30",
         "2015-12-30 08:21:25"
        ],
        [
         "2015-12-30 08:26:25",
         "2",
         "3.89",
         "2015-12-30",
         "2015-12-30 08:26:25"
        ],
        [
         "2015-12-30 08:31:25",
         "2",
         "3.72",
         "2015-12-30",
         "2015-12-30 08:31:25"
        ],
        [
         "2015-12-30 08:36:24",
         "2",
         "3.56",
         "2015-12-30",
         "2015-12-30 08:36:24"
        ],
        [
         "2015-12-30 08:41:24",
         "2",
         "3.67",
         "2015-12-30",
         "2015-12-30 08:41:24"
        ],
        [
         "2015-12-30 08:46:24",
         "2",
         "3.83",
         "2015-12-30",
         "2015-12-30 08:46:24"
        ],
        [
         "2015-12-30 08:51:24",
         "2",
         "3.89",
         "2015-12-30",
         "2015-12-30 08:51:24"
        ],
        [
         "2015-12-30 08:56:24",
         "2",
         "4.0",
         "2015-12-30",
         "2015-12-30 08:56:24"
        ],
        [
         "2015-12-30 09:01:24",
         "2",
         "4.0",
         "2015-12-30",
         "2015-12-30 09:01:24"
        ],
        [
         "2015-12-30 09:06:24",
         "2",
         "4.06",
         "2015-12-30",
         "2015-12-30 09:06:24"
        ],
        [
         "2015-12-30 09:11:24",
         "2",
         "4.17",
         "2015-12-30",
         "2015-12-30 09:11:24"
        ],
        [
         "2015-12-30 09:16:24",
         "2",
         "4.17",
         "2015-12-30",
         "2015-12-30 09:16:24"
        ],
        [
         "2015-12-30 09:21:24",
         "2",
         "4.17",
         "2015-12-30",
         "2015-12-30 09:21:24"
        ],
        [
         "2015-12-30 09:26:24",
         "2",
         "4.28",
         "2015-12-30",
         "2015-12-30 09:26:24"
        ],
        [
         "2015-12-30 09:31:24",
         "2",
         "4.39",
         "2015-12-30",
         "2015-12-30 09:31:24"
        ],
        [
         "2015-12-30 09:36:24",
         "2",
         "4.39",
         "2015-12-30",
         "2015-12-30 09:36:24"
        ],
        [
         "2015-12-30 09:41:24",
         "2",
         "4.5",
         "2015-12-30",
         "2015-12-30 09:41:24"
        ],
        [
         "2015-12-30 09:46:24",
         "2",
         "4.61",
         "2015-12-30",
         "2015-12-30 09:46:24"
        ],
        [
         "2015-12-30 09:51:24",
         "2",
         "4.61",
         "2015-12-30",
         "2015-12-30 09:51:24"
        ],
        [
         "2015-12-30 09:56:24",
         "2",
         "4.61",
         "2015-12-30",
         "2015-12-30 09:56:24"
        ],
        [
         "2015-12-30 10:01:24",
         "2",
         "4.83",
         "2015-12-30",
         "2015-12-30 10:01:24"
        ],
        [
         "2015-12-30 10:06:24",
         "2",
         "5.06",
         "2015-12-30",
         "2015-12-30 10:06:24"
        ],
        [
         "2015-12-30 10:11:24",
         "2",
         "5.28",
         "2015-12-30",
         "2015-12-30 10:11:24"
        ],
        [
         "2015-12-30 10:16:24",
         "2",
         "5.44",
         "2015-12-30",
         "2015-12-30 10:16:24"
        ],
        [
         "2015-12-30 10:21:24",
         "2",
         "5.61",
         "2015-12-30",
         "2015-12-30 10:21:24"
        ],
        [
         "2015-12-30 10:26:24",
         "2",
         "5.67",
         "2015-12-30",
         "2015-12-30 10:26:24"
        ],
        [
         "2015-12-30 10:31:24",
         "2",
         "5.67",
         "2015-12-30",
         "2015-12-30 10:31:24"
        ],
        [
         "2015-12-30 10:36:24",
         "2",
         "5.5",
         "2015-12-30",
         "2015-12-30 10:36:24"
        ],
        [
         "2015-12-30 10:41:24",
         "2",
         "5.33",
         "2015-12-30",
         "2015-12-30 10:41:24"
        ],
        [
         "2015-12-30 10:46:24",
         "2",
         "5.17",
         "2015-12-30",
         "2015-12-30 10:46:24"
        ],
        [
         "2015-12-30 10:51:24",
         "2",
         "5.0",
         "2015-12-30",
         "2015-12-30 10:51:24"
        ],
        [
         "2015-12-30 10:56:24",
         "2",
         "4.83",
         "2015-12-30",
         "2015-12-30 10:56:24"
        ],
        [
         "2015-12-30 11:01:24",
         "2",
         "4.72",
         "2015-12-30",
         "2015-12-30 11:01:24"
        ],
        [
         "2015-12-30 11:06:24",
         "2",
         "4.67",
         "2015-12-30",
         "2015-12-30 11:06:24"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1202240
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_num</th>\n",
       "      <th>bg-0:00</th>\n",
       "      <th>day_start_shift</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-30 07:01:25</th>\n",
       "      <td>2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015-12-30 07:01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30 07:06:25</th>\n",
       "      <td>2</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015-12-30 07:06:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30 07:11:25</th>\n",
       "      <td>2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015-12-30 07:11:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30 07:16:25</th>\n",
       "      <td>2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015-12-30 07:16:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30 07:21:25</th>\n",
       "      <td>2</td>\n",
       "      <td>4.89</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015-12-30 07:21:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30 06:38:08</th>\n",
       "      <td>293</td>\n",
       "      <td>9.06</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2015-11-30 06:38:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30 06:43:08</th>\n",
       "      <td>293</td>\n",
       "      <td>9.06</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2015-11-30 06:43:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30 06:48:08</th>\n",
       "      <td>293</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2015-11-30 06:48:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30 06:53:08</th>\n",
       "      <td>293</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2015-11-30 06:53:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30 06:58:08</th>\n",
       "      <td>293</td>\n",
       "      <td>8.83</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2015-11-30 06:58:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202240 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p_num  bg-0:00 day_start_shift            datetime\n",
       "date                                                                   \n",
       "2015-12-30 07:01:25      2     4.56      2015-12-30 2015-12-30 07:01:25\n",
       "2015-12-30 07:06:25      2     4.50      2015-12-30 2015-12-30 07:06:25\n",
       "2015-12-30 07:11:25      2     4.56      2015-12-30 2015-12-30 07:11:25\n",
       "2015-12-30 07:16:25      2     4.78      2015-12-30 2015-12-30 07:16:25\n",
       "2015-12-30 07:21:25      2     4.89      2015-12-30 2015-12-30 07:21:25\n",
       "...                    ...      ...             ...                 ...\n",
       "2015-11-30 06:38:08    293     9.06      2015-11-30 2015-11-30 06:38:08\n",
       "2015-11-30 06:43:08    293     9.06      2015-11-30 2015-11-30 06:43:08\n",
       "2015-11-30 06:48:08    293     9.00      2015-11-30 2015-11-30 06:48:08\n",
       "2015-11-30 06:53:08    293     8.89      2015-11-30 2015-11-30 06:53:08\n",
       "2015-11-30 06:58:08    293     8.83      2015-11-30 2015-11-30 06:58:08\n",
       "\n",
       "[1202240 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ce549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214aaddf3ad14d2ab64c8fb97aaebcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing patients:   0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-minute patients: [2, 3, 8, 14, 17, 19, 22, 29, 31, 32, 40, 48, 49, 52, 54, 58, 61, 69, 70, 74, 76, 80, 98, 105, 108, 112, 118, 123, 124, 127, 132, 134, 140, 145, 149, 158, 163, 166, 167, 168, 177, 179, 181, 184, 186, 189, 197, 203, 209, 215, 218, 223, 224, 226, 239, 243, 244, 252, 260, 265, 267, 291, 292]\n",
      "5-minute patients: [5, 7, 15, 16, 18, 20, 23, 24, 37, 38, 39, 41, 46, 55, 60, 67, 68, 72, 77, 79, 82, 95, 111, 116, 119, 121, 135, 137, 139, 141, 146, 155, 162, 164, 172, 176, 183, 185, 187, 193, 200, 201, 205, 213, 219, 220, 227, 228, 229, 235, 245, 249, 251, 263, 269, 271, 277, 281, 283, 285]\n",
      "9-minute patients: [9, 234]\n",
      "2-minute patients: [10, 109, 175, 211, 233, 256, 276, 284]\n",
      "35-minute patients: [11]\n",
      "12-minute patients: [21, 86]\n",
      "1-minute patients: [26, 27, 42, 45, 53, 62, 73, 87, 97, 102, 103, 113, 138, 148, 156, 190, 214, 217, 236, 248, 273]\n",
      "46-minute patients: [30]\n",
      "19-minute patients: [33, 136, 157, 210, 274]\n",
      "41-minute patients: [35, 101]\n",
      "25-minute patients: [36, 65, 264]\n",
      "4-minute patients: [43, 288]\n",
      "24-minute patients: [47, 198]\n",
      "36-minute patients: [50, 266]\n",
      "23-minute patients: [57, 115, 152, 160, 222]\n",
      "27-minute patients: [64, 241]\n",
      "57-minute patients: [71]\n",
      "16-minute patients: [78, 204, 206, 253, 254, 272, 290]\n",
      "6-minute patients: [81, 93, 131]\n",
      "42-minute patients: [89]\n",
      "30-minute patients: [90]\n",
      "15-minute patients: [91, 246]\n",
      "47-minute patients: [96]\n",
      "20-minute patients: [106, 143, 147, 188]\n",
      "18-minute patients: [110, 165]\n",
      "14-minute patients: [128, 129, 250]\n",
      "13-minute patients: [130, 289]\n",
      "17-minute patients: [169]\n",
      "52-minute patients: [170]\n",
      "26-minute patients: [171]\n",
      "3-minute patients: [173, 287]\n",
      "59-minute patients: [174]\n",
      "44-minute patients: [216]\n",
      "54-minute patients: [221]\n",
      "21-minute patients: [231, 293]\n",
      "31-minute patients: [232]\n",
      "56-minute patients: [240]\n",
      "11-minute patients: [247]\n",
      "8-minute patients: [257]\n",
      "28-minute patients: [258]\n",
      "48-minute patients: [275]\n",
      "58-minute patients: [278]\n",
      "53-minute patients: [280]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "patients_by_timestep: dict[int, list[int]] = {}\n",
    "train_df_by_timestep: dict[int, pd.DataFrame] = {}\n",
    "train_5min = None\n",
    "train_15min = None\n",
    "\n",
    "unique_patients = aleppo.train_data[\"p_num\"].unique()\n",
    "# Process each patient\n",
    "for patient in tqdm(\n",
    "    unique_patients, total=len(unique_patients), desc=\"Processing patients\"\n",
    "):\n",
    "    train_patient = aleppo.train_data[aleppo.train_data[\"p_num\"] == patient]\n",
    "    test_patient = aleppo.validation_data[aleppo.validation_data[\"p_num\"] == patient]\n",
    "\n",
    "    # use the first 2 rows to figure out the interval\n",
    "    time_step = (\n",
    "        train_patient[\"datetime\"].iloc[1] - train_patient[\"datetime\"].iloc[0]\n",
    "    ).components.minutes\n",
    "\n",
    "    # Add to appropriate list based on time step\n",
    "    if time_step not in patients_by_timestep:\n",
    "        patients_by_timestep[time_step] = []\n",
    "    patients_by_timestep[time_step].append(patient)\n",
    "\n",
    "    if time_step not in train_df_by_timestep:\n",
    "        train_df_by_timestep[time_step] = pd.concat([train_patient])\n",
    "    else:\n",
    "        train_df_by_timestep[time_step] = pd.concat(\n",
    "            [train_df_by_timestep[time_step], train_patient]\n",
    "        )\n",
    "\n",
    "for timestep, patients in patients_by_timestep.items():\n",
    "    print(f\"{timestep}-minute patients: {patients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1496414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.impute import Imputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def impute_missing_values(\n",
    "    df,\n",
    "    columns,\n",
    "    bg_method=\"linear\",\n",
    "    hr_method=\"linear\",\n",
    "    step_method=\"constant\",\n",
    "    cal_method=\"constant\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Imputes missing values in specified columns of a dataframe using different methods based on the data type.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe containing missing values\n",
    "        columns (list): List of column names to impute missing values for\n",
    "        bg_method (str, optional): Imputation method for blood glucose data.\n",
    "            Valid values: 'linear', 'nearest'. Defaults to \"linear\".\n",
    "        hr_method (str, optional): Imputation method for heart rate data.\n",
    "            Valid values: 'linear', 'nearest'. Defaults to \"linear\".\n",
    "        step_method (str, optional): Imputation method for step count data.\n",
    "            Valid values: 'constant'.\n",
    "        cal_method (str, optional): Imputation method for calorie data.\n",
    "            Valid values: 'constant'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Copy of input dataframe with missing values imputed using appropriate methods for each data type\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    transform = None\n",
    "\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            if \"bg\" in col.lower():\n",
    "                transform = Imputer(method=bg_method)\n",
    "            elif \"hr\" in col.lower():\n",
    "                # Use linear or nearest neighbor interpolation for heart rate\n",
    "                # TODO: Need more research on this\n",
    "                transform = Imputer(method=hr_method)\n",
    "            elif \"step\" in col.lower():\n",
    "                # Use constant imputation with 0 for steps\n",
    "                transform = Imputer(method=step_method, value=0)\n",
    "            elif \"cals\" in col.lower():\n",
    "                # Use constant imputation with minimum value for calories\n",
    "                min_val = df[col].min()\n",
    "                transform = Imputer(method=cal_method, value=min_val)\n",
    "\n",
    "            if transform is not None:\n",
    "                df_imputed[col] = transform.fit_transform(df[col].to_frame())\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcaa202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from src.tuning.benchmark import impute_missing_values\n",
    "\n",
    "\n",
    "def reduce_features(df):\n",
    "    p_df = df.copy()\n",
    "\n",
    "    y_feature = [\"bg-0:00\"]\n",
    "    x_features = [\"bg-0:00\"]\n",
    "    features = list(set(x_features + y_feature))\n",
    "    p_df = p_df[features]\n",
    "\n",
    "    # Get unique instance and time levels\n",
    "    instance_idx = p_df.index.get_level_values(0).unique()\n",
    "    time_idx = sorted(p_df.index.get_level_values(1).unique())\n",
    "\n",
    "    # Reindex each instance to ensure uniform time index\n",
    "    aligned_dfs = []\n",
    "    for inst in tqdm(\n",
    "        instance_idx, total=len(instance_idx), desc=\"Processing instances (patients)\"\n",
    "    ):\n",
    "        inst_df = p_df.loc[inst]  # get time-indexed df for this instance\n",
    "        # Drop duplicate time entries (keep first occurrence)\n",
    "        inst_df = inst_df[~inst_df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        inst_df = inst_df.reindex(time_idx)  # align time index\n",
    "        inst_df[\"instance\"] = inst\n",
    "        aligned_dfs.append(inst_df)\n",
    "\n",
    "    # Combine back into a panel DataFrame with MultiIndex\n",
    "    aligned_df = pd.concat(aligned_dfs)\n",
    "    aligned_df.set_index(\"instance\", append=True, inplace=True)\n",
    "    aligned_df = aligned_df.reorder_levels([1, 0])  # (instance, time)\n",
    "    aligned_df.sort_index(inplace=True)\n",
    "    print(\"Imputing missing values...\")\n",
    "\n",
    "    # Impute missing values caused by reindexing\n",
    "    aligned_df = impute_missing_values(aligned_df, columns=x_features)\n",
    "    aligned_df = impute_missing_values(aligned_df, columns=y_feature)\n",
    "\n",
    "    # Split into y and X\n",
    "    y = aligned_df[y_feature]\n",
    "    X = aligned_df[x_features]\n",
    "\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b51133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def reduce_features_x(df: pd.DataFrame):\n",
    "    # Define features\n",
    "    y_feature = [\"bg-0:00\"]\n",
    "    x_features = [\"bg-0:00\"]\n",
    "    features = list(set(x_features + y_feature))\n",
    "\n",
    "    # Convert to Polars\n",
    "    df_pl = pl.from_pandas(df.reset_index(), include_index=False)\n",
    "    print(df_pl.columns)\n",
    "\n",
    "    # Drop duplicates on (p_num, datetime)\n",
    "    df_pl = df_pl.unique(subset=[\"p_num\", \"datetime\"], keep=\"first\")\n",
    "\n",
    "    # Get full datetime range\n",
    "    # all_times = df_pl.select(\"datetime\").unique().sort(\"datetime\").to_series().to_list()\n",
    "\n",
    "    # Pivot each feature wide by datetime\n",
    "    wide_dfs = []\n",
    "    for feature in features:\n",
    "        print(f\"Processing feature: {feature}\")\n",
    "        pivoted = (\n",
    "            df_pl.select([\"p_num\", \"datetime\", feature])\n",
    "            .pivot(index=\"p_num\", columns=\"datetime\", values=feature)\n",
    "            .sort(\"p_num\")\n",
    "        )\n",
    "\n",
    "        # Rename columns with feature prefix\n",
    "        pivoted = pivoted.rename(\n",
    "            {\n",
    "                col: f\"{feature}_{col}\" if col != \"p_num\" else \"p_num\"\n",
    "                for col in pivoted.columns\n",
    "            }\n",
    "        )\n",
    "        wide_dfs.append(pivoted)\n",
    "\n",
    "    # Concatenate all features horizontally\n",
    "    df_wide = wide_dfs[0]\n",
    "    for wdf in wide_dfs[1:]:\n",
    "        df_wide = df_wide.join(wdf, on=\"p_num\", how=\"inner\")\n",
    "\n",
    "    # Melt back to long\n",
    "    df_long = df_wide.melt(id_vars=\"p_num\")\n",
    "\n",
    "    # Split column names into feature and datetime\n",
    "    df_long = (\n",
    "        df_long.with_columns(\n",
    "            [pl.col(\"variable\").str.split(\"_\", inclusive=False).alias(\"split\")]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"split\").arr.get(0).alias(\"feature\"),\n",
    "                pl.col(\"split\").arr.get(1).alias(\"datetime_str\"),\n",
    "            ]\n",
    "        )\n",
    "        .drop([\"split\", \"variable\"])\n",
    "    )\n",
    "\n",
    "    # Parse datetime\n",
    "    df_long = df_long.with_columns(\n",
    "        [\n",
    "            pl.col(\"datetime_str\")\n",
    "            .str.strip_chars()\n",
    "            .str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\", strict=False)\n",
    "        ]\n",
    "    ).rename({\"datetime_str\": \"datetime\", \"value\": \"value\"})\n",
    "\n",
    "    # Pivot to wide (columns = features), restore (p_num, datetime) index\n",
    "    df_final = df_long.pivot(\n",
    "        index=[\"p_num\", \"datetime\"], columns=\"feature\", values=\"value\"\n",
    "    )\n",
    "\n",
    "    # Convert to pandas\n",
    "    df_pd = df_final.to_pandas()\n",
    "    df_pd.set_index([\"p_num\", \"datetime\"], inplace=True)\n",
    "    df_pd.sort_index(inplace=True)\n",
    "\n",
    "    # Impute missing values\n",
    "    df_pd = impute_missing_values(df_pd, columns=features)\n",
    "\n",
    "    # Final split\n",
    "    y = df_pd[y_feature]\n",
    "    X = df_pd[x_features]\n",
    "\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01161d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p_num', 'date', 'bg-0:00', 'day_start_shift', 'datetime']\n",
      "Processing feature: bg-0:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viloh\\AppData\\Local\\Temp\\ipykernel_17908\\3994790620.py:26: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  .pivot(index=\"p_num\", columns=\"datetime\", values=feature)\n",
      "C:\\Users\\viloh\\AppData\\Local\\Temp\\ipykernel_17908\\3994790620.py:43: DeprecationWarning: `DataFrame.melt` is deprecated. Use `unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n",
      "  df_long = df_wide.melt(id_vars=\"p_num\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "timestep = 5\n",
    "# get the first patient\n",
    "df = train_df_by_timestep[timestep].reset_index()\n",
    "df = df.set_index([\"p_num\", \"date\"]).sort_index()\n",
    "y_train, X_train = reduce_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d37f71d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('p_num', 'date')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "bg-0:00",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "44964adf-4fbb-4c42-8240-a832e8517c16",
       "rows": [
        [
         "(5, Timestamp('2014-12-15 19:49:00'))",
         "8.0"
        ],
        [
         "(5, Timestamp('2014-12-15 19:54:00'))",
         "7.83"
        ],
        [
         "(5, Timestamp('2014-12-15 19:59:00'))",
         "7.56"
        ],
        [
         "(5, Timestamp('2014-12-15 20:04:00'))",
         "7.28"
        ],
        [
         "(5, Timestamp('2014-12-15 20:09:00'))",
         "7.17"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bg-0:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_num</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>2014-12-15 19:49:00</th>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-15 19:54:00</th>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-15 19:59:00</th>\n",
       "      <td>7.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-15 20:04:00</th>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-15 20:09:00</th>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           bg-0:00\n",
       "p_num date                        \n",
       "5     2014-12-15 19:49:00     8.00\n",
       "      2014-12-15 19:54:00     7.83\n",
       "      2014-12-15 19:59:00     7.56\n",
       "      2014-12-15 20:04:00     7.28\n",
       "      2014-12-15 20:09:00     7.17"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a111eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected interval:  05mins\n",
      "Training samples: 3957039\n",
      "Batch size: 128\n",
      "Steps per epoch: 30914\n",
      "Saving a checkpoint every 61828 steps\n"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.ttm import TinyTimeMixerForecaster\n",
    "import pandas as pd\n",
    "\n",
    "# loss_callback = LossPlottingCallback()\n",
    "\n",
    "current_time = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "training_samples = len(y_train)\n",
    "batch_size = 128\n",
    "steps_per_epoch = training_samples // batch_size\n",
    "\n",
    "TIME_STEP_SIZE = timestep\n",
    "SAVE_EVERY_EPOCH = 2  # How many epochs to save\n",
    "\n",
    "# interval = \"05mins\" if use_5min else \"15mins\"\n",
    "interval = \"05mins\"\n",
    "dir_path = f\"../../src/models/ttm/{interval}/{current_time}\"\n",
    "\n",
    "ttm_forecaster = TinyTimeMixerForecaster(\n",
    "    config={\n",
    "        \"context_length\": (60 // TIME_STEP_SIZE) * 18,  # 18 hours of context length\n",
    "        \"prediction_length\": (60 // TIME_STEP_SIZE) * 6,  # 6 hours of prediction length\n",
    "    },\n",
    "    training_args={\n",
    "        \"num_train_epochs\": 2,\n",
    "        \"output_dir\": dir_path,\n",
    "        \"use_cpu\": False,\n",
    "        \"per_device_train_batch_size\": batch_size,\n",
    "        \"save_steps\": steps_per_epoch * SAVE_EVERY_EPOCH,\n",
    "        # \"callbacks\": [],  # Add the callback here, why is this not working?\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"selected interval: \", interval)\n",
    "print(f\"Training samples: {training_samples}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Saving a checkpoint every {steps_per_epoch * SAVE_EVERY_EPOCH} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa235fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOURS_TO_PREDICT = 6\n",
    "NUM_STEPS = HOURS_TO_PREDICT * 60 // TIME_STEP_SIZE\n",
    "\n",
    "fh = np.arange(1, NUM_STEPS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7cf006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20ba851209f4bbebb7818172d837d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\sktime\\forecasting\\ttm.py:272: UserWarning: Invalid configuration detected. The provided values do not satisfy the required condition:\n",
      "context_length / num_patches == patch_length == patch_stride\n",
      "Provided configuration:\n",
      "- context_length: 216\n",
      "- num_patches: 8\n",
      "- patch_length: 64\n",
      "- patch_stride: 64\n",
      "Configuration has been automatically updated to:\n",
      "- context_length: 216\n",
      "- num_patches: 8\n",
      "- patch_length: 27\n",
      "- patch_stride: 27\n",
      "  warn(msg)\n",
      "c:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2260abc966114071b010edad8d9c89a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TinyTimeMixerForPrediction were not initialized from the model checkpoint at ibm/TTM and are newly initialized because the shapes did not match:\n",
      "- backbone.encoder.patcher.weight: found shape torch.Size([192, 64]) in the checkpoint and torch.Size([192, 27]) in the model instantiated\n",
      "- head.base_forecast_block.bias: found shape torch.Size([96]) in the checkpoint and torch.Size([72]) in the model instantiated\n",
      "- head.base_forecast_block.weight: found shape torch.Size([96, 1024]) in the checkpoint and torch.Size([72, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "All series must has the same index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mttm_forecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:395\u001b[0m, in \u001b[0;36mBaseForecaster.fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vectorization_needed:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of fit\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39my_inner, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\sktime\\forecasting\\ttm.py:309\u001b[0m, in \u001b[0;36mTinyTimeMixerForecaster._fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    305\u001b[0m     _model\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    307\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m temporal_train_test_split(y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_split)\n\u001b[1;32m--> 309\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m test \u001b[38;5;241m=\u001b[39m PyTorchDataset(\n\u001b[0;32m    315\u001b[0m     y\u001b[38;5;241m=\u001b[39my_test,\n\u001b[0;32m    316\u001b[0m     context_length\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length,\n\u001b[0;32m    317\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_length,\n\u001b[0;32m    318\u001b[0m )\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Get Training Configuration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\sktime\\forecasting\\ttm.py:564\u001b[0m, in \u001b[0;36mPyTorchDataset.__init__\u001b[1;34m(self, y, context_length, prediction_length)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# multi-index conversion\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y\u001b[38;5;241m.\u001b[39mindex, pd\u001b[38;5;241m.\u001b[39mMultiIndex):\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[43m_frame2numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(y\u001b[38;5;241m.\u001b[39mvalues, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\sktime\\forecasting\\ttm.py:536\u001b[0m, in \u001b[0;36m_frame2numpy\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_frame2numpy\u001b[39m(data):\n\u001b[1;32m--> 536\u001b[0m     idx, length \u001b[38;5;241m=\u001b[39m \u001b[43m_same_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    538\u001b[0m         (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, length, \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m    539\u001b[0m     )\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\viloh\\Documents\\nocturnal-hypo-gly-prob-forecast\\.venv\\Lib\\site-packages\\sktime\\forecasting\\ttm.py:529\u001b[0m, in \u001b[0;36m_same_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_same_index\u001b[39m(data):\n\u001b[0;32m    526\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mlevels) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m data\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mequals(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    531\u001b[0m     )\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll series must has the same index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mAssertionError\u001b[0m: All series must has the same index"
     ]
    }
   ],
   "source": [
    "ttm_forecaster.fit(y=y_train, X=X_train, fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f451041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.33.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
