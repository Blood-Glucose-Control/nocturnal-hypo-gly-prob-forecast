{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_loader import load_data\n",
    "from src.data.data_cleaner import clean_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivamjindal/Documents/WATai/BGC/nocturnal-hypo-gly-prob-forecast/src/data/data_loader.py:32: DtypeWarning: Columns (435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path, usecols=keep_columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id p_num      time  bg-0:00  insulin-0:00  carbs-0:00    hr-0:00  \\\n",
      "0  p01_0   p01  06:10:00     15.1        0.0417    48.01897  79.335216   \n",
      "1  p01_1   p01  06:25:00     14.4        0.0417    48.01897  79.335216   \n",
      "2  p01_2   p01  06:40:00     13.9        0.0417    48.01897  79.335216   \n",
      "3  p01_3   p01  06:55:00     13.8        0.0417    48.01897  79.335216   \n",
      "4  p01_4   p01  07:10:00     13.4        0.0417    48.01897  79.335216   \n",
      "\n",
      "   steps-0:00  cals-0:00  \n",
      "0   53.052685    9.36896  \n",
      "1   53.052685    9.36896  \n",
      "2   53.052685    9.36896  \n",
      "3   53.052685    9.36896  \n",
      "4   53.052685    9.36896  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivamjindal/Documents/WATai/BGC/nocturnal-hypo-gly-prob-forecast/env/lib/python3.12/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = clean_data(data=load_data(), data_source_name=\"kaggle_brisT1D\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = [col for col in df.columns if col.startswith(\"bg-\")][0] \n",
    "TIME_COL = [col for col in df.columns if col.startswith(\"time\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insulin-0:00', 'carbs-0:00', 'hr-0:00', 'steps-0:00', 'cals-0:00']\n",
      "insulin-0:00    float64\n",
      "carbs-0:00      float64\n",
      "hr-0:00         float64\n",
      "steps-0:00      float64\n",
      "cals-0:00       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# endogenous variables are the ones we predict; they are influenced by past values of themselves.\n",
    "# exogenous variables are external factors that impact the prediction but are not predicted.\n",
    "# in our case, \"bg\" is the target (endogenous), while the other metrics are exogenous variables.\n",
    "\n",
    "EXOGENOUS_PREFIXES = [\"activity\", \"cals\", \"insulin\", \"steps\", \"carbs\", \"hr\"]\n",
    "EXOGENOUS_COLS = [col for col in df.columns if any([col.startswith(prefix) for prefix in EXOGENOUS_PREFIXES])]\n",
    "print(EXOGENOUS_COLS)\n",
    "print(df[EXOGENOUS_COLS].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[TARGET_COL]) # might not be necessary given clean_data() but just in case\n",
    "\n",
    "# NOT SURE ABOUT THIS IMPUTING\n",
    "df[EXOGENOUS_COLS] = df[EXOGENOUS_COLS].fillna(0.0) # fill missing values with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "five_minute_patients: List[Tuple[str, pd.DataFrame]] = []\n",
    "fifteen_minute_patients: List[Tuple[str, pd.DataFrame]] = []\n",
    "\n",
    "df[TIME_COL] = pd.to_timedelta(df[TIME_COL])\n",
    "\n",
    "patient_dfs = df.groupby(\"p_num\")\n",
    "\n",
    "for p_num, patient_df in patient_dfs:\n",
    "    time_difference = patient_df.iloc[1][TIME_COL] - patient_df.iloc[0][TIME_COL]    \n",
    "\n",
    "    if time_difference == pd.Timedelta(minutes=5):\n",
    "        five_minute_patients.append((p_num, patient_df))\n",
    "    elif time_difference == pd.Timedelta(minutes=15):\n",
    "        fifteen_minute_patients.append((p_num, patient_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - The \"time\" column in the data contains only hours and minutes, with no date information.\n",
    "# - Since the dataset spans multiple days, identical times (e.g., \"06:10\") can appear on different days.\n",
    "# - This prevents us from using time directly as an index because it would create duplicate entries.\n",
    "# - Instead, we use the row number as the index to maintain uniqueness.\n",
    "# - If we are sure that the data is contiguous and sequential, we could construct a custom time index\n",
    "#   that accounts for the multi-day nature of the dataset.\n",
    "\n",
    "p1_num, p1_df = five_minute_patients[0]\n",
    "p1_df = p1_df.reset_index(drop=True)  \n",
    "p1_df = p1_df.set_index(p1_df.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.split import ExpandingSlidingWindowSplitter\n",
    "from sktime.forecasting.model_selection import ForecastingGridSearchCV\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "import numpy as np\n",
    "\n",
    "y = p1_df[TARGET_COL]\n",
    "X = p1_df[EXOGENOUS_COLS]\n",
    "\n",
    "pipe = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"imputer\", Imputer()),\n",
    "        (\"forecaster\", NaiveForecaster())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv = ExpandingSlidingWindowSplitter(\n",
    "    fh=np.arange(96),  # forecasting horizon of 96 indices i.e. 5 * 96 mins = 8 hours\n",
    "    step_length=12,    # shift forward by 12 indices (1 hour) when sliding (after max window size is reached)\n",
    "    initial_window=12, # start with a train window of size 12 (1 hour)\n",
    "    max_expanding_window_length=96 # maximum window size of 96 (8 hours)\n",
    ")\n",
    "\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster=pipe,\n",
    "    refit=True, # refit the best model on the whole data\n",
    "    param_grid=[\n",
    "        {\n",
    "            \"forecaster\": [NaiveForecaster(sp=12)],\n",
    "            \"forecaster__strategy\": [\"drift\", \"last\"],\n",
    "        }\n",
    "    ],\n",
    "    cv=cv,\n",
    ")  \n",
    "gscv.fit(y=y, X=X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33073468206443507\n",
      "{'forecaster': NaiveForecaster(sp=12), 'forecaster__strategy': 'last'}\n",
      "TransformedTargetForecaster(steps=[('imputer', Imputer()),\n",
      "                                   ('forecaster', NaiveForecaster(sp=12))])\n",
      "       bg-0:00\n",
      "25871     10.5\n",
      "25872     10.9\n",
      "25873     10.8\n",
      "25874     10.8\n",
      "25875     11.0\n",
      "...        ...\n",
      "25962     11.6\n",
      "25963     11.7\n",
      "25964     12.4\n",
      "25965     12.8\n",
      "25966     12.5\n",
      "\n",
      "[96 rows x 1 columns]         bg-0:00           \n",
      "            0.9           \n",
      "          lower      upper\n",
      "25871  6.403964  14.596036\n",
      "25872  6.803964  14.996036\n",
      "25873  6.703964  14.896036\n",
      "25874  6.703964  14.896036\n",
      "25875  6.903964  15.096036\n",
      "...         ...        ...\n",
      "25962  0.014661  23.185339\n",
      "25963  0.114661  23.285339\n",
      "25964  0.814661  23.985339\n",
      "25965  1.214661  24.385339\n",
      "25966  0.914661  24.085339\n",
      "\n",
      "[96 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_MeanAbsolutePercentageError</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_pred_time</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_MeanAbsolutePercentageError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436888</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>{'forecaster': NaiveForecaster(sp=12, strategy...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.330735</td>\n",
       "      <td>0.011069</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>{'forecaster': NaiveForecaster(sp=12), 'foreca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_MeanAbsolutePercentageError  mean_fit_time  mean_pred_time  \\\n",
       "0                               0.436888       0.011389        0.013332   \n",
       "1                               0.330735       0.011069        0.018721   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'forecaster': NaiveForecaster(sp=12, strategy...   \n",
       "1  {'forecaster': NaiveForecaster(sp=12), 'foreca...   \n",
       "\n",
       "   rank_test_MeanAbsolutePercentageError  \n",
       "0                                    2.0  \n",
       "1                                    1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gscv.best_score_)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_forecaster_)\n",
    "\n",
    "# use forecasting methods on best forecaster\n",
    "# since refit=True in ForecastingGridSearchCV, we can use predict directly\n",
    "# best model is already refitted on the whole data\n",
    "\n",
    "best_forecaster: TransformedTargetForecaster = gscv.best_forecaster_\n",
    "res_predict = best_forecaster.predict(X=y, fh=np.arange(96))\n",
    "res_predict_interval = best_forecaster.predict_interval(fh=np.arange(96))\n",
    "print(res_predict, res_predict_interval)\n",
    "\n",
    "gscv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
