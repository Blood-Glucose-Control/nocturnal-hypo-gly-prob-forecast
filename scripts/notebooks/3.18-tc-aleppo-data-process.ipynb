{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df612ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from src.utils.os_helper import get_project_root\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6705542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = get_project_root()\n",
    "\n",
    "CACHE_DIR = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\"\n",
    "data_tables = CACHE_DIR / \"raw\" / \"Data Tables\"\n",
    "db_path = CACHE_DIR / \"awesome_cgm.db\"\n",
    "\n",
    "# SQLite param cap (commonly 999). Keep a margin.\n",
    "SQLITE_MAX_VARS = 999\n",
    "MARGIN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ef861",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(db_path)\n",
    "cur = con.cursor()\n",
    "cur.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "cur.execute(\"PRAGMA synchronous=OFF;\")\n",
    "cur.execute(\"PRAGMA temp_store=MEMORY;\")\n",
    "\n",
    "for f in sorted(data_tables.glob(\"*.txt\")):\n",
    "    table = f.stem\n",
    "    print(f\"Importing {f.name} -> {table}\")\n",
    "\n",
    "    # Stream in chunks to control memory and SQL variables\n",
    "    first = True\n",
    "    for df in pd.read_csv(f, sep=\"|\", dtype=str, low_memory=False, chunksize=50_000):\n",
    "        ncols = len(df.columns)\n",
    "        # rows per insert so (rows * cols) <= SQLITE_MAX_VARS - MARGIN\n",
    "        safe_rows = max(1, (SQLITE_MAX_VARS - MARGIN) // max(1, ncols))\n",
    "\n",
    "        # method=None avoids multi-row SQL text construction; Pandas will executemany\n",
    "        df.to_sql(\n",
    "            table,\n",
    "            con,\n",
    "            if_exists=\"replace\" if first else \"append\",\n",
    "            index=False,\n",
    "            chunksize=safe_rows,\n",
    "            method=None,\n",
    "        )\n",
    "        first = False\n",
    "\n",
    "\n",
    "indexes = [\n",
    "    # Bolus Indexes\n",
    "    \"CREATE INDEX idx_hdevicebolus_ptid ON HDeviceBolus(PtID);\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_parentid ON HDeviceBolus(ParentHDeviceUploadsID);\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_ptid_days ON HDeviceBolus(PtID, DeviceDtTmDaysFromEnroll);\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_normal ON HDeviceBolus(Normal) WHERE Normal IS NOT NULL;\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_order ON HDeviceBolus(PtID, DeviceDtTmDaysFromEnroll, DeviceTm);\",\n",
    "    # Uploads Indexes\n",
    "    \"CREATE INDEX idx_hdeviceuploads_recid ON HDeviceUploads(RecID);\",\n",
    "    \"CREATE INDEX idx_hdeviceuploads_ptid ON HDeviceUploads(PtID);\",\n",
    "    \"CREATE INDEX idx_hdeviceuploads_device ON HDeviceUploads(DeviceModel, DeviceType);\",\n",
    "    # CGM Indexes\n",
    "    \"CREATE INDEX idx_hdevicecgm_recid ON HDeviceCGM(RecID);\",\n",
    "    \"CREATE INDEX idx_hdevicecgm_recordtype ON HDeviceCGM(RecordType);\",\n",
    "    \"CREATE INDEX idx_hdevicecgm_ptid_days ON HDeviceCGM(PtID, DeviceDtTmDaysFromEnroll);\",\n",
    "    \"CREATE INDEX idx_hdevicecgm_ptid_time ON HDeviceCGM(PtID, DeviceTm);\",\n",
    "    # Wizard Indexes\n",
    "    \"CREATE INDEX idx_hdevicewizard_recid ON HDeviceWizard(RecID);\",\n",
    "    \"CREATE INDEX idx_hdevicewizard_ptid ON HDeviceWizard(PtID);\",\n",
    "    \"CREATE INDEX idx_hdevicewizard_ptid_days ON HDeviceWizard(PtID, DeviceDtTmDaysFromEnroll);\",\n",
    "    \"CREATE INDEX idx_hdevicewizard_ptid_time ON HDeviceWizard(PtID, DeviceTm);\",\n",
    "]\n",
    "\n",
    "for i, index_sql in enumerate(indexes):\n",
    "    try:\n",
    "        cur.execute(index_sql)\n",
    "        print(\n",
    "            f\"Created index {i+1}/{len(indexes)}: {index_sql.split('ON ')[1].split('(')[0]}\"\n",
    "        )\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(query: str):\n",
    "    # Open the connection first\n",
    "    con = sqlite3.connect(db_path)\n",
    "    # cur = con.cursor()\n",
    "    df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37ac29",
   "metadata": {},
   "source": [
    "### Convert data to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30c080",
   "metadata": {},
   "source": [
    "- pid\n",
    "- date\n",
    "- tableType\n",
    "- bolusType\n",
    "- normalBolus\n",
    "- expectedNormalBolus\n",
    "- extendedBolus\n",
    "- expectedExtendedBolus\n",
    "- bgInput\n",
    "- foodG\n",
    "- iob\n",
    "- cr\n",
    "- isf\n",
    "- bgMgdl\n",
    "- rate\n",
    "- suprBasalType\n",
    "- suprRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f649c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH\n",
    "  params AS (\n",
    "    SELECT '2020-01-01' AS base_date\n",
    "  )\n",
    "SELECT\n",
    "    pid, date, tableType,\n",
    "    bolusType, normalBolus, expectedNormalBolus, extendedBolus, expectedExtendedBolus,\n",
    "    bgInput, foodG, iob, cr, isf,\n",
    "    bgMgdl,\n",
    "    rate, suprBasalType, suprRate\n",
    "FROM (\n",
    "    -- Bolus data\n",
    "    SELECT\n",
    "        HDeviceBolus.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceBolus.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceBolus.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'bolus' as tableType,\n",
    "        HDeviceBolus.BolusType as bolusType,\n",
    "        Normal as normalBolus,\n",
    "        ExpectedNormal as expectedNormalBolus,\n",
    "        Extended as extendedBolus,\n",
    "        ExpectedExtended as expectedExtendedBolus,\n",
    "        NULL as bgInput,\n",
    "        NULL as foodG,\n",
    "        NULL as iob,\n",
    "        NULL as cr,\n",
    "        NULL as isf,\n",
    "        NULL as bgMgdl,\n",
    "        NULL as rate,\n",
    "        NULL as suprBasalType,\n",
    "        NULL as suprRate\n",
    "    FROM HDeviceBolus\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Wizard data\n",
    "    SELECT\n",
    "        HDeviceWizard.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceWizard.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceWizard.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'wizard' as tableType,\n",
    "        NULL as bolusType,\n",
    "        NULL as normalBolus,\n",
    "        NULL as expectedNormalBolus,\n",
    "        NULL as extendedBolus,\n",
    "        NULL as expectedExtendedBolus,\n",
    "        HDeviceWizard.BgInput as bgInput,\n",
    "        HDeviceWizard.CarbInput / 1000 as foodG,\n",
    "        HDeviceWizard.InsulinOnBoard as iob,\n",
    "        HDeviceWizard.InsulinCarbRatio as cr,\n",
    "        HDeviceWizard.InsulinSensitivity as isf,\n",
    "        NULL as bgMgdl,\n",
    "        NULL as rate,\n",
    "        NULL as suprBasalType,\n",
    "        NULL as suprRate\n",
    "    FROM HDeviceWizard\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- CGM data\n",
    "    SELECT\n",
    "        HDeviceCGM.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceCGM.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceCGM.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'cgm' as tableType,\n",
    "        NULL as bolusType,\n",
    "        NULL as normalBolus,\n",
    "        NULL as expectedNormalBolus,\n",
    "        NULL as extendedBolus,\n",
    "        NULL as expectedExtendedBolus,\n",
    "        NULL as bgInput,\n",
    "        NULL as foodG,\n",
    "        NULL as iob,\n",
    "        NULL as cr,\n",
    "        NULL as isf,\n",
    "        HDeviceCGM.GlucoseValue as bgMgdl,\n",
    "        NULL as rate,\n",
    "        NULL as suprBasalType,\n",
    "        NULL as suprRate\n",
    "    FROM HDeviceCGM\n",
    "    WHERE HDeviceCGM.GlucoseValue IS NOT NULL\n",
    "    AND HDeviceCGM.RecordType = 'CGM'\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Basal data\n",
    "    SELECT\n",
    "        HDeviceBasal.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceBasal.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceBasal.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'basal' as tableType,\n",
    "        NULL as bolusType,\n",
    "        NULL as normalBolus,\n",
    "        NULL as expectedNormalBolus,\n",
    "        NULL as extendedBolus,\n",
    "        NULL as expectedExtendedBolus,\n",
    "        NULL as bgInput,\n",
    "        NULL as foodG,\n",
    "        NULL as iob,\n",
    "        NULL as cr,\n",
    "        NULL as isf,\n",
    "        NULL as bgMgdl,\n",
    "        HDeviceBasal.Rate as rate,\n",
    "        HDeviceBasal.SuprBasalType as suprBasalType,\n",
    "        HDeviceBasal.SuprRate as suprRate\n",
    "    FROM HDeviceBasal\n",
    ")\n",
    "ORDER BY pid, date ASC;\n",
    "\"\"\"\n",
    "df_all = query_db(query)\n",
    "df_all.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27057ae",
   "metadata": {},
   "source": [
    "### Raw -> Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c73035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing pid 10\n",
      "Done processing pid 101\n",
      "Done processing pid 102\n",
      "Done processing pid 103\n",
      "Done processing pid 105\n",
      "Done processing pid 106\n",
      "Done processing pid 108\n",
      "Done processing pid 109\n",
      "Done processing pid 11\n",
      "Done processing pid 110\n",
      "Done processing pid 111\n",
      "Done processing pid 112\n",
      "Done processing pid 113\n",
      "Done processing pid 115\n",
      "Done processing pid 116\n",
      "Done processing pid 118\n",
      "Done processing pid 119\n",
      "Done processing pid 121\n",
      "Done processing pid 123\n",
      "Done processing pid 124\n",
      "Done processing pid 127\n",
      "Done processing pid 128\n",
      "Done processing pid 129\n",
      "Done processing pid 130\n",
      "Done processing pid 131\n",
      "Done processing pid 132\n",
      "Done processing pid 134\n",
      "Done processing pid 135\n",
      "Done processing pid 136\n",
      "Done processing pid 137\n",
      "Done processing pid 138\n",
      "Done processing pid 139\n",
      "Done processing pid 14\n",
      "Done processing pid 140\n",
      "Done processing pid 141\n",
      "Done processing pid 143\n",
      "Done processing pid 145\n",
      "Done processing pid 146\n",
      "Done processing pid 147\n",
      "Done processing pid 148\n",
      "Done processing pid 149\n",
      "Done processing pid 15\n",
      "Done processing pid 152\n",
      "Done processing pid 155\n",
      "Done processing pid 156\n",
      "Done processing pid 157\n",
      "Done processing pid 158\n",
      "Done processing pid 16\n",
      "Done processing pid 160\n",
      "Done processing pid 162\n",
      "Done processing pid 163\n",
      "Done processing pid 164\n",
      "Done processing pid 165\n",
      "Done processing pid 166\n",
      "Done processing pid 167\n",
      "Done processing pid 168\n",
      "Done processing pid 169\n",
      "Done processing pid 17\n",
      "Done processing pid 170\n",
      "Done processing pid 171\n",
      "Done processing pid 172\n",
      "Done processing pid 173\n",
      "Done processing pid 174\n",
      "Done processing pid 175\n",
      "Done processing pid 176\n",
      "Done processing pid 177\n",
      "Done processing pid 179\n",
      "Done processing pid 18\n",
      "Done processing pid 181\n",
      "Done processing pid 183\n",
      "Done processing pid 184\n",
      "Done processing pid 185\n",
      "Done processing pid 186\n",
      "Done processing pid 187\n",
      "Done processing pid 188\n",
      "Done processing pid 189\n",
      "Done processing pid 19\n",
      "Done processing pid 190\n",
      "Done processing pid 193\n",
      "Done processing pid 197\n",
      "Done processing pid 198\n",
      "Done processing pid 2\n",
      "Done processing pid 20\n",
      "Done processing pid 200\n",
      "Done processing pid 201\n",
      "Done processing pid 203\n",
      "Done processing pid 204\n",
      "Done processing pid 205\n",
      "Done processing pid 206\n",
      "Done processing pid 209\n",
      "Done processing pid 21\n",
      "Done processing pid 210\n",
      "Done processing pid 211\n",
      "Done processing pid 213\n",
      "Done processing pid 214\n",
      "Done processing pid 215\n",
      "Done processing pid 216\n",
      "Done processing pid 217\n",
      "Done processing pid 218\n",
      "Done processing pid 219\n",
      "Done processing pid 22\n",
      "Done processing pid 220\n",
      "Done processing pid 221\n",
      "Done processing pid 222\n",
      "Done processing pid 223\n",
      "Done processing pid 224\n",
      "Done processing pid 226\n",
      "Done processing pid 227\n",
      "Done processing pid 228\n",
      "Done processing pid 229\n",
      "Done processing pid 23\n",
      "Done processing pid 231\n",
      "Done processing pid 232\n",
      "Done processing pid 233\n",
      "Done processing pid 234\n",
      "Done processing pid 235\n",
      "Done processing pid 236\n",
      "Done processing pid 239\n",
      "Done processing pid 24\n",
      "Done processing pid 240\n",
      "Done processing pid 241\n",
      "Done processing pid 243\n",
      "Done processing pid 244\n",
      "Done processing pid 245\n",
      "Done processing pid 246\n",
      "Done processing pid 247\n",
      "Done processing pid 248\n",
      "Done processing pid 249\n",
      "Done processing pid 250\n",
      "Done processing pid 251\n",
      "Done processing pid 252\n",
      "Done processing pid 253\n",
      "Done processing pid 254\n",
      "Done processing pid 256\n",
      "Done processing pid 257\n",
      "Done processing pid 258\n",
      "Done processing pid 26\n",
      "Done processing pid 260\n",
      "Done processing pid 263\n",
      "Done processing pid 264\n",
      "Done processing pid 265\n",
      "Done processing pid 266\n",
      "Done processing pid 267\n",
      "Done processing pid 269\n",
      "Done processing pid 27\n",
      "Done processing pid 271\n",
      "Done processing pid 272\n",
      "Done processing pid 273\n",
      "Done processing pid 274\n",
      "Done processing pid 275\n",
      "Done processing pid 276\n",
      "Done processing pid 277\n",
      "Done processing pid 278\n",
      "Done processing pid 280\n",
      "Done processing pid 281\n",
      "Done processing pid 283\n",
      "Done processing pid 284\n",
      "Done processing pid 285\n",
      "Done processing pid 287\n",
      "Done processing pid 288\n",
      "Done processing pid 289\n",
      "Done processing pid 29\n",
      "Done processing pid 290\n",
      "Done processing pid 291\n",
      "Done processing pid 292\n",
      "Done processing pid 293\n",
      "Done processing pid 3\n",
      "Done processing pid 30\n",
      "Done processing pid 31\n",
      "Done processing pid 32\n",
      "Done processing pid 33\n",
      "Done processing pid 35\n",
      "Done processing pid 36\n",
      "Done processing pid 37\n",
      "Done processing pid 38\n",
      "Done processing pid 39\n",
      "Done processing pid 40\n",
      "Done processing pid 41\n",
      "Done processing pid 42\n",
      "Done processing pid 43\n",
      "Done processing pid 45\n",
      "Done processing pid 46\n",
      "Done processing pid 47\n",
      "Done processing pid 48\n",
      "Done processing pid 49\n",
      "Done processing pid 5\n",
      "Done processing pid 50\n",
      "Done processing pid 52\n",
      "Done processing pid 53\n",
      "Done processing pid 54\n",
      "Done processing pid 55\n",
      "Done processing pid 57\n",
      "Done processing pid 58\n",
      "Done processing pid 60\n",
      "Done processing pid 61\n",
      "Done processing pid 62\n",
      "Done processing pid 64\n",
      "Done processing pid 65\n",
      "Done processing pid 67\n",
      "Done processing pid 68\n",
      "Done processing pid 69\n",
      "Done processing pid 7\n",
      "Done processing pid 70\n",
      "Done processing pid 71\n",
      "Done processing pid 72\n",
      "Done processing pid 73\n",
      "Done processing pid 74\n",
      "Done processing pid 76\n",
      "Done processing pid 77\n",
      "Done processing pid 78\n",
      "Done processing pid 79\n",
      "Done processing pid 8\n",
      "Done processing pid 80\n",
      "Done processing pid 81\n",
      "Done processing pid 82\n",
      "Done processing pid 86\n",
      "Done processing pid 87\n",
      "Done processing pid 89\n",
      "Done processing pid 9\n",
      "Done processing pid 90\n",
      "Done processing pid 91\n",
      "Done processing pid 93\n",
      "Done processing pid 95\n",
      "Done processing pid 96\n",
      "Done processing pid 97\n",
      "Done processing pid 98\n"
     ]
    }
   ],
   "source": [
    "def convert_to_csv(df):\n",
    "    project_root = get_project_root()\n",
    "    data_dir = project_root / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"interim\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    for pid in df[\"pid\"].unique():\n",
    "        df_pid = df[df[\"pid\"] == pid]\n",
    "        df_pid.to_csv(data_dir / f\"p{pid}_full.csv\", index=False)\n",
    "        print(f\"Done processing pid {pid}\")\n",
    "\n",
    "\n",
    "convert_to_csv(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5dfaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.models import ColumnNames\n",
    "from src.data.preprocessing.pipeline import preprocessing_pipeline\n",
    "from src.utils.unit import mg_dl_to_mmol_l\n",
    "\n",
    "\n",
    "# \tpid\tdate\ttableType\tbolusType\tnormalBolus\texpectedNormalBolus\textendedBolus\texpectedExtendedBolus\tbgInput\tfoodG\tiob\tcr\tisf\tbgMgdl\trate\tsuprBasalType\tsuprRate\n",
    "def data_translation(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    'pid' -> p_num\n",
    "    'date' -> datetime\n",
    "    'tableType' -> msg_type (bolus, wizard, cgm). wizard contains information like carbs intake\n",
    "    'eventType': This is bolus type\n",
    "    'normal': Number of units of normal bolus\n",
    "    'expectedNormal'\n",
    "    'extended': Number of units for extended delivery\n",
    "    'expectedExtended'\n",
    "    'bgInput' -> Blood glucose as inputted into wizard in mg\n",
    "    'carbInput' -> Carbohydrates as inputted into wizard in mg\n",
    "    'iob': Units of insulin on board\n",
    "    'cr': Number of mg carbs covered by unit of insulin. Not used yet but we can find a way to give model a hint about the slope of the glucose curve\n",
    "    'isf': Number of bgs covered by unit of insulin. Same as above\n",
    "    'recordType': CGM | CALIBRATION\n",
    "    'glucoseValue' -> bg_mM\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "    # TODO: Rename to the correct column names\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"pid\": ColumnNames.P_NUM.value,\n",
    "            \"date\": ColumnNames.DATETIME.value,\n",
    "            \"tableType\": ColumnNames.MSG_TYPE.value,\n",
    "            \"normalBolus\": ColumnNames.DOSE_UNITS.value,\n",
    "            # \"expectedNormalBolus\": ColumnNames.EXPECTED_NORMAL.value,\n",
    "            # \"extendedBolus\": ColumnNames.EXTENDED.value,\n",
    "            # \"expectedExtendedBolus\": ColumnNames.EXPECTED_EXTENDED.value,\n",
    "            # \"bgInput\": ColumnNames.BG.value, todo: Maybe tag the record type as bgInput\n",
    "            \"foodG\": ColumnNames.FOOD_G.value,\n",
    "            \"iob\": ColumnNames.IOB.value,\n",
    "            # \"cr\": ColumnNames.INSULIN_CARB_RATIO.value,\n",
    "            # \"isf\": ColumnNames.ISF.value,\n",
    "            \"recordType\": ColumnNames.RECORD_TYPE.value,\n",
    "            \"bgMgdl\": ColumnNames.BG.value,\n",
    "            \"rate\": ColumnNames.RATE.value,\n",
    "            \"suprBasalType\": ColumnNames.SUPR_BASAL_TYPE.value,\n",
    "            \"suprRate\": ColumnNames.SUPR_RATE.value,\n",
    "        }\n",
    "    )\n",
    "    df.drop(columns=[\"expectedNormalBolus\", \"expectedExtendedBolus\"], inplace=True)\n",
    "    df.set_index(ColumnNames.DATETIME.value, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Convert blood glucose from mg/dL to mmol/L\n",
    "    # TODO: Add this back in\n",
    "    df[ColumnNames.BG.value] = mg_dl_to_mmol_l(df, bgl_col=ColumnNames.BG.value)\n",
    "\n",
    "    # Convert carbs from mg to g\n",
    "    df[ColumnNames.FOOD_G.value] = df[ColumnNames.FOOD_G.value].astype(float) / 1000\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def keep_overlapping_data(patient_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        patient_df: A dataframe that has been through data_translation (datetime is the index)\n",
    "    Keep data that has overlapping time windows for all table types.\n",
    "    Note that not all patients have data for all table types so we only consider the table types that are present.\n",
    "    \"\"\"\n",
    "    table_types = patient_df[ColumnNames.MSG_TYPE.value].unique()\n",
    "    start_datetime = None  # This should be the max of all the min datetimes\n",
    "    end_datetime = None  # This should be the min of all the max datetimes\n",
    "\n",
    "    for table_type in table_types:\n",
    "        table_data = patient_df[patient_df[ColumnNames.MSG_TYPE.value] == table_type]\n",
    "        if table_data.empty:\n",
    "            continue\n",
    "\n",
    "        min_datetime = table_data.index.min()\n",
    "        max_datetime = table_data.index.max()\n",
    "\n",
    "        if start_datetime is None or min_datetime > start_datetime:\n",
    "            start_datetime = min_datetime\n",
    "        if end_datetime is None or max_datetime < end_datetime:\n",
    "            end_datetime = max_datetime\n",
    "\n",
    "    if start_datetime is None or end_datetime is None:\n",
    "        return None\n",
    "\n",
    "    has_overlap = start_datetime < end_datetime\n",
    "    if not has_overlap:\n",
    "        return None\n",
    "\n",
    "    # Filter using the index (datetime)\n",
    "    return patient_df[\n",
    "        (patient_df.index >= start_datetime) & (patient_df.index <= end_datetime)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_patient(\n",
    "    df_raw: pd.DataFrame,\n",
    "    to_csv: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the raw data for one patient:\n",
    "    1. Translate the data (columns and units)\n",
    "    2. Keep overlapping data (for bolus, wizard, cgm and basal)\n",
    "    3. TODO: Convert basal rate to 5-min interval\n",
    "    4. preprocessing_pipeline (This include resampling and deriving cob and iob)\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Translate the data\n",
    "    df = data_translation(df)\n",
    "    pid = df[ColumnNames.P_NUM.value].iloc[0]\n",
    "\n",
    "    # Keep overlapping data\n",
    "    days_before = (df.index.max() - df.index.min()).days\n",
    "\n",
    "    df = keep_overlapping_data(df)\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    days_after = (df.index.max() - df.index.min()).days\n",
    "    percent_before = days_after / days_before\n",
    "\n",
    "    print(\n",
    "        f\"p{str(pid).zfill(3)} From {days_before} to {days_after} days ({round(days_after / 30, 2)} months) ({round(percent_before * 100, 2)}%)\"\n",
    "    )\n",
    "\n",
    "    # food_g = df[df[ColumnNames.FOOD_G.value].notna()]\n",
    "    # print(f\"Number of rows with food intake: {len(food_g)}\")\n",
    "\n",
    "    # bolus = df[df[ColumnNames.DOSE_UNITS.value].notna()]\n",
    "    # print(f\"Number of rows with bolus: {len(bolus)}\")\n",
    "\n",
    "    # Let the pipeline handle the rest\n",
    "    # This derives iob and cob which we is information we already have\n",
    "    df = preprocessing_pipeline(pid, df)\n",
    "    # Debug only\n",
    "    if to_csv:\n",
    "        debug_dir = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"debug\"\n",
    "        os.makedirs(debug_dir, exist_ok=True)\n",
    "        df.to_csv(debug_dir / f\"p{pid}.csv\", index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_all_patients(\n",
    "    interim_path: Path,\n",
    "    processed_path: Path,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean all patients' data in the interim path and save the processed data to the processed path.\n",
    "    \"\"\"\n",
    "    for pid in os.listdir(interim_path):\n",
    "        df = pd.read_csv(interim_path / pid)\n",
    "        df = process_one_patient(df)\n",
    "        df.to_csv(processed_path / pid, index=True)\n",
    "        print(f\"{\"-\"*10}Done processing pid {pid} {\"-\"*10}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p047 From 248 to 170 days (5.67 months) (68.55%)\n",
      "p046 From 304 to 233 days (7.77 months) (76.64%)\n",
      "p260 From 251 to 146 days (4.87 months) (58.17%)\n",
      "p147 From 279 to 246 days (8.2 months) (88.17%)\n",
      "p146 From 386 to 283 days (9.43 months) (73.32%)\n",
      "p229 From 461 to 226 days (7.53 months) (49.02%)\n",
      "p228 From 415 to 362 days (12.07 months) (87.23%)\n",
      "p130 From 426 to 290 days (9.67 months) (68.08%)\n",
      "p131 From 459 to 240 days (8.0 months) (52.29%)\n",
      "p079 From 504 to 291 days (9.7 months) (57.74%)\n",
      "p078 From 467 to 201 days (6.7 months) (43.04%)\n",
      "p285 From 426 to 225 days (7.5 months) (52.82%)\n",
      "p284 From 415 to 241 days (8.03 months) (58.07%)\n",
      "p179 From 411 to 239 days (7.97 months) (58.15%)\n",
      "p030 From 401 to 226 days (7.53 months) (56.36%)\n",
      "p031 From 290 to 248 days (8.27 months) (85.52%)\n",
      "p217 From 221 to 161 days (5.37 months) (72.85%)\n",
      "p216 From 441 to 44 days (1.47 months) (9.98%)\n",
      "p223 From 120 to 120 days (4.0 months) (100.0%)\n",
      "p222 From 372 to 223 days (7.43 months) (59.95%)\n",
      "p096 From 251 to 229 days (7.63 months) (91.24%)\n",
      "p097 From 321 to 251 days (8.37 months) (78.19%)\n",
      "p197 From 265 to 261 days (8.7 months) (98.49%)\n",
      "p105 From 343 to 270 days (9.0 months) (78.72%)\n",
      "p173 From 373 to 268 days (8.93 months) (71.85%)\n",
      "p172 From 244 to 229 days (7.63 months) (93.85%)\n",
      "p073 From 341 to 153 days (5.1 months) (44.87%)\n",
      "p072 From 272 to 256 days (8.53 months) (94.12%)\n",
      "p254 From 289 to 259 days (8.63 months) (89.62%)\n",
      "p019 From 330 to 38 days (1.27 months) (11.52%)\n",
      "p018 From 352 to 263 days (8.77 months) (74.72%)\n",
      "p050 From 238 to 224 days (7.47 months) (94.12%)\n",
      "p277 From 335 to 332 days (11.07 months) (99.1%)\n",
      "p276 From 313 to 239 days (7.97 months) (76.36%)\n",
      "p119 From 283 to 255 days (8.5 months) (90.11%)\n",
      "p118 From 382 to 193 days (6.43 months) (50.52%)\n",
      "p027 From 318 to 208 days (6.93 months) (65.41%)\n",
      "p007 From 409 to 332 days (11.07 months) (81.17%)\n",
      "p026 From 252 to 243 days (8.1 months) (96.43%)\n",
      "p200 From 311 to 287 days (9.57 months) (92.28%)\n",
      "p201 From 349 to 261 days (8.7 months) (74.79%)\n",
      "p292 From 555 to 262 days (8.73 months) (47.21%)\n",
      "p293 From 290 to 222 days (7.4 months) (76.55%)\n",
      "p249 From 322 to 183 days (6.1 months) (56.83%)\n",
      "p248 From 249 to 209 days (6.97 months) (83.94%)\n",
      "p127 From 268 to 222 days (7.4 months) (82.84%)\n",
      "p113 From 249 to 182 days (6.07 months) (73.09%)\n",
      "p112 From 258 to 192 days (6.4 months) (74.42%)\n",
      "p181 From 590 to 174 days (5.8 months) (29.49%)\n",
      "p081 From 258 to 13 days (0.43 months) (5.04%)\n",
      "p080 From 481 to 200 days (6.67 months) (41.58%)\n",
      "p234 From 322 to 252 days (8.4 months) (78.26%)\n",
      "p235 From 362 to 257 days (8.57 months) (70.99%)\n",
      "p064 From 258 to 252 days (8.4 months) (97.67%)\n",
      "p065 From 279 to 259 days (8.63 months) (92.83%)\n",
      "p243 From 363 to 283 days (9.43 months) (77.96%)\n",
      "p164 From 348 to 314 days (10.47 months) (90.23%)\n",
      "p165 From 411 to 244 days (8.13 months) (59.37%)\n",
      "p157 From 242 to 223 days (7.43 months) (92.15%)\n",
      "p156 From 321 to 246 days (8.2 months) (76.64%)\n",
      "p239 From 319 to 251 days (8.37 months) (78.68%)\n",
      "p057 From 362 to 219 days (7.3 months) (60.5%)\n",
      "p271 From 397 to 315 days (10.5 months) (79.35%)\n",
      "p169 From 281 to 228 days (7.6 months) (81.14%)\n",
      "p168 From 274 to 242 days (8.07 months) (88.32%)\n",
      "p020 From 278 to 226 days (7.53 months) (81.29%)\n",
      "p021 From 240 to 216 days (7.2 months) (90.0%)\n",
      "p206 From 326 to 253 days (8.43 months) (77.61%)\n",
      "p121 From 353 to 244 days (8.13 months) (69.12%)\n",
      "p069 From 248 to 204 days (6.8 months) (82.26%)\n",
      "p068 From 408 to 319 days (10.63 months) (78.19%)\n",
      "p186 From 643 to 250 days (8.33 months) (38.88%)\n",
      "p187 From 397 to 393 days (13.1 months) (98.99%)\n",
      "p115 From 334 to 254 days (8.47 months) (76.05%)\n",
      "p014 From 629 to 257 days (8.57 months) (40.86%)\n",
      "p015 From 360 to 221 days (7.37 months) (61.39%)\n",
      "p233 From 426 to 254 days (8.47 months) (59.62%)\n",
      "p232 From 340 to 243 days (8.1 months) (71.47%)\n",
      "p086 From 299 to 296 days (9.87 months) (99.0%)\n",
      "p087 From 542 to 238 days (7.93 months) (43.91%)\n",
      "p062 From 387 to 253 days (8.43 months) (65.37%)\n",
      "p244 From 280 to 242 days (8.07 months) (86.43%)\n",
      "p245 From 418 to 325 days (10.83 months) (77.75%)\n",
      "p163 From 322 to 253 days (8.43 months) (78.57%)\n",
      "p162 From 364 to 275 days (9.17 months) (75.55%)\n",
      "p040 From 738 to 242 days (8.07 months) (32.79%)\n",
      "p041 From 253 to 242 days (8.07 months) (95.65%)\n",
      "p267 From 258 to 183 days (6.1 months) (70.93%)\n",
      "p266 From 103 to 99 days (3.3 months) (96.12%)\n",
      "p109 From 315 to 154 days (5.13 months) (48.89%)\n",
      "p108 From 282 to 248 days (8.27 months) (87.94%)\n",
      "p140 From 370 to 227 days (7.57 months) (61.35%)\n",
      "p141 From 297 to 244 days (8.13 months) (82.15%)\n",
      "p258 From 887 to 251 days (8.37 months) (28.3%)\n",
      "p137 From 415 to 321 days (10.7 months) (77.35%)\n",
      "p136 From 395 to 257 days (8.57 months) (65.06%)\n",
      "p037 From 316 to 252 days (8.4 months) (79.75%)\n",
      "p036 From 318 to 237 days (7.9 months) (74.53%)\n",
      "p210 From 259 to 207 days (6.9 months) (79.92%)\n",
      "p211 From 313 to 249 days (8.3 months) (79.55%)\n",
      "p283 From 250 to 218 days (7.27 months) (87.2%)\n",
      "p091 From 365 to 218 days (7.27 months) (59.73%)\n",
      "p090 From 308 to 243 days (8.1 months) (78.9%)\n",
      "p224 From 253 to 246 days (8.2 months) (97.23%)\n",
      "p103 From 294 to 228 days (7.6 months) (77.55%)\n",
      "p102 From 422 to 275 days (9.17 months) (65.17%)\n",
      "p190 From 261 to 261 days (8.7 months) (100.0%)\n",
      "p174 From 420 to 228 days (7.6 months) (54.29%)\n",
      "p175 From 256 to 249 days (8.3 months) (97.27%)\n",
      "p288 From 301 to 243 days (8.1 months) (80.73%)\n",
      "p289 From 72 to 72 days (2.4 months) (100.0%)\n",
      "p074 From 595 to 251 days (8.37 months) (42.18%)\n",
      "p253 From 398 to 236 days (7.87 months) (59.3%)\n",
      "p252 From 225 to 195 days (6.5 months) (86.67%)\n",
      "p110 From 264 to 187 days (6.23 months) (70.83%)\n",
      "p111 From 342 to 338 days (11.27 months) (98.83%)\n",
      "p058 From 246 to 198 days (6.6 months) (80.49%)\n",
      "p183 From 364 to 226 days (7.53 months) (62.09%)\n",
      "p082 From 241 to 238 days (7.93 months) (98.76%)\n",
      "p158 From 298 to 251 days (8.37 months) (84.23%)\n",
      "p236 From 250 to 167 days (5.57 months) (66.8%)\n",
      "p010 From 676 to 190 days (6.33 months) (28.11%)\n",
      "p011 From 270 to 249 days (8.3 months) (92.22%)\n",
      "p240 From 369 to 357 days (11.9 months) (96.75%)\n",
      "p241 From 289 to 264 days (8.8 months) (91.35%)\n",
      "p067 From 291 to 251 days (8.37 months) (86.25%)\n",
      "p167 From 244 to 226 days (7.53 months) (92.62%)\n",
      "p166 From 277 to 258 days (8.6 months) (93.14%)\n",
      "p209 From 284 to 202 days (6.73 months) (71.13%)\n",
      "p152 From 272 to 224 days (7.47 months) (82.35%)\n",
      "p089 From 248 to 174 days (5.8 months) (70.16%)\n",
      "p274 From 325 to 252 days (8.4 months) (77.54%)\n",
      "p275 From 579 to 297 days (9.9 months) (51.3%)\n",
      "p188 From 311 to 247 days (8.23 months) (79.42%)\n",
      "p053 From 367 to 257 days (8.57 months) (70.03%)\n",
      "p052 From 142 to 97 days (3.23 months) (68.31%)\n",
      "p189 From 326 to 266 days (8.87 months) (81.6%)\n",
      "p203 From 451 to 110 days (3.67 months) (24.39%)\n",
      "p024 From 358 to 314 days (10.47 months) (87.71%)\n",
      "p005 From 353 to 277 days (9.23 months) (78.47%)\n",
      "p291 From 368 to 258 days (8.6 months) (70.11%)\n",
      "p290 From 299 to 254 days (8.47 months) (84.95%)\n",
      "p124 From 269 to 253 days (8.43 months) (94.05%)\n",
      "p220 From 289 to 274 days (9.13 months) (94.81%)\n",
      "p221 From 285 to 251 days (8.37 months) (88.07%)\n",
      "p095 From 435 to 315 days (10.5 months) (72.41%)\n",
      "p269 From 288 to 274 days (9.13 months) (95.14%)\n",
      "p106 From 296 to 246 days (8.2 months) (83.11%)\n",
      "p039 From 279 to 162 days (5.4 months) (58.06%)\n",
      "p038 From 233 to 221 days (7.37 months) (94.85%)\n",
      "p170 From 812 to 279 days (9.3 months) (34.36%)\n",
      "p171 From 296 to 240 days (8.0 months) (81.08%)\n",
      "p257 From 219 to 175 days (5.83 months) (79.91%)\n",
      "p256 From 344 to 202 days (6.73 months) (58.72%)\n",
      "p070 From 365 to 279 days (9.3 months) (76.44%)\n",
      "p071 From 255 to 246 days (8.2 months) (96.47%)\n",
      "p139 From 302 to 275 days (9.17 months) (91.06%)\n",
      "p138 From 261 to 95 days (3.17 months) (36.4%)\n",
      "p263 From 408 to 289 days (9.63 months) (70.83%)\n",
      "p045 From 950 to 263 days (8.77 months) (27.68%)\n",
      "p145 From 412 to 179 days (5.97 months) (43.45%)\n",
      "p132 From 252 to 155 days (5.17 months) (61.51%)\n",
      "p287 From 318 to 245 days (8.17 months) (77.04%)\n",
      "p214 From 282 to 262 days (8.73 months) (92.91%)\n",
      "p215 From 337 to 287 days (9.57 months) (85.16%)\n",
      "p033 From 336 to 258 days (8.6 months) (76.79%)\n",
      "p032 From 265 to 257 days (8.57 months) (96.98%)\n",
      "p149 From 301 to 258 days (8.6 months) (85.71%)\n",
      "p093 From 593 to 356 days (11.87 months) (60.03%)\n",
      "p148 From 343 to 251 days (8.37 months) (73.18%)\n",
      "p227 From 319 to 209 days (6.97 months) (65.52%)\n",
      "p226 From 231 to 200 days (6.67 months) (86.58%)\n",
      "p101 From 313 to 179 days (5.97 months) (57.19%)\n",
      "p049 From 302 to 206 days (6.87 months) (68.21%)\n",
      "p193 From 357 to 312 days (10.4 months) (87.39%)\n",
      "p048 From 372 to 257 days (8.57 months) (69.09%)\n",
      "p177 From 324 to 256 days (8.53 months) (79.01%)\n",
      "p176 From 587 to 365 days (12.17 months) (62.18%)\n",
      "p219 From 305 to 294 days (9.8 months) (96.39%)\n",
      "p218 From 250 to 250 days (8.33 months) (100.0%)\n",
      "p250 From 345 to 267 days (8.9 months) (77.39%)\n",
      "p251 From 306 to 252 days (8.4 months) (82.35%)\n",
      "p077 From 354 to 323 days (10.77 months) (91.24%)\n",
      "p076 From 265 to 240 days (8.0 months) (90.57%)\n",
      "p264 From 258 to 180 days (6.0 months) (69.77%)\n",
      "p265 From 282 to 112 days (3.73 months) (39.72%)\n",
      "p043 From 249 to 222 days (7.4 months) (89.16%)\n",
      "p198 From 356 to 258 days (8.6 months) (72.47%)\n",
      "p042 From 212 to 184 days (6.13 months) (86.79%)\n",
      "p143 From 335 to 259 days (8.63 months) (77.31%)\n",
      "p098 From 223 to 175 days (5.83 months) (78.48%)\n",
      "p134 From 324 to 251 days (8.37 months) (77.47%)\n",
      "p135 From 326 to 276 days (9.2 months) (84.66%)\n",
      "p213 From 242 to 238 days (7.93 months) (98.35%)\n",
      "p035 From 501 to 227 days (7.57 months) (45.31%)\n",
      "p281 From 371 to 237 days (7.9 months) (63.88%)\n",
      "p280 From 300 to 239 days (7.97 months) (79.67%)\n",
      "p185 From 283 to 250 days (8.33 months) (88.34%)\n",
      "p184 From 255 to 175 days (5.83 months) (68.63%)\n",
      "p278 From 337 to 254 days (8.47 months) (75.37%)\n",
      "p116 From 302 to 282 days (9.4 months) (93.38%)\n",
      "p231 From 262 to 239 days (7.97 months) (91.22%)\n",
      "p017 From 259 to 237 days (7.9 months) (91.51%)\n",
      "p016 From 521 to 328 days (10.93 months) (62.96%)\n",
      "p247 From 272 to 264 days (8.8 months) (97.06%)\n",
      "p246 From 325 to 226 days (7.53 months) (69.54%)\n",
      "p060 From 253 to 253 days (8.43 months) (100.0%)\n",
      "p061 From 259 to 250 days (8.33 months) (96.53%)\n",
      "p129 From 363 to 273 days (9.1 months) (75.21%)\n",
      "p128 From 246 to 185 days (6.17 months) (75.2%)\n",
      "p009 From 253 to 189 days (6.3 months) (74.7%)\n",
      "p029 From 419 to 252 days (8.4 months) (60.14%)\n",
      "p008 From 255 to 194 days (6.47 months) (76.08%)\n",
      "p160 From 239 to 231 days (7.7 months) (96.65%)\n",
      "p155 From 420 to 313 days (10.43 months) (74.52%)\n",
      "p273 From 419 to 261 days (8.7 months) (62.29%)\n",
      "p272 From 280 to 236 days (7.87 months) (84.29%)\n",
      "p054 From 276 to 216 days (7.2 months) (78.26%)\n",
      "p055 From 270 to 261 days (8.7 months) (96.67%)\n",
      "p204 From 430 to 228 days (7.6 months) (53.02%)\n",
      "p205 From 417 to 258 days (8.6 months) (61.87%)\n",
      "p003 From 422 to 257 days (8.57 months) (60.9%)\n",
      "p023 From 296 to 262 days (8.73 months) (88.51%)\n",
      "p022 From 253 to 216 days (7.2 months) (85.38%)\n",
      "p002 From 364 to 238 days (7.93 months) (65.38%)\n",
      "p123 From 341 to 256 days (8.53 months) (75.07%)\n"
     ]
    }
   ],
   "source": [
    "interim_path = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"interim\"\n",
    "for pid in os.listdir(interim_path):\n",
    "    df = pd.read_csv(interim_path / pid, low_memory=False)\n",
    "    processed_df = process_one_patient(df)\n",
    "    min_date = pd.to_datetime(processed_df.index.min())\n",
    "    max_date = pd.to_datetime(processed_df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f6d98",
   "metadata": {},
   "source": [
    "### Interesting patients:\n",
    "Most patients seems to have significant data still after trimming (at least 6 months worth of data) except for some patients:\n",
    "- p216 From 441 to 44 days (1.47 months) (9.98%)\n",
    "- p019 From 330 to 38 days (1.27 months) (11.52%)\n",
    "- p081 From 258 to 13 days (0.43 months) (5.04%)\n",
    "- p289 From 72 to 72 days (2.4 months) (100.0%)\n",
    "- p138 From 261 to 95 days (3.17 months) (36.4%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418bb74",
   "metadata": {},
   "source": [
    "### Interim -> Processed for one patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 7 original data spans from 2019-08-17 14:32:00 to 2020-09-30 10:14:30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>date</th>\n",
       "      <th>tableType</th>\n",
       "      <th>bolusType</th>\n",
       "      <th>normalBolus</th>\n",
       "      <th>expectedNormalBolus</th>\n",
       "      <th>extendedBolus</th>\n",
       "      <th>expectedExtendedBolus</th>\n",
       "      <th>bgInput</th>\n",
       "      <th>foodG</th>\n",
       "      <th>iob</th>\n",
       "      <th>cr</th>\n",
       "      <th>isf</th>\n",
       "      <th>bgMgdl</th>\n",
       "      <th>rate</th>\n",
       "      <th>suprBasalType</th>\n",
       "      <th>suprRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-17 14:32:00</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-17 14:37:00</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-17 14:42:00</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-17 14:47:00</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-17 14:52:00</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83229</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-30 09:51:44</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83230</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-30 09:56:44</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83231</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-30 10:00:00</td>\n",
       "      <td>basal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83232</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-30 10:01:44</td>\n",
       "      <td>cgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83233</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-30 10:14:30</td>\n",
       "      <td>basal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83234 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pid                 date tableType bolusType  normalBolus  \\\n",
       "0        7  2019-08-17 14:32:00       cgm       NaN          NaN   \n",
       "1        7  2019-08-17 14:37:00       cgm       NaN          NaN   \n",
       "2        7  2019-08-17 14:42:00       cgm       NaN          NaN   \n",
       "3        7  2019-08-17 14:47:00       cgm       NaN          NaN   \n",
       "4        7  2019-08-17 14:52:00       cgm       NaN          NaN   \n",
       "...    ...                  ...       ...       ...          ...   \n",
       "83229    7  2020-09-30 09:51:44       cgm       NaN          NaN   \n",
       "83230    7  2020-09-30 09:56:44       cgm       NaN          NaN   \n",
       "83231    7  2020-09-30 10:00:00     basal       NaN          NaN   \n",
       "83232    7  2020-09-30 10:01:44       cgm       NaN          NaN   \n",
       "83233    7  2020-09-30 10:14:30     basal       NaN          NaN   \n",
       "\n",
       "       expectedNormalBolus  extendedBolus  expectedExtendedBolus  bgInput  \\\n",
       "0                      NaN            NaN                    NaN      NaN   \n",
       "1                      NaN            NaN                    NaN      NaN   \n",
       "2                      NaN            NaN                    NaN      NaN   \n",
       "3                      NaN            NaN                    NaN      NaN   \n",
       "4                      NaN            NaN                    NaN      NaN   \n",
       "...                    ...            ...                    ...      ...   \n",
       "83229                  NaN            NaN                    NaN      NaN   \n",
       "83230                  NaN            NaN                    NaN      NaN   \n",
       "83231                  NaN            NaN                    NaN      NaN   \n",
       "83232                  NaN            NaN                    NaN      NaN   \n",
       "83233                  NaN            NaN                    NaN      NaN   \n",
       "\n",
       "       foodG  iob  cr  isf  bgMgdl   rate suprBasalType  suprRate  \n",
       "0        NaN  NaN NaN  NaN   208.0    NaN           NaN       NaN  \n",
       "1        NaN  NaN NaN  NaN   215.0    NaN           NaN       NaN  \n",
       "2        NaN  NaN NaN  NaN   213.0    NaN           NaN       NaN  \n",
       "3        NaN  NaN NaN  NaN   205.0    NaN           NaN       NaN  \n",
       "4        NaN  NaN NaN  NaN   199.0    NaN           NaN       NaN  \n",
       "...      ...  ...  ..  ...     ...    ...           ...       ...  \n",
       "83229    NaN  NaN NaN  NaN   164.0    NaN           NaN       NaN  \n",
       "83230    NaN  NaN NaN  NaN   165.0    NaN           NaN       NaN  \n",
       "83231    NaN  NaN NaN  NaN     NaN  0.875           NaN       NaN  \n",
       "83232    NaN  NaN NaN  NaN   163.0    NaN           NaN       NaN  \n",
       "83233    NaN  NaN NaN  NaN     NaN    NaN     scheduled     0.875  \n",
       "\n",
       "[83234 rows x 17 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_check = 7\n",
    "root = get_project_root()\n",
    "patient_df = pd.read_csv(\n",
    "    f\"{root}/cache/data/awesome_cgm/aleppo/interim/p{pid_check}_full.csv\"\n",
    ")\n",
    "\n",
    "start_time = patient_df.date.min()\n",
    "end_time = patient_df.date.max()\n",
    "print(f\"Patient {pid_check} original data spans from {start_time} to {end_time}\")\n",
    "# processed_df = process_one_patient(patient_df)\n",
    "\n",
    "\n",
    "patient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0440df3",
   "metadata": {},
   "source": [
    "### Process all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_path = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"interim\"\n",
    "processed_path = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"processed\"\n",
    "\n",
    "\n",
    "# TODO: Double check this. This is too fast to be true.\n",
    "process_all_patients(interim_path, processed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0eeee6",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- [x] Figure out why we are missing some patients like p04 - There is no reason\n",
    "- [x] Verify db is created correctly in the right directory\n",
    "- [x] Figure out the columns of the tables and make sure the unit is actually correct. Is CarbInput in g and \"normal\" in units at all?\n",
    "- [ ] Plot a histogram to see if there are significantly less data before the enrollment day.\n",
    "- [ ] Figure out how to handle missing data (Some patients have missing cgm data). - Need to filter out calibaration. That seems to remove some of the large gap\n",
    "- [ ] Union with Basal table too (the rate should be roll to the next few rows. For example, a patient with 5-min interval has a rate of 0.1 units/hour, then we should have a 12 rows of 0.1/12 unit each). Also need to do a addition with whatever bolus is already there. So if a row already has 8 units of insulin, then it will be 8 + 0.1/12 units. Also need to keep rate as 0 if null.\n",
    "- [ ] Take a look at some patients' raw data and see if it makes sense at all first\n",
    "\n",
    "\n",
    "## Loader\n",
    "- [ ] Add a test split for the loader (5% of the entire dataset is enough)\n",
    "- [ ] Verify the `clean_all_patients` is working\n",
    "- [ ] Verify that `data_loader` works at all\n",
    "- [ ] For the loader class, cross check with Kaggle to do a similar data check\n",
    "- [ ] Update `README.md`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aedc9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".noctprob-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
