{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df612ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from src.utils.os_helper import get_project_root\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6705542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = get_project_root()\n",
    "\n",
    "CACHE_DIR = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\"\n",
    "data_tables = CACHE_DIR / \"raw\" / \"Data Tables\"\n",
    "db_path = CACHE_DIR / \"awesome_cgm.db\"\n",
    "\n",
    "# SQLite param cap (commonly 999). Keep a margin.\n",
    "SQLITE_MAX_VARS = 999\n",
    "MARGIN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e44ef861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing HAEDeviceProblems.txt -> HAEDeviceProblems\n",
      "Importing HAdvEvent.txt -> HAdvEvent\n",
      "Importing HComplUnblindCGM.txt -> HComplUnblindCGM\n",
      "Importing HDeviceBGM.txt -> HDeviceBGM\n",
      "Importing HDeviceBasal.txt -> HDeviceBasal\n",
      "Importing HDeviceBolus.txt -> HDeviceBolus\n",
      "Importing HDeviceCGM.txt -> HDeviceCGM\n",
      "Importing HDeviceDtTmVer.txt -> HDeviceDtTmVer\n",
      "Importing HDeviceEvents.txt -> HDeviceEvents\n",
      "Importing HDeviceIssue.txt -> HDeviceIssue\n",
      "Importing HDeviceUploads.txt -> HDeviceUploads\n",
      "Importing HDeviceWizard.txt -> HDeviceWizard\n",
      "Importing HFollowUp.txt -> HFollowUp\n",
      "Importing HHypoEvent.txt -> HHypoEvent\n",
      "Importing HInitialStudyCGM.txt -> HInitialStudyCGM\n",
      "Importing HInsulin.txt -> HInsulin\n",
      "Importing HLocalHbA1c.txt -> HLocalHbA1c\n",
      "Importing HMedicalCondition.txt -> HMedicalCondition\n",
      "Importing HMedication.txt -> HMedication\n",
      "Importing HPostRandPtFinalStatus.txt -> HPostRandPtFinalStatus\n",
      "Importing HPtRoster.txt -> HPtRoster\n",
      "Importing HQuestDiabTech.txt -> HQuestDiabTech\n",
      "Importing HQuestHypoFear.txt -> HQuestHypoFear\n",
      "Importing HQuestHypoUnaware.txt -> HQuestHypoUnaware\n",
      "Importing HRandomization.txt -> HRandomization\n",
      "Importing HRunInVisitStatus.txt -> HRunInVisitStatus\n",
      "Importing HScreening.txt -> HScreening\n",
      "Importing HUnscheduledVisit.txt -> HUnscheduledVisit\n",
      "Importing HVisitInfo.txt -> HVisitInfo\n",
      "Importing Sample.txt -> Sample\n",
      "Created index 1/16: HDeviceBolus\n",
      "Created index 2/16: HDeviceBolus\n",
      "Created index 3/16: HDeviceBolus\n",
      "Created index 4/16: HDeviceBolus\n",
      "Created index 5/16: HDeviceBolus\n",
      "Created index 6/16: HDeviceUploads\n",
      "Created index 7/16: HDeviceUploads\n",
      "Created index 8/16: HDeviceUploads\n",
      "Created index 9/16: HDeviceCGM\n",
      "Created index 10/16: HDeviceCGM\n",
      "Created index 11/16: HDeviceCGM\n",
      "Created index 12/16: HDeviceCGM\n",
      "Created index 13/16: HDeviceWizard\n",
      "Created index 14/16: HDeviceWizard\n",
      "Created index 15/16: HDeviceWizard\n",
      "Created index 16/16: HDeviceWizard\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect(db_path)\n",
    "cur = con.cursor()\n",
    "cur.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "cur.execute(\"PRAGMA synchronous=OFF;\")\n",
    "cur.execute(\"PRAGMA temp_store=MEMORY;\")\n",
    "\n",
    "for f in sorted(data_tables.glob(\"*.txt\")):\n",
    "    table = f.stem\n",
    "    print(f\"Importing {f.name} -> {table}\")\n",
    "\n",
    "    # Stream in chunks to control memory and SQL variables\n",
    "    first = True\n",
    "    for df in pd.read_csv(f, sep=\"|\", dtype=str, low_memory=False, chunksize=50_000):\n",
    "        ncols = len(df.columns)\n",
    "        # rows per insert so (rows * cols) <= SQLITE_MAX_VARS - MARGIN\n",
    "        safe_rows = max(1, (SQLITE_MAX_VARS - MARGIN) // max(1, ncols))\n",
    "\n",
    "        # method=None avoids multi-row SQL text construction; Pandas will executemany\n",
    "        df.to_sql(\n",
    "            table,\n",
    "            con,\n",
    "            if_exists=\"replace\" if first else \"append\",\n",
    "            index=False,\n",
    "            chunksize=safe_rows,\n",
    "            method=None,\n",
    "        )\n",
    "        first = False\n",
    "\n",
    "\n",
    "indexes = [\n",
    "    # Bolus Indexes\n",
    "    \"CREATE INDEX idx_hdevicebolus_ptid ON HDeviceBolus(PtID);\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_parentid ON HDeviceBolus(ParentHDeviceUploadsID);\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_ptid_days ON HDeviceBolus(PtID, DeviceDtTmDaysFromEnroll);\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_normal ON HDeviceBolus(Normal) WHERE Normal IS NOT NULL;\",\n",
    "    \"CREATE INDEX idx_hdevicebolus_order ON HDeviceBolus(PtID, DeviceDtTmDaysFromEnroll, DeviceTm);\",\n",
    "    # Uploads Indexes\n",
    "    \"CREATE INDEX idx_hdeviceuploads_recid ON HDeviceUploads(RecID);\",\n",
    "    \"CREATE INDEX idx_hdeviceuploads_ptid ON HDeviceUploads(PtID);\",\n",
    "    \"CREATE INDEX idx_hdeviceuploads_device ON HDeviceUploads(DeviceModel, DeviceType);\",\n",
    "    # CGM Indexes\n",
    "    \"CREATE INDEX idx_hdevicecgm_recid ON HDeviceCGM(RecID);\",\n",
    "    \"CREATE INDEX idx_hdevicecgm_recordtype ON HDeviceCGM(RecordType);\",\n",
    "    \"CREATE INDEX idx_hdevicecgm_ptid_days ON HDeviceCGM(PtID, DeviceDtTmDaysFromEnroll);\",\n",
    "    \"CREATE INDEX idx_hdevicecgm_ptid_time ON HDeviceCGM(PtID, DeviceTm);\",\n",
    "    # Wizard Indexes\n",
    "    \"CREATE INDEX idx_hdevicewizard_recid ON HDeviceWizard(RecID);\",\n",
    "    \"CREATE INDEX idx_hdevicewizard_ptid ON HDeviceWizard(PtID);\",\n",
    "    \"CREATE INDEX idx_hdevicewizard_ptid_days ON HDeviceWizard(PtID, DeviceDtTmDaysFromEnroll);\",\n",
    "    \"CREATE INDEX idx_hdevicewizard_ptid_time ON HDeviceWizard(PtID, DeviceTm);\",\n",
    "]\n",
    "\n",
    "for i, index_sql in enumerate(indexes):\n",
    "    try:\n",
    "        cur.execute(index_sql)\n",
    "        print(\n",
    "            f\"Created index {i+1}/{len(indexes)}: {index_sql.split('ON ')[1].split('(')[0]}\"\n",
    "        )\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aa64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(query: str):\n",
    "    # Open the connection first\n",
    "    con = sqlite3.connect(db_path)\n",
    "    # cur = con.cursor()\n",
    "    df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37ac29",
   "metadata": {},
   "source": [
    "### Convert data to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30c080",
   "metadata": {},
   "source": [
    "- pid\n",
    "- date\n",
    "- tableType\n",
    "- bolusType\n",
    "- normalBolus\n",
    "- expectedNormalBolus\n",
    "- extendedBolus\n",
    "- expectedExtendedBolus\n",
    "- bgInput\n",
    "- foodG\n",
    "- iob\n",
    "- cr\n",
    "- isf\n",
    "- bgMgdl\n",
    "- rate\n",
    "- suprBasalType\n",
    "- suprRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f649c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH\n",
    "  params AS (\n",
    "    SELECT '2020-01-01' AS base_date\n",
    "  )\n",
    "SELECT\n",
    "    pid, date, tableType,\n",
    "    bolusType, normalBolus, expectedNormalBolus, extendedBolus, expectedExtendedBolus,\n",
    "    bgInput, foodG, iob, cr, isf,\n",
    "    bgMgdl,\n",
    "    rate, basalDurationMins, suprBasalType, suprRate\n",
    "FROM (\n",
    "    -- Bolus data\n",
    "    SELECT\n",
    "        HDeviceBolus.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceBolus.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceBolus.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'bolus' as tableType,\n",
    "        HDeviceBolus.BolusType as bolusType,\n",
    "        HDeviceBolus.Normal as normalBolus,\n",
    "        HDeviceBolus.ExpectedNormal as expectedNormalBolus,\n",
    "        HDeviceBolus.Extended as extendedBolus,\n",
    "        HDeviceBolus.ExpectedExtended as expectedExtendedBolus,\n",
    "        NULL as bgInput,\n",
    "        NULL as foodG,\n",
    "        NULL as iob,\n",
    "        NULL as cr,\n",
    "        NULL as isf,\n",
    "        NULL as bgMgdl,\n",
    "        NULL as rate,\n",
    "        NULL as basalDurationMins,\n",
    "        NULL as suprBasalType,\n",
    "        NULL as suprRate\n",
    "    FROM HDeviceBolus\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Wizard data\n",
    "    SELECT\n",
    "        HDeviceWizard.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceWizard.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceWizard.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'wizard' as tableType,\n",
    "        NULL as bolusType,\n",
    "        NULL as normalBolus,\n",
    "        NULL as expectedNormalBolus,\n",
    "        NULL as extendedBolus,\n",
    "        NULL as expectedExtendedBolus,\n",
    "        HDeviceWizard.BgInput as bgInput,\n",
    "        HDeviceWizard.CarbInput / 1000 as foodG,\n",
    "        HDeviceWizard.InsulinOnBoard as iob,\n",
    "        HDeviceWizard.InsulinCarbRatio as cr,\n",
    "        HDeviceWizard.InsulinSensitivity as isf,\n",
    "        NULL as bgMgdl,\n",
    "        NULL as rate,\n",
    "        NULL as basalDurationMins,\n",
    "        NULL as suprBasalType,\n",
    "        NULL as suprRate\n",
    "    FROM HDeviceWizard\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- CGM data\n",
    "    SELECT\n",
    "        HDeviceCGM.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceCGM.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceCGM.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'cgm' as tableType,\n",
    "        NULL as bolusType,\n",
    "        NULL as normalBolus,\n",
    "        NULL as expectedNormalBolus,\n",
    "        NULL as extendedBolus,\n",
    "        NULL as expectedExtendedBolus,\n",
    "        NULL as bgInput,\n",
    "        NULL as foodG,\n",
    "        NULL as iob,\n",
    "        NULL as cr,\n",
    "        NULL as isf,\n",
    "        HDeviceCGM.GlucoseValue as bgMgdl,\n",
    "        NULL as rate,\n",
    "        NULL as basalDurationMins,\n",
    "        NULL as suprBasalType,\n",
    "        NULL as suprRate\n",
    "    FROM HDeviceCGM\n",
    "    WHERE HDeviceCGM.GlucoseValue IS NOT NULL\n",
    "    AND HDeviceCGM.RecordType = 'CGM'\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Basal data\n",
    "    SELECT\n",
    "        HDeviceBasal.PtID as pid,\n",
    "        datetime(julianday((SELECT base_date FROM params)) + CAST(HDeviceBasal.DeviceDtTmDaysFromEnroll AS INTEGER) + (julianday(HDeviceBasal.DeviceTm) - julianday('00:00:00'))) AS date,\n",
    "        'basal' as tableType,\n",
    "        NULL as bolusType,\n",
    "        NULL as normalBolus,\n",
    "        NULL as expectedNormalBolus,\n",
    "        NULL as extendedBolus,\n",
    "        NULL as expectedExtendedBolus,\n",
    "        NULL as bgInput,\n",
    "        NULL as foodG,\n",
    "        NULL as iob,\n",
    "        NULL as cr,\n",
    "        NULL as isf,\n",
    "        NULL as bgMgdl,\n",
    "        HDeviceBasal.Rate as rate,\n",
    "        HDeviceBasal.Duration / 60000 as basalDurationMins,\n",
    "        HDeviceBasal.SuprBasalType as suprBasalType,\n",
    "        HDeviceBasal.SuprRate as suprRate\n",
    "    FROM HDeviceBasal\n",
    ")\n",
    "ORDER BY pid, date ASC;\n",
    "\"\"\"\n",
    "df_all = query_db(query)\n",
    "df_all.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27057ae",
   "metadata": {},
   "source": [
    "### Raw -> Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c73035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing pid 10\n",
      "Done processing pid 101\n",
      "Done processing pid 102\n",
      "Done processing pid 103\n",
      "Done processing pid 105\n",
      "Done processing pid 106\n",
      "Done processing pid 108\n",
      "Done processing pid 109\n",
      "Done processing pid 11\n",
      "Done processing pid 110\n",
      "Done processing pid 111\n",
      "Done processing pid 112\n",
      "Done processing pid 113\n",
      "Done processing pid 115\n",
      "Done processing pid 116\n",
      "Done processing pid 118\n",
      "Done processing pid 119\n",
      "Done processing pid 121\n",
      "Done processing pid 123\n",
      "Done processing pid 124\n",
      "Done processing pid 127\n",
      "Done processing pid 128\n",
      "Done processing pid 129\n",
      "Done processing pid 130\n",
      "Done processing pid 131\n",
      "Done processing pid 132\n",
      "Done processing pid 134\n",
      "Done processing pid 135\n",
      "Done processing pid 136\n",
      "Done processing pid 137\n",
      "Done processing pid 138\n",
      "Done processing pid 139\n",
      "Done processing pid 14\n",
      "Done processing pid 140\n",
      "Done processing pid 141\n",
      "Done processing pid 143\n",
      "Done processing pid 145\n",
      "Done processing pid 146\n",
      "Done processing pid 147\n",
      "Done processing pid 148\n",
      "Done processing pid 149\n",
      "Done processing pid 15\n",
      "Done processing pid 152\n",
      "Done processing pid 155\n",
      "Done processing pid 156\n",
      "Done processing pid 157\n",
      "Done processing pid 158\n",
      "Done processing pid 16\n",
      "Done processing pid 160\n",
      "Done processing pid 162\n",
      "Done processing pid 163\n",
      "Done processing pid 164\n",
      "Done processing pid 165\n",
      "Done processing pid 166\n",
      "Done processing pid 167\n",
      "Done processing pid 168\n",
      "Done processing pid 169\n",
      "Done processing pid 17\n",
      "Done processing pid 170\n",
      "Done processing pid 171\n",
      "Done processing pid 172\n",
      "Done processing pid 173\n",
      "Done processing pid 174\n",
      "Done processing pid 175\n",
      "Done processing pid 176\n",
      "Done processing pid 177\n",
      "Done processing pid 179\n",
      "Done processing pid 18\n",
      "Done processing pid 181\n",
      "Done processing pid 183\n",
      "Done processing pid 184\n",
      "Done processing pid 185\n",
      "Done processing pid 186\n",
      "Done processing pid 187\n",
      "Done processing pid 188\n",
      "Done processing pid 189\n",
      "Done processing pid 19\n",
      "Done processing pid 190\n",
      "Done processing pid 193\n",
      "Done processing pid 197\n",
      "Done processing pid 198\n",
      "Done processing pid 2\n",
      "Done processing pid 20\n",
      "Done processing pid 200\n",
      "Done processing pid 201\n",
      "Done processing pid 203\n",
      "Done processing pid 204\n",
      "Done processing pid 205\n",
      "Done processing pid 206\n",
      "Done processing pid 209\n",
      "Done processing pid 21\n",
      "Done processing pid 210\n",
      "Done processing pid 211\n",
      "Done processing pid 213\n",
      "Done processing pid 214\n",
      "Done processing pid 215\n",
      "Done processing pid 216\n",
      "Done processing pid 217\n",
      "Done processing pid 218\n",
      "Done processing pid 219\n",
      "Done processing pid 22\n",
      "Done processing pid 220\n",
      "Done processing pid 221\n",
      "Done processing pid 222\n",
      "Done processing pid 223\n",
      "Done processing pid 224\n",
      "Done processing pid 226\n",
      "Done processing pid 227\n",
      "Done processing pid 228\n",
      "Done processing pid 229\n",
      "Done processing pid 23\n",
      "Done processing pid 231\n",
      "Done processing pid 232\n",
      "Done processing pid 233\n",
      "Done processing pid 234\n",
      "Done processing pid 235\n",
      "Done processing pid 236\n",
      "Done processing pid 239\n",
      "Done processing pid 24\n",
      "Done processing pid 240\n",
      "Done processing pid 241\n",
      "Done processing pid 243\n",
      "Done processing pid 244\n",
      "Done processing pid 245\n",
      "Done processing pid 246\n",
      "Done processing pid 247\n",
      "Done processing pid 248\n",
      "Done processing pid 249\n",
      "Done processing pid 250\n",
      "Done processing pid 251\n",
      "Done processing pid 252\n",
      "Done processing pid 253\n",
      "Done processing pid 254\n",
      "Done processing pid 256\n",
      "Done processing pid 257\n",
      "Done processing pid 258\n",
      "Done processing pid 26\n",
      "Done processing pid 260\n",
      "Done processing pid 263\n",
      "Done processing pid 264\n",
      "Done processing pid 265\n",
      "Done processing pid 266\n",
      "Done processing pid 267\n",
      "Done processing pid 269\n",
      "Done processing pid 27\n",
      "Done processing pid 271\n",
      "Done processing pid 272\n",
      "Done processing pid 273\n",
      "Done processing pid 274\n",
      "Done processing pid 275\n",
      "Done processing pid 276\n",
      "Done processing pid 277\n",
      "Done processing pid 278\n",
      "Done processing pid 280\n",
      "Done processing pid 281\n",
      "Done processing pid 283\n",
      "Done processing pid 284\n",
      "Done processing pid 285\n",
      "Done processing pid 287\n",
      "Done processing pid 288\n",
      "Done processing pid 289\n",
      "Done processing pid 29\n",
      "Done processing pid 290\n",
      "Done processing pid 291\n",
      "Done processing pid 292\n",
      "Done processing pid 293\n",
      "Done processing pid 3\n",
      "Done processing pid 30\n",
      "Done processing pid 31\n",
      "Done processing pid 32\n",
      "Done processing pid 33\n",
      "Done processing pid 35\n",
      "Done processing pid 36\n",
      "Done processing pid 37\n",
      "Done processing pid 38\n",
      "Done processing pid 39\n",
      "Done processing pid 40\n",
      "Done processing pid 41\n",
      "Done processing pid 42\n",
      "Done processing pid 43\n",
      "Done processing pid 45\n",
      "Done processing pid 46\n",
      "Done processing pid 47\n",
      "Done processing pid 48\n",
      "Done processing pid 49\n",
      "Done processing pid 5\n",
      "Done processing pid 50\n",
      "Done processing pid 52\n",
      "Done processing pid 53\n",
      "Done processing pid 54\n",
      "Done processing pid 55\n",
      "Done processing pid 57\n",
      "Done processing pid 58\n",
      "Done processing pid 60\n",
      "Done processing pid 61\n",
      "Done processing pid 62\n",
      "Done processing pid 64\n",
      "Done processing pid 65\n",
      "Done processing pid 67\n",
      "Done processing pid 68\n",
      "Done processing pid 69\n",
      "Done processing pid 7\n",
      "Done processing pid 70\n",
      "Done processing pid 71\n",
      "Done processing pid 72\n",
      "Done processing pid 73\n",
      "Done processing pid 74\n",
      "Done processing pid 76\n",
      "Done processing pid 77\n",
      "Done processing pid 78\n",
      "Done processing pid 79\n",
      "Done processing pid 8\n",
      "Done processing pid 80\n",
      "Done processing pid 81\n",
      "Done processing pid 82\n",
      "Done processing pid 86\n",
      "Done processing pid 87\n",
      "Done processing pid 89\n",
      "Done processing pid 9\n",
      "Done processing pid 90\n",
      "Done processing pid 91\n",
      "Done processing pid 93\n",
      "Done processing pid 95\n",
      "Done processing pid 96\n",
      "Done processing pid 97\n",
      "Done processing pid 98\n"
     ]
    }
   ],
   "source": [
    "def convert_to_csv(df):\n",
    "    project_root = get_project_root()\n",
    "    data_dir = project_root / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"interim\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    for pid in df[\"pid\"].unique():\n",
    "        df_pid = df[df[\"pid\"] == pid]\n",
    "        df_pid.to_csv(data_dir / f\"p{pid}_full.csv\", index=False)\n",
    "        print(f\"Done processing pid {pid}\")\n",
    "\n",
    "\n",
    "convert_to_csv(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5dfaea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T22:38:15.885942Z",
     "start_time": "2025-10-27T22:38:15.795604Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.models import ColumnNames\n",
    "from src.data.preprocessing.pipeline import preprocessing_pipeline\n",
    "from src.utils.unit import mg_dl_to_mmol_l\n",
    "import pandas as pd\n",
    "from src.utils.os_helper import get_project_root\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# \tpid\tdate\ttableType\tbolusType\tnormalBolus\texpectedNormalBolus\textendedBolus\texpectedExtendedBolus\tbgInput\tfoodG\tiob\tcr\tisf\tbgMgdl\trate\tsuprBasalType\tsuprRate\n",
    "def data_translation(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    'pid' -> p_num\n",
    "    'date' -> datetime\n",
    "    'tableType' -> msg_type (bolus, wizard, cgm). wizard contains information like carbs intake\n",
    "    'eventType': This is bolus type\n",
    "    'normal': Number of units of normal bolus\n",
    "    'expectedNormal'\n",
    "    'extended': Number of units for extended delivery\n",
    "    'expectedExtended'\n",
    "    'bgInput' -> Blood glucose as inputted into wizard in mg\n",
    "    'carbInput' -> Carbohydrates as inputted into wizard in mg\n",
    "    'iob': Units of insulin on board\n",
    "    'cr': Number of mg carbs covered by unit of insulin. Not used yet but we can find a way to give model a hint about the slope of the glucose curve\n",
    "    'isf': Number of bgs covered by unit of insulin. Same as above\n",
    "    'recordType': CGM | CALIBRATION\n",
    "    'glucoseValue' -> bg_mM\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "    # TODO: Rename to the correct column names\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"pid\": ColumnNames.P_NUM.value,\n",
    "            \"date\": ColumnNames.DATETIME.value,\n",
    "            \"tableType\": ColumnNames.MSG_TYPE.value,\n",
    "            \"normalBolus\": ColumnNames.DOSE_UNITS.value,\n",
    "            # \"expectedNormalBolus\": ColumnNames.EXPECTED_NORMAL.value,\n",
    "            # \"extendedBolus\": ColumnNames.EXTENDED.value,\n",
    "            # \"expectedExtendedBolus\": ColumnNames.EXPECTED_EXTENDED.value,\n",
    "            # \"bgInput\": ColumnNames.BG.value, todo: Maybe tag the record type as bgInput\n",
    "            \"foodG\": ColumnNames.FOOD_G.value,\n",
    "            \"iob\": ColumnNames.IOB.value,\n",
    "            # \"cr\": ColumnNames.INSULIN_CARB_RATIO.value,\n",
    "            # \"isf\": ColumnNames.ISF.value,\n",
    "            \"recordType\": ColumnNames.RECORD_TYPE.value,\n",
    "            \"bgMgdl\": ColumnNames.BG.value,\n",
    "            # \"rate\": ColumnNames.RATE.value,\n",
    "            \"basalDurationMins\": ColumnNames.BASAL_DURATION_MINS.value,\n",
    "            \"suprBasalType\": ColumnNames.SUPR_BASAL_TYPE.value,\n",
    "            \"suprRate\": ColumnNames.SUPR_RATE.value,\n",
    "        }\n",
    "    )\n",
    "    # Drop the expected columns for now\n",
    "    df.drop(columns=[\"expectedNormalBolus\", \"expectedExtendedBolus\"], inplace=True)\n",
    "    df.set_index(ColumnNames.DATETIME.value, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Convert blood glucose from mg/dL to mmol/L\n",
    "    df[ColumnNames.BG.value] = mg_dl_to_mmol_l(df, bgl_col=ColumnNames.BG.value)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def keep_overlapping_data(patient_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        patient_df: A dataframe that has been through data_translation (datetime is the index)\n",
    "\n",
    "    Keep data that has overlapping time windows for all table types.\n",
    "    Note that not all patients have data for all table types so we only consider the table types that are present.\n",
    "\n",
    "    Don't think we are losing too much data here. Most patients still have at least 6 months worth of data after this step except for some patients.\n",
    "    - p216, p019, p081, p289, p138 (check 3.18 notebook for more details)\n",
    "    \"\"\"\n",
    "    table_types = patient_df[ColumnNames.MSG_TYPE.value].unique()\n",
    "    start_datetime = None  # This should be the max of all the min datetimes\n",
    "    end_datetime = None  # This should be the min of all the max datetimes\n",
    "\n",
    "    for table_type in table_types:\n",
    "        table_data = patient_df[patient_df[ColumnNames.MSG_TYPE.value] == table_type]\n",
    "        if table_data.empty:\n",
    "            continue\n",
    "\n",
    "        min_datetime = table_data.index.min()\n",
    "        max_datetime = table_data.index.max()\n",
    "\n",
    "        # Find the latest start time of all table types\n",
    "        if start_datetime is None or min_datetime > start_datetime:\n",
    "            start_datetime = min_datetime\n",
    "\n",
    "        # Find the earliest end time of all table types\n",
    "        if end_datetime is None or max_datetime < end_datetime:\n",
    "            end_datetime = max_datetime\n",
    "\n",
    "    if start_datetime is None or end_datetime is None:\n",
    "        return None\n",
    "\n",
    "    has_overlap = start_datetime < end_datetime\n",
    "    if not has_overlap:\n",
    "        # This shouldn't happen\n",
    "        logger.warning(\n",
    "            f\"Patient {patient_df[ColumnNames.P_NUM.value].iloc[0]} has no overlapping data\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Filter using the index (datetime)\n",
    "    return patient_df[\n",
    "        (patient_df.index >= start_datetime) & (patient_df.index <= end_datetime)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f890c847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T22:38:16.451276Z",
     "start_time": "2025-10-27T22:38:16.446625Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.preprocessing.generic_cleaning import erase_consecutive_nan_values\n",
    "from src.data.preprocessing.time_processing import get_most_common_time_interval\n",
    "\n",
    "\n",
    "def process_one_patient(\n",
    "    df_raw: pd.DataFrame, debug: bool = False, verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the raw data for one patient:\n",
    "        1. Translate the data (columns and units)\n",
    "        2. Keep overlapping data (for bolus, wizard, cgm and basal)\n",
    "        3. Rollover basal rate to the next few rows if the rate is not null\n",
    "        4. preprocessing_pipeline (This include resampling and deriving cob and iob)\n",
    "    \"\"\"\n",
    "    HOURS_OF_CONSECUTIVE_NAN_VALUES = 6\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Translate the data\n",
    "    df = data_translation(df)\n",
    "    pid = df[ColumnNames.P_NUM.value].iloc[0]\n",
    "\n",
    "    # Keep overlapping data\n",
    "    logger.info(f\"Keeping overlapping data for patient {pid}\")\n",
    "    df = keep_overlapping_data(df)\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    # Print data meta: span of datetime index and number of rows\n",
    "    if verbose:\n",
    "        start_dt = df.index.min()\n",
    "        end_dt = df.index.max()\n",
    "        food_g = df[df[ColumnNames.FOOD_G.value].notna()]\n",
    "        bolus = df[df[ColumnNames.DOSE_UNITS.value].notna()]\n",
    "        logger.info(\n",
    "            f\"Patient {pid} processed data spans from {start_dt} to {end_dt} ({(end_dt - start_dt)})\"\n",
    "        )\n",
    "        logger.info(f\"Number of rows with food intake: {len(food_g)}\")\n",
    "        logger.info(f\"Number of rows with bolus: {len(bolus)}\")\n",
    "\n",
    "    # Resampling to constant interval, rollover basal rate and derive cob and iob\n",
    "    df = preprocessing_pipeline(pid, df, use_aggregation=True)\n",
    "\n",
    "    # Drop days with more than 6 hours of consecutive NaN values\n",
    "    freq_mins = get_most_common_time_interval(df)\n",
    "    max_consecutive_nan_values_per_day = (\n",
    "        HOURS_OF_CONSECUTIVE_NAN_VALUES * 60\n",
    "    ) // freq_mins\n",
    "    # Note that it is possible that we have bolus from the deleted days. becase we rollover first then delete.\n",
    "    df = erase_consecutive_nan_values(\n",
    "        df, max_consecutive_nan_values_per_day=max_consecutive_nan_values_per_day\n",
    "    )\n",
    "\n",
    "    # Debug only\n",
    "    if debug:\n",
    "        debug_dir = (\n",
    "            get_project_root() / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"debug\"\n",
    "        )\n",
    "        os.makedirs(debug_dir, exist_ok=True)\n",
    "        df.to_csv(debug_dir / f\"p{pid}.csv\", index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_all_patients(\n",
    "    interim_path: Path,\n",
    "    processed_path: Path,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean all patients' data in the interim path and save the processed data to the processed path.\n",
    "    \"\"\"\n",
    "    total_patients = len(os.listdir(interim_path))\n",
    "    for index, pid in enumerate(os.listdir(interim_path)):\n",
    "        progress = f\"({index+1}/{total_patients})\"\n",
    "        save_path = processed_path / pid\n",
    "        # Don't process the patient if the processed data already exists\n",
    "        if save_path.exists():\n",
    "            print(f\"Skipping pid {pid} because {save_path} already exists {progress}.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(interim_path / pid)\n",
    "        df = process_one_patient(df)\n",
    "        df.to_csv(save_path, index=True)\n",
    "        print(f\"{\"-\"*10}Done processing pid {pid} {progress} {\"-\"*10}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418bb74",
   "metadata": {},
   "source": [
    "### Interim -> Processed for one patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0781bdba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-28T02:48:02.360499Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29T04:06:40 - Keeping overlapping data for patient 7\n",
      "2025-10-29T04:06:40 - ==============================\n",
      "2025-10-29T04:06:40 - Preprocessing patient 7\n",
      "2025-10-29T04:06:40 - ==============================\n",
      "2025-10-29T04:06:40 - create_physiological_features(): Deriving features...\n",
      "2025-10-29T04:06:40 - \tEnsuring regular time intervals with aggregation...\n",
      "2025-10-29T04:06:40 - ensure_regular_time_intervals_with_aggregation(): Ensuring regular time intervals with aggregation...\n",
      "2025-10-29T04:06:40 - \tMost common time interval: 5 minutes\n",
      "2025-10-29T04:06:40 - \tAggregation strategy: {'p_num': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x147978540>, 'msg_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x1479789a0>, 'bolusType': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x1479784a0>, 'dose_units': 'sum', 'extendedBolus': 'sum', 'bgInput': 'sum', 'food_g': 'sum', 'iob': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x147978680>, 'cr': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x1479785e0>, 'isf': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x147978900>, 'bg_mM': 'mean', 'rate': 'mean', 'basal_duration_mins': 'sum', 'supr_basal_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x147978c20>, 'supr_rate': 'sum'}\n",
      "2025-10-29T04:08:42 - Post-ensure_regular_time_intervals_with_aggregation(): \n",
      "\t\t\tPatient 7 \n",
      "\t\t\t - old index length: 80519, \n",
      "\t\t\t - new index length: 95900\n",
      "2025-10-29T04:08:43 - \tRollover basal rate...\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "2025-10-29T04:08:44 - \tCreating COB/IOB and availability columns. This may take a while depending on the size of the data.\n",
      "2025-10-29T04:08:44 - \tCreating COB and carb availability columns...\n",
      "2025-10-29T04:08:44 - \tProcessing glucose dynamics\n",
      "2025-10-29T04:09:58 - \tCreating IOB and insulin availability columns...\n",
      "2025-10-29T04:09:58 - \tProcessing insulin dynamics\n",
      "2025-10-29T04:11:13 - \tDone deriving features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PID = 7\n",
    "\n",
    "root = get_project_root()\n",
    "patient_df = pd.read_csv(\n",
    "    f\"{root}/cache/data/awesome_cgm/aleppo/interim/p{PID}_full.csv\"\n",
    ")\n",
    "\n",
    "processed_df = process_one_patient(patient_df)\n",
    "processed_df.to_csv(f\"p{PID}_full.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90517cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGM data spans from 2019-08-17 14:32:00 to 2020-09-30 10:01:44\n",
      "Bolus data spans from 2019-11-01 20:38:27 to 2020-09-30 08:58:17\n",
      "Wizard data spans from 2019-11-02 09:19:27 to 2020-09-30 08:58:17\n",
      "Basal data spans from 2019-11-01 23:12:23 to 2020-09-30 10:14:30\n",
      "Data spans from 2019-11-02 09:19:27 to 2020-09-30 08:58:17\n"
     ]
    }
   ],
   "source": [
    "cgm_df = patient_df[patient_df[\"tableType\"] == \"cgm\"]\n",
    "cgm_start = cgm_df.date.min()\n",
    "cgm_end = cgm_df.date.max()\n",
    "print(f\"CGM data spans from {cgm_start} to {cgm_end}\")\n",
    "\n",
    "\n",
    "bolus_df = patient_df[patient_df[\"tableType\"] == \"bolus\"]\n",
    "bolus_start = bolus_df.date.min()\n",
    "bolus_end = bolus_df.date.max()\n",
    "print(f\"Bolus data spans from {bolus_start} to {bolus_end}\")\n",
    "\n",
    "wizard_df = patient_df[patient_df[\"tableType\"] == \"wizard\"]\n",
    "wizard_start = wizard_df.date.min()\n",
    "wizard_end = wizard_df.date.max()\n",
    "print(f\"Wizard data spans from {wizard_start} to {wizard_end}\")\n",
    "\n",
    "basal_df = patient_df[patient_df[\"tableType\"] == \"basal\"]\n",
    "basal_start = basal_df.date.min()\n",
    "basal_end = basal_df.date.max()\n",
    "print(f\"Basal data spans from {basal_start} to {basal_end}\")\n",
    "\n",
    "\n",
    "data_start = max(cgm_start, bolus_start, wizard_start, basal_start)\n",
    "data_end = min(cgm_end, bolus_end, wizard_end, basal_end)\n",
    "print(f\"Data spans from {data_start} to {data_end}\")\n",
    "\n",
    "\n",
    "cgm_df.to_csv(\"cgm_p7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0440df3",
   "metadata": {},
   "source": [
    "### Process all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e6612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29T20:24:25 - Keeping overlapping data for patient 29\n",
      "2025-10-29T20:24:25 - ==============================\n",
      "2025-10-29T20:24:25 - Preprocessing patient 29\n",
      "2025-10-29T20:24:25 - ==============================\n",
      "2025-10-29T20:24:25 - create_physiological_features(): Deriving features...\n",
      "2025-10-29T20:24:25 - \tEnsuring regular time intervals with aggregation...\n",
      "2025-10-29T20:24:25 - ensure_regular_time_intervals_with_aggregation(): Ensuring regular time intervals with aggregation...\n",
      "2025-10-29T20:24:25 - \tMost common time interval: 5 minutes\n",
      "2025-10-29T20:24:25 - \tAggregation strategy: {'p_num': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48ee80>, 'msg_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48f560>, 'bolusType': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48f380>, 'dose_units': 'sum', 'extendedBolus': 'sum', 'bgInput': 'sum', 'food_g': 'sum', 'iob': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48f4c0>, 'cr': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48ed40>, 'isf': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48f7e0>, 'bg_mM': 'mean', 'rate': 'mean', 'basal_duration_mins': 'sum', 'supr_basal_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x16a48f920>, 'supr_rate': 'sum'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping pid p47_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p47_full.csv already exists (1/226).\n",
      "Skipping pid p46_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p46_full.csv already exists (2/226).\n",
      "Skipping pid p260_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p260_full.csv already exists (3/226).\n",
      "Skipping pid p147_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p147_full.csv already exists (4/226).\n",
      "Skipping pid p146_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p146_full.csv already exists (5/226).\n",
      "Skipping pid p229_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p229_full.csv already exists (6/226).\n",
      "Skipping pid p228_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p228_full.csv already exists (7/226).\n",
      "Skipping pid p130_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p130_full.csv already exists (8/226).\n",
      "Skipping pid p131_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p131_full.csv already exists (9/226).\n",
      "Skipping pid p79_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p79_full.csv already exists (10/226).\n",
      "Skipping pid p78_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p78_full.csv already exists (11/226).\n",
      "Skipping pid p285_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p285_full.csv already exists (12/226).\n",
      "Skipping pid p284_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p284_full.csv already exists (13/226).\n",
      "Skipping pid p179_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p179_full.csv already exists (14/226).\n",
      "Skipping pid p30_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p30_full.csv already exists (15/226).\n",
      "Skipping pid p31_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p31_full.csv already exists (16/226).\n",
      "Skipping pid p217_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p217_full.csv already exists (17/226).\n",
      "Skipping pid p216_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p216_full.csv already exists (18/226).\n",
      "Skipping pid p223_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p223_full.csv already exists (19/226).\n",
      "Skipping pid p222_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p222_full.csv already exists (20/226).\n",
      "Skipping pid p96_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p96_full.csv already exists (21/226).\n",
      "Skipping pid p97_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p97_full.csv already exists (22/226).\n",
      "Skipping pid p197_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p197_full.csv already exists (23/226).\n",
      "Skipping pid p105_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p105_full.csv already exists (24/226).\n",
      "Skipping pid p173_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p173_full.csv already exists (25/226).\n",
      "Skipping pid p172_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p172_full.csv already exists (26/226).\n",
      "Skipping pid p73_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p73_full.csv already exists (27/226).\n",
      "Skipping pid p72_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p72_full.csv already exists (28/226).\n",
      "Skipping pid p254_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p254_full.csv already exists (29/226).\n",
      "Skipping pid p19_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p19_full.csv already exists (30/226).\n",
      "Skipping pid p18_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p18_full.csv already exists (31/226).\n",
      "Skipping pid p50_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p50_full.csv already exists (32/226).\n",
      "Skipping pid p277_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p277_full.csv already exists (33/226).\n",
      "Skipping pid p276_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p276_full.csv already exists (34/226).\n",
      "Skipping pid p119_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p119_full.csv already exists (35/226).\n",
      "Skipping pid p118_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p118_full.csv already exists (36/226).\n",
      "Skipping pid p27_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p27_full.csv already exists (37/226).\n",
      "Skipping pid p7_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p7_full.csv already exists (38/226).\n",
      "Skipping pid p26_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p26_full.csv already exists (39/226).\n",
      "Skipping pid p200_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p200_full.csv already exists (40/226).\n",
      "Skipping pid p201_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p201_full.csv already exists (41/226).\n",
      "Skipping pid p292_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p292_full.csv already exists (42/226).\n",
      "Skipping pid p293_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p293_full.csv already exists (43/226).\n",
      "Skipping pid p249_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p249_full.csv already exists (44/226).\n",
      "Skipping pid p248_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p248_full.csv already exists (45/226).\n",
      "Skipping pid p127_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p127_full.csv already exists (46/226).\n",
      "Skipping pid p113_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p113_full.csv already exists (47/226).\n",
      "Skipping pid p112_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p112_full.csv already exists (48/226).\n",
      "Skipping pid p181_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p181_full.csv already exists (49/226).\n",
      "Skipping pid p81_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p81_full.csv already exists (50/226).\n",
      "Skipping pid p80_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p80_full.csv already exists (51/226).\n",
      "Skipping pid p234_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p234_full.csv already exists (52/226).\n",
      "Skipping pid p235_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p235_full.csv already exists (53/226).\n",
      "Skipping pid p64_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p64_full.csv already exists (54/226).\n",
      "Skipping pid p65_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p65_full.csv already exists (55/226).\n",
      "Skipping pid p243_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p243_full.csv already exists (56/226).\n",
      "Skipping pid p164_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p164_full.csv already exists (57/226).\n",
      "Skipping pid p165_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p165_full.csv already exists (58/226).\n",
      "Skipping pid p157_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p157_full.csv already exists (59/226).\n",
      "Skipping pid p156_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p156_full.csv already exists (60/226).\n",
      "Skipping pid p239_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p239_full.csv already exists (61/226).\n",
      "Skipping pid p57_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p57_full.csv already exists (62/226).\n",
      "Skipping pid p271_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p271_full.csv already exists (63/226).\n",
      "Skipping pid p169_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p169_full.csv already exists (64/226).\n",
      "Skipping pid p168_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p168_full.csv already exists (65/226).\n",
      "Skipping pid p20_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p20_full.csv already exists (66/226).\n",
      "Skipping pid p21_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p21_full.csv already exists (67/226).\n",
      "Skipping pid p206_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p206_full.csv already exists (68/226).\n",
      "Skipping pid p121_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p121_full.csv already exists (69/226).\n",
      "Skipping pid p69_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p69_full.csv already exists (70/226).\n",
      "Skipping pid p68_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p68_full.csv already exists (71/226).\n",
      "Skipping pid p186_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p186_full.csv already exists (72/226).\n",
      "Skipping pid p187_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p187_full.csv already exists (73/226).\n",
      "Skipping pid p115_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p115_full.csv already exists (74/226).\n",
      "Skipping pid p14_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p14_full.csv already exists (75/226).\n",
      "Skipping pid p15_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p15_full.csv already exists (76/226).\n",
      "Skipping pid p233_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p233_full.csv already exists (77/226).\n",
      "Skipping pid p232_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p232_full.csv already exists (78/226).\n",
      "Skipping pid p86_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p86_full.csv already exists (79/226).\n",
      "Skipping pid p87_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p87_full.csv already exists (80/226).\n",
      "Skipping pid p62_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p62_full.csv already exists (81/226).\n",
      "Skipping pid p244_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p244_full.csv already exists (82/226).\n",
      "Skipping pid p245_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p245_full.csv already exists (83/226).\n",
      "Skipping pid p163_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p163_full.csv already exists (84/226).\n",
      "Skipping pid p162_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p162_full.csv already exists (85/226).\n",
      "Skipping pid p40_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p40_full.csv already exists (86/226).\n",
      "Skipping pid p41_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p41_full.csv already exists (87/226).\n",
      "Skipping pid p267_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p267_full.csv already exists (88/226).\n",
      "Skipping pid p266_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p266_full.csv already exists (89/226).\n",
      "Skipping pid p109_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p109_full.csv already exists (90/226).\n",
      "Skipping pid p108_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p108_full.csv already exists (91/226).\n",
      "Skipping pid p140_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p140_full.csv already exists (92/226).\n",
      "Skipping pid p141_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p141_full.csv already exists (93/226).\n",
      "Skipping pid p258_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p258_full.csv already exists (94/226).\n",
      "Skipping pid p137_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p137_full.csv already exists (95/226).\n",
      "Skipping pid p136_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p136_full.csv already exists (96/226).\n",
      "Skipping pid p37_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p37_full.csv already exists (97/226).\n",
      "Skipping pid p36_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p36_full.csv already exists (98/226).\n",
      "Skipping pid p210_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p210_full.csv already exists (99/226).\n",
      "Skipping pid p211_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p211_full.csv already exists (100/226).\n",
      "Skipping pid p283_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p283_full.csv already exists (101/226).\n",
      "Skipping pid p91_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p91_full.csv already exists (102/226).\n",
      "Skipping pid p90_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p90_full.csv already exists (103/226).\n",
      "Skipping pid p224_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p224_full.csv already exists (104/226).\n",
      "Skipping pid p103_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p103_full.csv already exists (105/226).\n",
      "Skipping pid p102_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p102_full.csv already exists (106/226).\n",
      "Skipping pid p190_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p190_full.csv already exists (107/226).\n",
      "Skipping pid p174_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p174_full.csv already exists (108/226).\n",
      "Skipping pid p175_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p175_full.csv already exists (109/226).\n",
      "Skipping pid p288_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p288_full.csv already exists (110/226).\n",
      "Skipping pid p289_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p289_full.csv already exists (111/226).\n",
      "Skipping pid p74_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p74_full.csv already exists (112/226).\n",
      "Skipping pid p253_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p253_full.csv already exists (113/226).\n",
      "Skipping pid p252_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p252_full.csv already exists (114/226).\n",
      "Skipping pid p110_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p110_full.csv already exists (115/226).\n",
      "Skipping pid p111_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p111_full.csv already exists (116/226).\n",
      "Skipping pid p58_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p58_full.csv already exists (117/226).\n",
      "Skipping pid p183_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p183_full.csv already exists (118/226).\n",
      "Skipping pid p82_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p82_full.csv already exists (119/226).\n",
      "Skipping pid p158_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p158_full.csv already exists (120/226).\n",
      "Skipping pid p236_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p236_full.csv already exists (121/226).\n",
      "Skipping pid p10_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p10_full.csv already exists (122/226).\n",
      "Skipping pid p11_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p11_full.csv already exists (123/226).\n",
      "Skipping pid p240_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p240_full.csv already exists (124/226).\n",
      "Skipping pid p241_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p241_full.csv already exists (125/226).\n",
      "Skipping pid p67_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p67_full.csv already exists (126/226).\n",
      "Skipping pid p167_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p167_full.csv already exists (127/226).\n",
      "Skipping pid p166_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p166_full.csv already exists (128/226).\n",
      "Skipping pid p209_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p209_full.csv already exists (129/226).\n",
      "Skipping pid p152_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p152_full.csv already exists (130/226).\n",
      "Skipping pid p89_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p89_full.csv already exists (131/226).\n",
      "Skipping pid p274_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p274_full.csv already exists (132/226).\n",
      "Skipping pid p275_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p275_full.csv already exists (133/226).\n",
      "Skipping pid p188_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p188_full.csv already exists (134/226).\n",
      "Skipping pid p53_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p53_full.csv already exists (135/226).\n",
      "Skipping pid p52_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p52_full.csv already exists (136/226).\n",
      "Skipping pid p189_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p189_full.csv already exists (137/226).\n",
      "Skipping pid p203_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p203_full.csv already exists (138/226).\n",
      "Skipping pid p24_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p24_full.csv already exists (139/226).\n",
      "Skipping pid p5_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p5_full.csv already exists (140/226).\n",
      "Skipping pid p291_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p291_full.csv already exists (141/226).\n",
      "Skipping pid p290_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p290_full.csv already exists (142/226).\n",
      "Skipping pid p124_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p124_full.csv already exists (143/226).\n",
      "Skipping pid p220_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p220_full.csv already exists (144/226).\n",
      "Skipping pid p221_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p221_full.csv already exists (145/226).\n",
      "Skipping pid p95_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p95_full.csv already exists (146/226).\n",
      "Skipping pid p269_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p269_full.csv already exists (147/226).\n",
      "Skipping pid p106_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p106_full.csv already exists (148/226).\n",
      "Skipping pid p39_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p39_full.csv already exists (149/226).\n",
      "Skipping pid p38_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p38_full.csv already exists (150/226).\n",
      "Skipping pid p170_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p170_full.csv already exists (151/226).\n",
      "Skipping pid p171_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p171_full.csv already exists (152/226).\n",
      "Skipping pid p257_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p257_full.csv already exists (153/226).\n",
      "Skipping pid p256_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p256_full.csv already exists (154/226).\n",
      "Skipping pid p70_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p70_full.csv already exists (155/226).\n",
      "Skipping pid p71_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p71_full.csv already exists (156/226).\n",
      "Skipping pid p139_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p139_full.csv already exists (157/226).\n",
      "Skipping pid p138_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p138_full.csv already exists (158/226).\n",
      "Skipping pid p263_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p263_full.csv already exists (159/226).\n",
      "Skipping pid p45_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p45_full.csv already exists (160/226).\n",
      "Skipping pid p145_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p145_full.csv already exists (161/226).\n",
      "Skipping pid p132_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p132_full.csv already exists (162/226).\n",
      "Skipping pid p287_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p287_full.csv already exists (163/226).\n",
      "Skipping pid p214_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p214_full.csv already exists (164/226).\n",
      "Skipping pid p215_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p215_full.csv already exists (165/226).\n",
      "Skipping pid p33_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p33_full.csv already exists (166/226).\n",
      "Skipping pid p32_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p32_full.csv already exists (167/226).\n",
      "Skipping pid p149_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p149_full.csv already exists (168/226).\n",
      "Skipping pid p93_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p93_full.csv already exists (169/226).\n",
      "Skipping pid p148_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p148_full.csv already exists (170/226).\n",
      "Skipping pid p227_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p227_full.csv already exists (171/226).\n",
      "Skipping pid p226_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p226_full.csv already exists (172/226).\n",
      "Skipping pid p101_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p101_full.csv already exists (173/226).\n",
      "Skipping pid p49_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p49_full.csv already exists (174/226).\n",
      "Skipping pid p193_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p193_full.csv already exists (175/226).\n",
      "Skipping pid p48_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p48_full.csv already exists (176/226).\n",
      "Skipping pid p177_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p177_full.csv already exists (177/226).\n",
      "Skipping pid p176_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p176_full.csv already exists (178/226).\n",
      "Skipping pid p219_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p219_full.csv already exists (179/226).\n",
      "Skipping pid p218_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p218_full.csv already exists (180/226).\n",
      "Skipping pid p250_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p250_full.csv already exists (181/226).\n",
      "Skipping pid p251_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p251_full.csv already exists (182/226).\n",
      "Skipping pid p77_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p77_full.csv already exists (183/226).\n",
      "Skipping pid p76_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p76_full.csv already exists (184/226).\n",
      "Skipping pid p264_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p264_full.csv already exists (185/226).\n",
      "Skipping pid p265_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p265_full.csv already exists (186/226).\n",
      "Skipping pid p43_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p43_full.csv already exists (187/226).\n",
      "Skipping pid p198_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p198_full.csv already exists (188/226).\n",
      "Skipping pid p42_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p42_full.csv already exists (189/226).\n",
      "Skipping pid p143_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p143_full.csv already exists (190/226).\n",
      "Skipping pid p98_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p98_full.csv already exists (191/226).\n",
      "Skipping pid p134_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p134_full.csv already exists (192/226).\n",
      "Skipping pid p135_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p135_full.csv already exists (193/226).\n",
      "Skipping pid p213_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p213_full.csv already exists (194/226).\n",
      "Skipping pid p35_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p35_full.csv already exists (195/226).\n",
      "Skipping pid p281_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p281_full.csv already exists (196/226).\n",
      "Skipping pid p280_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p280_full.csv already exists (197/226).\n",
      "Skipping pid p185_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p185_full.csv already exists (198/226).\n",
      "Skipping pid p184_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p184_full.csv already exists (199/226).\n",
      "Skipping pid p278_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p278_full.csv already exists (200/226).\n",
      "Skipping pid p116_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p116_full.csv already exists (201/226).\n",
      "Skipping pid p231_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p231_full.csv already exists (202/226).\n",
      "Skipping pid p17_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p17_full.csv already exists (203/226).\n",
      "Skipping pid p16_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p16_full.csv already exists (204/226).\n",
      "Skipping pid p247_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p247_full.csv already exists (205/226).\n",
      "Skipping pid p246_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p246_full.csv already exists (206/226).\n",
      "Skipping pid p60_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p60_full.csv already exists (207/226).\n",
      "Skipping pid p61_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p61_full.csv already exists (208/226).\n",
      "Skipping pid p129_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p129_full.csv already exists (209/226).\n",
      "Skipping pid p128_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p128_full.csv already exists (210/226).\n",
      "Skipping pid p9_full.csv because /Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/cache/data/awesome_cgm/aleppo/processed/p9_full.csv already exists (211/226).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29T20:25:41 - Post-ensure_regular_time_intervals_with_aggregation(): \n",
      "\t\t\tPatient 29 \n",
      "\t\t\t - old index length: 70487, \n",
      "\t\t\t - new index length: 72601\n",
      "2025-10-29T20:25:42 - \tRollover basal rate...\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "2025-10-29T20:25:42 - \tCreating COB/IOB and availability columns. This may take a while depending on the size of the data.\n",
      "2025-10-29T20:25:42 - \tCreating COB and carb availability columns...\n",
      "2025-10-29T20:25:42 - \tProcessing glucose dynamics\n",
      "2025-10-29T20:26:38 - \tCreating IOB and insulin availability columns...\n",
      "2025-10-29T20:26:38 - \tProcessing insulin dynamics\n",
      "2025-10-29T20:27:30 - \tDone deriving features.\n",
      "\n",
      "2025-10-29T20:27:31 - Keeping overlapping data for patient 8\n",
      "2025-10-29T20:27:31 - ==============================\n",
      "2025-10-29T20:27:31 - Preprocessing patient 8\n",
      "2025-10-29T20:27:31 - ==============================\n",
      "2025-10-29T20:27:31 - create_physiological_features(): Deriving features...\n",
      "2025-10-29T20:27:31 - \tEnsuring regular time intervals with aggregation...\n",
      "2025-10-29T20:27:31 - ensure_regular_time_intervals_with_aggregation(): Ensuring regular time intervals with aggregation...\n",
      "2025-10-29T20:27:31 - \tMost common time interval: 5 minutes\n",
      "2025-10-29T20:27:31 - \tAggregation strategy: {'p_num': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83240>, 'msg_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b82e80>, 'bolusType': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83920>, 'dose_units': 'sum', 'extendedBolus': 'sum', 'bgInput': 'sum', 'food_g': 'sum', 'iob': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b80180>, 'cr': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83ce0>, 'isf': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83880>, 'bg_mM': 'mean', 'rate': 'mean', 'basal_duration_mins': 'sum', 'supr_basal_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b80540>, 'supr_rate': 'sum'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Done processing pid p29_full.csv (212/226) ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29T20:28:19 - Post-ensure_regular_time_intervals_with_aggregation(): \n",
      "\t\t\tPatient 8 \n",
      "\t\t\t - old index length: 54265, \n",
      "\t\t\t - new index length: 56094\n",
      "2025-10-29T20:28:19 - \tRollover basal rate...\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "2025-10-29T20:28:20 - \tCreating COB/IOB and availability columns. This may take a while depending on the size of the data.\n",
      "2025-10-29T20:28:20 - \tCreating COB and carb availability columns...\n",
      "2025-10-29T20:28:20 - \tProcessing glucose dynamics\n",
      "2025-10-29T20:28:57 - \tCreating IOB and insulin availability columns...\n",
      "2025-10-29T20:28:57 - \tProcessing insulin dynamics\n",
      "2025-10-29T20:29:28 - \tDone deriving features.\n",
      "\n",
      "2025-10-29T20:29:29 - Keeping overlapping data for patient 160\n",
      "2025-10-29T20:29:29 - ==============================\n",
      "2025-10-29T20:29:29 - Preprocessing patient 160\n",
      "2025-10-29T20:29:29 - ==============================\n",
      "2025-10-29T20:29:29 - create_physiological_features(): Deriving features...\n",
      "2025-10-29T20:29:29 - \tEnsuring regular time intervals with aggregation...\n",
      "2025-10-29T20:29:29 - ensure_regular_time_intervals_with_aggregation(): Ensuring regular time intervals with aggregation...\n",
      "2025-10-29T20:29:29 - \tMost common time interval: 5 minutes\n",
      "2025-10-29T20:29:29 - \tAggregation strategy: {'p_num': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b82ca0>, 'msg_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b82700>, 'bolusType': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83060>, 'dose_units': 'sum', 'extendedBolus': 'sum', 'bgInput': 'sum', 'food_g': 'sum', 'iob': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b80400>, 'cr': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b831a0>, 'isf': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83ec0>, 'bg_mM': 'mean', 'rate': 'mean', 'basal_duration_mins': 'sum', 'supr_basal_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83880>, 'supr_rate': 'sum'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Done processing pid p8_full.csv (213/226) ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29T20:30:31 - Post-ensure_regular_time_intervals_with_aggregation(): \n",
      "\t\t\tPatient 160 \n",
      "\t\t\t - old index length: 67901, \n",
      "\t\t\t - new index length: 66643\n",
      "2025-10-29T20:30:32 - \tRollover basal rate...\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "2025-10-29T20:30:32 - \tCreating COB/IOB and availability columns. This may take a while depending on the size of the data.\n",
      "2025-10-29T20:30:32 - \tCreating COB and carb availability columns...\n",
      "2025-10-29T20:30:32 - \tProcessing glucose dynamics\n",
      "2025-10-29T20:31:19 - \tCreating IOB and insulin availability columns...\n",
      "2025-10-29T20:31:19 - \tProcessing insulin dynamics\n",
      "2025-10-29T20:31:22 - \tDone deriving features.\n",
      "\n",
      "2025-10-29T20:31:22 - Keeping overlapping data for patient 155\n",
      "2025-10-29T20:31:22 - ==============================\n",
      "2025-10-29T20:31:22 - Preprocessing patient 155\n",
      "2025-10-29T20:31:22 - ==============================\n",
      "2025-10-29T20:31:22 - create_physiological_features(): Deriving features...\n",
      "2025-10-29T20:31:22 - \tEnsuring regular time intervals with aggregation...\n",
      "2025-10-29T20:31:22 - ensure_regular_time_intervals_with_aggregation(): Ensuring regular time intervals with aggregation...\n",
      "2025-10-29T20:31:22 - \tMost common time interval: 5 minutes\n",
      "2025-10-29T20:31:22 - \tAggregation strategy: {'p_num': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b80ae0>, 'msg_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83380>, 'bolusType': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83f60>, 'dose_units': 'sum', 'extendedBolus': 'sum', 'bgInput': 'sum', 'food_g': 'sum', 'iob': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83ec0>, 'cr': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b80e00>, 'isf': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83a60>, 'bg_mM': 'mean', 'rate': 'mean', 'basal_duration_mins': 'sum', 'supr_basal_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83880>, 'supr_rate': 'sum'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Done processing pid p160_full.csv (214/226) ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29T20:32:57 - Post-ensure_regular_time_intervals_with_aggregation(): \n",
      "\t\t\tPatient 155 \n",
      "\t\t\t - old index length: 81183, \n",
      "\t\t\t - new index length: 90393\n",
      "2025-10-29T20:32:57 - \tRollover basal rate...\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "/Users/tonychan/GlucoseML/nocturnal-hypo-gly-prob-forecast/src/data/preprocessing/feature_engineering.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i:end_idx][ColumnNames.DOSE_UNITS.value] += dose_per_row\n",
      "2025-10-29T20:32:58 - \tCreating COB/IOB and availability columns. This may take a while depending on the size of the data.\n",
      "2025-10-29T20:32:58 - \tCreating COB and carb availability columns...\n",
      "2025-10-29T20:32:58 - \tProcessing glucose dynamics\n",
      "2025-10-29T20:33:56 - \tCreating IOB and insulin availability columns...\n",
      "2025-10-29T20:33:56 - \tProcessing insulin dynamics\n",
      "2025-10-29T20:34:55 - \tDone deriving features.\n",
      "\n",
      "2025-10-29T20:34:56 - Keeping overlapping data for patient 273\n",
      "2025-10-29T20:34:56 - ==============================\n",
      "2025-10-29T20:34:56 - Preprocessing patient 273\n",
      "2025-10-29T20:34:56 - ==============================\n",
      "2025-10-29T20:34:56 - create_physiological_features(): Deriving features...\n",
      "2025-10-29T20:34:56 - \tEnsuring regular time intervals with aggregation...\n",
      "2025-10-29T20:34:56 - ensure_regular_time_intervals_with_aggregation(): Ensuring regular time intervals with aggregation...\n",
      "2025-10-29T20:34:56 - \tMost common time interval: 5 minutes\n",
      "2025-10-29T20:34:56 - \tAggregation strategy: {'p_num': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b822a0>, 'msg_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b82840>, 'bolusType': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b836a0>, 'dose_units': 'sum', 'extendedBolus': 'sum', 'bgInput': 'sum', 'food_g': 'sum', 'iob': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b82160>, 'cr': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83420>, 'isf': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b83740>, 'bg_mM': 'mean', 'rate': 'mean', 'basal_duration_mins': 'sum', 'supr_basal_type': <function ensure_regular_time_intervals_with_aggregation.<locals>.<lambda> at 0x311b831a0>, 'supr_rate': 'sum'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Done processing pid p155_full.csv (215/226) ----------\n"
     ]
    }
   ],
   "source": [
    "interim_path = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"interim\"\n",
    "processed_path = repo / \"cache\" / \"data\" / \"awesome_cgm\" / \"aleppo\" / \"processed\"\n",
    "\n",
    "process_all_patients(interim_path, processed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0eeee6",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- [x] Figure out why we are missing some patients like p04 - There is no reason\n",
    "- [x] Verify db is created correctly in the right directory\n",
    "- [x] Figure out the columns of the tables and make sure the unit is actually correct. Is CarbInput in g and \"normal\" in units at all?\n",
    "- [ ] Plot a histogram to see if there are significantly less data before the enrollment day.\n",
    "- [ ] Figure out how to handle missing data (Some patients have missing cgm data). - Need to filter out calibaration. That seems to remove some of the large gap\n",
    "- [ ] Union with Basal table too (the rate should be roll to the next few rows. For example, a patient with 5-min interval has a rate of 0.1 units/hour, then we should have a 12 rows of 0.1/12 unit each). Also need to do a addition with whatever bolus is already there. So if a row already has 8 units of insulin, then it will be 8 + 0.1/12 units. Also need to keep rate as 0 if null.\n",
    "- [ ] Take a look at some patients' raw data and see if it makes sense at all first\n",
    "\n",
    "\n",
    "## Loader\n",
    "- [ ] Add a test split for the loader (5% of the entire dataset is enough)\n",
    "- [ ] Verify the `clean_all_patients` is working\n",
    "- [ ] Verify that `data_loader` works at all\n",
    "- [ ] For the loader class, cross check with Kaggle to do a similar data check\n",
    "- [ ] Update `README.md`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aedc9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".noctprob-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
