{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836f3fe2",
   "metadata": {},
   "source": [
    "TiDE (time series dense encoder implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed162e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path('../../.').resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a0f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "import json\n",
    "\n",
    "\n",
    "from src.models.tide.TiDE import TiDEModel\n",
    "from src.data.diabetes_datasets.data_loader import get_loader\n",
    "from src.data.models import ColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6026ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13T18:44:35 - ============================================================\n",
      "2026-01-13T18:44:35 - Beginning data loading process with the following parmeters:\n",
      "2026-01-13T18:44:35 - \tDataset: kaggle_brisT1D - train\n",
      "2026-01-13T18:44:35 - \tColumns: None\n",
      "2026-01-13T18:44:35 - \tGeneric patient start date: 2024-01-01 00:00:00\n",
      "2026-01-13T18:44:35 - \tNumber of validation days: 20\n",
      "2026-01-13T18:44:35 - \tIn parallel with up to 3 workers.\n",
      "\n",
      "2026-01-13T18:44:35 - Processed cache not found or not used, processing raw data and saving to cache...\n",
      "2026-01-13T18:44:35 - Raw data for kaggle_brisT1D already exists in cache\n",
      "2026-01-13T18:44:41 - _process_raw_train_data: Processing train data. This may take a while...\n",
      "2026-01-13T18:44:41 - Processing 9 patients:\n",
      "2026-01-13T18:44:52 - processed_results: Successfully processed patient p01\n",
      "2026-01-13T18:45:11 - processed_results: Successfully processed patient p03\n",
      "2026-01-13T18:45:11 - processed_results: Successfully processed patient p02\n",
      "2026-01-13T18:45:17 - processed_results: Successfully processed patient p04\n",
      "2026-01-13T18:45:19 - processed_results: Successfully processed patient p05\n",
      "2026-01-13T18:45:20 - processed_results: Successfully processed patient p06\n",
      "2026-01-13T18:45:36 - processed_results: Successfully processed patient p12\n",
      "2026-01-13T18:45:37 - processed_results: Successfully processed patient p11\n",
      "2026-01-13T18:45:42 - processed_results: Successfully processed patient p10\n",
      "2026-01-13T18:45:42 - Done processing train data. Saving full processed data to cache...\n",
      "2026-01-13T18:45:42 - Saved full processed data for kaggle_brisT1D - 9 patients\n",
      "2026-01-13T18:45:42 - Successfully processed and cached full data for 9 patients\n",
      "2026-01-13T18:45:42 - Loaded existing train/validation split from cache for 0 patients\n",
      "2026-01-13T18:45:43 - ============================================================\n",
      "2026-01-13T18:45:43 - Beginning data loading process with the following parmeters:\n",
      "2026-01-13T18:45:43 - \tDataset: kaggle_brisT1D - test\n",
      "2026-01-13T18:45:43 - \tColumns: None\n",
      "2026-01-13T18:45:43 - \tGeneric patient start date: 2024-01-01 00:00:00\n",
      "2026-01-13T18:45:43 - \tIn parallel with up to 3 workers.\n",
      "\n",
      "2026-01-13T18:45:43 - Processed cache not found or not used, processing raw data and saving to cache...\n",
      "2026-01-13T18:45:43 - Raw data for kaggle_brisT1D already exists in cache\n",
      "2026-01-13T18:45:43 - Processing test data. This may take a while...\n",
      "2026-01-13T18:46:47 - Processed test data will be cached at: c:\\Users\\kirpa\\WatAI\\nocturnal-hypo-gly-prob-forecast\\cache\\data\\kaggle_brisT1D\\processed\\test\n",
      "2026-01-13T18:46:47 - Processing test data in parallel with up to 3 workers...\n",
      "2026-01-13T18:48:24 - Successfully processed and cached test data for 15 patients\n",
      "2026-01-13T18:48:26 - Saved nested test data to: c:\\Users\\kirpa\\WatAI\\nocturnal-hypo-gly-prob-forecast\\cache\\data\\kaggle_brisT1D\\processed\\test\\nested_test_data.pkl.gz\n",
      "2026-01-13T18:48:26 - Skipping train/validation split for test data or invalid processed data type. \n",
      "Dataset: test\n",
      "Processed data type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Load data using the data loader\n",
    "train_loader = get_loader(\n",
    "    data_source_name=\"kaggle_brisT1D\", dataset_type=\"train\", use_cached=False\n",
    ")\n",
    "test_loader = get_loader(\n",
    "    data_source_name=\"kaggle_brisT1D\", dataset_type=\"test\", use_cached=False\n",
    ")\n",
    "\n",
    "train_data = train_loader.train_data\n",
    "test_data = test_loader.test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "72b8d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TiDEWindowedDataset(Dataset):\n",
    "    \"\"\"Dataset for TiDE model with proper windowing for time series prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, data_loader_instance, lookback_steps=480, horizon_steps=120, \n",
    "                 dataset_type='train', stride=60):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_loader_instance: Instance of BrisT1DDataLoader\n",
    "            lookback_steps: Number of timesteps for lookback (480 = 8 hours if 1 min resolution)\n",
    "            horizon_steps: Number of timesteps for prediction (120 = 2 hours)\n",
    "            dataset_type: 'train', 'validation', or 'test'\n",
    "            stride: Step size for sliding window (60 = 1 hour)\n",
    "        \"\"\"\n",
    "        self.lookback = lookback_steps\n",
    "        self.horizon = horizon_steps\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Get the appropriate data\n",
    "        if dataset_type == 'train' and data_loader_instance.train_data:\n",
    "            self.data_dict = data_loader_instance.train_data\n",
    "        elif dataset_type == 'validation' and data_loader_instance.validation_data:\n",
    "            self.data_dict = data_loader_instance.validation_data\n",
    "        else:\n",
    "            self.data_dict = data_loader_instance.processed_data\n",
    "        \n",
    "        # Priority features for glucose prediction\n",
    "        self.feature_cols = ['bg_mM', 'food_g', 'dose_units', 'iob', 'cob']\n",
    "        self.target_col = 'bg_mM'  # What we're predicting\n",
    "        \n",
    "        # Validate columns exist\n",
    "        first_value = next(iter(self.data_dict.values()))\n",
    "        \n",
    "        # Handle nested dict structure (get first DataFrame from nested dict)\n",
    "        if isinstance(first_value, dict):\n",
    "            first_df = next(iter(first_value.values()))\n",
    "        else:\n",
    "            first_df = first_value\n",
    "        \n",
    "        self.feature_cols = [col for col in self.feature_cols if col in first_df.columns]\n",
    "        \n",
    "        # Prepare valid windows\n",
    "        self.windows = []\n",
    "        self.prepare_windows()\n",
    "        \n",
    "        print(f\"Created TiDE dataset:\")\n",
    "        print(f\"  - Lookback: {lookback_steps} steps\")\n",
    "        print(f\"  - Horizon: {horizon_steps} steps\")\n",
    "        print(f\"  - Features: {self.feature_cols}\")\n",
    "        print(f\"  - Total windows: {len(self.windows)}\")\n",
    "    \n",
    "    def prepare_windows(self):\n",
    "        \"\"\"Prepare all valid windows from all patients, handling nested dict structures\"\"\"\n",
    "        for patient_id, patient_data in self.data_dict.items():\n",
    "            # Handle nested dictionary structure (e.g., test data: {patient_id: {session_id: df}})\n",
    "            if isinstance(patient_data, dict):\n",
    "                for session_id, patient_df in patient_data.items():\n",
    "                    self._process_patient_df(patient_df, f\"{patient_id}_{session_id}\")\n",
    "            # Handle flat dictionary structure (e.g., train data: {patient_id: df})\n",
    "            elif isinstance(patient_data, pd.DataFrame):\n",
    "                self._process_patient_df(patient_data, patient_id)\n",
    "\n",
    "    def _process_patient_df(self, patient_df, patient_key):\n",
    "        \"\"\"Process a single patient dataframe and create windows\"\"\"\n",
    "        n_samples = len(patient_df)\n",
    "        min_length = self.lookback + self.horizon\n",
    "        if n_samples >= min_length:\n",
    "            windows_count = 0\n",
    "            for i in range(self.lookback, n_samples - self.horizon + 1, self.stride):\n",
    "                self.windows.append((patient_key, i))\n",
    "                windows_count += 1\n",
    "            if windows_count > 0:\n",
    "                print(f\"  Patient {patient_key}: {len(patient_df)} samples -> {windows_count} windows\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patient_id, end_lookback_idx = self.windows[idx]\n",
    "        patient_df = self.data_dict[patient_id]\n",
    "        \n",
    "        # Get lookback window (input sequence)\n",
    "        lookback_start = end_lookback_idx - self.lookback\n",
    "        lookback_data = patient_df.iloc[lookback_start:end_lookback_idx]\n",
    "        \n",
    "        # Get prediction horizon (target sequence)\n",
    "        horizon_data = patient_df.iloc[end_lookback_idx:end_lookback_idx + self.horizon]\n",
    "        \n",
    "        # Extract features\n",
    "        seq_x = lookback_data[self.feature_cols].values.astype(np.float32)\n",
    "        \n",
    "        # For target, typically just predict glucose (bg_mM)\n",
    "        # You can modify this based on what TiDE expects\n",
    "        seq_y = horizon_data[[self.target_col]].values.astype(np.float32)\n",
    "        \n",
    "        # Handle NaN values\n",
    "        seq_x = np.nan_to_num(seq_x, nan=0.0)\n",
    "        seq_y = np.nan_to_num(seq_y, nan=0.0)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "        seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "        \n",
    "        # Time features (can be enhanced with hour of day, day of week, etc.)\n",
    "        seq_x_mark = torch.arange(self.lookback, dtype=torch.float32).reshape(-1, 1)\n",
    "        seq_y_mark = torch.arange(self.horizon, dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "04acb4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient p01: 8711 samples -> 136 windows\n",
      "  Patient p03: 26423 samples -> 431 windows\n",
      "  Patient p02: 26423 samples -> 431 windows\n",
      "  Patient p04: 24983 samples -> 407 windows\n",
      "  Patient p05: 8808 samples -> 137 windows\n",
      "  Patient p06: 8791 samples -> 137 windows\n",
      "  Patient p12: 26371 samples -> 430 windows\n",
      "  Patient p11: 25559 samples -> 416 windows\n",
      "  Patient p10: 25803 samples -> 421 windows\n",
      "Created TiDE dataset:\n",
      "  - Lookback: 480 steps\n",
      "  - Horizon: 120 steps\n",
      "  - Features: ['bg_mM', 'food_g', 'dose_units', 'iob', 'cob']\n",
      "  - Total windows: 2946\n",
      "  Patient p01: 8711 samples -> 136 windows\n",
      "  Patient p03: 26423 samples -> 431 windows\n",
      "  Patient p02: 26423 samples -> 431 windows\n",
      "  Patient p04: 24983 samples -> 407 windows\n",
      "  Patient p05: 8808 samples -> 137 windows\n",
      "  Patient p06: 8791 samples -> 137 windows\n",
      "  Patient p12: 26371 samples -> 430 windows\n",
      "  Patient p11: 25559 samples -> 416 windows\n",
      "  Patient p10: 25803 samples -> 421 windows\n",
      "Created TiDE dataset:\n",
      "  - Lookback: 480 steps\n",
      "  - Horizon: 120 steps\n",
      "  - Features: ['bg_mM', 'food_g', 'dose_units', 'iob', 'cob']\n",
      "  - Total windows: 2946\n"
     ]
    }
   ],
   "source": [
    "train_data = TiDEWindowedDataset(train_loader, dataset_type='train')\n",
    "val_data = TiDEWindowedDataset(train_loader, dataset_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5d1c3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, targets):\n",
    "    \"\"\"Compute RMSE, MAE, MAPE for forecast evaluation.\"\"\"\n",
    "    y_pred = np.asarray(predictions).flatten()\n",
    "    y_true = np.asarray(targets).flatten()\n",
    "    \n",
    "    # Filter out near-zero targets to avoid MAPE explosion\n",
    "    mask = np.abs(y_true) > 0.1  # Only use targets > 0.1 mmol/L\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    y_true_filtered = y_true[mask]\n",
    "    \n",
    "    if len(y_true_filtered) == 0:\n",
    "        mape = np.nan\n",
    "    else:\n",
    "        mape = float(np.mean(np.abs((y_pred_filtered - y_true_filtered) / y_true_filtered)) * 100)\n",
    "    \n",
    "    return {\n",
    "        \"rmse\": float(root_mean_squared_error(y_true, y_pred)),\n",
    "        \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"mape\": mape,\n",
    "        \"samples_used\": len(y_true_filtered),\n",
    "        \"samples_filtered\": len(y_true) - len(y_true_filtered)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9b476acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.tide.parse_args import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "31d6fd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch shapes:\n",
      "  seq_x (features):     torch.Size([32, 480, 5])\n",
      "  seq_y (target):       torch.Size([32, 120, 1])\n",
      "  seq_x_mark (time):    torch.Size([32, 480, 1])\n",
      "  seq_y_mark (time):    torch.Size([32, 120, 1])\n",
      "  lookback: (120, 1)\n",
      "  attr: (480, 5)\n",
      "  dynCov: (120, 1)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "    \n",
    "for seq_x, seq_y, seq_x_mark, seq_y_mark in train_dataloader:\n",
    "    print(\"Sample batch shapes:\")\n",
    "    print(f\"  seq_x (features):     {seq_x.shape}\")\n",
    "    print(f\"  seq_y (target):       {seq_y.shape}\")\n",
    "    print(f\"  seq_x_mark (time):    {seq_x_mark.shape}\")\n",
    "    print(f\"  seq_y_mark (time):    {seq_y_mark.shape}\")\n",
    "\n",
    "    sizes = {\n",
    "    'lookback': (seq_y.shape[1], seq_y.shape[2]),\n",
    "    'attr': (seq_x.shape[1], seq_x.shape[2]),\n",
    "    'dynCov': (seq_y_mark.shape[1], seq_y_mark.shape[2])\n",
    "}\n",
    "    print(f\"  lookback: {sizes['lookback']}\")\n",
    "    print(f\"  attr: {sizes['attr']}\")\n",
    "    print(f\"  dynCov: {sizes['dynCov']}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = 'bg_mM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e7759652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "{\n",
      "  \"target\": \"bg_mM\",\n",
      "  \"seq_len\": 72,\n",
      "  \"lookback_len\": 72,\n",
      "  \"pred_len\": 12,\n",
      "  \"feat_size\": 4,\n",
      "  \"hidden_size\": 128,\n",
      "  \"num_encoder_layers\": 2,\n",
      "  \"num_decoder_layers\": 2,\n",
      "  \"decoder_output_dim\": 8,\n",
      "  \"temporal_decoder_hidden\": 64,\n",
      "  \"drop_prob\": 0.3,\n",
      "  \"batch_size\": 32,\n",
      "  \"epochs\": 50,\n",
      "  \"lr\": 0.0001,\n",
      "  \"patience\": 10,\n",
      "  \"train_ratio\": 0.7,\n",
      "  \"val_ratio\": 0.15,\n",
      "  \"test_ratio\": 0.15,\n",
      "  \"use_cuda\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for TiDE model and training.\"\"\"\n",
    "\n",
    "    # Data parameters\n",
    "    target: str = TARGET_COL  # Blood glucose in mmol/L\n",
    "\n",
    "    # Sequence parameters (in 5-minute intervals)\n",
    "    # Lookback: 6 hours = 72 intervals of 5 minutes\n",
    "    # Prediction: 1 hour = 12 intervals of 5 minutes\n",
    "    seq_len: int = 72        # Input sequence length (6 hours)\n",
    "    lookback_len: int = 72   # Lookback length for decoder\n",
    "    pred_len: int = 12       # Prediction horizon (1 hour)\n",
    "\n",
    "    # Model parameters\n",
    "    feat_size: int = 4           # Feature projection size\n",
    "    hidden_size: int = 128       # Hidden layer size\n",
    "    num_encoder_layers: int = 2  # Number of encoder layers\n",
    "    num_decoder_layers: int = 2  # Number of decoder layers\n",
    "    decoder_output_dim: int = 8  # Decoder output dimension per timestep\n",
    "    temporal_decoder_hidden: int = 64  # Temporal decoder hidden size\n",
    "    drop_prob: float = 0.3       # Dropout probability\n",
    "\n",
    "    # Training parameters\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 50\n",
    "    lr: float = 1e-4\n",
    "    patience: int = 10  # Early stopping patience\n",
    "\n",
    "    # Data split\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.15\n",
    "    test_ratio: float = 0.15\n",
    "\n",
    "    # Device\n",
    "    use_cuda: bool = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps({k: v for k, v in self.__class__.__dict__.items()\n",
    "                          if not k.startswith('_')}, indent=2, default=str)\n",
    "\n",
    "config = Config()\n",
    "print(\"Configuration:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "36aa9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TiDEModel(\n",
      "  (featproj): ResidualBlock(\n",
      "    (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (shortcut): Linear(in_features=1, out_features=4, bias=True)\n",
      "  )\n",
      "  (encoder): TiDEEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResidualBlock(\n",
      "        (fc1): Linear(in_features=2952, out_features=128, bias=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (shortcut): Linear(in_features=2952, out_features=128, bias=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (shortcut): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (denseDecoder): TiDEDenseDecoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResidualBlock(\n",
      "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (fc2): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (shortcut): Linear(in_features=128, out_features=96, bias=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (fc1): Linear(in_features=96, out_features=128, bias=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (fc2): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (shortcut): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (temporalDecoder): TiDETemporalDecoder(\n",
      "    (residual): ResidualBlock(\n",
      "      (fc1): Linear(in_features=12, out_features=64, bias=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
      "      (shortcut): Linear(in_features=12, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=72, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TiDEModel(sizes, config)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b3036cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8488babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device, epoch):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    train_mse_loss = 0.\n",
    "    train_mae_loss = 0.\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "\n",
    "    for seq_x, seq_y, seq_x_mark, seq_y_mark in train_loader:\n",
    "        seq_x = seq_x.float().to(device)\n",
    "        seq_y = seq_y.float().to(device)\n",
    "        seq_x_mark = seq_x_mark.float().to(device)\n",
    "        seq_y_mark = seq_y_mark.float().to(device)\n",
    "\n",
    "        # Keep seq_y as 3D: [batch, seq_len, features]\n",
    "        # Do NOT squeeze the last dimension\n",
    "        \n",
    "        # Update model batch size for variable batch sizes\n",
    "        current_batch_size = seq_x.shape[0]\n",
    "        model.batch_size = current_batch_size\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred, ans = model(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "\n",
    "        loss = criterion(pred, ans)\n",
    "        mae_loss = torch.mean(torch.abs(pred - ans))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_mse_loss += loss.item()\n",
    "        train_mae_loss += mae_loss.item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'MSE': f'{loss.item():.4f}',\n",
    "            'MAE': f'{mae_loss.item():.4f}'\n",
    "        })\n",
    "\n",
    "    avg_mse = train_mse_loss / len(train_loader)\n",
    "    avg_mae = train_mae_loss / len(train_loader)\n",
    "\n",
    "    return avg_mse, avg_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5bfea668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    val_mse_loss = 0.\n",
    "    val_mae_loss = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq_x, seq_y, seq_x_mark, seq_y_mark in val_loader:\n",
    "            seq_x = seq_x.float().to(device)\n",
    "            seq_y = seq_y.float().to(device)\n",
    "            seq_x_mark = seq_x_mark.float().to(device)\n",
    "            seq_y_mark = seq_y_mark.float().to(device)\n",
    "\n",
    "            # Keep seq_y as 3D: [batch, seq_len, features]\n",
    "            \n",
    "            # Update model batch size for variable batch sizes\n",
    "            current_batch_size = seq_x.shape[0]\n",
    "            model.batch_size = current_batch_size\n",
    "\n",
    "            pred, ans = model(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "\n",
    "            loss = criterion(pred, ans)\n",
    "            mae_loss = torch.mean(torch.abs(pred - ans))\n",
    "\n",
    "            val_mse_loss += loss.item()\n",
    "            val_mae_loss += mae_loss.item()\n",
    "\n",
    "    val_mse_loss /= len(val_loader)\n",
    "    val_mae_loss /= len(val_loader)\n",
    "\n",
    "    model.train()\n",
    "    return val_mse_loss, val_mae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3a03d2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, config, device):\n",
    "    \"\"\"Train the TiDE model.\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_mse': [],\n",
    "        'train_mae': [],\n",
    "        'val_mse': [],\n",
    "        'val_mae': []\n",
    "    }\n",
    "\n",
    "    print(f\"\\nStarting training for {config.epochs} epochs...\")\n",
    "    print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
    "    print(f\"Batch size: {config.batch_size}\")\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        # Train\n",
    "        train_mse, train_mae = train_epoch(\n",
    "            model, train_loader, optimizer, criterion, device, epoch\n",
    "        )\n",
    "\n",
    "        # Validate\n",
    "        ## val_mse, val_mae = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        # Log\n",
    "        history['epoch'].append(epoch)\n",
    "        history['train_mse'].append(train_mse)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        # history['val_mse'].append(val_mse)\n",
    "        # history['val_mae'].append(val_mae)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}/{config.epochs}:\")\n",
    "        print(f\"  Train - MSE: {train_mse:.4f}, MAE: {train_mae:.4f}\")\n",
    "        ## print(f\"  Val   - MSE: {val_mse:.4f}, MAE: {val_mae:.4f}\")\n",
    "\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "    history['training_time'] = [total_time]\n",
    "\n",
    "    return history\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "013978a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 50 epochs...\n",
      "Training samples: 2946\n",
      "Validation samples: 2946\n",
      "Batch size: 32\n",
      "Device: cpu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1:   0%|          | 0/93 [00:05<?, ?it/s, MSE=8.3819, MAE=2.2106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50:\n",
      "  Train - MSE: 14.8361, MAE: 2.8379\n",
      "  Val   - MSE: 14.1437, MAE: 2.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1:   0%|          | 0/93 [05:22<?, ?it/s, MSE=31.3040, MAE=4.3877]\n",
      "Epoch 1:   0%|          | 0/93 [03:54<?, ?it/s, MSE=14.4192, MAE=3.0552]\n",
      "Epoch 1:   0%|          | 0/93 [02:42<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/93 [02:38<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/93 [01:28<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2:   0%|          | 0/93 [00:05<?, ?it/s, MSE=0.3229, MAE=0.4420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50:\n",
      "  Train - MSE: 14.0459, MAE: 2.7399\n",
      "  Val   - MSE: 13.9285, MAE: 2.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/93 [00:06<?, ?it/s, MSE=28.6542, MAE=5.3045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50:\n",
      "  Train - MSE: 14.1424, MAE: 2.7710\n",
      "  Val   - MSE: 13.7762, MAE: 2.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/93 [00:07<?, ?it/s, MSE=16.6694, MAE=3.6438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50:\n",
      "  Train - MSE: 13.8554, MAE: 2.7344\n",
      "  Val   - MSE: 13.6250, MAE: 2.7060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/93 [00:06<?, ?it/s, MSE=15.6150, MAE=2.9119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50:\n",
      "  Train - MSE: 13.7376, MAE: 2.7231\n",
      "  Val   - MSE: 13.5015, MAE: 2.6913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/93 [00:06<?, ?it/s, MSE=1.7350, MAE=1.0692] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50:\n",
      "  Train - MSE: 13.4870, MAE: 2.6916\n",
      "  Val   - MSE: 13.4089, MAE: 2.6771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/93 [00:07<?, ?it/s, MSE=2.6831, MAE=1.4259] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50:\n",
      "  Train - MSE: 13.4192, MAE: 2.6842\n",
      "  Val   - MSE: 13.3292, MAE: 2.6716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/93 [00:07<?, ?it/s, MSE=1.6050, MAE=1.0751] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50:\n",
      "  Train - MSE: 13.3127, MAE: 2.6691\n",
      "  Val   - MSE: 13.2561, MAE: 2.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/93 [00:07<?, ?it/s, MSE=4.8937, MAE=1.7493] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50:\n",
      "  Train - MSE: 13.2762, MAE: 2.6711\n",
      "  Val   - MSE: 13.1993, MAE: 2.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:   0%|          | 0/93 [00:07<?, ?it/s, MSE=1.8350, MAE=1.0898] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50:\n",
      "  Train - MSE: 13.2136, MAE: 2.6614\n",
      "  Val   - MSE: 13.1453, MAE: 2.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%|          | 0/93 [00:07<?, ?it/s, MSE=7.4498, MAE=2.3197] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/50:\n",
      "  Train - MSE: 13.2092, MAE: 2.6671\n",
      "  Val   - MSE: 13.1023, MAE: 2.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 0/93 [00:05<?, ?it/s, MSE=8.6962, MAE=2.4079] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/50:\n",
      "  Train - MSE: 13.1587, MAE: 2.6646\n",
      "  Val   - MSE: 13.0960, MAE: 2.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:   0%|          | 0/93 [00:05<?, ?it/s, MSE=2.6586, MAE=1.5200] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/50:\n",
      "  Train - MSE: 13.0818, MAE: 2.6483\n",
      "  Val   - MSE: 13.0140, MAE: 2.6403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 0/93 [00:07<?, ?it/s, MSE=5.2861, MAE=1.8738] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50:\n",
      "  Train - MSE: 13.0424, MAE: 2.6488\n",
      "  Val   - MSE: 12.9999, MAE: 2.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:   0%|          | 0/93 [00:05<?, ?it/s, MSE=2.9298, MAE=1.3931] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/50:\n",
      "  Train - MSE: 12.9934, MAE: 2.6361\n",
      "  Val   - MSE: 12.9480, MAE: 2.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:   0%|          | 0/93 [00:05<?, ?it/s, MSE=5.6256, MAE=2.1026] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/50:\n",
      "  Train - MSE: 12.9894, MAE: 2.6447\n",
      "  Val   - MSE: 12.9131, MAE: 2.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:   0%|          | 0/93 [00:05<?, ?it/s, MSE=6.8566, MAE=2.3971] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/50:\n",
      "  Train - MSE: 12.9801, MAE: 2.6423\n",
      "  Val   - MSE: 12.9259, MAE: 2.6196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:   0%|          | 0/93 [00:06<?, ?it/s, MSE=25.0449, MAE=3.4939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/50:\n",
      "  Train - MSE: 13.1586, MAE: 2.6558\n",
      "  Val   - MSE: 12.8736, MAE: 2.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:   0%|          | 0/93 [00:07<?, ?it/s, MSE=3.7285, MAE=1.6364] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/50:\n",
      "  Train - MSE: 12.9176, MAE: 2.6347\n",
      "  Val   - MSE: 12.8305, MAE: 2.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:   0%|          | 0/93 [00:06<?, ?it/s, MSE=2.2627, MAE=1.3823] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/50:\n",
      "  Train - MSE: 12.8437, MAE: 2.6229\n",
      "  Val   - MSE: 12.8171, MAE: 2.6242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21:   0%|          | 0/93 [00:07<?, ?it/s, MSE=5.2966, MAE=1.9147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/50:\n",
      "  Train - MSE: 12.8572, MAE: 2.6284\n",
      "  Val   - MSE: 12.7804, MAE: 2.6120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22:   0%|          | 0/93 [00:07<?, ?it/s, MSE=6.4643, MAE=2.2542] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/50:\n",
      "  Train - MSE: 12.8487, MAE: 2.6269\n",
      "  Val   - MSE: 12.8271, MAE: 2.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23:   0%|          | 0/93 [00:06<?, ?it/s, MSE=8.7689, MAE=2.3330] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/50:\n",
      "  Train - MSE: 12.8571, MAE: 2.6250\n",
      "  Val   - MSE: 12.7436, MAE: 2.6057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24:   0%|          | 0/93 [00:05<?, ?it/s, MSE=1.8627, MAE=1.2596] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/50:\n",
      "  Train - MSE: 12.7639, MAE: 2.6145\n",
      "  Val   - MSE: 12.7182, MAE: 2.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25:   0%|          | 0/93 [00:07<?, ?it/s, MSE=14.3770, MAE=3.1154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/50:\n",
      "  Train - MSE: 12.8635, MAE: 2.6308\n",
      "  Val   - MSE: 12.7225, MAE: 2.6163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26:   0%|          | 0/93 [00:07<?, ?it/s, MSE=22.2712, MAE=4.2900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/50:\n",
      "  Train - MSE: 12.9387, MAE: 2.6452\n",
      "  Val   - MSE: 12.6846, MAE: 2.6003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27:   0%|          | 0/93 [00:07<?, ?it/s, MSE=2.0465, MAE=1.3409] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/50:\n",
      "  Train - MSE: 12.7210, MAE: 2.6046\n",
      "  Val   - MSE: 12.6800, MAE: 2.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28:   0%|          | 0/93 [00:07<?, ?it/s, MSE=5.2261, MAE=2.0224] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/50:\n",
      "  Train - MSE: 12.7280, MAE: 2.6171\n",
      "  Val   - MSE: 12.6475, MAE: 2.5980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29:   0%|          | 0/93 [00:06<?, ?it/s, MSE=13.7585, MAE=3.0582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/50:\n",
      "  Train - MSE: 12.7884, MAE: 2.6249\n",
      "  Val   - MSE: 12.6571, MAE: 2.5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30:   0%|          | 0/93 [00:06<?, ?it/s, MSE=9.5454, MAE=2.6553] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/50:\n",
      "  Train - MSE: 12.7439, MAE: 2.6195\n",
      "  Val   - MSE: 12.6183, MAE: 2.5957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31:   0%|          | 0/93 [00:06<?, ?it/s, MSE=7.3228, MAE=2.5103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/50:\n",
      "  Train - MSE: 12.6891, MAE: 2.6141\n",
      "  Val   - MSE: 12.6064, MAE: 2.6002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32:   0%|          | 0/93 [00:06<?, ?it/s, MSE=52.6112, MAE=6.2344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/50:\n",
      "  Train - MSE: 13.1294, MAE: 2.6501\n",
      "  Val   - MSE: 12.5901, MAE: 2.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33:   0%|          | 0/93 [00:07<?, ?it/s, MSE=1.6962, MAE=0.9512] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/50:\n",
      "  Train - MSE: 12.5966, MAE: 2.5998\n",
      "  Val   - MSE: 12.5848, MAE: 2.5861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34:   0%|          | 0/93 [00:05<?, ?it/s, MSE=3.2149, MAE=1.4439] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/50:\n",
      "  Train - MSE: 12.6012, MAE: 2.5981\n",
      "  Val   - MSE: 12.5570, MAE: 2.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35:   0%|          | 0/93 [00:06<?, ?it/s, MSE=7.4949, MAE=2.0250] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/50:\n",
      "  Train - MSE: 12.6367, MAE: 2.6038\n",
      "  Val   - MSE: 12.5528, MAE: 2.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36:   0%|          | 0/93 [00:07<?, ?it/s, MSE=4.8052, MAE=1.9413] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/50:\n",
      "  Train - MSE: 12.6004, MAE: 2.6004\n",
      "  Val   - MSE: 12.5261, MAE: 2.5884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37:   0%|          | 0/93 [00:08<?, ?it/s, MSE=24.8009, MAE=4.6559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/50:\n",
      "  Train - MSE: 12.7795, MAE: 2.6272\n",
      "  Val   - MSE: 12.5140, MAE: 2.5830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38:   0%|          | 0/93 [00:08<?, ?it/s, MSE=0.8689, MAE=0.6887] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/50:\n",
      "  Train - MSE: 12.5188, MAE: 2.5804\n",
      "  Val   - MSE: 12.5226, MAE: 2.5954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39:   0%|          | 0/93 [00:07<?, ?it/s, MSE=5.1112, MAE=1.3792] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/50:\n",
      "  Train - MSE: 12.5586, MAE: 2.5963\n",
      "  Val   - MSE: 12.5127, MAE: 2.5764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40:   0%|          | 0/93 [00:05<?, ?it/s, MSE=2.1652, MAE=1.2620] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/50:\n",
      "  Train - MSE: 12.5423, MAE: 2.5877\n",
      "  Val   - MSE: 12.4808, MAE: 2.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41:   0%|          | 0/93 [00:07<?, ?it/s, MSE=12.6981, MAE=2.6375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/50:\n",
      "  Train - MSE: 12.6085, MAE: 2.5984\n",
      "  Val   - MSE: 12.4678, MAE: 2.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42:   0%|          | 0/93 [00:07<?, ?it/s, MSE=4.0814, MAE=1.4443] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/50:\n",
      "  Train - MSE: 12.5032, MAE: 2.5899\n",
      "  Val   - MSE: 12.4620, MAE: 2.5740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43:   0%|          | 0/93 [00:07<?, ?it/s, MSE=90.1585, MAE=7.0115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/50:\n",
      "  Train - MSE: 13.3537, MAE: 2.6400\n",
      "  Val   - MSE: 12.4593, MAE: 2.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44:   0%|          | 0/93 [00:06<?, ?it/s, MSE=1.4648, MAE=1.0877] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/50:\n",
      "  Train - MSE: 12.4707, MAE: 2.5874\n",
      "  Val   - MSE: 12.4276, MAE: 2.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45:   0%|          | 0/93 [00:06<?, ?it/s, MSE=14.6526, MAE=2.7566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/50:\n",
      "  Train - MSE: 12.5593, MAE: 2.5985\n",
      "  Val   - MSE: 12.4873, MAE: 2.5696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46:   0%|          | 0/93 [00:07<?, ?it/s, MSE=6.8046, MAE=2.1721] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/50:\n",
      "  Train - MSE: 12.4906, MAE: 2.5905\n",
      "  Val   - MSE: 12.4159, MAE: 2.5684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47:   0%|          | 0/93 [00:07<?, ?it/s, MSE=3.5240, MAE=1.2286] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/50:\n",
      "  Train - MSE: 12.4523, MAE: 2.5764\n",
      "  Val   - MSE: 12.3994, MAE: 2.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48:   0%|          | 0/93 [00:07<?, ?it/s, MSE=4.5747, MAE=1.5011] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/50:\n",
      "  Train - MSE: 12.4484, MAE: 2.5829\n",
      "  Val   - MSE: 12.3781, MAE: 2.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49:   0%|          | 0/93 [00:07<?, ?it/s, MSE=0.8932, MAE=0.8153] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/50:\n",
      "  Train - MSE: 12.3926, MAE: 2.5735\n",
      "  Val   - MSE: 12.3738, MAE: 2.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50:   0%|          | 0/93 [00:07<?, ?it/s, MSE=9.1597, MAE=2.0403] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/50:\n",
      "  Train - MSE: 12.4590, MAE: 2.5820\n",
      "  Val   - MSE: 12.3570, MAE: 2.5674\n",
      "\n",
      "Training completed in 344.61 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, train_dataloader, val_dataloader, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "900c435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, scaler=None):\n",
    "    \"\"\"Evaluate the model on test set.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq_x, seq_y, seq_x_mark, seq_y_mark in tqdm(test_loader, desc='Evaluating'):\n",
    "            seq_x = seq_x.float().to(device)\n",
    "            seq_y = seq_y.float().to(device)\n",
    "            seq_x_mark = seq_x_mark.float().to(device)\n",
    "            seq_y_mark = seq_y_mark.float().to(device)\n",
    "\n",
    "            # Update model batch size for variable batch sizes\n",
    "            current_batch_size = seq_x.shape[0]\n",
    "            model.batch_size = current_batch_size\n",
    "\n",
    "            pred, ans = model(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_targets.append(ans.cpu().numpy())\n",
    "\n",
    "    # Handle empty predictions\n",
    "    if len(all_preds) == 0:\n",
    "        print(\"No predictions made - test dataset may be empty\")\n",
    "        return None\n",
    "\n",
    "    # Concatenate all batches\n",
    "    preds = np.concatenate(all_preds, axis=0)\n",
    "    targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Inverse transform if scaler provided\n",
    "    if scaler is not None:\n",
    "        preds_flat = preds.reshape(-1, 1)\n",
    "        targets_flat = targets.reshape(-1, 1)\n",
    "\n",
    "        preds_flat = scaler.inverse_transform(preds_flat)\n",
    "        targets_flat = scaler.inverse_transform(targets_flat)\n",
    "\n",
    "        preds = preds_flat.reshape(preds.shape)\n",
    "        targets = targets_flat.reshape(targets.shape)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(preds.flatten(), targets.flatten())\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Test Set Evaluation Results\")\n",
    "    print(\"=\"*50)\n",
    "    for metric_name, value in metrics.items():\n",
    "        if metric_name == 'MAPE':\n",
    "            print(f\"{metric_name}: {value:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'predictions': preds,\n",
    "        'targets': targets,\n",
    "        'metrics': metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "99b563af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/93 [20:21<?, ?it/s] 49.50it/s]\n",
      "Evaluating: 100%|| 93/93 [00:02<00:00, 42.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Test Set Evaluation Results\n",
      "==================================================\n",
      "rmse: 3.5316\n",
      "mae: 2.5846\n",
      "mape: 29.9998\n",
      "samples_used: 33967.0000\n",
      "samples_filtered: 1385.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(\n",
    "    model,\n",
    "    val_dataloader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8288f24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     plt.tight_layout()\n\u001b[32m     32\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m plot_predictions(\u001b[43mresults\u001b[49m, num_samples=\u001b[32m5\u001b[39m, pred_horizon=config.pred_len)\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_predictions(results, num_samples=5, pred_horizon=12):\n",
    "    \"\"\"Plot sample predictions vs ground truth.\"\"\"\n",
    "    preds = results['predictions']\n",
    "    targets = results['targets']\n",
    "\n",
    "    # Select random samples\n",
    "    indices = np.random.choice(len(preds), min(num_samples, len(preds)), replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(12, 3*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    time_steps = np.arange(pred_horizon) * 5  # Convert to minutes\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        pred = preds[idx].flatten()\n",
    "        target = targets[idx].flatten()\n",
    "\n",
    "        axes[i].plot(time_steps, target, 'b-o', label='Actual BG', markersize=4)\n",
    "        axes[i].plot(time_steps, pred, 'r--s', label='Predicted BG', markersize=4)\n",
    "        axes[i].set_xlabel('Minutes ahead')\n",
    "        axes[i].set_ylabel('Blood Glucose (mmol/L)')\n",
    "        axes[i].set_title(f'Sample {idx}: Blood Glucose Prediction')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "        # Add reference lines for hypo/hyper glycemia\n",
    "        axes[i].axhline(y=3.9, color='orange', linestyle=':', alpha=0.7)\n",
    "        axes[i].axhline(y=10.0, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(results, num_samples=5, pred_horizon=config.pred_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".noctprob-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
