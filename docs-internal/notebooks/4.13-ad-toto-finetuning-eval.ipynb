{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toto Fine-Tuning Evaluation\n",
    "\n",
    "Compare zero-shot vs fine-tuned Toto model performance on nocturnal blood glucose forecasting.\n",
    "\n",
    "**Task**: Predict 6 hours of nocturnal blood glucose (72 timesteps at 5-min intervals)\n",
    "**Context**: 42 hours of historical data (504 timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "from toto.model.toto import Toto\n",
    "from toto.data.util.dataset import MaskedTimeseries\n",
    "from toto.inference.forecaster import TotoForecaster\n",
    "\n",
    "from src.models.toto import TotoForecaster as TotoTSFM\n",
    "from src.models.toto.config import TotoConfig\n",
    "from src.data.diabetes_datasets.data_loader import get_loader\n",
    "from src.data.models import ColumnNames\n",
    "from src.utils.time_series_helper import get_interval_minutes\n",
    "from src.data.preprocessing.time_processing import iter_daily_context_forecast_splits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting configuration\n",
    "INTERVAL_MINS = 5\n",
    "CONTEXT_LENGTH = 504  # 42 hours (matches training)\n",
    "FORECAST_LENGTH = 72  # 6 hours nocturnal\n",
    "TARGET_COL = ColumnNames.BG.value\n",
    "\n",
    "# Model paths\n",
    "notebook_dir = Path.cwd()\n",
    "repo_root = (\n",
    "    notebook_dir.parent.parent if \"notebooks\" in str(notebook_dir) else notebook_dir\n",
    ")\n",
    "\n",
    "# UPDATE THIS to your training run directory\n",
    "# Format: {timestamp}_JID{job_id}_toto\n",
    "MODEL_DIR = repo_root / \"trained_models/artifacts/_tsfm_testing/2026-01-14_22:39_JID1393095_toto\"\n",
    "\n",
    "print(\n",
    "    f\"Context: {CONTEXT_LENGTH} steps ({CONTEXT_LENGTH * INTERVAL_MINS / 60:.1f} hours)\"\n",
    ")\n",
    "print(\n",
    "    f\"Forecast: {FORECAST_LENGTH} steps ({FORECAST_LENGTH * INTERVAL_MINS / 60:.1f} hours)\"\n",
    ")\n",
    "print(f\"Model dir: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load zero-shot model\n",
    "print(\"Loading zero-shot Toto model...\")\n",
    "toto_zs = Toto.from_pretrained(\"Datadog/Toto-Open-Base-1.0\")\n",
    "toto_zs.to(device)\n",
    "toto_zs.eval()\n",
    "forecaster_zs = TotoForecaster(toto_zs.model)\n",
    "print(\"âœ“ Zero-shot model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned model using load_model with explicit config\n",
    "print(f\"Loading fine-tuned model from: {MODEL_DIR}\")\n",
    "\n",
    "if not MODEL_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Model not found at {MODEL_DIR}\")\n",
    "\n",
    "# Create config matching training settings\n",
    "config = TotoConfig(\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    forecast_length=FORECAST_LENGTH,\n",
    ")\n",
    "\n",
    "# Load using base class load_model with explicit config\n",
    "wrapper = TotoTSFM.load_model(str(MODEL_DIR), config=config)\n",
    "toto_ft = wrapper.model\n",
    "toto_ft.to(device)\n",
    "toto_ft.eval()\n",
    "\n",
    "# Extract backbone for TotoForecaster, handling PEFT-wrapped models\n",
    "# When LoRA is used, the model is wrapped by PEFT but LoRA layers are\n",
    "# injected into the backbone, so accessing base_model.model.model gives\n",
    "# us the backbone with LoRA active\n",
    "if hasattr(toto_ft, \"base_model\"):  # PEFT model\n",
    "    backbone_ft = toto_ft.base_model.model.model\n",
    "    print(\"Loaded PEFT model with LoRA adapter\")\n",
    "else:\n",
    "    backbone_ft = toto_ft.model\n",
    "\n",
    "forecaster_ft = TotoForecaster(backbone_ft)\n",
    "print(\"Fine-tuned model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data (held out from training)\n",
    "loader = get_loader(\n",
    "    data_source_name=\"kaggle_brisT1D\", dataset_type=\"train\", use_cached=True\n",
    ")\n",
    "val_data = loader.validation_data\n",
    "\n",
    "print(f\"Validation patients: {list(val_data.keys())}\")\n",
    "print(f\"Total validation days: {sum(len(df) // 288 for df in val_data.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, targets):\n",
    "    \"\"\"Compute RMSE and MAE.\"\"\"\n",
    "    y_pred = np.asarray(predictions).flatten()\n",
    "    y_true = np.asarray(targets).flatten()\n",
    "    return {\n",
    "        \"rmse\": float(root_mean_squared_error(y_true, y_pred)),\n",
    "        \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def forecast(context, timestamps, forecaster, prediction_length, num_samples=100):\n",
    "    \"\"\"Run Toto forecast and return median + quantiles.\"\"\"\n",
    "    # series: (batch=1, variates=1, timesteps)\n",
    "    series = torch.tensor(context, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    # timestamp_seconds: (batch=1, variates=1, timesteps)\n",
    "    ts_seconds = (\n",
    "        torch.tensor([int(ts.timestamp()) for ts in timestamps], dtype=torch.int)\n",
    "        .unsqueeze(0).unsqueeze(0)\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "    inputs = MaskedTimeseries(\n",
    "        series=series,\n",
    "        padding_mask=torch.ones_like(series, dtype=torch.bool),\n",
    "        id_mask=torch.zeros(series.shape, dtype=torch.int, device=device),\n",
    "        timestamp_seconds=ts_seconds,\n",
    "        # time_interval_seconds: (batch=1, variates=1)\n",
    "        time_interval_seconds=torch.full((1, 1), INTERVAL_MINS * 60, dtype=torch.int, device=device),\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fc = forecaster.forecast(\n",
    "            inputs,\n",
    "            prediction_length=prediction_length,\n",
    "            num_samples=num_samples,\n",
    "            samples_per_batch=50,\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        fc.median.cpu().numpy()[0].flatten(),\n",
    "        fc.quantile(0.1).cpu().numpy()[0].flatten(),\n",
    "        fc.quantile(0.9).cpu().numpy()[0].flatten(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models on all valid validation days\n",
    "results = []\n",
    "\n",
    "for patient_id, patient_df in val_data.items():\n",
    "    if get_interval_minutes(patient_df) != INTERVAL_MINS:\n",
    "        continue\n",
    "\n",
    "    df = patient_df.sort_index()\n",
    "    if TARGET_COL not in df.columns:\n",
    "        continue\n",
    "\n",
    "    for daytime, nocturnal in iter_daily_context_forecast_splits(df):\n",
    "        target = nocturnal[TARGET_COL].values[:FORECAST_LENGTH]\n",
    "        if np.isnan(target).any() or len(target) < FORECAST_LENGTH:\n",
    "            continue\n",
    "\n",
    "        # Get context ending at midnight\n",
    "        nocturnal_start = nocturnal.index[0]\n",
    "        available = df.loc[df.index < nocturnal_start, TARGET_COL].dropna()\n",
    "\n",
    "        if len(available) < CONTEXT_LENGTH:\n",
    "            continue  # Not enough history\n",
    "\n",
    "        context = available.iloc[-CONTEXT_LENGTH:].values\n",
    "        timestamps = available.iloc[-CONTEXT_LENGTH:].index\n",
    "\n",
    "        if np.isnan(context).any():\n",
    "            continue\n",
    "\n",
    "        # Zero-shot prediction\n",
    "        pred_zs, q10_zs, q90_zs = forecast(\n",
    "            context, timestamps, forecaster_zs, FORECAST_LENGTH\n",
    "        )\n",
    "\n",
    "        # Fine-tuned prediction\n",
    "        pred_ft, q10_ft, q90_ft = forecast(\n",
    "            context, timestamps, forecaster_ft, FORECAST_LENGTH\n",
    "        )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"patient\": patient_id,\n",
    "                \"target\": target.flatten(),\n",
    "                \"context\": context,\n",
    "                \"pred_zs\": pred_zs,\n",
    "                \"q10_zs\": q10_zs,\n",
    "                \"q90_zs\": q90_zs,\n",
    "                \"pred_ft\": pred_ft,\n",
    "                \"q10_ft\": q10_ft,\n",
    "                \"q90_ft\": q90_ft,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"Evaluated {len(results)} validation days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-patient metrics\n",
    "print(\"Per-Patient Results:\")\n",
    "print(\"=\" * 70)\n",
    "print(\n",
    "    f\"{'Patient':<10} {'Days':<6} {'ZS RMSE':<12} {'FT RMSE':<12} {'Improvement':<12}\"\n",
    ")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "patient_stats = []\n",
    "for pid in sorted(set(r[\"patient\"] for r in results)):\n",
    "    patient_days = [r for r in results if r[\"patient\"] == pid]\n",
    "\n",
    "    preds_zs = np.concatenate([r[\"pred_zs\"] for r in patient_days])\n",
    "    preds_ft = np.concatenate([r[\"pred_ft\"] for r in patient_days])\n",
    "    targets = np.concatenate([r[\"target\"] for r in patient_days])\n",
    "\n",
    "    rmse_zs = compute_metrics(preds_zs, targets)[\"rmse\"]\n",
    "    rmse_ft = compute_metrics(preds_ft, targets)[\"rmse\"]\n",
    "    improvement = (rmse_zs - rmse_ft) / rmse_zs * 100\n",
    "\n",
    "    patient_stats.append(\n",
    "        {\n",
    "            \"patient\": pid,\n",
    "            \"days\": len(patient_days),\n",
    "            \"rmse_zs\": rmse_zs,\n",
    "            \"rmse_ft\": rmse_ft,\n",
    "            \"improvement\": improvement,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{pid:<10} {len(patient_days):<6} {rmse_zs:<12.3f} {rmse_ft:<12.3f} {improvement:+.1f}%\"\n",
    "    )\n",
    "\n",
    "# Overall metrics\n",
    "all_preds_zs = np.concatenate([r[\"pred_zs\"] for r in results])\n",
    "all_preds_ft = np.concatenate([r[\"pred_ft\"] for r in results])\n",
    "all_targets = np.concatenate([r[\"target\"] for r in results])\n",
    "\n",
    "overall_zs = compute_metrics(all_preds_zs, all_targets)\n",
    "overall_ft = compute_metrics(all_preds_ft, all_targets)\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\n",
    "    f\"{'OVERALL':<10} {len(results):<6} {overall_zs['rmse']:<12.3f} {overall_ft['rmse']:<12.3f} \",\n",
    "    end=\"\",\n",
    ")\n",
    "print(f\"{(overall_zs['rmse'] - overall_ft['rmse']) / overall_zs['rmse'] * 100:+.1f}%\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Model\": \"Zero-Shot\",\n",
    "            \"RMSE (mmol/L)\": overall_zs[\"rmse\"],\n",
    "            \"MAE (mmol/L)\": overall_zs[\"mae\"],\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"Fine-Tuned (LoRA)\",\n",
    "            \"RMSE (mmol/L)\": overall_ft[\"rmse\"],\n",
    "            \"MAE (mmol/L)\": overall_ft[\"mae\"],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: All Days for a Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PATIENT = \"p10\"  # Change to visualize different patient\n",
    "NCOLS = 4\n",
    "\n",
    "patient_results = [r for r in results if r[\"patient\"] == PLOT_PATIENT]\n",
    "num_days = len(patient_results)\n",
    "print(f\"Patient {PLOT_PATIENT}: {num_days} validation days\")\n",
    "\n",
    "if num_days > 0:\n",
    "    nrows = int(np.ceil(num_days / NCOLS))\n",
    "    fig, axes = plt.subplots(nrows, NCOLS, figsize=(4 * NCOLS, 3.5 * nrows))\n",
    "    axes = np.array(axes).flatten() if num_days > 1 else [axes]\n",
    "\n",
    "    for i, day in enumerate(patient_results):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Show last 18h of context for cleaner visualization\n",
    "        display_context = day[\"context\"][-216:]\n",
    "        target = day[\"target\"]\n",
    "\n",
    "        t_ctx = np.arange(len(display_context))\n",
    "        t_pred = np.arange(len(display_context), len(display_context) + len(target))\n",
    "\n",
    "        # Plot\n",
    "        ax.plot(t_ctx, display_context, \"b-\", alpha=0.5, lw=1, label=\"Context\")\n",
    "        ax.plot(t_pred, target, \"k--\", lw=2, label=\"Actual\")\n",
    "        ax.plot(t_pred, day[\"pred_zs\"], \"orange\", lw=1.5, alpha=0.8, label=\"Zero-Shot\")\n",
    "        ax.fill_between(\n",
    "            t_pred, day[\"q10_zs\"], day[\"q90_zs\"], alpha=0.15, color=\"orange\"\n",
    "        )\n",
    "        ax.plot(t_pred, day[\"pred_ft\"], \"green\", lw=1.5, alpha=0.8, label=\"Fine-Tuned\")\n",
    "        ax.fill_between(t_pred, day[\"q10_ft\"], day[\"q90_ft\"], alpha=0.15, color=\"green\")\n",
    "\n",
    "        # Reference lines\n",
    "        ax.axvline(len(display_context), color=\"gray\", ls=\":\", alpha=0.5)\n",
    "        ax.axhline(3.9, color=\"crimson\", ls=\"--\", alpha=0.3, lw=0.8)  # Hypoglycemia\n",
    "        ax.axhline(10.0, color=\"orange\", ls=\"--\", alpha=0.3, lw=0.8)  # Hyperglycemia\n",
    "\n",
    "        # Metrics\n",
    "        rmse_zs = compute_metrics(day[\"pred_zs\"], target)[\"rmse\"]\n",
    "        rmse_ft = compute_metrics(day[\"pred_ft\"], target)[\"rmse\"]\n",
    "        ax.set_title(f\"Day {i}: ZS={rmse_zs:.2f}, FT={rmse_ft:.2f}\", fontsize=9)\n",
    "\n",
    "        ax.set_ylim(0, 18)\n",
    "        ax.tick_params(labelsize=7)\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(num_days, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    axes[0].legend(fontsize=7, loc=\"upper right\")\n",
    "    fig.suptitle(\n",
    "        f\"Patient {PLOT_PATIENT}: Zero-Shot vs Fine-Tuned\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-day RMSE comparison\n",
    "day_rmse = []\n",
    "for r in results:\n",
    "    rmse_zs = compute_metrics(r[\"pred_zs\"], r[\"target\"])[\"rmse\"]\n",
    "    rmse_ft = compute_metrics(r[\"pred_ft\"], r[\"target\"])[\"rmse\"]\n",
    "    day_rmse.append({\"rmse_zs\": rmse_zs, \"rmse_ft\": rmse_ft, \"patient\": r[\"patient\"]})\n",
    "\n",
    "rmse_df = pd.DataFrame(day_rmse)\n",
    "rmse_df[\"improvement\"] = (\n",
    "    (rmse_df[\"rmse_zs\"] - rmse_df[\"rmse_ft\"]) / rmse_df[\"rmse_zs\"] * 100\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Scatter plot: ZS vs FT RMSE per day\n",
    "ax = axes[0]\n",
    "ax.scatter(rmse_df[\"rmse_zs\"], rmse_df[\"rmse_ft\"], alpha=0.5, c=\"steelblue\")\n",
    "lims = [0, max(rmse_df[\"rmse_zs\"].max(), rmse_df[\"rmse_ft\"].max()) + 0.5]\n",
    "ax.plot(lims, lims, \"k--\", alpha=0.5, label=\"Equal performance\")\n",
    "ax.set_xlabel(\"Zero-Shot RMSE (mmol/L)\")\n",
    "ax.set_ylabel(\"Fine-Tuned RMSE (mmol/L)\")\n",
    "ax.set_title(\"Per-Day RMSE: Zero-Shot vs Fine-Tuned\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Histogram of improvement\n",
    "ax = axes[1]\n",
    "ax.hist(\n",
    "    rmse_df[\"improvement\"], bins=20, color=\"steelblue\", alpha=0.7, edgecolor=\"white\"\n",
    ")\n",
    "ax.axvline(0, color=\"red\", ls=\"--\", alpha=0.7, label=\"No improvement\")\n",
    "ax.axvline(\n",
    "    rmse_df[\"improvement\"].mean(),\n",
    "    color=\"green\",\n",
    "    ls=\"-\",\n",
    "    lw=2,\n",
    "    label=f\"Mean: {rmse_df['improvement'].mean():.1f}%\",\n",
    ")\n",
    "ax.set_xlabel(\"Improvement (%)\")\n",
    "ax.set_ylabel(\"Number of Days\")\n",
    "ax.set_title(\"Distribution of Per-Day Improvement\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "improved_days = (rmse_df[\"rmse_ft\"] < rmse_df[\"rmse_zs\"]).sum()\n",
    "print(\n",
    "    f\"Days where fine-tuned is better: {improved_days}/{len(rmse_df)} ({100*improved_days/len(rmse_df):.1f}%)\"\n",
    ")\n",
    "print(f\"Average improvement: {rmse_df['improvement'].mean():.2f}%\")\n",
    "print(f\"Median improvement: {rmse_df['improvement'].median():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
