{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toto Fine-Tuning Evaluation\n",
    "\n",
    "Compare zero-shot vs fine-tuned Toto model performance on nocturnal blood glucose forecasting.\n",
    "\n",
    "**Task**: Predict 6 hours of nocturnal blood glucose (72 timesteps at 5-min intervals)\n",
    "**Context**: 42 hours of historical data (504 timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "from toto.model.toto import Toto\n",
    "from toto.data.util.dataset import MaskedTimeseries\n",
    "from toto.inference.forecaster import TotoForecaster\n",
    "from peft import PeftModel\n",
    "\n",
    "from src.data.diabetes_datasets.data_loader import get_loader\n",
    "from src.data.models import ColumnNames\n",
    "from src.utils.time_series_helper import get_interval_minutes\n",
    "from src.data.preprocessing.time_processing import iter_daily_context_forecast_splits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting configuration\n",
    "INTERVAL_MINS = 5\n",
    "CONTEXT_LENGTH = 504        # 42 hours (matches training)\n",
    "FORECAST_LENGTH = 72        # 6 hours nocturnal\n",
    "TARGET_COL = ColumnNames.BG.value\n",
    "\n",
    "# Model paths\n",
    "notebook_dir = Path.cwd()\n",
    "repo_root = notebook_dir.parent.parent if \"notebooks\" in str(notebook_dir) else notebook_dir\n",
    "PEFT_ADAPTER_DIR = repo_root / \"trained_models/artifacts/_tsfm_testing/output_single_gpu_toto_lora/peft_adapter\"\n",
    "\n",
    "print(f\"Context: {CONTEXT_LENGTH} steps ({CONTEXT_LENGTH * INTERVAL_MINS / 60:.1f} hours)\")\n",
    "print(f\"Forecast: {FORECAST_LENGTH} steps ({FORECAST_LENGTH * INTERVAL_MINS / 60:.1f} hours)\")\n",
    "print(f\"LoRA adapter: {PEFT_ADAPTER_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zero-shot model\n",
    "print(\"Loading zero-shot Toto model...\")\n",
    "toto_zs = Toto.from_pretrained(\"Datadog/Toto-Open-Base-1.0\")\n",
    "toto_zs.to(device)\n",
    "toto_zs.eval()\n",
    "forecaster_zs = TotoForecaster(toto_zs.model)\n",
    "print(\"Zero-shot model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned model (LoRA)\n",
    "print(f\"Loading LoRA fine-tuned model from {PEFT_ADAPTER_DIR}...\")\n",
    "toto_base = Toto.from_pretrained(\"Datadog/Toto-Open-Base-1.0\")\n",
    "toto_ft = PeftModel.from_pretrained(toto_base, str(PEFT_ADAPTER_DIR))\n",
    "toto_ft = toto_ft.merge_and_unload()  # Merge LoRA weights for faster inference\n",
    "toto_ft.to(device)\n",
    "toto_ft.eval()\n",
    "forecaster_ft = TotoForecaster(toto_ft.model)\n",
    "print(\"Fine-tuned model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data (held out from training)\n",
    "loader = get_loader(data_source_name=\"kaggle_brisT1D\", dataset_type=\"train\", use_cached=True)\n",
    "val_data = loader.validation_data\n",
    "\n",
    "print(f\"Validation patients: {list(val_data.keys())}\")\n",
    "print(f\"Total validation days: {sum(len(df) // 288 for df in val_data.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, targets):\n",
    "    \"\"\"Compute RMSE and MAE.\"\"\"\n",
    "    y_pred = np.asarray(predictions).flatten()\n",
    "    y_true = np.asarray(targets).flatten()\n",
    "    return {\n",
    "        \"rmse\": float(root_mean_squared_error(y_true, y_pred)),\n",
    "        \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def forecast(context, timestamps, forecaster, prediction_length, num_samples=100):\n",
    "    \"\"\"Run Toto forecast and return median + quantiles.\"\"\"\n",
    "    series = torch.tensor(context, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    ts_seconds = (\n",
    "        torch.tensor([ts.timestamp() for ts in timestamps], dtype=torch.float32)\n",
    "        .unsqueeze(0)\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "    inputs = MaskedTimeseries(\n",
    "        series=series,\n",
    "        padding_mask=torch.ones_like(series, dtype=torch.bool),\n",
    "        id_mask=torch.zeros_like(series),\n",
    "        timestamp_seconds=ts_seconds,\n",
    "        time_interval_seconds=torch.tensor([INTERVAL_MINS * 60], dtype=torch.float32).to(device),\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fc = forecaster.forecast(\n",
    "            inputs,\n",
    "            prediction_length=prediction_length,\n",
    "            num_samples=num_samples,\n",
    "            samples_per_batch=50,\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        fc.median.cpu().numpy()[0].flatten(),\n",
    "        fc.quantile(0.1).cpu().numpy()[0].flatten(),\n",
    "        fc.quantile(0.9).cpu().numpy()[0].flatten(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models on all valid validation days\n",
    "results = []\n",
    "\n",
    "for patient_id, patient_df in val_data.items():\n",
    "    if get_interval_minutes(patient_df) != INTERVAL_MINS:\n",
    "        continue\n",
    "\n",
    "    df = patient_df.sort_index()\n",
    "    if TARGET_COL not in df.columns:\n",
    "        continue\n",
    "\n",
    "    for daytime, nocturnal in iter_daily_context_forecast_splits(df):\n",
    "        target = nocturnal[TARGET_COL].values[:FORECAST_LENGTH]\n",
    "        if np.isnan(target).any() or len(target) < FORECAST_LENGTH:\n",
    "            continue\n",
    "\n",
    "        # Get context ending at midnight\n",
    "        nocturnal_start = nocturnal.index[0]\n",
    "        available = df.loc[df.index < nocturnal_start, TARGET_COL].dropna()\n",
    "\n",
    "        if len(available) < CONTEXT_LENGTH:\n",
    "            continue  # Not enough history\n",
    "\n",
    "        context = available.iloc[-CONTEXT_LENGTH:].values\n",
    "        timestamps = available.iloc[-CONTEXT_LENGTH:].index\n",
    "\n",
    "        if np.isnan(context).any():\n",
    "            continue\n",
    "\n",
    "        # Zero-shot prediction\n",
    "        pred_zs, q10_zs, q90_zs = forecast(context, timestamps, forecaster_zs, FORECAST_LENGTH)\n",
    "        \n",
    "        # Fine-tuned prediction\n",
    "        pred_ft, q10_ft, q90_ft = forecast(context, timestamps, forecaster_ft, FORECAST_LENGTH)\n",
    "\n",
    "        results.append({\n",
    "            \"patient\": patient_id,\n",
    "            \"target\": target.flatten(),\n",
    "            \"context\": context,\n",
    "            \"pred_zs\": pred_zs,\n",
    "            \"q10_zs\": q10_zs,\n",
    "            \"q90_zs\": q90_zs,\n",
    "            \"pred_ft\": pred_ft,\n",
    "            \"q10_ft\": q10_ft,\n",
    "            \"q90_ft\": q90_ft,\n",
    "        })\n",
    "\n",
    "print(f\"Evaluated {len(results)} validation days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-patient metrics\n",
    "print(\"Per-Patient Results:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Patient':<10} {'Days':<6} {'ZS RMSE':<12} {'FT RMSE':<12} {'Improvement':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "patient_stats = []\n",
    "for pid in sorted(set(r[\"patient\"] for r in results)):\n",
    "    patient_days = [r for r in results if r[\"patient\"] == pid]\n",
    "    \n",
    "    preds_zs = np.concatenate([r[\"pred_zs\"] for r in patient_days])\n",
    "    preds_ft = np.concatenate([r[\"pred_ft\"] for r in patient_days])\n",
    "    targets = np.concatenate([r[\"target\"] for r in patient_days])\n",
    "    \n",
    "    rmse_zs = compute_metrics(preds_zs, targets)[\"rmse\"]\n",
    "    rmse_ft = compute_metrics(preds_ft, targets)[\"rmse\"]\n",
    "    improvement = (rmse_zs - rmse_ft) / rmse_zs * 100\n",
    "    \n",
    "    patient_stats.append({\n",
    "        \"patient\": pid,\n",
    "        \"days\": len(patient_days),\n",
    "        \"rmse_zs\": rmse_zs,\n",
    "        \"rmse_ft\": rmse_ft,\n",
    "        \"improvement\": improvement,\n",
    "    })\n",
    "    \n",
    "    print(f\"{pid:<10} {len(patient_days):<6} {rmse_zs:<12.3f} {rmse_ft:<12.3f} {improvement:+.1f}%\")\n",
    "\n",
    "# Overall metrics\n",
    "all_preds_zs = np.concatenate([r[\"pred_zs\"] for r in results])\n",
    "all_preds_ft = np.concatenate([r[\"pred_ft\"] for r in results])\n",
    "all_targets = np.concatenate([r[\"target\"] for r in results])\n",
    "\n",
    "overall_zs = compute_metrics(all_preds_zs, all_targets)\n",
    "overall_ft = compute_metrics(all_preds_ft, all_targets)\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'OVERALL':<10} {len(results):<6} {overall_zs['rmse']:<12.3f} {overall_ft['rmse']:<12.3f} \", end=\"\")\n",
    "print(f\"{(overall_zs['rmse'] - overall_ft['rmse']) / overall_zs['rmse'] * 100:+.1f}%\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary_df = pd.DataFrame([\n",
    "    {\"Model\": \"Zero-Shot\", \"RMSE (mmol/L)\": overall_zs[\"rmse\"], \"MAE (mmol/L)\": overall_zs[\"mae\"]},\n",
    "    {\"Model\": \"Fine-Tuned (LoRA)\", \"RMSE (mmol/L)\": overall_ft[\"rmse\"], \"MAE (mmol/L)\": overall_ft[\"mae\"]},\n",
    "])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: All Days for a Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PATIENT = \"p10\"  # Change to visualize different patient\n",
    "NCOLS = 4\n",
    "\n",
    "patient_results = [r for r in results if r[\"patient\"] == PLOT_PATIENT]\n",
    "num_days = len(patient_results)\n",
    "print(f\"Patient {PLOT_PATIENT}: {num_days} validation days\")\n",
    "\n",
    "if num_days > 0:\n",
    "    nrows = int(np.ceil(num_days / NCOLS))\n",
    "    fig, axes = plt.subplots(nrows, NCOLS, figsize=(4 * NCOLS, 3.5 * nrows))\n",
    "    axes = np.array(axes).flatten() if num_days > 1 else [axes]\n",
    "\n",
    "    for i, day in enumerate(patient_results):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Show last 18h of context for cleaner visualization\n",
    "        display_context = day[\"context\"][-216:]\n",
    "        target = day[\"target\"]\n",
    "        \n",
    "        t_ctx = np.arange(len(display_context))\n",
    "        t_pred = np.arange(len(display_context), len(display_context) + len(target))\n",
    "\n",
    "        # Plot\n",
    "        ax.plot(t_ctx, display_context, \"b-\", alpha=0.5, lw=1, label=\"Context\")\n",
    "        ax.plot(t_pred, target, \"k--\", lw=2, label=\"Actual\")\n",
    "        ax.plot(t_pred, day[\"pred_zs\"], \"orange\", lw=1.5, alpha=0.8, label=\"Zero-Shot\")\n",
    "        ax.fill_between(t_pred, day[\"q10_zs\"], day[\"q90_zs\"], alpha=0.15, color=\"orange\")\n",
    "        ax.plot(t_pred, day[\"pred_ft\"], \"green\", lw=1.5, alpha=0.8, label=\"Fine-Tuned\")\n",
    "        ax.fill_between(t_pred, day[\"q10_ft\"], day[\"q90_ft\"], alpha=0.15, color=\"green\")\n",
    "\n",
    "        # Reference lines\n",
    "        ax.axvline(len(display_context), color=\"gray\", ls=\":\", alpha=0.5)\n",
    "        ax.axhline(3.9, color=\"crimson\", ls=\"--\", alpha=0.3, lw=0.8)  # Hypoglycemia\n",
    "        ax.axhline(10.0, color=\"orange\", ls=\"--\", alpha=0.3, lw=0.8)  # Hyperglycemia\n",
    "\n",
    "        # Metrics\n",
    "        rmse_zs = compute_metrics(day[\"pred_zs\"], target)[\"rmse\"]\n",
    "        rmse_ft = compute_metrics(day[\"pred_ft\"], target)[\"rmse\"]\n",
    "        ax.set_title(f\"Day {i}: ZS={rmse_zs:.2f}, FT={rmse_ft:.2f}\", fontsize=9)\n",
    "        \n",
    "        ax.set_ylim(0, 18)\n",
    "        ax.tick_params(labelsize=7)\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(num_days, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    axes[0].legend(fontsize=7, loc=\"upper right\")\n",
    "    fig.suptitle(f\"Patient {PLOT_PATIENT}: Zero-Shot vs Fine-Tuned\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-day RMSE comparison\n",
    "day_rmse = []\n",
    "for r in results:\n",
    "    rmse_zs = compute_metrics(r[\"pred_zs\"], r[\"target\"])[\"rmse\"]\n",
    "    rmse_ft = compute_metrics(r[\"pred_ft\"], r[\"target\"])[\"rmse\"]\n",
    "    day_rmse.append({\"rmse_zs\": rmse_zs, \"rmse_ft\": rmse_ft, \"patient\": r[\"patient\"]})\n",
    "\n",
    "rmse_df = pd.DataFrame(day_rmse)\n",
    "rmse_df[\"improvement\"] = (rmse_df[\"rmse_zs\"] - rmse_df[\"rmse_ft\"]) / rmse_df[\"rmse_zs\"] * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Scatter plot: ZS vs FT RMSE per day\n",
    "ax = axes[0]\n",
    "ax.scatter(rmse_df[\"rmse_zs\"], rmse_df[\"rmse_ft\"], alpha=0.5, c=\"steelblue\")\n",
    "lims = [0, max(rmse_df[\"rmse_zs\"].max(), rmse_df[\"rmse_ft\"].max()) + 0.5]\n",
    "ax.plot(lims, lims, \"k--\", alpha=0.5, label=\"Equal performance\")\n",
    "ax.set_xlabel(\"Zero-Shot RMSE (mmol/L)\")\n",
    "ax.set_ylabel(\"Fine-Tuned RMSE (mmol/L)\")\n",
    "ax.set_title(\"Per-Day RMSE: Zero-Shot vs Fine-Tuned\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Histogram of improvement\n",
    "ax = axes[1]\n",
    "ax.hist(rmse_df[\"improvement\"], bins=20, color=\"steelblue\", alpha=0.7, edgecolor=\"white\")\n",
    "ax.axvline(0, color=\"red\", ls=\"--\", alpha=0.7, label=\"No improvement\")\n",
    "ax.axvline(rmse_df[\"improvement\"].mean(), color=\"green\", ls=\"-\", lw=2, \n",
    "           label=f\"Mean: {rmse_df['improvement'].mean():.1f}%\")\n",
    "ax.set_xlabel(\"Improvement (%)\")\n",
    "ax.set_ylabel(\"Number of Days\")\n",
    "ax.set_title(\"Distribution of Per-Day Improvement\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "improved_days = (rmse_df[\"rmse_ft\"] < rmse_df[\"rmse_zs\"]).sum()\n",
    "print(f\"Days where fine-tuned is better: {improved_days}/{len(rmse_df)} ({100*improved_days/len(rmse_df):.1f}%)\")\n",
    "print(f\"Average improvement: {rmse_df['improvement'].mean():.2f}%\")\n",
    "print(f\"Median improvement: {rmse_df['improvement'].median():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Details\n",
    "\n",
    "**LoRA Configuration:**\n",
    "- Rank: 16\n",
    "- Alpha: 32\n",
    "- Target modules: `wQKV`, `wO` (attention layers)\n",
    "- Trainable parameters: ~1-2% of model\n",
    "\n",
    "**Training Configuration:**\n",
    "- Context: 504 steps (42 hours)\n",
    "- Forecast: 72 steps (6 hours)\n",
    "- Batch size: 16\n",
    "- Learning rate: 1e-4\n",
    "- Epochs: 10\n",
    "- Dataset: kaggle_brisT1D training set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
