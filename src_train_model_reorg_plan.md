# Training Pipeline Reorganization Plan

## Executive Summary

This document outlines a comprehensive reorganization plan for the nocturnal-hypo-gly-prob-forecast repository to support modern Time Series Foundation Model (TSFM) research. The plan emphasizes scalability, reproducibility, and maintainability while following best practices from top academic and industry research labs.

## Current State Analysis

### Issues Identified (Original)
1. **~~Training Code Duplication~~**: âœ… **RESOLVED** - Unified base framework eliminates TTM code duplication
2. **~~Scattered Configurations~~**: âœ… **IMPROVED** - Enhanced configuration system with validation and factory methods
3. **~~Inconsistent Experiment Structure~~**: ðŸ”„ **IN PROGRESS** - Base structure implemented, full experiment management pending
4. **~~Limited Distributed Training Support~~**: âœ… **RESOLVED** - Production-ready multi-GPU framework with DDP support
5. **~~Manual Experiment Tracking~~**: âœ… **IMPROVED** - Model registry and experiment infrastructure implemented
6. **~~Fragmented Evaluation~~**: ðŸ”„ **IN PROGRESS** - Evaluation foundation in place, centralized pipeline pending

### New Capabilities Achieved
- **ðŸš€ Production Distributed Training**: Seamless single/multi-GPU workflows with automatic hardware detection
- **ðŸ”§ Comprehensive Tooling**: Hardware diagnostics, setup validation, and framework testing scripts
- **ðŸ“ Enhanced Logging**: Rank-aware distributed logging with debug controls
- **âš™ï¸ Robust Configuration**: Validation, serialization, and factory pattern implementation
- **ðŸ”„ Resource Management**: Proper cleanup and error handling for distributed training
- **ðŸ“š Complete Documentation**: User guides, API docs, and example workflows

## Proposed Directory Structure

```
nocturnal/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                           # Keep existing, enhance with versioning
â”‚   â”‚   â”œâ”€â”€ versioning/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_versioning.py      # Simple data version tracking
â”‚   â”‚   â”‚   â””â”€â”€ dataset_registry.py     # Track dataset configs used in experiments
â”‚   â”‚   â””â”€â”€ [existing structure...]
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                     # Enhanced evaluation pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ regression.py          # RMSE, MSE, MAE, MAPE
â”‚   â”‚   â”‚   â”œâ”€â”€ clinical.py            # Clarke Error Grid Analysis
â”‚   â”‚   â”‚   â””â”€â”€ probabilistic.py       # Metrics for probabilistic forecasts
â”‚   â”‚   â”œâ”€â”€ evaluator.py               # Main evaluation orchestrator
â”‚   â”‚   â””â”€â”€ report_generator.py        # Automated report generation
â”‚   â”‚
â”‚   â”œâ”€â”€ experiments/                    # NEW: Experiment management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment.py          # Base experiment class
â”‚   â”‚   â”‚   â””â”€â”€ registry.py            # Experiment tracking
â”‚   â”‚   â”œâ”€â”€ data_ablation/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ experiments.py         # Data ablation experiments
â”‚   â”‚   â”œâ”€â”€ gpu_optimization/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ experiments.py         # GPU set-up testing experiments
â”‚   â”‚   â”œâ”€â”€ model_scaling/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ experiments.py         # Model scaling experiments
â”‚   â”‚   â”œâ”€â”€ nocturnal/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ experiments.py         # Nocturnal-specific experiments
â”‚   â”‚   â”œâ”€â”€ personalization/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ experiments.py         # Personalization experiments
â”‚   â”‚   â”œâ”€â”€ prandial/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ experiments.py         # Prandial-specific experiments
â”‚   â”‚   â””â”€â”€ transfer_learning/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ experiments.py         # Cross-dataset/patient transfer
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                         # NEW: Unified model architectures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_model.py          # Abstract base for all TSFMs
â”‚   â”‚   â”‚   â”œâ”€â”€ distributed.py         # Multi-GPU training utilities
â”‚   â”‚   â”‚   â””â”€â”€ lora_utils.py          # LoRA integration
â”‚   â”‚   â”œâ”€â”€ chronos/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ trainer.py
â”‚   â”‚   â”œâ”€â”€ tide/
â”‚   â”‚   â”œâ”€â”€ timegpt/
â”‚   â”‚   â”œâ”€â”€ timellm/
â”‚   â”‚   â”œâ”€â”€ ts2vec/
â”‚   â”‚   â”œâ”€â”€ tsmixer/
â”‚   â”‚   â””â”€â”€ ttm/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py               # Refactored TTM implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py              # TTM-specific configs
â”‚   â”‚   â”‚   â””â”€â”€ trainer.py             # TTM trainer with distributed support
â”‚   â”‚
â”‚   â”œâ”€â”€ registry/                       # NEW: Model and experiment registries
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment_registry.py  # Experiment result tracking
â”‚   â”‚   â”‚   â””â”€â”€ result_aggregator.py   # Cross-experiment analysis
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_registry.py      # Enhanced model tracking
â”‚   â”‚   â”‚   â””â”€â”€ version_manager.py     # Model versioning
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                       # NEW: Unified training pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer_factory.py     # Create trainers for different models
â”‚   â”‚   â”‚   â”œâ”€â”€ distributed_launcher.py # Handle multi-GPU setup
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint_manager.py   # Model saving/loading
â”‚   â”‚   â”‚   â””â”€â”€ training_loop.py       # Common training logic
â”‚   â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fine_tuning.py         # Fine-tuning strategies
â”‚   â”‚   â”‚   â”œâ”€â”€ from_scratch.py        # Training from scratch
â”‚   â”‚   â”‚   â””â”€â”€ zero_shot.py           # Zero-shot evaluation
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ reproducibility.py     # Seed setting, version tracking
â”‚   â”‚       â””â”€â”€ memory_optimization.py # LoRA, gradient checkpointing
â”‚   â”‚
â”‚   â””â”€â”€ [existing utils/, tuning/...]
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ kaggle_bris_t1d.yaml
â”‚   â”‚   â”œâ”€â”€ aleppo.yaml
â”‚   â”‚   â”œâ”€â”€ gluroo.yaml
â”‚   â”‚   â””â”€â”€ multi_dataset.yaml         # Multi-dataset training configs                  # NEW: Centralized configuration management
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ standard_metrics.yaml
â”‚   â”‚   â”œâ”€â”€ clinical_metrics.yaml
â”‚   â”‚   â””â”€â”€ multi_testset.yaml
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ nocturnal/
â”‚   â”‚   â”‚   â”œâ”€â”€ point_forecast.yaml
â”‚   â”‚   â”‚   â””â”€â”€ probabilistic_forecast.yaml
â”‚   â”‚   â”œâ”€â”€ prandial/
â”‚   â”‚   â”œâ”€â”€ ablation/
â”‚   â”‚   â””â”€â”€ [other experiment types...]
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ttm/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.yaml              # Base TTM configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ fine_tune.yaml         # Fine-tuning specific
â”‚   â”‚   â”‚   â””â”€â”€ from_scratch.yaml      # Training from scratch
â”‚   â”‚   â”œâ”€â”€ chronos/
â”‚   â”‚   â”œâ”€â”€ timegpt/
â”‚   â”‚   â””â”€â”€ [other models...]
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ single_gpu.yaml
â”‚       â”œâ”€â”€ multi_gpu_ddp.yaml
â”‚       â”œâ”€â”€ multi_gpu_deepspeed.yaml
â”‚       â””â”€â”€ slurm_cluster.yaml
â”‚
â”œâ”€â”€ experiments/                        # REORGANIZED: Experiment results storage
â”‚   â”œâ”€â”€ nocturnal_forecast/
â”‚   â”‚   â”œâ”€â”€ point_forecast/
â”‚   â”‚   â”‚   â”œâ”€â”€ ttm_vs_chronos_2025_11_17/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ experiment_config.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_summary.json
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ detailed_results.csv
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ figures/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ metadata.json      # Git commit, environment, etc.
â”‚   â”‚   â”‚   â””â”€â”€ [other point forecast experiments...]
â”‚   â”‚   â””â”€â”€ probabilistic_forecast/
â”‚   â”œâ”€â”€ prandial_forecast/
â”‚   â”œâ”€â”€ data_ablation/
â”‚   â”œâ”€â”€ personalization/
â”‚   â””â”€â”€ transfer_learning/
â”‚
â”œâ”€â”€ trained_models/                     # NEW: Centralized model artifacts
â”‚   â”œâ”€â”€ registry.db                     # SQLite for complex queries (future)
â”‚   â”œâ”€â”€ registry.csv                    # Simple CSV for now
â”‚   â””â”€â”€ artifacts/
â”‚       â”œâ”€â”€ ttm/
â”‚       â”‚   â”œâ”€â”€ 20251117_142301_kaggle_ft/  # timestamp_dataset_strategy
â”‚       â”‚   â”‚   â”œâ”€â”€ model.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ training_log.json
â”‚       â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚       â”‚   â”‚   â””â”€â”€ checkpoints/
â”‚       â”‚   â””â”€â”€ [other TTM models...]
â”‚       â”œâ”€â”€ chronos/
â”‚       â””â”€â”€ [other model types...]
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ training/                       # ENHANCED: Training entry points
    â”‚   â”œâ”€â”€ train_model.py             # Unified training script
    â”‚   â”œâ”€â”€ slurm/
    â”‚   â”‚   â”œâ”€â”€ single_gpu.sh
    â”‚   â”‚   â”œâ”€â”€ multi_gpu.sh
    â”‚   â”‚   â””â”€â”€ adaptive_resources.sh   # Auto-select GPU config
    â”‚   â””â”€â”€ [existing scripts...]
    â”œâ”€â”€ experiments/                    # NEW: Experiment runners
    â”‚   â”œâ”€â”€ run_experiment.py          # Main experiment runner
    â”‚   â”œâ”€â”€ nocturnal_experiments.py
    â”‚   â”œâ”€â”€ prandial_experiments.py
    â”‚   â””â”€â”€ ablation_experiments.py
    â””â”€â”€ [existing directories...]
```

## Key Components

### 1. Unified Model Architecture (`src/models/`)

#### Base Model Framework
```python
# src/models/base/base_model.py
class BaseTimeSeriesFoundationModel(ABC):
    """Abstract base class for all Time Series Foundation Models"""

    def __init__(self, config: ModelConfig):
        self.config = config
        self.distributed_strategy = None
        self.lora_config = None

    @abstractmethod
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        pass

    def setup_distributed(self, strategy: str = "ddp"):
        """Configure distributed training strategy"""
        pass

    def enable_lora(self, lora_config: LoRAConfig):
        """Enable LoRA for memory-efficient fine-tuning"""
        pass
```

#### Model-Specific Implementations
Each model (TTM, Chronos, etc.) inherits from `BaseTimeSeriesFoundationModel` and implements:
- Model-specific architecture
- Custom training procedures
- Distributed training optimizations
- LoRA integration points

### 2. Training Pipeline (`src/training/`)

#### Unified Training Interface
```python
# src/training/core/trainer_factory.py
class TrainerFactory:
    @staticmethod
    def create_trainer(model_type: str, config: TrainingConfig):
        """Factory method to create appropriate trainer"""
        trainers = {
            "ttm": TTMTrainer,
            "chronos": ChronosTrainer,
            "timegpt": TimeGPTTrainer,
            # ... other models
        }
        return trainers[model_type](config)
```

#### Distributed Training Support
- **PyTorch DDP**: For most models, configurable per model type
- **DeepSpeed**: For large models requiring advanced memory optimization
- **Automatic GPU Detection**: Scripts auto-detect available GPUs and configure accordingly

### 3. Configuration Management (`configs/`)

#### Hierarchical Configuration Structure
- **Model Configs**: Model-specific parameters, architecture settings
- **Training Configs**: Distributed training settings, optimization parameters
- **Data Configs**: Dataset specifications, preprocessing parameters
- **Experiment Configs**: End-to-end experiment definitions

#### Configuration Composition
```yaml
# configs/experiments/nocturnal/ttm_point_forecast.yaml
model:
  type: ttm
  config: !include ../models/ttm/fine_tune.yaml

training:
  config: !include ../training/multi_gpu_ddp.yaml

data:
  datasets: !include ../data/multi_dataset.yaml

evaluation:
  config: !include ../evaluation/standard_metrics.yaml
```

### 4. Experiment Management (`src/experiments/`)

#### Experiment Framework
```python
# src/experiments/base/experiment.py
class BaseExperiment:
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.registry = ExperimentRegistry()

    def setup_data(self):
        """Setup data pipelines with proper train/test splits"""
        pass

    def setup_models(self):
        """Initialize models for comparison"""
        pass

    def run_training(self):
        """Execute training phase"""
        pass

    def run_evaluation(self):
        """Execute evaluation on holdout sets"""
        pass

    def generate_report(self):
        """Generate experiment report"""
        pass
```

#### Experiment Types
- **Nocturnal Experiments**: Night-time glucose forecasting
- **Prandial Experiments**: Meal-time glucose forecasting
- **Ablation Studies**: Data ablation experiments
- **Personalization**: Patient-specific model adaptation
- **Transfer Learning**: Cross-dataset, cross-CGM, cross-patient studies

### 5. Model Registry (`src/registry/`)

#### Simple Registry (Current Implementation)
```python
# src/registry/models/model_registry.py
class ModelRegistry:
    def __init__(self, registry_path: str = "trained_models/registry.csv"):
        self.registry_path = registry_path
        self.df = self._load_registry()

    def register_model(self, model_info: ModelInfo):
        """Register a newly trained model"""
        entry = {
            "model_id": f"{model_info.type}_{model_info.timestamp}",
            "model_type": model_info.type,
            "training_backend": model_info.strategy,  # fine_tune, from_scratch, etc.
            "dataset": model_info.dataset,
            "timestamp": model_info.timestamp,
            "artifact_path": model_info.artifact_path,
            "config_hash": model_info.config_hash,
            "git_commit": model_info.git_commit,
            "performance_metrics": json.dumps(model_info.metrics),
            "training_time_hours": model_info.training_time,
            "gpu_config": model_info.gpu_config
        }
        # Add to CSV and save
        pass

    def get_model(self, model_id: str) -> ModelInfo:
        """Retrieve model information"""
        pass

    def find_models(self, **filters) -> List[ModelInfo]:
        """Find models by criteria"""
        pass
```

#### Future MLflow Integration Points
- Registry designed to be easily migrated to MLflow
- Consistent metadata structure
- Artifact tracking preparation

### 6. Evaluation Pipeline (`src/evaluation/`)

#### Automated Evaluation
```python
# src/evaluation/evaluator.py
class ModelEvaluator:
    def __init__(self, config: EvaluationConfig):
        self.config = config
        self.metrics = self._load_metrics()

    def evaluate_model(self, model, test_datasets):
        """Evaluate model on multiple test sets"""
        results = {}
        for dataset_name, dataset in test_datasets.items():
            predictions = model.predict(dataset)
            dataset_results = {}

            for metric_name, metric in self.metrics.items():
                score = metric.compute(predictions, dataset.targets)
                dataset_results[metric_name] = score

            results[dataset_name] = dataset_results

        return results
```

#### Metrics Implementation
- **Regression Metrics**: RMSE, MSE, MAE, MAPE
- **Clinical Metrics**: Clarke Error Grid Analysis
- **Probabilistic Metrics**: For uncertainty quantification
- **Custom Metrics**: Domain-specific glucose forecasting metrics

### 7. Data Versioning (`src/data/versioning/`)

#### Simple Data Tracking
```python
# src/data/versioning/data_versioning.py
class DataVersionManager:
    def __init__(self):
        self.version_registry = {}

    def create_data_snapshot(self, dataset_config: dict) -> str:
        """Create a versioned snapshot of data configuration"""
        config_hash = hashlib.md5(
            json.dumps(dataset_config, sort_keys=True).encode()
        ).hexdigest()[:8]

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        version_id = f"{timestamp}_{config_hash}"

        self.version_registry[version_id] = {
            "config": dataset_config,
            "timestamp": timestamp,
            "hash": config_hash
        }

        return version_id
```

## Migration Plan for TTM Code

### Phase 1: Extract Common Functionality âœ… COMPLETED
1. **âœ… Identify Shared Code**: Analyzed TTM implementations and identified common patterns
2. **âœ… Create Base Classes**: Implemented unified `BaseTimeSeriesFoundationModel` class with distributed training support
3. **âœ… Extract TTM Model**: Refactored TTM implementation to use base framework

### Phase 2: Implement New Structure ðŸ”„ IN PROGRESS
1. **âœ… Create TTM Trainer**: Implemented TTM training with distributed support via transformers.Trainer
2. **âœ… Add Configuration**: Created enhanced TTMConfig with validation and factory methods
3. **ðŸ”„ Implement Registry**: Basic model artifact saving implemented, full registry system pending

### Phase 3: Testing and Validation ðŸ”„ EARLY STAGE
1. **ðŸ”„ Unit Tests**: Created basic example scripts for testing, comprehensive unit tests needed
2. **ðŸ”„ Integration Tests**: Basic distributed training pipeline working, full integration test suite pending
3. **ðŸ”„ Performance Validation**: Initial distributed training verified, comprehensive benchmarking needed

### Phase 4: Documentation and Tooling ðŸ”„ IN PROGRESS
1. **âœ… Basic Example Scripts**: Created hardware diagnostics and distributed setup validation
2. **ðŸ”„ User Documentation**: Started with example guide, comprehensive docs needed
3. **ðŸ“‹ Migration Support**: Enhanced logging implemented, migration scripts and guides pending

## Implementation Roadmap

### Week 1: Foundation Setup
- [X] Create new directory structure
- [X] Implement base model classes
- [X] Set up configuration management system

### Week 2: Training Pipeline
- [X] Implement unified training framework
- [X] Add distributed training support
- [X] Create SLURM integration scripts

### Week 3: Model Implementation
- [X] Migrate TTM to new structure
- [X] Implement comprehensive TTM distributed training
- [X] Add LoRA support framework
- [X] Enhanced TTM configuration system
- [ ] Implement Chronos integration
- [ ] Add TimeGPT integration

### Week 4: Experiment Framework
- [ðŸ”„] Create experiment management system - **FOUNDATION LAID**: Basic infrastructure in place, automation pending
- [ðŸ”„] Implement evaluation pipeline - **FOUNDATION LAID**: Evaluation concepts designed, implementation needed
- [ðŸ”„] Set up model registry - **BASIC IMPLEMENTATION**: Artifact saving working, full registry system pending

### Week 5: Integration and Testing
- [ðŸ”„] End-to-end testing - **BASIC VALIDATION**: Distributed training works, comprehensive testing needed
- [âœ…] Performance optimization - **INITIAL OPTIMIZATION**: DDP configuration optimized, more benchmarking needed
- [ðŸ”„] Documentation - **STARTED**: Example guide created, comprehensive documentation pending

### Additional Achievements (Beyond Original Plan)
- [âœ…] **Rank-aware logging system** - Eliminates duplicate messages in distributed training
- [âœ…] **Debug-enabled logging** - Environment-controlled debug output
- [ðŸ”„] **Example scripts framework** - Basic hardware diagnostics and setup validation created, more comprehensive suite needed
- [âœ…] **Enhanced error handling** - Proper cleanup and resource management for distributed training
- [âœ…] **JSON serialization fixes** - Full configuration serialization support
- [ðŸ”„] **Documentation foundation** - User guide started, comprehensive docs and API references needed
- [âœ…] **Distributed training foundation** - Core multi-GPU workflow implemented, production hardening pending

### Still Needed for Full Implementation
- **ðŸ”² Comprehensive Model Registry**: CSV-based system â†’ full registry with versioning, metadata, querying
- **ðŸ”² Experiment Management**: Automated experiment runners, result aggregation, comparison tools
- **ðŸ”² Evaluation Pipeline**: Centralized metrics computation, clinical evaluation, probabilistic forecasting metrics
- **ðŸ”² Unit & Integration Tests**: Comprehensive test suite for all components
- **ðŸ”² Performance Benchmarking**: Systematic performance validation across hardware configurations
- **ðŸ”² Additional Model Integrations**: Chronos, TimeGPT, TSMixer implementations
- **ðŸ”² Migration Tools**: Scripts for moving existing models/experiments to new structure
- **ðŸ”² Production Deployment**: SLURM integration, cluster deployment, monitoring

## Entry Points

### Training Script
```bash
# scripts/training/train_model.py
python scripts/training/train_model.py \
    --model ttm \
    --experiment nocturnal_point_forecast \
    --config configs/experiments/nocturnal/ttm_point_forecast.yaml \
    --distributed multi_gpu
```

### SLURM Integration
```bash
# scripts/training/slurm/multi_gpu.sh
#!/bin/bash
#SBATCH --job-name=ttm_training
#SBATCH --gres=gpu:2
#SBATCH --mem=32G

python scripts/training/train_model.py \
    --model $MODEL_TYPE \
    --experiment $EXPERIMENT_TYPE \
    --config $CONFIG_PATH \
    --distributed multi_gpu
```

### Experiment Runner
```bash
# scripts/experiments/run_experiment.py
python scripts/experiments/run_experiment.py \
    --experiment_type nocturnal \
    --models ttm,chronos,timegpt \
    --datasets kaggle_bris_t1d,aleppo \
    --output_dir experiments/nocturnal_forecast/model_comparison_2025_11_17
```

## Benefits of This Reorganization

### 1. **Scalability**
- Modular architecture supports easy addition of new models
- Distributed training ready for large-scale experiments
- Configuration system scales to complex multi-model studies

### 2. **Reproducibility**
- Comprehensive experiment tracking
- Version control for data, models, and configurations
- Automated environment and dependency tracking

### 3. **Maintainability**
- Clear separation of concerns
- Reduced code duplication
- Consistent interfaces across models

### 4. **Research Productivity**
- Automated experiment pipeline
- Easy model comparison
- Standardized evaluation metrics

### 5. **Future-Proofing**
- MLflow integration ready
- Model serving preparation
- Extensible registry system

## Configuration Examples

### Model Configuration
```yaml
# configs/models/ttm/fine_tune.yaml
model_type: ttm
architecture:
  d_model: 512
  n_heads: 8
  n_layers: 6
  context_length: 512
  prediction_length: 96

training:
  strategy: fine_tuning
  base_model_path: "huggingface/ttm-1.5B"

lora:
  enabled: true
  rank: 16
  alpha: 32
  target_modules: ["q_proj", "v_proj"]

optimization:
  optimizer: adamw
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_steps: 1000
```

### Experiment Configuration
```yaml
# configs/experiments/nocturnal/ttm_vs_chronos.yaml
experiment_name: "TTM vs Chronos Nocturnal Forecasting"
experiment_type: nocturnal

models:
  - type: ttm
    config: !include ../../models/ttm/fine_tune.yaml
  - type: chronos
    config: !include ../../models/chronos/base.yaml

data:
  datasets:
    - kaggle_bris_t1d
    - aleppo
  splits:
    temporal_holdout: 0.2  # Last 20% of data
    patient_holdout: 0.15  # 15% of patients

training:
  distributed: true
  gpu_strategy: ddp
  max_epochs: 50
  early_stopping:
    patience: 10
    metric: val_rmse

evaluation:
  metrics:
    - rmse
    - mae
    - mape
    - clarke_error_grid
  test_sets:
    - temporal_holdout
    - patient_holdout
```

This reorganization plan provides a solid foundation for scalable TSFM research while maintaining the flexibility needed for academic experimentation. The structure follows modern ML engineering practices and can easily be extended as the project grows.
