Using configuration file: models/configs/ttm_gpu_optimization/aleppo_experiment/ttm_high_performance_config_test_run.yaml

=== Environment Check ===
Job started at: 2025-11-11 03:11:50 UTC
Job ID: 1364858
Node: watgpu608
Run Directory: /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858
Virtual Environment source python path: /u6/cjrisi/nocturnal/.noctprob-venv/bin/python
Python Version: Python 3.11.4
Python internal path check: /u6/cjrisi/nocturnal/.noctprob-venv/bin/python

=== GPU Information ===
Tue Nov 11 03:11:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:04:00.0 Off |                    0 |
| N/A   27C    P8             31W /  350W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
GPU Driver Version: 575.57.08
GPU Name: NVIDIA L40S
GPU Memory: 46068 MiB
=====================================

=== Model Registry Initialization ===
Registering run in model registry...
Registered run: run_20251111_031145_job1364858

=== GPU Monitoring Log Setup ===
Starting GPU monitoring...
Started GPU monitoring (PID: 1537757) and utilization logging (PID: 1537758)

=== Starting Training ===
Training started at: 2025-11-11 03:11:52 UTC
Running command:
  python /u6/cjrisi/nocturnal/src/train/ttm_runner.py \
    --run-dir "/u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858"
    --config "/u6/cjrisi/nocturnal/models/configs/ttm_gpu_optimization/aleppo_experiment/ttm_high_performance_config_test_run.yaml"

2025-11-11 03:12:01.538691: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-11 03:12:01.984797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762830722.123354 1537765 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762830722.160388 1537765 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762830722.550530 1537765 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762830722.550568 1537765 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762830722.550572 1537765 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762830722.550575 1537765 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-11 03:12:02.584211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-11T03:12:09 - TensorFlow version 2.19.1 available.
INFO: [info_print] [main] =====================================
INFO: [info_print] [main] === TTM Runner Starting ===
INFO: [info_print] [main] Loading configuration from: /u6/cjrisi/nocturnal/models/configs/ttm_gpu_optimization/aleppo_experiment/ttm_high_performance_config_test_run.yaml
INFO: [info_print] [main] Configuration saved to: /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858/experiment_config.yaml
INFO: [info_print] [main] =====================================
INFO: [info_print] [main] === Calling finetune_ttm() ===
INFO: [finetune_ttm] -------------------- Preparing data... -------------------- 

Traceback (most recent call last):
  File "/u6/cjrisi/nocturnal/src/train/ttm_runner.py", line 185, in <module>
    main()
  File "/u6/cjrisi/nocturnal/src/train/ttm_runner.py", line 44, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/u6/cjrisi/nocturnal/src/train/ttm_runner.py", line 116, in main
    metrics = finetune_ttm(
              ^^^^^^^^^^^^^
  File "/u6/cjrisi/nocturnal/src/train/ttm.py", line 606, in finetune_ttm
    data_dict = load_processed_data_from_cache(data_source_name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u6/cjrisi/nocturnal/src/train/ttm.py", line 306, in load_processed_data_from_cache
    raise FileNotFoundError(f"No processed CSV files found in {cache_dir}")
FileNotFoundError: No processed CSV files found in /u6/cjrisi/nocturnal/cache/data/aleppo/processed
Training finished at: 2025-11-11 03:12:19 UTC
Training exit code: 0
Total elapsed time: 0h 0m 34s (34 seconds)
Run completed. Logs and monitoring data saved to: /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858
Updating model registry with completion info...
Warning: Could not load metrics: name 'os' is not defined
Updated registry for run: run_20251111_031145_job1364858 with status: completed
All run data and logs saved to: /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858
Configuration and results tracked in model registry
Moving SLURM output files to run directory...
Moved SLURM output file to /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858/
Moved SLURM error file to /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251111_031145_job1364858/
