Using configuration file: models/configs/ttm_gpu_optimization/aleppo_experiment/ttm_high_performance_config_128batch.yaml

=== Environment Check ===
Job started at: 2025-11-12 16:21:16 UTC
Job ID: 1364977
Node: watgpu608
Run Directory: /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251112_162110_job1364977
Virtual Environment source python path: /u6/cjrisi/nocturnal/.noctprob-venv/bin/python
Python Version: Python 3.11.4
Python internal path check: /u6/cjrisi/nocturnal/.noctprob-venv/bin/python

=== GPU Information ===
Wed Nov 12 16:21:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:04:00.0 Off |                    0 |
| N/A   33C    P8             46W /  350W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
GPU Driver Version: 575.57.08
GPU Name: NVIDIA L40S
GPU Memory: 46068 MiB
=====================================

=== Model Registry Initialization ===
Registering run in model registry...
Registered run: run_20251112_162110_job1364977

=== GPU Monitoring Log Setup ===
Starting GPU monitoring...
Started GPU monitoring (PID: 1714295) and utilization logging (PID: 1714296)

=== Starting Training ===
Training started at: 2025-11-12 16:21:17 UTC
Running command:
  python /u6/cjrisi/nocturnal/src/train/ttm_runner.py \
    --run-dir "/u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251112_162110_job1364977"
    --config "/u6/cjrisi/nocturnal/models/configs/ttm_gpu_optimization/aleppo_experiment/ttm_high_performance_config_128batch.yaml"

2025-11-12 16:21:23.582751: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:21:23.594223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964483.607467 1714303 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964483.611526 1714303 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964483.622809 1714303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964483.622824 1714303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964483.622826 1714303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964483.622828 1714303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:21:23.626017: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:21:28 - TensorFlow version 2.19.1 available.
INFO: [info_print] [main] =====================================
INFO: [info_print] [main] === TTM Runner Starting ===
INFO: [info_print] [main] Loading configuration from: /u6/cjrisi/nocturnal/models/configs/ttm_gpu_optimization/aleppo_experiment/ttm_high_performance_config_128batch.yaml
INFO: [info_print] [main] Configuration saved to: /u6/cjrisi/nocturnal/results/runs/ttm_finetune/run_20251112_162110_job1364977/experiment_config.yaml
INFO: [info_print] [main] =====================================
INFO: [info_print] [main] === Calling finetune_ttm() ===
INFO: [finetune_ttm] -------------------- Preparing data... -------------------- 

INFO: [load_processed_data_from_cache] Found 226 processed CSV files in /u6/cjrisi/nocturnal/cache/data/awesome_cgm/aleppo/processed
INFO: [load_processed_data_from_cache] Loaded p40_full: 63574 rows
INFO: [load_processed_data_from_cache] Loaded p205_full: 74507 rows
INFO: [load_processed_data_from_cache] Loaded p108_full: 63893 rows
INFO: [load_processed_data_from_cache] Loaded p252_full: 54063 rows
INFO: [load_processed_data_from_cache] Loaded p18_full: 69911 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p17_full: 68190 rows
INFO: [load_processed_data_from_cache] Loaded p50_full: 62048 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p215_full: 66511 rows
INFO: [load_processed_data_from_cache] Loaded p118_full: 52104 rows
INFO: [load_processed_data_from_cache] Loaded p140_full: 63209 rows
INFO: [load_processed_data_from_cache] Loaded p86_full: 54947 rows
INFO: [load_processed_data_from_cache] Loaded p127_full: 60852 rows
INFO: [load_processed_data_from_cache] Loaded p128_full: 45570 rows
INFO: [load_processed_data_from_cache] Loaded p89_full: 45674 rows
INFO: [load_processed_data_from_cache] Loaded p60_full: 70940 rows
INFO: [load_processed_data_from_cache] Loaded p37_full: 55739 rows
INFO: [load_processed_data_from_cache] Loaded p38_full: 63297 rows
INFO: [load_processed_data_from_cache] Loaded p170_full: 61055 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p272_full: 67973 rows
INFO: [load_processed_data_from_cache] Loaded p138_full: 27341 rows
INFO: [load_processed_data_from_cache] Loaded p235_full: 45532 rows
INFO: [load_processed_data_from_cache] Loaded p137_full: 71973 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p96_full: 61366 rows
INFO: [load_processed_data_from_cache] Loaded p70_full: 77417 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p284_full: 52904 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p189_full: 70822 rows
INFO: [load_processed_data_from_cache] Loaded p186_full: 39954 rows
INFO: [load_processed_data_from_cache] Loaded p27_full: 59633 rows
INFO: [load_processed_data_from_cache] Loaded p160_full: 65492 rows
INFO: [load_processed_data_from_cache] Loaded p58_full: 56951 rows
INFO: [load_processed_data_from_cache] Loaded p57_full: 53503 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p110_full: 41398 rows
INFO: [load_processed_data_from_cache] Loaded p245_full: 76428 rows
INFO: [load_processed_data_from_cache] Loaded p148_full: 59839 rows
INFO: [load_processed_data_from_cache] Loaded p147_full: 62689 rows
INFO: [load_processed_data_from_cache] Loaded p47_full: 49063 rows
INFO: [load_processed_data_from_cache] Loaded p48_full: 69002 rows
INFO: [load_processed_data_from_cache] Loaded p157_full: 57649 rows
INFO: [load_processed_data_from_cache] Loaded p158_full: 69787 rows
INFO: [load_processed_data_from_cache] Loaded p10_full: 53115 rows
INFO: [load_processed_data_from_cache] Loaded p91_full: 57276 rows
INFO: [load_processed_data_from_cache] Loaded p130_full: 81935 rows
INFO: [load_processed_data_from_cache] Loaded p232_full: 69982 rows
INFO: [load_processed_data_from_cache] Loaded p77_full: 84823 rows
INFO: [load_processed_data_from_cache] Loaded p78_full: 56273 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p20_full: 57934 rows
INFO: [load_processed_data_from_cache] Loaded p181_full: 40809 rows
INFO: [load_processed_data_from_cache] Loaded p283_full: 62985 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p167_full: 41146 rows
INFO: [load_processed_data_from_cache] Loaded p168_full: 68444 rows
INFO: [load_processed_data_from_cache] Loaded p265_full: 30692 rows
INFO: [load_processed_data_from_cache] Loaded p222_full: 63418 rows
INFO: [load_processed_data_from_cache] Loaded p81_full: 3748 rows
INFO: [load_processed_data_from_cache] Loaded p68_full: 69044 rows
INFO: [load_processed_data_from_cache] Loaded p67_full: 66239 rows
INFO: [load_processed_data_from_cache] Loaded p293_full: 61533 rows
INFO: [load_processed_data_from_cache] Loaded p30_full: 65118 rows
INFO: [load_processed_data_from_cache] Loaded p275_full: 64176 rows
INFO: [load_processed_data_from_cache] Loaded p3_full: 73092 rows
INFO: [load_processed_data_from_cache] Loaded p177_full: 50651 rows
INFO: [load_processed_data_from_cache] Loaded p61_full: 71357 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p224_full: 67285 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p129_full: 71969 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p87_full: 66102 rows
INFO: [load_processed_data_from_cache] Loaded p5_full: 51932 rows
INFO: [load_processed_data_from_cache] Loaded p273_full: 70792 rows
INFO: [load_processed_data_from_cache] Loaded p171_full: 58677 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p198_full: 73818 rows
INFO: [load_processed_data_from_cache] Loaded p39_full: 28081 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p36_full: 67868 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p197_full: 66135 rows
INFO: [load_processed_data_from_cache] Loaded p71_full: 70181 rows
INFO: [load_processed_data_from_cache] Loaded p136_full: 72876 rows
INFO: [load_processed_data_from_cache] Loaded p97_full: 64872 rows
INFO: [load_processed_data_from_cache] Loaded p234_full: 70777 rows
INFO: [load_processed_data_from_cache] Loaded p98_full: 48505 rows
INFO: [load_processed_data_from_cache] Loaded p139_full: 74414 rows
INFO: [load_processed_data_from_cache] Loaded p263_full: 77576 rows
INFO: [load_processed_data_from_cache] Loaded p187_full: 73678 rows
INFO: [load_processed_data_from_cache] Loaded p26_full: 66651 rows
INFO: [load_processed_data_from_cache] Loaded p29_full: 66553 rows
INFO: [load_processed_data_from_cache] Loaded p188_full: 70756 rows
INFO: [load_processed_data_from_cache] Loaded p285_full: 64699 rows
INFO: [load_processed_data_from_cache] Loaded p106_full: 70741 rows
INFO: [load_processed_data_from_cache] Loaded p109_full: 44267 rows
INFO: [load_processed_data_from_cache] Loaded p204_full: 59220 rows
INFO: [load_processed_data_from_cache] Loaded p41_full: 61702 rows
INFO: [load_processed_data_from_cache] Loaded p16_full: 68915 rows
INFO: [load_processed_data_from_cache] Loaded p19_full: 10852 rows
INFO: [load_processed_data_from_cache] Loaded p253_full: 66365 rows
INFO: [load_processed_data_from_cache] Loaded p119_full: 63765 rows
INFO: [load_processed_data_from_cache] Loaded p214_full: 75174 rows
INFO: [load_processed_data_from_cache] Loaded p116_full: 72473 rows
INFO: [load_processed_data_from_cache] Loaded p243_full: 78544 rows
INFO: [load_processed_data_from_cache] Loaded p141_full: 53561 rows
INFO: [load_processed_data_from_cache] Loaded p79_full: 70136 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p76_full: 66679 rows
INFO: [load_processed_data_from_cache] Loaded p233_full: 68396 rows
INFO: [load_processed_data_from_cache] Loaded p90_full: 68258 rows
INFO: [load_processed_data_from_cache] Loaded p131_full: 60284 rows
INFO: [load_processed_data_from_cache] Loaded p264_full: 45257 rows
INFO: [load_processed_data_from_cache] Loaded p169_full: 58119 rows
INFO: [load_processed_data_from_cache] Loaded p166_full: 73846 rows
INFO: [load_processed_data_from_cache] Loaded p21_full: 52289 rows
INFO: [load_processed_data_from_cache] Loaded p69_full: 51779 rows
INFO: [load_processed_data_from_cache] Loaded p121_full: 64655 rows
INFO: [load_processed_data_from_cache] Loaded p80_full: 49761 rows
INFO: [load_processed_data_from_cache] Loaded p223_full: 18864 rows
INFO: [load_processed_data_from_cache] Loaded p176_full: 66316 rows
INFO: [load_processed_data_from_cache] Loaded p2_full: 67549 rows
INFO: [load_processed_data_from_cache] Loaded p274_full: 71778 rows
INFO: [load_processed_data_from_cache] Loaded p179_full: 65429 rows
INFO: [load_processed_data_from_cache] Loaded p190_full: 66016 rows
INFO: [load_processed_data_from_cache] Loaded p31_full: 68632 rows
INFO: [load_processed_data_from_cache] Loaded p292_full: 61502 rows
INFO: [load_processed_data_from_cache] Loaded p111_full: 85006 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p213_full: 65797 rows
INFO: [load_processed_data_from_cache] Loaded p146_full: 73314 rows
INFO: [load_processed_data_from_cache] Loaded p149_full: 62466 rows
INFO: [load_processed_data_from_cache] Loaded p244_full: 54190 rows
INFO: [load_processed_data_from_cache] Loaded p203_full: 23784 rows
INFO: [load_processed_data_from_cache] Loaded p101_full: 50666 rows
INFO: [load_processed_data_from_cache] Loaded p49_full: 51069 rows
INFO: [load_processed_data_from_cache] Loaded p46_full: 58162 rows
INFO: [load_processed_data_from_cache] Loaded p11_full: 62069 rows
INFO: [load_processed_data_from_cache] Loaded p254_full: 57800 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p156_full: 70766 rows
INFO: [load_processed_data_from_cache] Loaded p145_full: 31238 rows
INFO: [load_processed_data_from_cache] Loaded p248_full: 45690 rows
INFO: [load_processed_data_from_cache] Loaded p247_full: 71768 rows
INFO: [load_processed_data_from_cache] Loaded p112_full: 55352 rows
INFO: [load_processed_data_from_cache] Loaded p210_full: 49995 rows
INFO: [load_processed_data_from_cache] Loaded p55_full: 51696 rows
INFO: [load_processed_data_from_cache] Loaded p257_full: 44354 rows
INFO: [load_processed_data_from_cache] Loaded p155_full: 76570 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p258_full: 71476 rows
INFO: [load_processed_data_from_cache] Loaded p200_full: 61863 rows
INFO: [load_processed_data_from_cache] Loaded p102_full: 78556 rows
INFO: [load_processed_data_from_cache] Loaded p45_full: 57391 rows
INFO: [load_processed_data_from_cache] Loaded p267_full: 47447 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p165_full: 69816 rows
INFO: [load_processed_data_from_cache] Loaded p281_full: 63230 rows
INFO: [load_processed_data_from_cache] Loaded p183_full: 64888 rows
INFO: [load_processed_data_from_cache] Loaded p22_full: 59741 rows
INFO: [load_processed_data_from_cache] Loaded p132_full: 39016 rows
INFO: [load_processed_data_from_cache] Loaded p93_full: 63213 rows
INFO: [load_processed_data_from_cache] Loaded p278_full: 72415 rows
INFO: [load_processed_data_from_cache] Loaded p175_full: 71049 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p277_full: 87660 rows
INFO: [load_processed_data_from_cache] Loaded p32_full: 71860 rows
INFO: [load_processed_data_from_cache] Loaded p193_full: 80628 rows
INFO: [load_processed_data_from_cache] Loaded p291_full: 62062 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p65_full: 73591 rows
INFO: [load_processed_data_from_cache] Loaded p220_full: 71018 rows
INFO: [load_processed_data_from_cache] Loaded p15_full: 63920 rows
INFO: [load_processed_data_from_cache] Loaded p152_full: 62763 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p250_full: 76618 rows
INFO: [load_processed_data_from_cache] Loaded p105_full: 77616 rows
INFO: [load_processed_data_from_cache] Loaded p42_full: 50046 rows
INFO: [load_processed_data_from_cache] Loaded p240_full: 70783 rows
INFO: [load_processed_data_from_cache] Loaded p217_full: 46167 rows
INFO: [load_processed_data_from_cache] Loaded p115_full: 61861 rows
INFO: [load_processed_data_from_cache] Loaded p218_full: 71232 rows
INFO: [load_processed_data_from_cache] Loaded p52_full: 27597 rows
INFO: [load_processed_data_from_cache] Loaded p9_full: 54554 rows
INFO: [load_processed_data_from_cache] Loaded p172_full: 65862 rows
INFO: [load_processed_data_from_cache] Loaded p35_full: 63468 rows
INFO: [load_processed_data_from_cache] Loaded p62_full: 57857 rows
INFO: [load_processed_data_from_cache] Loaded p227_full: 58942 rows
INFO: [load_processed_data_from_cache] Loaded p228_full: 77545 rows
INFO: [load_processed_data_from_cache] Loaded p162_full: 36133 rows
INFO: [load_processed_data_from_cache] Loaded p260_full: 36980 rows
INFO: [load_processed_data_from_cache] Loaded p184_full: 49068 rows
INFO: [load_processed_data_from_cache] Loaded p289_full: 15516 rows
INFO: [load_processed_data_from_cache] Loaded p72_full: 58895 rows
INFO: [load_processed_data_from_cache] Loaded p135_full: 72513 rows
INFO: [load_processed_data_from_cache] Loaded p23_full: 72627 rows
INFO: [load_processed_data_from_cache] Loaded p280_full: 57564 rows
INFO: [load_processed_data_from_cache] Loaded p164_full: 74845 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p269_full: 71689 rows
INFO: [load_processed_data_from_cache] Loaded p266_full: 25428 rows
INFO: [load_processed_data_from_cache] Loaded p231_full: 68602 rows
INFO: [load_processed_data_from_cache] Loaded p74_full: 72529 rows
INFO: [load_processed_data_from_cache] Loaded p290_full: 61237 rows
INFO: [load_processed_data_from_cache] Loaded p33_full: 70997 rows
INFO: [load_processed_data_from_cache] Loaded p276_full: 68440 rows
INFO: [load_processed_data_from_cache] Loaded p174_full: 60402 rows
INFO: [load_processed_data_from_cache] Loaded p221_full: 57449 rows
INFO: [load_processed_data_from_cache] Loaded p82_full: 62828 rows
INFO: [load_processed_data_from_cache] Loaded p123_full: 74002 rows
INFO: [load_processed_data_from_cache] Loaded p64_full: 67825 rows
INFO: [load_processed_data_from_cache] Loaded p246_full: 64151 rows
INFO: [load_processed_data_from_cache] Loaded p249_full: 29288 rows
INFO: [load_processed_data_from_cache] Loaded p54_full: 62443 rows
INFO: [load_processed_data_from_cache] Loaded p211_full: 61675 rows
INFO: [load_processed_data_from_cache] Loaded p113_full: 52374 rows
INFO: [load_processed_data_from_cache] Loaded p256_full: 57532 rows
INFO: [load_processed_data_from_cache] Loaded p103_full: 64837 rows
INFO: [load_processed_data_from_cache] Loaded p201_full: 64829 rows
INFO: [load_processed_data_from_cache] Loaded p173_full: 64750 rows
INFO: [load_processed_data_from_cache] Loaded p8_full: 52927 rows
INFO: [load_processed_data_from_cache] Loaded p271_full: 68120 rows
INFO: [load_processed_data_from_cache] Loaded p7_full: 78157 rows
INFO: [load_processed_data_from_cache] Loaded p124_full: 70494 rows
INFO: [load_processed_data_from_cache] Loaded p229_full: 56591 rows
INFO: [load_processed_data_from_cache] Loaded p226_full: 57827 rows
INFO: [load_processed_data_from_cache] Loaded p287_full: 63823 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p288_full: 66734 rows
INFO: [load_processed_data_from_cache] Loaded p24_full: 56758 rows
INFO: [load_processed_data_from_cache] Loaded p185_full: 70779 rows
INFO: [load_processed_data_from_cache] Loaded p163_full: 65012 rows
INFO: [load_processed_data_from_cache] Loaded p236_full: 44437 rows
INFO: [load_processed_data_from_cache] Loaded p95_full: 77578 rows
INFO: [load_processed_data_from_cache] Loaded p134_full: 71944 rows
INFO: [load_processed_data_from_cache] Loaded p239_full: 62149 rows
INFO: [load_processed_data_from_cache] Loaded p73_full: 44251 rows
INFO: [load_processed_data_from_cache] Loaded p251_full: 70600 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p14_full: 70986 rows
INFO: [load_processed_data_from_cache] Loaded p43_full: 62676 rows
INFO: [load_processed_data_from_cache] Loaded p206_full: 69076 rows
INFO: [load_processed_data_from_cache] Loaded p209_full: 48888 rows
/u6/cjrisi/nocturnal/src/train/ttm.py:320: DtypeWarning: Columns (3,13) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(csv_file, index_col=0, parse_dates=True)
INFO: [load_processed_data_from_cache] Loaded p143_full: 65621 rows
INFO: [load_processed_data_from_cache] Loaded p241_full: 67492 rows
INFO: [load_processed_data_from_cache] Loaded p53_full: 71434 rows
INFO: [load_processed_data_from_cache] Loaded p219_full: 66868 rows
INFO: [load_processed_data_from_cache] Loaded p216_full: 12648 rows
INFO: [load_processed_data_from_cache] Successfully loaded 226 patients
INFO: [reduce_features_multi_patient] Processing patient p40_full...
INFO: [reduce_features_multi_patient] Processing patient p205_full...
INFO: [reduce_features_multi_patient] Processing patient p108_full...
INFO: [reduce_features_multi_patient] Processing patient p252_full...
INFO: [reduce_features_multi_patient] Processing patient p18_full...
INFO: [reduce_features_multi_patient] Processing patient p17_full...
INFO: [reduce_features_multi_patient] Processing patient p50_full...
INFO: [reduce_features_multi_patient] Processing patient p215_full...
INFO: [reduce_features_multi_patient] Processing patient p118_full...
INFO: [reduce_features_multi_patient] Processing patient p140_full...
INFO: [reduce_features_multi_patient] Processing patient p86_full...
INFO: [reduce_features_multi_patient] Processing patient p127_full...
INFO: [reduce_features_multi_patient] Processing patient p128_full...
INFO: [reduce_features_multi_patient] Processing patient p89_full...
INFO: [reduce_features_multi_patient] Processing patient p60_full...
INFO: [reduce_features_multi_patient] Processing patient p37_full...
INFO: [reduce_features_multi_patient] Processing patient p38_full...
INFO: [reduce_features_multi_patient] Processing patient p170_full...
INFO: [reduce_features_multi_patient] Processing patient p272_full...
INFO: [reduce_features_multi_patient] Processing patient p138_full...
INFO: [reduce_features_multi_patient] Processing patient p235_full...
INFO: [reduce_features_multi_patient] Processing patient p137_full...
INFO: [reduce_features_multi_patient] Processing patient p96_full...
INFO: [reduce_features_multi_patient] Processing patient p70_full...
INFO: [reduce_features_multi_patient] Processing patient p284_full...
INFO: [reduce_features_multi_patient] Processing patient p189_full...
INFO: [reduce_features_multi_patient] Processing patient p186_full...
INFO: [reduce_features_multi_patient] Processing patient p27_full...
INFO: [reduce_features_multi_patient] Processing patient p160_full...
INFO: [reduce_features_multi_patient] Processing patient p58_full...
INFO: [reduce_features_multi_patient] Processing patient p57_full...
INFO: [reduce_features_multi_patient] Processing patient p110_full...
INFO: [reduce_features_multi_patient] Processing patient p245_full...
INFO: [reduce_features_multi_patient] Processing patient p148_full...
INFO: [reduce_features_multi_patient] Processing patient p147_full...
INFO: [reduce_features_multi_patient] Processing patient p47_full...
INFO: [reduce_features_multi_patient] Processing patient p48_full...
INFO: [reduce_features_multi_patient] Processing patient p157_full...
INFO: [reduce_features_multi_patient] Processing patient p158_full...
INFO: [reduce_features_multi_patient] Processing patient p10_full...
INFO: [reduce_features_multi_patient] Processing patient p91_full...
INFO: [reduce_features_multi_patient] Processing patient p130_full...
INFO: [reduce_features_multi_patient] Processing patient p232_full...
INFO: [reduce_features_multi_patient] Processing patient p77_full...
INFO: [reduce_features_multi_patient] Processing patient p78_full...
INFO: [reduce_features_multi_patient] Processing patient p20_full...
INFO: [reduce_features_multi_patient] Processing patient p181_full...
INFO: [reduce_features_multi_patient] Processing patient p283_full...
INFO: [reduce_features_multi_patient] Processing patient p167_full...
INFO: [reduce_features_multi_patient] Processing patient p168_full...
INFO: [reduce_features_multi_patient] Processing patient p265_full...
INFO: [reduce_features_multi_patient] Processing patient p222_full...
INFO: [reduce_features_multi_patient] Processing patient p81_full...
INFO: [reduce_features_multi_patient] Processing patient p68_full...
INFO: [reduce_features_multi_patient] Processing patient p67_full...
INFO: [reduce_features_multi_patient] Processing patient p293_full...
INFO: [reduce_features_multi_patient] Processing patient p30_full...
INFO: [reduce_features_multi_patient] Processing patient p275_full...
INFO: [reduce_features_multi_patient] Processing patient p3_full...
INFO: [reduce_features_multi_patient] Processing patient p177_full...
INFO: [reduce_features_multi_patient] Processing patient p61_full...
INFO: [reduce_features_multi_patient] Processing patient p224_full...
INFO: [reduce_features_multi_patient] Processing patient p129_full...
INFO: [reduce_features_multi_patient] Processing patient p87_full...
INFO: [reduce_features_multi_patient] Processing patient p5_full...
INFO: [reduce_features_multi_patient] Processing patient p273_full...
INFO: [reduce_features_multi_patient] Processing patient p171_full...
INFO: [reduce_features_multi_patient] Processing patient p198_full...
INFO: [reduce_features_multi_patient] Processing patient p39_full...
INFO: [reduce_features_multi_patient] Processing patient p36_full...
INFO: [reduce_features_multi_patient] Processing patient p197_full...
INFO: [reduce_features_multi_patient] Processing patient p71_full...
INFO: [reduce_features_multi_patient] Processing patient p136_full...
INFO: [reduce_features_multi_patient] Processing patient p97_full...
INFO: [reduce_features_multi_patient] Processing patient p234_full...
INFO: [reduce_features_multi_patient] Processing patient p98_full...
INFO: [reduce_features_multi_patient] Processing patient p139_full...
INFO: [reduce_features_multi_patient] Processing patient p263_full...
INFO: [reduce_features_multi_patient] Processing patient p187_full...
INFO: [reduce_features_multi_patient] Processing patient p26_full...
INFO: [reduce_features_multi_patient] Processing patient p29_full...
INFO: [reduce_features_multi_patient] Processing patient p188_full...
INFO: [reduce_features_multi_patient] Processing patient p285_full...
INFO: [reduce_features_multi_patient] Processing patient p106_full...
INFO: [reduce_features_multi_patient] Processing patient p109_full...
INFO: [reduce_features_multi_patient] Processing patient p204_full...
INFO: [reduce_features_multi_patient] Processing patient p41_full...
INFO: [reduce_features_multi_patient] Processing patient p16_full...
INFO: [reduce_features_multi_patient] Processing patient p19_full...
INFO: [reduce_features_multi_patient] Processing patient p253_full...
INFO: [reduce_features_multi_patient] Processing patient p119_full...
INFO: [reduce_features_multi_patient] Processing patient p214_full...
INFO: [reduce_features_multi_patient] Processing patient p116_full...
INFO: [reduce_features_multi_patient] Processing patient p243_full...
INFO: [reduce_features_multi_patient] Processing patient p141_full...
INFO: [reduce_features_multi_patient] Processing patient p79_full...
INFO: [reduce_features_multi_patient] Processing patient p76_full...
INFO: [reduce_features_multi_patient] Processing patient p233_full...
INFO: [reduce_features_multi_patient] Processing patient p90_full...
INFO: [reduce_features_multi_patient] Processing patient p131_full...
INFO: [reduce_features_multi_patient] Processing patient p264_full...
INFO: [reduce_features_multi_patient] Processing patient p169_full...
INFO: [reduce_features_multi_patient] Processing patient p166_full...
INFO: [reduce_features_multi_patient] Processing patient p21_full...
INFO: [reduce_features_multi_patient] Processing patient p69_full...
INFO: [reduce_features_multi_patient] Processing patient p121_full...
INFO: [reduce_features_multi_patient] Processing patient p80_full...
INFO: [reduce_features_multi_patient] Processing patient p223_full...
INFO: [reduce_features_multi_patient] Processing patient p176_full...
INFO: [reduce_features_multi_patient] Processing patient p2_full...
INFO: [reduce_features_multi_patient] Processing patient p274_full...
INFO: [reduce_features_multi_patient] Processing patient p179_full...
INFO: [reduce_features_multi_patient] Processing patient p190_full...
INFO: [reduce_features_multi_patient] Processing patient p31_full...
INFO: [reduce_features_multi_patient] Processing patient p292_full...
INFO: [reduce_features_multi_patient] Processing patient p111_full...
INFO: [reduce_features_multi_patient] Processing patient p213_full...
INFO: [reduce_features_multi_patient] Processing patient p146_full...
INFO: [reduce_features_multi_patient] Processing patient p149_full...
INFO: [reduce_features_multi_patient] Processing patient p244_full...
INFO: [reduce_features_multi_patient] Processing patient p203_full...
INFO: [reduce_features_multi_patient] Processing patient p101_full...
INFO: [reduce_features_multi_patient] Processing patient p49_full...
INFO: [reduce_features_multi_patient] Processing patient p46_full...
INFO: [reduce_features_multi_patient] Processing patient p11_full...
INFO: [reduce_features_multi_patient] Processing patient p254_full...
INFO: [reduce_features_multi_patient] Processing patient p156_full...
INFO: [reduce_features_multi_patient] Processing patient p145_full...
INFO: [reduce_features_multi_patient] Processing patient p248_full...
INFO: [reduce_features_multi_patient] Processing patient p247_full...
INFO: [reduce_features_multi_patient] Processing patient p112_full...
INFO: [reduce_features_multi_patient] Processing patient p210_full...
INFO: [reduce_features_multi_patient] Processing patient p55_full...
INFO: [reduce_features_multi_patient] Processing patient p257_full...
INFO: [reduce_features_multi_patient] Processing patient p155_full...
INFO: [reduce_features_multi_patient] Processing patient p258_full...
INFO: [reduce_features_multi_patient] Processing patient p200_full...
INFO: [reduce_features_multi_patient] Processing patient p102_full...
INFO: [reduce_features_multi_patient] Processing patient p45_full...
INFO: [reduce_features_multi_patient] Processing patient p267_full...
INFO: [reduce_features_multi_patient] Processing patient p165_full...
INFO: [reduce_features_multi_patient] Processing patient p281_full...
INFO: [reduce_features_multi_patient] Processing patient p183_full...
INFO: [reduce_features_multi_patient] Processing patient p22_full...
INFO: [reduce_features_multi_patient] Processing patient p132_full...
INFO: [reduce_features_multi_patient] Processing patient p93_full...
INFO: [reduce_features_multi_patient] Processing patient p278_full...
INFO: [reduce_features_multi_patient] Processing patient p175_full...
INFO: [reduce_features_multi_patient] Processing patient p277_full...
INFO: [reduce_features_multi_patient] Processing patient p32_full...
INFO: [reduce_features_multi_patient] Processing patient p193_full...
INFO: [reduce_features_multi_patient] Processing patient p291_full...
INFO: [reduce_features_multi_patient] Processing patient p65_full...
INFO: [reduce_features_multi_patient] Processing patient p220_full...
INFO: [reduce_features_multi_patient] Processing patient p15_full...
INFO: [reduce_features_multi_patient] Processing patient p152_full...
INFO: [reduce_features_multi_patient] Processing patient p250_full...
INFO: [reduce_features_multi_patient] Processing patient p105_full...
INFO: [reduce_features_multi_patient] Processing patient p42_full...
INFO: [reduce_features_multi_patient] Processing patient p240_full...
INFO: [reduce_features_multi_patient] Processing patient p217_full...
INFO: [reduce_features_multi_patient] Processing patient p115_full...
INFO: [reduce_features_multi_patient] Processing patient p218_full...
INFO: [reduce_features_multi_patient] Processing patient p52_full...
INFO: [reduce_features_multi_patient] Processing patient p9_full...
INFO: [reduce_features_multi_patient] Processing patient p172_full...
INFO: [reduce_features_multi_patient] Processing patient p35_full...
INFO: [reduce_features_multi_patient] Processing patient p62_full...
INFO: [reduce_features_multi_patient] Processing patient p227_full...
INFO: [reduce_features_multi_patient] Processing patient p228_full...
INFO: [reduce_features_multi_patient] Processing patient p162_full...
INFO: [reduce_features_multi_patient] Processing patient p260_full...
INFO: [reduce_features_multi_patient] Processing patient p184_full...
INFO: [reduce_features_multi_patient] Processing patient p289_full...
INFO: [reduce_features_multi_patient] Processing patient p72_full...
INFO: [reduce_features_multi_patient] Processing patient p135_full...
INFO: [reduce_features_multi_patient] Processing patient p23_full...
INFO: [reduce_features_multi_patient] Processing patient p280_full...
INFO: [reduce_features_multi_patient] Processing patient p164_full...
INFO: [reduce_features_multi_patient] Processing patient p269_full...
INFO: [reduce_features_multi_patient] Processing patient p266_full...
INFO: [reduce_features_multi_patient] Processing patient p231_full...
INFO: [reduce_features_multi_patient] Processing patient p74_full...
INFO: [reduce_features_multi_patient] Processing patient p290_full...
INFO: [reduce_features_multi_patient] Processing patient p33_full...
INFO: [reduce_features_multi_patient] Processing patient p276_full...
INFO: [reduce_features_multi_patient] Processing patient p174_full...
INFO: [reduce_features_multi_patient] Processing patient p221_full...
INFO: [reduce_features_multi_patient] Processing patient p82_full...
INFO: [reduce_features_multi_patient] Processing patient p123_full...
INFO: [reduce_features_multi_patient] Processing patient p64_full...
INFO: [reduce_features_multi_patient] Processing patient p246_full...
INFO: [reduce_features_multi_patient] Processing patient p249_full...
INFO: [reduce_features_multi_patient] Processing patient p54_full...
INFO: [reduce_features_multi_patient] Processing patient p211_full...
INFO: [reduce_features_multi_patient] Processing patient p113_full...
INFO: [reduce_features_multi_patient] Processing patient p256_full...
INFO: [reduce_features_multi_patient] Processing patient p103_full...
INFO: [reduce_features_multi_patient] Processing patient p201_full...
INFO: [reduce_features_multi_patient] Processing patient p173_full...
INFO: [reduce_features_multi_patient] Processing patient p8_full...
INFO: [reduce_features_multi_patient] Processing patient p271_full...
INFO: [reduce_features_multi_patient] Processing patient p7_full...
INFO: [reduce_features_multi_patient] Processing patient p124_full...
INFO: [reduce_features_multi_patient] Processing patient p229_full...
INFO: [reduce_features_multi_patient] Processing patient p226_full...
INFO: [reduce_features_multi_patient] Processing patient p287_full...
INFO: [reduce_features_multi_patient] Processing patient p288_full...
INFO: [reduce_features_multi_patient] Processing patient p24_full...
INFO: [reduce_features_multi_patient] Processing patient p185_full...
INFO: [reduce_features_multi_patient] Processing patient p163_full...
INFO: [reduce_features_multi_patient] Processing patient p236_full...
INFO: [reduce_features_multi_patient] Processing patient p95_full...
INFO: [reduce_features_multi_patient] Processing patient p134_full...
INFO: [reduce_features_multi_patient] Processing patient p239_full...
INFO: [reduce_features_multi_patient] Processing patient p73_full...
INFO: [reduce_features_multi_patient] Processing patient p251_full...
INFO: [reduce_features_multi_patient] Processing patient p14_full...
INFO: [reduce_features_multi_patient] Processing patient p43_full...
INFO: [reduce_features_multi_patient] Processing patient p206_full...
INFO: [reduce_features_multi_patient] Processing patient p209_full...
INFO: [reduce_features_multi_patient] Processing patient p143_full...
INFO: [reduce_features_multi_patient] Processing patient p241_full...
INFO: [reduce_features_multi_patient] Processing patient p53_full...
INFO: [reduce_features_multi_patient] Processing patient p219_full...
INFO: [reduce_features_multi_patient] Processing patient p216_full...
INFO: [finetune_ttm] Data length: 13778732
INFO: [finetune_ttm] Split config: Train 95.0%, Test 5.0%
INFO: [finetune_ttm] Data ids: ['p40_full' 'p205_full' 'p108_full' 'p252_full' 'p18_full' 'p17_full'
 'p50_full' 'p215_full' 'p118_full' 'p140_full' 'p86_full' 'p127_full'
 'p128_full' 'p89_full' 'p60_full' 'p37_full' 'p38_full' 'p170_full'
 'p272_full' 'p138_full' 'p235_full' 'p137_full' 'p96_full' 'p70_full'
 'p284_full' 'p189_full' 'p186_full' 'p27_full' 'p160_full' 'p58_full'
 'p57_full' 'p110_full' 'p245_full' 'p148_full' 'p147_full' 'p47_full'
 'p48_full' 'p157_full' 'p158_full' 'p10_full' 'p91_full' 'p130_full'
 'p232_full' 'p77_full' 'p78_full' 'p20_full' 'p181_full' 'p283_full'
 'p167_full' 'p168_full' 'p265_full' 'p222_full' 'p81_full' 'p68_full'
 'p67_full' 'p293_full' 'p30_full' 'p275_full' 'p3_full' 'p177_full'
 'p61_full' 'p224_full' 'p129_full' 'p87_full' 'p5_full' 'p273_full'
 'p171_full' 'p198_full' 'p39_full' 'p36_full' 'p197_full' 'p71_full'
 'p136_full' 'p97_full' 'p234_full' 'p98_full' 'p139_full' 'p263_full'
 'p187_full' 'p26_full' 'p29_full' 'p188_full' 'p285_full' 'p106_full'
 'p109_full' 'p204_full' 'p41_full' 'p16_full' 'p19_full' 'p253_full'
 'p119_full' 'p214_full' 'p116_full' 'p243_full' 'p141_full' 'p79_full'
 'p76_full' 'p233_full' 'p90_full' 'p131_full' 'p264_full' 'p169_full'
 'p166_full' 'p21_full' 'p69_full' 'p121_full' 'p80_full' 'p223_full'
 'p176_full' 'p2_full' 'p274_full' 'p179_full' 'p190_full' 'p31_full'
 'p292_full' 'p111_full' 'p213_full' 'p146_full' 'p149_full' 'p244_full'
 'p203_full' 'p101_full' 'p49_full' 'p46_full' 'p11_full' 'p254_full'
 'p156_full' 'p145_full' 'p248_full' 'p247_full' 'p112_full' 'p210_full'
 'p55_full' 'p257_full' 'p155_full' 'p258_full' 'p200_full' 'p102_full'
 'p45_full' 'p267_full' 'p165_full' 'p281_full' 'p183_full' 'p22_full'
 'p132_full' 'p93_full' 'p278_full' 'p175_full' 'p277_full' 'p32_full'
 'p193_full' 'p291_full' 'p65_full' 'p220_full' 'p15_full' 'p152_full'
 'p250_full' 'p105_full' 'p42_full' 'p240_full' 'p217_full' 'p115_full'
 'p218_full' 'p52_full' 'p9_full' 'p172_full' 'p35_full' 'p62_full'
 'p227_full' 'p228_full' 'p162_full' 'p260_full' 'p184_full' 'p289_full'
 'p72_full' 'p135_full' 'p23_full' 'p280_full' 'p164_full' 'p269_full'
 'p266_full' 'p231_full' 'p74_full' 'p290_full' 'p33_full' 'p276_full'
 'p174_full' 'p221_full' 'p82_full' 'p123_full' 'p64_full' 'p246_full'
 'p249_full' 'p54_full' 'p211_full' 'p113_full' 'p256_full' 'p103_full'
 'p201_full' 'p173_full' 'p8_full' 'p271_full' 'p7_full' 'p124_full'
 'p229_full' 'p226_full' 'p287_full' 'p288_full' 'p24_full' 'p185_full'
 'p163_full' 'p236_full' 'p95_full' 'p134_full' 'p239_full' 'p73_full'
 'p251_full' 'p14_full' 'p43_full' 'p206_full' 'p209_full' 'p143_full'
 'p241_full' 'p53_full' 'p219_full' 'p216_full']
INFO: [finetune_ttm] Data processing complete
INFO: [finetune_ttm] -------------------- Preparing model... -------------------- 

INFO: [finetune_ttm] Model path: ibm-granite/granite-timeseries-ttm-r2
INFO: [_get_finetune_trainer] -------------------- Running few-shot 100% -------------------- 

2025-11-12T16:21:49 - Loading model from: ibm-granite/granite-timeseries-ttm-r2
2025-11-12T16:21:49 - Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = main.
2025-11-12T16:21:49 - [TTM] context_length = 512, prediction_length = 96
INFO: [_get_finetune_trainer] Using learning rate = 0.001
INFO: [_get_finetune_trainer] Training for 3 epochs
Using auto half precision backend
INFO: [finetune_ttm] -------------------- Fine-tuning... -------------------- 

INFO: [finetune_ttm] Starting new training run in output directory: /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49
***** Running training *****
  Num examples = 12,952,510
  Num Epochs = 3
  Instantaneous batch size per device = 128
  Total train batch size (w. parallel, distributed & accumulation) = 128
  Gradient Accumulation steps = 1
  Total optimization steps = 303,576
  Number of trainable parameters = 289,696
Number of params before freezing backbone 805280
Number of params after freezing the backbone 289696
  0%|          | 0/303576 [00:00<?, ?it/s]2025-11-12 16:22:34.658726: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:22:34.669375: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964554.682089 1714372 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964554.685814 1714372 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964554.696216 1714372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964554.696232 1714372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964554.696234 1714372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964554.696236 1714372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:22:34.699309: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:22:37 - TensorFlow version 2.19.1 available.
2025-11-12 16:23:22.653771: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:23:22.664195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964602.676561 1714418 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964602.680224 1714418 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964602.690519 1714418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964602.690535 1714418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964602.690537 1714418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964602.690538 1714418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:23:22.693644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:23:24 - TensorFlow version 2.19.1 available.
  0%|          | 1/303576 [01:36<8117:35:50, 96.26s/it]                                                         0%|          | 1/303576 [01:36<8117:35:50, 96.26s/it]  0%|          | 10/303576 [01:36<586:45:03,  6.96s/it]  0%|          | 19/303576 [01:36<252:53:05,  3.00s/it]  0%|          | 28/303576 [01:36<139:49:59,  1.66s/it]  0%|          | 37/303576 [01:36<85:35:13,  1.02s/it]   0%|          | 46/303576 [01:36<55:18:46,  1.52it/s]  0%|          | 55/303576 [01:36<36:55:38,  2.28it/s]  0%|          | 64/303576 [01:37<25:12:48,  3.34it/s]  0%|          | 73/303576 [01:37<17:30:45,  4.81it/s]  0%|          | 82/303576 [01:37<12:21:00,  6.83it/s]  0%|          | 91/303576 [01:37<8:50:27,  9.54it/s]   0%|          | 100/303576 [01:37<6:26:02, 13.10it/s]                                                        0%|          | 100/303576 [01:37<6:26:02, 13.10it/s]  0%|          | 109/303576 [01:37<4:47:07, 17.62it/s]  0%|          | 118/303576 [01:37<3:38:35, 23.14it/s]  0%|          | 127/303576 [01:37<2:54:40, 28.95it/s]  0%|          | 135/303576 [01:37<2:26:32, 34.51it/s]  0%|          | 143/303576 [01:38<2:05:58, 40.15it/s]  0%|          | 151/303576 [01:38<1:51:03, 45.54it/s]  0%|          | 159/303576 [01:38<1:40:10, 50.48it/s]  0%|          | 167/303576 [01:38<1:33:56, 53.83it/s]  0%|          | 176/303576 [01:38<1:23:25, 60.62it/s]  0%|          | 186/303576 [01:38<1:14:23, 67.97it/s]  0%|          | 195/303576 [01:38<1:10:14, 71.98it/s]                                                        0%|          | 200/303576 [01:38<1:10:14, 71.98it/s]  0%|          | 204/303576 [01:38<1:07:36, 74.78it/s]  0%|          | 213/303576 [01:38<1:05:19, 77.41it/s]  0%|          | 222/303576 [01:39<1:04:06, 78.86it/s]  0%|          | 231/303576 [01:39<1:02:52, 80.41it/s]  0%|          | 240/303576 [01:39<1:02:29, 80.89it/s]  0%|          | 249/303576 [01:39<1:01:39, 81.98it/s]  0%|          | 258/303576 [01:39<1:01:35, 82.07it/s]  0%|          | 267/303576 [01:39<1:01:04, 82.77it/s]  0%|          | 276/303576 [01:39<1:01:07, 82.69it/s]  0%|          | 285/303576 [01:39<1:00:45, 83.20it/s]  0%|          | 294/303576 [01:39<1:00:56, 82.94it/s]                                                        0%|          | 300/303576 [01:39<1:00:56, 82.94it/s]  0%|          | 303/303576 [01:40<1:00:44, 83.21it/s]  0%|          | 312/303576 [01:40<1:00:57, 82.92it/s]  0%|          | 321/303576 [01:40<1:01:37, 82.01it/s]  0%|          | 330/303576 [01:40<1:00:24, 83.66it/s]  0%|          | 341/303576 [01:40<56:46, 89.02it/s]    0%|          | 352/303576 [01:40<53:56, 93.69it/s]  0%|          | 363/303576 [01:40<52:58, 95.38it/s]  0%|          | 373/303576 [01:40<54:04, 93.47it/s]  0%|          | 383/303576 [01:40<56:31, 89.40it/s]  0%|          | 392/303576 [01:41<58:59, 85.67it/s]                                                      0%|          | 400/303576 [01:41<58:59, 85.67it/s]  0%|          | 401/303576 [01:41<1:01:11, 82.59it/s]  0%|          | 410/303576 [01:41<1:01:59, 81.50it/s]  0%|          | 421/303576 [01:41<58:11, 86.82it/s]    0%|          | 431/303576 [01:41<56:15, 89.82it/s]  0%|          | 441/303576 [01:41<57:58, 87.14it/s]  0%|          | 450/303576 [01:41<58:31, 86.32it/s]  0%|          | 459/303576 [01:41<58:28, 86.38it/s]  0%|          | 468/303576 [01:41<58:54, 85.75it/s]  0%|          | 477/303576 [01:42<1:01:51, 81.66it/s]  0%|          | 486/303576 [01:42<1:04:46, 77.98it/s]  0%|          | 494/303576 [01:42<1:06:54, 75.50it/s]                                                        0%|          | 500/303576 [01:42<1:06:54, 75.50it/s]  0%|          | 503/303576 [01:42<1:05:15, 77.39it/s]  0%|          | 512/303576 [01:42<1:03:45, 79.21it/s]  0%|          | 521/303576 [01:42<1:02:26, 80.89it/s]  0%|          | 530/303576 [01:42<1:02:31, 80.79it/s]  0%|          | 539/303576 [01:42<1:02:30, 80.79it/s]  0%|          | 548/303576 [01:42<1:02:30, 80.80it/s]  0%|          | 557/303576 [01:43<1:02:27, 80.87it/s]  0%|          | 566/303576 [01:43<1:02:36, 80.65it/s]  0%|          | 575/303576 [01:43<1:03:03, 80.08it/s]  0%|          | 584/303576 [01:43<1:01:00, 82.77it/s]  0%|          | 594/303576 [01:43<57:41, 87.54it/s]                                                        0%|          | 600/303576 [01:43<57:40, 87.54it/s]  0%|          | 603/303576 [01:43<1:00:20, 83.68it/s]  0%|          | 612/303576 [01:43<1:03:32, 79.46it/s]  0%|          | 621/303576 [01:43<1:06:17, 76.18it/s]  0%|          | 629/303576 [01:43<1:08:10, 74.06it/s]  0%|          | 637/303576 [01:44<1:09:25, 72.72it/s]  0%|          | 645/303576 [01:44<1:10:16, 71.85it/s]  0%|          | 653/303576 [01:44<1:11:05, 71.02it/s]  0%|          | 661/303576 [01:44<1:11:29, 70.62it/s]  0%|          | 669/303576 [01:44<1:21:18, 62.09it/s]  0%|          | 677/303576 [01:44<1:18:49, 64.04it/s]  0%|          | 685/303576 [01:44<1:16:53, 65.65it/s]  0%|          | 693/303576 [01:44<1:15:38, 66.74it/s]                                                        0%|          | 700/303576 [01:45<1:15:38, 66.74it/s]  0%|          | 702/303576 [01:45<1:10:42, 71.38it/s]  0%|          | 712/303576 [01:45<1:04:31, 78.22it/s]  0%|          | 721/303576 [01:45<1:02:52, 80.29it/s]  0%|          | 730/303576 [01:45<1:01:17, 82.34it/s]  0%|          | 739/303576 [01:45<1:00:20, 83.65it/s]  0%|          | 748/303576 [01:45<59:37, 84.65it/s]    0%|          | 757/303576 [01:45<59:14, 85.20it/s]  0%|          | 766/303576 [01:45<58:54, 85.68it/s]  0%|          | 776/303576 [01:45<56:11, 89.81it/s]  0%|          | 787/303576 [01:45<52:51, 95.47it/s]  0%|          | 798/303576 [01:46<51:07, 98.71it/s]                                                      0%|          | 800/303576 [01:46<51:07, 98.71it/s]  0%|          | 809/303576 [01:46<49:46, 101.38it/s]  0%|          | 820/303576 [01:46<50:12, 100.50it/s]  0%|          | 831/303576 [01:46<53:15, 94.74it/s]   0%|          | 841/303576 [01:46<55:02, 91.68it/s]  0%|          | 851/303576 [01:46<56:18, 89.60it/s]  0%|          | 861/303576 [01:46<57:19, 88.00it/s]  0%|          | 870/303576 [01:46<58:50, 85.73it/s]  0%|          | 879/303576 [01:46<59:39, 84.56it/s]  0%|          | 888/303576 [01:47<59:47, 84.37it/s]  0%|          | 897/303576 [01:47<1:00:24, 83.52it/s]                                                        0%|          | 900/303576 [01:47<1:00:24, 83.52it/s]  0%|          | 906/303576 [01:47<1:00:25, 83.49it/s]  0%|          | 915/303576 [01:47<1:00:48, 82.95it/s]  0%|          | 924/303576 [01:47<1:00:21, 83.56it/s]  0%|          | 935/303576 [01:47<56:25, 89.39it/s]    0%|          | 946/303576 [01:47<52:58, 95.21it/s]  0%|          | 958/303576 [01:47<50:34, 99.71it/s]  0%|          | 969/303576 [01:47<49:42, 101.46it/s]  0%|          | 980/303576 [01:48<48:57, 103.02it/s]  0%|          | 991/303576 [01:48<48:09, 104.72it/s]                                                       0%|          | 1000/303576 [01:48<48:09, 104.72it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'loss': 1.0168, 'grad_norm': 0.8563506007194519, 'learning_rate': 0.001, 'epoch': 0.0, 'timestamp': 1762964629.7059693, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8301, 'grad_norm': 0.3596075177192688, 'learning_rate': 0.0009901483535267252, 'epoch': 0.0, 'timestamp': 1762964630.8804529, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8057, 'grad_norm': 0.26954972743988037, 'learning_rate': 0.0009802957226154841, 'epoch': 0.0, 'timestamp': 1762964632.209205, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8459, 'grad_norm': 0.3427028954029083, 'learning_rate': 0.0009705411318974409, 'epoch': 0.0, 'timestamp': 1762964633.4094038, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7987, 'grad_norm': 0.24130766093730927, 'learning_rate': 0.0009608836058078363, 'epoch': 0.0, 'timestamp': 1762964634.5504777, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7938, 'grad_norm': 0.21084563434123993, 'learning_rate': 0.0009513221784894295, 'epoch': 0.0, 'timestamp': 1762964635.7718995, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7985, 'grad_norm': 0.2223241925239563, 'learning_rate': 0.0009418558936958948, 'epoch': 0.01, 'timestamp': 1762964636.9665241, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.806, 'grad_norm': 0.24936744570732117, 'learning_rate': 0.0009324838046961915, 'epoch': 0.01, 'timestamp': 1762964638.444735, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.823, 'grad_norm': 0.2265598177909851, 'learning_rate': 0.0009232049741798791, 'epoch': 0.01, 'timestamp': 1762964639.5162365, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8049, 'grad_norm': 0.26223692297935486, 'learning_rate': 0.0009140184741633745, 'epoch': 0.01, 'timestamp': 1762964640.6702666, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7983, 'grad_norm': 0.2782788872718811, 'learning_rate': 0.0009049233858971455, 'epoch': 0.01, 'timestamp': 1762964641.6660392, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:24:05.530427: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:24:05.541161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964645.554039 1714467 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964645.557859 1714467 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964645.568239 1714467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964645.568256 1714467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964645.568258 1714467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964645.568260 1714467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:24:05.571449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:24:07 - TensorFlow version 2.19.1 available.
  0%|          | 1000/303576 [02:00<48:09, 104.72it/s]2025-11-12 16:24:16.063008: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:24:16.073646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964656.086319 1714493 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964656.090077 1714493 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964656.100384 1714493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964656.100401 1714493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964656.100403 1714493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964656.100405 1714493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:24:16.103548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:24:18 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.17it/s][A                                                      
                                             [A  0%|          | 1000/303576 [02:10<48:09, 104.72it/s]
100%|| 2/2 [00:01<00:00,  1.17it/s][A
                                             [A  0%|          | 1001/303576 [02:10<54:21:57,  1.55it/s]  0%|          | 1006/303576 [02:10<45:33:54,  1.84it/s]  0%|          | 1015/303576 [02:11<32:16:38,  2.60it/s]  0%|          | 1023/303576 [02:11<23:41:38,  3.55it/s]  0%|          | 1031/303576 [02:11<17:23:11,  4.83it/s]  0%|          | 1038/303576 [02:11<13:15:58,  6.33it/s]  0%|          | 1045/303576 [02:11<10:04:46,  8.34it/s]  0%|          | 1052/303576 [02:11<7:42:40, 10.90it/s]   0%|          | 1058/303576 [02:11<6:08:48, 13.67it/s]  0%|          | 1064/303576 [02:11<4:55:58, 17.04it/s]  0%|          | 1071/303576 [02:12<3:48:20, 22.08it/s]  0%|          | 1078/303576 [02:12<3:04:10, 27.38it/s]  0%|          | 1084/303576 [02:12<2:37:13, 32.07it/s]  0%|          | 1090/303576 [02:12<2:17:08, 36.76it/s]  0%|          | 1096/303576 [02:12<2:02:35, 41.12it/s]                                                         0%|          | 1100/303576 [02:12<2:02:35, 41.12it/s]  0%|          | 1102/303576 [02:12<1:51:59, 45.01it/s]  0%|          | 1108/303576 [02:12<1:44:38, 48.17it/s]  0%|          | 1114/303576 [02:12<1:39:04, 50.88it/s]  0%|          | 1120/303576 [02:12<1:35:43, 52.66it/s]  0%|          | 1126/303576 [02:12<1:33:04, 54.16it/s]  0%|          | 1132/303576 [02:13<1:31:27, 55.12it/s]  0%|          | 1138/303576 [02:13<1:30:38, 55.61it/s]  0%|          | 1144/303576 [02:13<1:29:30, 56.31it/s]  0%|          | 1150/303576 [02:13<1:28:52, 56.71it/s]  0%|          | 1156/303576 [02:13<1:28:36, 56.88it/s]  0%|          | 1162/303576 [02:13<1:28:18, 57.07it/s]  0%|          | 1168/303576 [02:13<1:27:48, 57.40it/s]  0%|          | 1174/303576 [02:13<1:27:26, 57.64it/s]  0%|          | 1180/303576 [02:13<1:27:08, 57.84it/s]  0%|          | 1186/303576 [02:14<1:27:42, 57.46it/s]  0%|          | 1192/303576 [02:14<1:27:43, 57.45it/s]  0%|          | 1198/303576 [02:14<1:28:10, 57.16it/s]                                                         0%|          | 1200/303576 [02:14<1:28:10, 57.16it/s]  0%|          | 1204/303576 [02:14<1:28:01, 57.25it/s]  0%|          | 1210/303576 [02:14<1:28:35, 56.88it/s]  0%|          | 1216/303576 [02:14<1:27:18, 57.72it/s]  0%|          | 1223/303576 [02:14<1:25:45, 58.76it/s]  0%|          | 1230/303576 [02:14<1:25:15, 59.10it/s]  0%|          | 1237/303576 [02:14<1:24:23, 59.71it/s]  0%|          | 1243/303576 [02:15<1:24:55, 59.33it/s]  0%|          | 1249/303576 [02:15<1:25:50, 58.70it/s]  0%|          | 1255/303576 [02:15<1:25:22, 59.01it/s]  0%|          | 1261/303576 [02:15<1:26:33, 58.21it/s]  0%|          | 1269/303576 [02:15<1:20:52, 62.30it/s]  0%|          | 1277/303576 [02:15<1:17:17, 65.19it/s]  0%|          | 1286/303576 [02:15<1:12:11, 69.79it/s]  0%|          | 1294/303576 [02:15<1:09:40, 72.30it/s]                                                         0%|          | 1300/303576 [02:15<1:09:40, 72.30it/s]  0%|          | 1302/303576 [02:15<1:07:54, 74.18it/s]  0%|          | 1311/303576 [02:15<1:05:31, 76.87it/s]  0%|          | 1319/303576 [02:16<1:05:03, 77.43it/s]  0%|          | 1327/303576 [02:16<1:04:37, 77.94it/s]  0%|          | 1336/303576 [02:16<1:03:48, 78.94it/s]  0%|          | 1344/303576 [02:16<1:04:13, 78.42it/s]  0%|          | 1352/303576 [02:16<1:04:26, 78.17it/s]  0%|          | 1360/303576 [02:16<1:04:15, 78.38it/s]  0%|          | 1368/303576 [02:16<1:04:13, 78.43it/s]  0%|          | 1376/303576 [02:16<1:04:36, 77.96it/s]  0%|          | 1384/303576 [02:16<1:04:36, 77.96it/s]  0%|          | 1392/303576 [02:17<1:04:24, 78.20it/s]  0%|          | 1400/303576 [02:17<1:04:15, 78.38it/s]                                                         0%|          | 1400/303576 [02:17<1:04:15, 78.38it/s]  0%|          | 1408/303576 [02:17<1:04:34, 78.00it/s]  0%|          | 1416/303576 [02:17<1:04:42, 77.82it/s]  0%|          | 1424/303576 [02:17<1:04:18, 78.30it/s]  0%|          | 1432/303576 [02:17<1:04:19, 78.28it/s]  0%|          | 1440/303576 [02:17<1:04:39, 77.87it/s]  0%|          | 1448/303576 [02:17<1:05:40, 76.68it/s]  0%|          | 1456/303576 [02:17<1:09:43, 72.21it/s]  0%|          | 1464/303576 [02:17<1:14:07, 67.92it/s]  0%|          | 1471/303576 [02:18<1:18:19, 64.29it/s]  0%|          | 1478/303576 [02:18<1:19:50, 63.06it/s]  0%|          | 1485/303576 [02:18<1:21:17, 61.94it/s]  0%|          | 1492/303576 [02:18<1:21:54, 61.46it/s]  0%|          | 1499/303576 [02:18<1:22:54, 60.73it/s]                                                         0%|          | 1500/303576 [02:18<1:22:54, 60.73it/s]  0%|          | 1506/303576 [02:18<1:23:16, 60.45it/s]  0%|          | 1513/303576 [02:18<1:23:44, 60.11it/s]  1%|          | 1520/303576 [02:18<1:23:38, 60.19it/s]  1%|          | 1527/303576 [02:19<1:24:02, 59.90it/s]  1%|          | 1533/303576 [02:19<1:24:14, 59.76it/s]  1%|          | 1539/303576 [02:19<1:24:18, 59.71it/s]  1%|          | 1545/303576 [02:19<1:24:24, 59.64it/s]  1%|          | 1551/303576 [02:19<1:24:29, 59.58it/s]  1%|          | 1557/303576 [02:19<1:25:39, 58.76it/s]  1%|          | 1563/303576 [02:19<1:25:24, 58.93it/s]  1%|          | 1569/303576 [02:19<1:26:23, 58.26it/s]  1%|          | 1575/303576 [02:19<1:26:09, 58.42it/s]  1%|          | 1581/303576 [02:19<1:25:54, 58.59it/s]  1%|          | 1588/303576 [02:20<1:25:13, 59.06it/s]  1%|          | 1594/303576 [02:20<1:25:27, 58.90it/s]                                                         1%|          | 1600/303576 [02:20<1:25:27, 58.90it/s]  1%|          | 1601/303576 [02:20<1:24:47, 59.35it/s]  1%|          | 1608/303576 [02:20<1:24:26, 59.60it/s]  1%|          | 1615/303576 [02:20<1:24:03, 59.87it/s]  1%|          | 1622/303576 [02:20<1:23:57, 59.95it/s]  1%|          | 1628/303576 [02:20<1:24:07, 59.82it/s]  1%|          | 1635/303576 [02:20<1:23:38, 60.17it/s]  1%|          | 1642/303576 [02:20<1:23:51, 60.01it/s]  1%|          | 1648/303576 [02:21<1:24:53, 59.27it/s]  1%|          | 1654/303576 [02:21<1:25:59, 58.52it/s]  1%|          | 1660/303576 [02:21<1:26:46, 57.98it/s]  1%|          | 1666/303576 [02:21<1:27:18, 57.63it/s]  1%|          | 1672/303576 [02:21<1:27:44, 57.34it/s]  1%|          | 1678/303576 [02:21<1:28:07, 57.10it/s]  1%|          | 1684/303576 [02:21<1:28:08, 57.08it/s]  1%|          | 1690/303576 [02:21<1:28:12, 57.04it/s]  1%|          | 1696/303576 [02:21<1:28:12, 57.04it/s]                                                         1%|          | 1700/303576 [02:22<1:28:12, 57.04it/s]  1%|          | 1702/303576 [02:22<1:28:11, 57.05it/s]  1%|          | 1708/303576 [02:22<1:28:11, 57.05it/s]  1%|          | 1714/303576 [02:22<1:28:12, 57.04it/s]  1%|          | 1720/303576 [02:22<1:27:05, 57.76it/s]  1%|          | 1726/303576 [02:22<1:27:33, 57.46it/s]  1%|          | 1732/303576 [02:22<1:28:57, 56.55it/s]  1%|          | 1739/303576 [02:22<1:26:40, 58.04it/s]  1%|          | 1745/303576 [02:22<1:28:01, 57.15it/s]  1%|          | 1751/303576 [02:22<1:28:52, 56.60it/s]  1%|          | 1757/303576 [02:23<1:29:36, 56.14it/s]  1%|          | 1763/303576 [02:23<1:30:07, 55.81it/s]  1%|          | 1769/303576 [02:23<1:30:11, 55.78it/s]  1%|          | 1775/303576 [02:23<1:29:51, 55.98it/s]  1%|          | 1781/303576 [02:23<1:29:19, 56.31it/s]  1%|          | 1787/303576 [02:23<1:28:38, 56.74it/s]  1%|          | 1793/303576 [02:23<1:28:06, 57.08it/s]  1%|          | 1799/303576 [02:23<1:27:50, 57.25it/s]                                                         1%|          | 1800/303576 [02:23<1:27:50, 57.25it/s]  1%|          | 1805/303576 [02:23<1:27:38, 57.39it/s]  1%|          | 1811/303576 [02:23<1:27:19, 57.60it/s]  1%|          | 1817/303576 [02:24<1:27:36, 57.40it/s]  1%|          | 1823/303576 [02:24<1:28:09, 57.05it/s]  1%|          | 1829/303576 [02:24<1:28:40, 56.71it/s]  1%|          | 1835/303576 [02:24<1:28:57, 56.53it/s]  1%|          | 1841/303576 [02:24<1:29:05, 56.45it/s]  1%|          | 1847/303576 [02:24<1:29:12, 56.38it/s]  1%|          | 1853/303576 [02:24<1:29:26, 56.22it/s]  1%|          | 1859/303576 [02:24<1:29:39, 56.09it/s]  1%|          | 1865/303576 [02:24<1:29:49, 55.98it/s]  1%|          | 1871/303576 [02:25<1:29:48, 55.99it/s]  1%|          | 1877/303576 [02:25<1:29:45, 56.02it/s]  1%|          | 1883/303576 [02:25<1:29:41, 56.06it/s]  1%|          | 1889/303576 [02:25<1:30:00, 55.86it/s]  1%|          | 1895/303576 [02:25<1:29:42, 56.04it/s]                                                         1%|          | 1900/303576 [02:25<1:29:42, 56.04it/s]  1%|          | 1901/303576 [02:25<1:30:03, 55.83it/s]  1%|          | 1907/303576 [02:25<1:30:13, 55.73it/s]  1%|          | 1913/303576 [02:25<1:30:05, 55.81it/s]  1%|          | 1919/303576 [02:25<1:30:01, 55.85it/s]  1%|          | 1925/303576 [02:25<1:29:53, 55.92it/s]  1%|          | 1931/303576 [02:26<1:28:38, 56.72it/s]  1%|          | 1938/303576 [02:26<1:26:08, 58.36it/s]  1%|          | 1944/303576 [02:26<1:25:33, 58.76it/s]  1%|          | 1950/303576 [02:26<1:26:30, 58.11it/s]  1%|          | 1956/303576 [02:26<1:27:01, 57.76it/s]  1%|          | 1962/303576 [02:26<1:27:15, 57.61it/s]  1%|          | 1968/303576 [02:26<1:27:35, 57.38it/s]  1%|          | 1974/303576 [02:26<1:28:06, 57.05it/s]  1%|          | 1980/303576 [02:26<1:28:04, 57.07it/s]  1%|          | 1986/303576 [02:27<1:28:21, 56.89it/s]  1%|          | 1992/303576 [02:27<1:28:23, 56.86it/s]  1%|          | 1998/303576 [02:27<1:28:24, 56.86it/s]                                                         1%|          | 2000/303576 [02:27<1:28:24, 56.86it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7441288828849792, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.5489, 'eval_samples_per_second': 10.023, 'eval_steps_per_second': 0.089, 'epoch': 0.01, 'timestamp': 1762964664.21573, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.796, 'grad_norm': 0.21807469427585602, 'learning_rate': 0.000895918799773826, 'epoch': 0.01, 'timestamp': 1762964665.9938216, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7899, 'grad_norm': 0.3004777431488037, 'learning_rate': 0.0008870038152372441, 'epoch': 0.01, 'timestamp': 1762964667.7284741, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7864, 'grad_norm': 0.2943209409713745, 'learning_rate': 0.0008781775406923574, 'epoch': 0.01, 'timestamp': 1762964669.2796233, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7962, 'grad_norm': 0.21565869450569153, 'learning_rate': 0.0008694390934160834, 'epoch': 0.01, 'timestamp': 1762964670.5472205, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7959, 'grad_norm': 0.20042124390602112, 'learning_rate': 0.0008607875994690192, 'epoch': 0.01, 'timestamp': 1762964672.038849, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7808, 'grad_norm': 0.20799373090267181, 'learning_rate': 0.0008522221936080363, 'epoch': 0.02, 'timestamp': 1762964673.730529, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7878, 'grad_norm': 0.23548316955566406, 'learning_rate': 0.0008437420191997465, 'epoch': 0.02, 'timestamp': 1762964675.4483075, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7854, 'grad_norm': 0.22048808634281158, 'learning_rate': 0.0008353462281348318, 'epoch': 0.02, 'timestamp': 1762964677.2078533, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7746, 'grad_norm': 0.22039902210235596, 'learning_rate': 0.0008270339807432219, 'epoch': 0.02, 'timestamp': 1762964678.985788, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8021, 'grad_norm': 0.2940700352191925, 'learning_rate': 0.0008188044457101195, 'epoch': 0.02, 'timestamp': 1762964680.7339134, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:24:44.030916: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:24:44.041725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964684.054654 1714538 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964684.058525 1714538 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964684.069081 1714538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964684.069097 1714538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964684.069099 1714538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964684.069101 1714538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:24:44.072265: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:24:45 - TensorFlow version 2.19.1 available.
  1%|          | 2000/303576 [02:40<1:28:24, 56.86it/s]2025-11-12 16:24:53.788168: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:24:53.798843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964693.811573 1714565 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964693.815333 1714565 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964693.825762 1714565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964693.825780 1714565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964693.825781 1714565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964693.825783 1714565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:24:53.828952: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:24:55 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                       
                                             [A  1%|          | 2000/303576 [02:48<1:28:24, 56.86it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-2000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-2000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-2000/model.safetensors
  1%|          | 2001/303576 [02:48<106:16:49,  1.27s/it]  1%|          | 2007/303576 [02:48<71:12:10,  1.18it/s]   1%|          | 2013/303576 [02:48<48:38:51,  1.72it/s]  1%|          | 2019/303576 [02:48<33:43:57,  2.48it/s]  1%|          | 2025/303576 [02:49<23:41:08,  3.54it/s]  1%|          | 2032/303576 [02:49<16:03:29,  5.22it/s]  1%|          | 2039/303576 [02:49<11:13:52,  7.46it/s]  1%|          | 2046/303576 [02:49<8:04:04, 10.38it/s]   1%|          | 2053/303576 [02:49<5:57:06, 14.07it/s]  1%|          | 2060/303576 [02:49<4:30:47, 18.56it/s]  1%|          | 2067/303576 [02:49<3:31:42, 23.74it/s]  1%|          | 2074/303576 [02:49<2:52:33, 29.12it/s]  1%|          | 2081/303576 [02:49<2:22:33, 35.25it/s]  1%|          | 2092/303576 [02:50<1:44:27, 48.10it/s]                                                         1%|          | 2100/303576 [02:50<1:44:27, 48.10it/s]  1%|          | 2103/303576 [02:50<1:23:58, 59.83it/s]  1%|          | 2114/303576 [02:50<1:11:57, 69.82it/s]  1%|          | 2123/303576 [02:50<1:08:36, 73.24it/s]  1%|          | 2132/303576 [02:50<1:05:17, 76.95it/s]  1%|          | 2143/303576 [02:50<1:00:38, 82.85it/s]  1%|          | 2154/303576 [02:50<56:55, 88.26it/s]    1%|          | 2165/303576 [02:50<54:27, 92.25it/s]  1%|          | 2176/303576 [02:50<52:35, 95.51it/s]  1%|          | 2186/303576 [02:50<53:16, 94.27it/s]  1%|          | 2196/303576 [02:51<54:41, 91.84it/s]                                                       1%|          | 2200/303576 [02:51<54:41, 91.84it/s]  1%|          | 2206/303576 [02:51<55:21, 90.73it/s]  1%|          | 2216/303576 [02:51<55:49, 89.98it/s]  1%|          | 2226/303576 [02:51<55:55, 89.80it/s]  1%|          | 2236/303576 [02:51<56:27, 88.96it/s]  1%|          | 2245/303576 [02:51<58:34, 85.74it/s]  1%|          | 2254/303576 [02:51<58:43, 85.53it/s]  1%|          | 2263/303576 [02:51<59:24, 84.53it/s]  1%|          | 2272/303576 [02:51<59:34, 84.29it/s]  1%|          | 2281/303576 [02:52<59:38, 84.20it/s]  1%|          | 2290/303576 [02:52<59:39, 84.18it/s]  1%|          | 2299/303576 [02:52<1:00:02, 83.64it/s]                                                         1%|          | 2300/303576 [02:52<1:00:02, 83.64it/s]  1%|          | 2308/303576 [02:52<1:00:08, 83.49it/s]  1%|          | 2317/303576 [02:52<59:52, 83.87it/s]    1%|          | 2326/303576 [02:52<1:00:20, 83.22it/s]  1%|          | 2335/303576 [02:52<1:00:09, 83.45it/s]  1%|          | 2344/303576 [02:52<1:00:20, 83.19it/s]  1%|          | 2353/303576 [02:52<1:00:09, 83.46it/s]  1%|          | 2362/303576 [02:53<1:00:22, 83.16it/s]  1%|          | 2371/303576 [02:53<1:00:11, 83.40it/s]  1%|          | 2380/303576 [02:53<1:00:43, 82.66it/s]  1%|          | 2389/303576 [02:53<1:00:35, 82.86it/s]  1%|          | 2398/303576 [02:53<1:00:16, 83.27it/s]                                                         1%|          | 2400/303576 [02:53<1:00:16, 83.27it/s]  1%|          | 2407/303576 [02:53<1:00:23, 83.12it/s]  1%|          | 2416/303576 [02:53<1:00:01, 83.62it/s]  1%|          | 2425/303576 [02:53<59:09, 84.84it/s]    1%|          | 2434/303576 [02:53<59:06, 84.90it/s]  1%|          | 2443/303576 [02:54<58:29, 85.80it/s]  1%|          | 2452/303576 [02:54<59:05, 84.93it/s]  1%|          | 2461/303576 [02:54<59:21, 84.54it/s]  1%|          | 2470/303576 [02:54<59:52, 83.81it/s]  1%|          | 2479/303576 [02:54<59:52, 83.81it/s]  1%|          | 2488/303576 [02:54<1:00:14, 83.30it/s]  1%|          | 2497/303576 [02:54<1:00:04, 83.54it/s]                                                         1%|          | 2500/303576 [02:54<1:00:04, 83.54it/s]  1%|          | 2506/303576 [02:54<1:00:20, 83.15it/s]  1%|          | 2515/303576 [02:54<1:00:07, 83.45it/s]  1%|          | 2524/303576 [02:55<1:00:24, 83.06it/s]  1%|          | 2533/303576 [02:55<1:00:15, 83.27it/s]  1%|          | 2542/303576 [02:55<1:00:05, 83.49it/s]  1%|          | 2551/303576 [02:55<1:00:28, 82.96it/s]  1%|          | 2560/303576 [02:55<1:00:31, 82.90it/s]  1%|          | 2569/303576 [02:55<1:00:47, 82.52it/s]  1%|          | 2578/303576 [02:55<1:01:42, 81.29it/s]  1%|          | 2587/303576 [02:55<1:01:41, 81.31it/s]  1%|          | 2596/303576 [02:55<1:01:24, 81.69it/s]                                                         1%|          | 2600/303576 [02:55<1:01:24, 81.69it/s]  1%|          | 2605/303576 [02:55<1:01:17, 81.83it/s]  1%|          | 2614/303576 [02:56<1:01:01, 82.19it/s]  1%|          | 2623/303576 [02:56<1:01:01, 82.20it/s]  1%|          | 2632/303576 [02:56<1:00:52, 82.39it/s]  1%|          | 2641/303576 [02:56<1:00:59, 82.23it/s]  1%|          | 2650/303576 [02:56<59:41, 84.03it/s]    1%|          | 2659/303576 [02:56<59:54, 83.73it/s]  1%|          | 2668/303576 [02:56<1:00:09, 83.37it/s]  1%|          | 2677/303576 [02:56<59:32, 84.22it/s]    1%|          | 2686/303576 [02:56<59:46, 83.89it/s]  1%|          | 2695/303576 [02:57<59:29, 84.29it/s]                                                       1%|          | 2700/303576 [02:57<59:29, 84.29it/s]  1%|          | 2704/303576 [02:57<1:00:25, 82.98it/s]  1%|          | 2713/303576 [02:57<1:00:57, 82.27it/s]  1%|          | 2722/303576 [02:57<59:35, 84.15it/s]    1%|          | 2731/303576 [02:57<59:00, 84.96it/s]  1%|          | 2740/303576 [02:57<1:00:34, 82.76it/s]  1%|          | 2749/303576 [02:57<59:48, 83.84it/s]    1%|          | 2758/303576 [02:57<59:43, 83.94it/s]  1%|          | 2767/303576 [02:57<59:16, 84.57it/s]  1%|          | 2776/303576 [02:58<59:29, 84.28it/s]  1%|          | 2785/303576 [02:58<59:13, 84.64it/s]  1%|          | 2794/303576 [02:58<59:19, 84.49it/s]                                                       1%|          | 2800/303576 [02:58<59:19, 84.49it/s]  1%|          | 2803/303576 [02:58<59:10, 84.72it/s]  1%|          | 2812/303576 [02:58<59:23, 84.40it/s]  1%|          | 2821/303576 [02:58<59:05, 84.84it/s]  1%|          | 2830/303576 [02:58<59:18, 84.51it/s]  1%|          | 2839/303576 [02:58<59:31, 84.20it/s]  1%|          | 2848/303576 [02:58<1:00:22, 83.03it/s]  1%|          | 2857/303576 [02:59<1:00:27, 82.89it/s]  1%|          | 2866/303576 [02:59<1:01:00, 82.14it/s]  1%|          | 2875/303576 [02:59<1:01:02, 82.11it/s]  1%|          | 2885/303576 [02:59<58:53, 85.11it/s]    1%|          | 2894/303576 [02:59<1:00:08, 83.33it/s]                                                         1%|          | 2900/303576 [02:59<1:00:08, 83.33it/s]  1%|          | 2903/303576 [02:59<1:00:13, 83.20it/s]  1%|          | 2912/303576 [02:59<1:00:14, 83.18it/s]  1%|          | 2921/303576 [02:59<1:00:12, 83.23it/s]  1%|          | 2930/303576 [02:59<1:00:16, 83.13it/s]  1%|          | 2939/303576 [02:59<1:00:15, 83.16it/s]  1%|          | 2948/303576 [03:00<1:00:09, 83.30it/s]  1%|          | 2957/303576 [03:00<1:00:14, 83.17it/s]  1%|          | 2966/303576 [03:00<1:00:16, 83.12it/s]  1%|          | 2975/303576 [03:00<1:00:16, 83.11it/s]  1%|          | 2984/303576 [03:00<1:01:14, 81.81it/s]  1%|          | 2993/303576 [03:00<1:01:50, 81.01it/s]                                                         1%|          | 3000/303576 [03:00<1:01:50, 81.01it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.74991375207901, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.2254, 'eval_samples_per_second': 10.648, 'eval_steps_per_second': 0.094, 'epoch': 0.02, 'timestamp': 1762964701.960343, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7777, 'grad_norm': 0.22838859260082245, 'learning_rate': 0.0008106567999928592, 'epoch': 0.02, 'timestamp': 1762964703.536855, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7834, 'grad_norm': 0.293698251247406, 'learning_rate': 0.000802590228738594, 'epoch': 0.02, 'timestamp': 1762964704.5888724, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7878, 'grad_norm': 0.2137467861175537, 'learning_rate': 0.0007946039252028022, 'epoch': 0.02, 'timestamp': 1762964705.7690496, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.777, 'grad_norm': 0.2111509144306183, 'learning_rate': 0.0007866970906686023, 'epoch': 0.02, 'timestamp': 1762964706.9711716, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7892, 'grad_norm': 0.2372215837240219, 'learning_rate': 0.0007788689343668761, 'epoch': 0.02, 'timestamp': 1762964708.1603355, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7823, 'grad_norm': 0.2364799529314041, 'learning_rate': 0.0007711186733971792, 'epoch': 0.03, 'timestamp': 1762964709.3761332, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7674, 'grad_norm': 0.21721717715263367, 'learning_rate': 0.0007634455326494451, 'epoch': 0.03, 'timestamp': 1762964710.5723588, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7868, 'grad_norm': 0.21116195619106293, 'learning_rate': 0.0007558487447264661, 'epoch': 0.03, 'timestamp': 1762964711.7608943, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7956, 'grad_norm': 0.20743408799171448, 'learning_rate': 0.000748327549867141, 'epoch': 0.03, 'timestamp': 1762964712.9593933, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.798, 'grad_norm': 0.22531093657016754, 'learning_rate': 0.000740881195870498, 'epoch': 0.03, 'timestamp': 1762964714.1785178, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:25:18.030098: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:25:18.040424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964718.052958 1714604 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964718.056675 1714604 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964718.066947 1714604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964718.066964 1714604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964718.066966 1714604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964718.066967 1714604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:25:18.070074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:25:20 - TensorFlow version 2.19.1 available.
2025-11-12 16:25:28.475594: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:25:28.486045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964728.498403 1714630 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964728.502065 1714630 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964728.512489 1714630 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964728.512503 1714630 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964728.512505 1714630 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964728.512506 1714630 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:25:28.515558: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:25:30 - TensorFlow version 2.19.1 available.
  1%|          | 3000/303576 [03:20<1:01:50, 81.01it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                       
                                             [A  1%|          | 3000/303576 [03:23<1:01:50, 81.01it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [A  1%|          | 3001/303576 [03:23<65:42:42,  1.27it/s]  1%|          | 3006/303576 [03:23<53:06:41,  1.57it/s]  1%|          | 3013/303576 [03:23<38:34:08,  2.16it/s]  1%|          | 3020/303576 [03:23<27:53:41,  2.99it/s]  1%|          | 3027/303576 [03:23<20:12:51,  4.13it/s]  1%|          | 3033/303576 [03:23<15:18:50,  5.45it/s]  1%|          | 3039/303576 [03:23<11:34:23,  7.21it/s]  1%|          | 3045/303576 [03:24<8:45:55,  9.52it/s]   1%|          | 3051/303576 [03:24<6:42:50, 12.43it/s]  1%|          | 3057/303576 [03:24<5:13:40, 15.97it/s]  1%|          | 3063/303576 [03:24<4:10:12, 20.02it/s]  1%|          | 3069/303576 [03:24<3:25:10, 24.41it/s]  1%|          | 3075/303576 [03:24<2:52:41, 29.00it/s]  1%|          | 3081/303576 [03:24<2:30:04, 33.37it/s]  1%|          | 3087/303576 [03:24<2:14:12, 37.32it/s]  1%|          | 3093/303576 [03:25<2:03:07, 40.68it/s]  1%|          | 3099/303576 [03:25<1:55:33, 43.34it/s]                                                         1%|          | 3100/303576 [03:25<1:55:33, 43.34it/s]  1%|          | 3105/303576 [03:25<1:49:45, 45.63it/s]  1%|          | 3111/303576 [03:25<1:44:56, 47.72it/s]  1%|          | 3117/303576 [03:25<1:43:48, 48.24it/s]  1%|          | 3123/303576 [03:25<1:42:02, 49.07it/s]  1%|          | 3129/303576 [03:25<1:40:52, 49.64it/s]  1%|          | 3135/303576 [03:25<1:38:11, 50.99it/s]  1%|          | 3141/303576 [03:25<1:35:58, 52.17it/s]  1%|          | 3147/303576 [03:26<1:34:20, 53.08it/s]  1%|          | 3153/303576 [03:26<1:32:34, 54.08it/s]  1%|          | 3159/303576 [03:26<1:31:40, 54.62it/s]  1%|          | 3165/303576 [03:26<1:30:53, 55.09it/s]  1%|          | 3171/303576 [03:26<1:30:09, 55.53it/s]  1%|          | 3177/303576 [03:26<1:29:59, 55.64it/s]  1%|          | 3183/303576 [03:26<1:30:11, 55.51it/s]  1%|          | 3189/303576 [03:26<1:28:44, 56.42it/s]  1%|          | 3195/303576 [03:26<1:27:42, 57.08it/s]                                                         1%|          | 3200/303576 [03:26<1:27:42, 57.08it/s]  1%|          | 3201/303576 [03:26<1:28:33, 56.53it/s]  1%|          | 3207/303576 [03:27<1:29:03, 56.21it/s]  1%|          | 3213/303576 [03:27<1:31:12, 54.89it/s]  1%|          | 3219/303576 [03:27<1:32:07, 54.34it/s]  1%|          | 3225/303576 [03:27<1:34:21, 53.05it/s]  1%|          | 3231/303576 [03:27<1:35:21, 52.50it/s]  1%|          | 3237/303576 [03:27<1:35:49, 52.24it/s]  1%|          | 3243/303576 [03:27<1:36:10, 52.04it/s]  1%|          | 3249/303576 [03:27<1:36:48, 51.71it/s]  1%|          | 3255/303576 [03:28<1:39:01, 50.55it/s]  1%|          | 3261/303576 [03:28<1:38:52, 50.62it/s]  1%|          | 3267/303576 [03:28<1:36:45, 51.73it/s]  1%|          | 3273/303576 [03:28<1:33:59, 53.25it/s]  1%|          | 3279/303576 [03:28<1:32:08, 54.31it/s]  1%|          | 3285/303576 [03:28<1:32:09, 54.31it/s]  1%|          | 3291/303576 [03:28<1:33:13, 53.68it/s]  1%|          | 3297/303576 [03:28<1:34:14, 53.10it/s]                                                         1%|          | 3300/303576 [03:28<1:34:14, 53.10it/s]  1%|          | 3303/303576 [03:28<1:35:07, 52.61it/s]  1%|          | 3309/303576 [03:29<1:37:41, 51.23it/s]  1%|          | 3315/303576 [03:29<1:37:13, 51.47it/s]  1%|          | 3321/303576 [03:29<1:36:53, 51.65it/s]  1%|          | 3327/303576 [03:29<1:36:37, 51.79it/s]  1%|          | 3333/303576 [03:29<1:37:06, 51.53it/s]  1%|          | 3339/303576 [03:29<1:36:53, 51.64it/s]  1%|          | 3345/303576 [03:29<1:36:49, 51.68it/s]  1%|          | 3351/303576 [03:29<1:36:31, 51.84it/s]  1%|          | 3357/303576 [03:29<1:36:57, 51.60it/s]  1%|          | 3363/303576 [03:30<1:36:45, 51.71it/s]  1%|          | 3369/303576 [03:30<1:36:25, 51.89it/s]  1%|          | 3375/303576 [03:30<1:36:11, 52.02it/s]  1%|          | 3381/303576 [03:30<1:37:16, 51.44it/s]  1%|          | 3387/303576 [03:30<1:37:00, 51.58it/s]  1%|          | 3393/303576 [03:30<1:37:20, 51.40it/s]  1%|          | 3399/303576 [03:30<1:37:16, 51.43it/s]                                                         1%|          | 3400/303576 [03:30<1:37:16, 51.43it/s]  1%|          | 3405/303576 [03:30<1:37:08, 51.50it/s]  1%|          | 3411/303576 [03:31<1:40:30, 49.78it/s]  1%|          | 3417/303576 [03:31<1:39:06, 50.48it/s]  1%|          | 3423/303576 [03:31<1:38:19, 50.88it/s]  1%|          | 3429/303576 [03:31<1:37:43, 51.19it/s]  1%|          | 3435/303576 [03:31<1:37:14, 51.44it/s]  1%|          | 3441/303576 [03:31<1:36:52, 51.63it/s]  1%|          | 3447/303576 [03:31<1:38:53, 50.59it/s]  1%|          | 3453/303576 [03:31<1:37:47, 51.15it/s]  1%|          | 3459/303576 [03:31<1:37:25, 51.34it/s]  1%|          | 3465/303576 [03:32<1:37:43, 51.18it/s]  1%|          | 3471/303576 [03:32<1:37:27, 51.32it/s]  1%|          | 3477/303576 [03:32<1:34:16, 53.06it/s]  1%|          | 3483/303576 [03:32<1:33:20, 53.59it/s]  1%|          | 3489/303576 [03:32<1:33:16, 53.62it/s]  1%|          | 3495/303576 [03:32<1:34:54, 52.69it/s]                                                         1%|          | 3500/303576 [03:32<1:34:54, 52.69it/s]  1%|          | 3501/303576 [03:32<1:36:21, 51.90it/s]  1%|          | 3507/303576 [03:32<1:37:19, 51.38it/s]  1%|          | 3513/303576 [03:33<1:39:37, 50.20it/s]  1%|          | 3519/303576 [03:33<1:39:11, 50.42it/s]  1%|          | 3525/303576 [03:33<1:38:15, 50.90it/s]  1%|          | 3531/303576 [03:33<1:36:45, 51.69it/s]  1%|          | 3537/303576 [03:33<1:36:59, 51.56it/s]  1%|          | 3543/303576 [03:33<1:33:24, 53.53it/s]  1%|          | 3550/303576 [03:33<1:27:42, 57.02it/s]  1%|          | 3557/303576 [03:33<1:25:51, 58.24it/s]  1%|          | 3563/303576 [03:33<1:25:30, 58.48it/s]  1%|          | 3570/303576 [03:34<1:24:00, 59.52it/s]  1%|          | 3577/303576 [03:34<1:21:44, 61.17it/s]  1%|          | 3584/303576 [03:34<1:20:24, 62.18it/s]  1%|          | 3591/303576 [03:34<1:19:18, 63.05it/s]  1%|          | 3598/303576 [03:34<1:18:38, 63.57it/s]                                                         1%|          | 3600/303576 [03:34<1:18:38, 63.57it/s]  1%|          | 3605/303576 [03:34<1:20:29, 62.12it/s]  1%|          | 3613/303576 [03:34<1:17:26, 64.56it/s]  1%|          | 3620/303576 [03:34<1:15:51, 65.90it/s]  1%|          | 3628/303576 [03:34<1:13:50, 67.69it/s]  1%|          | 3636/303576 [03:35<1:12:39, 68.81it/s]  1%|          | 3644/303576 [03:35<1:11:48, 69.62it/s]  1%|          | 3652/303576 [03:35<1:11:11, 70.21it/s]  1%|          | 3660/303576 [03:35<1:10:53, 70.52it/s]  1%|          | 3668/303576 [03:35<1:10:36, 70.79it/s]  1%|          | 3676/303576 [03:35<1:10:39, 70.74it/s]  1%|          | 3684/303576 [03:35<1:10:43, 70.67it/s]  1%|          | 3692/303576 [03:35<1:11:01, 70.37it/s]  1%|          | 3700/303576 [03:35<1:11:58, 69.44it/s]                                                         1%|          | 3700/303576 [03:35<1:11:58, 69.44it/s]  1%|          | 3707/303576 [03:36<1:12:03, 69.35it/s]  1%|          | 3714/303576 [03:36<1:13:09, 68.32it/s]  1%|          | 3721/303576 [03:36<1:12:46, 68.67it/s]  1%|          | 3728/303576 [03:36<1:16:01, 65.73it/s]  1%|          | 3735/303576 [03:36<1:14:53, 66.73it/s]  1%|          | 3742/303576 [03:36<1:13:57, 67.56it/s]  1%|          | 3750/303576 [03:36<1:12:10, 69.23it/s]  1%|          | 3758/303576 [03:36<1:11:21, 70.03it/s]  1%|          | 3766/303576 [03:36<1:09:52, 71.51it/s]  1%|          | 3774/303576 [03:36<1:09:47, 71.59it/s]  1%|          | 3782/303576 [03:37<1:09:58, 71.41it/s]  1%|          | 3790/303576 [03:37<1:10:06, 71.27it/s]  1%|         | 3798/303576 [03:37<1:10:45, 70.62it/s]                                                         1%|         | 3800/303576 [03:37<1:10:45, 70.62it/s]  1%|         | 3806/303576 [03:37<1:11:27, 69.92it/s]  1%|         | 3814/303576 [03:37<1:11:48, 69.58it/s]  1%|         | 3821/303576 [03:37<1:11:48, 69.58it/s]  1%|         | 3828/303576 [03:37<1:12:05, 69.30it/s]  1%|         | 3836/303576 [03:37<1:12:15, 69.13it/s]  1%|         | 3844/303576 [03:37<1:12:16, 69.12it/s]  1%|         | 3851/303576 [03:38<1:12:58, 68.45it/s]  1%|         | 3858/303576 [03:38<1:13:27, 68.00it/s]  1%|         | 3865/303576 [03:38<1:13:08, 68.30it/s]  1%|         | 3872/303576 [03:38<1:13:17, 68.15it/s]  1%|         | 3880/303576 [03:38<1:12:12, 69.18it/s]  1%|         | 3888/303576 [03:38<1:11:33, 69.80it/s]  1%|         | 3896/303576 [03:38<1:11:14, 70.12it/s]                                                         1%|         | 3900/303576 [03:38<1:11:14, 70.12it/s]  1%|         | 3904/303576 [03:38<1:10:59, 70.36it/s]  1%|         | 3912/303576 [03:38<1:10:40, 70.66it/s]  1%|         | 3920/303576 [03:39<1:10:26, 70.89it/s]  1%|         | 3928/303576 [03:39<1:12:18, 69.07it/s]  1%|         | 3936/303576 [03:39<1:10:48, 70.52it/s]  1%|         | 3945/303576 [03:39<1:07:31, 73.95it/s]  1%|         | 3954/303576 [03:39<1:04:30, 77.41it/s]  1%|         | 3963/303576 [03:39<1:03:15, 78.93it/s]  1%|         | 3972/303576 [03:39<1:02:41, 79.64it/s]  1%|         | 3981/303576 [03:39<1:01:17, 81.47it/s]  1%|         | 3990/303576 [03:39<1:01:08, 81.65it/s]  1%|         | 3999/303576 [03:40<1:01:04, 81.74it/s]                                                         1%|         | 4000/303576 [03:40<1:01:04, 81.74it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.751595675945282, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4632, 'eval_samples_per_second': 10.061, 'eval_steps_per_second': 0.089, 'epoch': 0.03, 'timestamp': 1762964736.6422899, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7868, 'grad_norm': 0.19920064508914948, 'learning_rate': 0.0007335089380204594, 'epoch': 0.03, 'timestamp': 1762964738.5924964, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7746, 'grad_norm': 0.21736931800842285, 'learning_rate': 0.0007262100390113666, 'epoch': 0.03, 'timestamp': 1762964740.4180105, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.793, 'grad_norm': 0.2122635394334793, 'learning_rate': 0.0007189837688742388, 'epoch': 0.03, 'timestamp': 1762964742.3241026, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7909, 'grad_norm': 0.2528863549232483, 'learning_rate': 0.0007118294049037708, 'epoch': 0.03, 'timestamp': 1762964744.2676768, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7883, 'grad_norm': 0.235753133893013, 'learning_rate': 0.0007047462315860511, 'epoch': 0.03, 'timestamp': 1762964746.2025456, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8007, 'grad_norm': 0.2023240476846695, 'learning_rate': 0.0006977335405270059, 'epoch': 0.04, 'timestamp': 1762964747.9295075, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7925, 'grad_norm': 0.2346576750278473, 'learning_rate': 0.0006907906303815519, 'epoch': 0.04, 'timestamp': 1762964749.3640285, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7976, 'grad_norm': 0.21439963579177856, 'learning_rate': 0.0006839168067834515, 'epoch': 0.04, 'timestamp': 1762964750.8009953, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7883, 'grad_norm': 0.21885253489017487, 'learning_rate': 0.0006771113822758709, 'epoch': 0.04, 'timestamp': 1762964752.247501, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7727, 'grad_norm': 0.1998143196105957, 'learning_rate': 0.000670373676242627, 'epoch': 0.04, 'timestamp': 1762964753.5292041, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:25:56.832708: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:25:56.843284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964756.855886 1714674 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964756.859615 1714674 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964756.870121 1714674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964756.870135 1714674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964756.870137 1714674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964756.870138 1714674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:25:56.873251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:25:58 - TensorFlow version 2.19.1 available.
  1%|         | 4000/303576 [03:50<1:01:04, 81.74it/s]2025-11-12 16:26:06.476759: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:26:06.487271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964766.499878 1714701 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964766.503766 1714701 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964766.513996 1714701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964766.514012 1714701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964766.514013 1714701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964766.514015 1714701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:26:06.517127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:26:08 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                       
                                             [A  1%|         | 4000/303576 [04:01<1:01:04, 81.74it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-4000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-4000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-4000/model.safetensors
  1%|         | 4001/303576 [04:01<77:40:18,  1.07it/s]  1%|         | 4007/303576 [04:01<56:49:57,  1.46it/s]  1%|         | 4015/303576 [04:01<37:53:11,  2.20it/s]  1%|         | 4022/303576 [04:01<26:55:40,  3.09it/s]  1%|         | 4029/303576 [04:01<19:15:06,  4.32it/s]  1%|         | 4037/303576 [04:01<13:17:30,  6.26it/s]  1%|         | 4045/303576 [04:01<9:25:32,  8.83it/s]   1%|         | 4053/303576 [04:01<6:50:39, 12.16it/s]  1%|         | 4060/303576 [04:02<5:15:09, 15.84it/s]  1%|         | 4067/303576 [04:02<4:06:19, 20.27it/s]  1%|         | 4074/303576 [04:02<3:16:13, 25.44it/s]  1%|         | 4082/303576 [04:02<2:33:48, 32.45it/s]  1%|         | 4091/303576 [04:02<2:01:06, 41.21it/s]  1%|         | 4100/303576 [04:02<1:40:16, 49.77it/s]                                                         1%|         | 4100/303576 [04:02<1:40:16, 49.77it/s]  1%|         | 4109/303576 [04:02<1:26:28, 57.72it/s]  1%|         | 4118/303576 [04:02<1:17:03, 64.77it/s]  1%|         | 4127/303576 [04:02<1:10:44, 70.56it/s]  1%|         | 4136/303576 [04:02<1:06:45, 74.76it/s]  1%|         | 4145/303576 [04:03<1:03:40, 78.37it/s]  1%|         | 4154/303576 [04:03<1:02:00, 80.47it/s]  1%|         | 4163/303576 [04:03<1:00:33, 82.40it/s]  1%|         | 4172/303576 [04:03<59:31, 83.84it/s]    1%|         | 4181/303576 [04:03<58:35, 85.17it/s]  1%|         | 4190/303576 [04:03<58:15, 85.64it/s]  1%|         | 4199/303576 [04:03<59:06, 84.41it/s]                                                       1%|         | 4200/303576 [04:03<59:06, 84.41it/s]  1%|         | 4208/303576 [04:03<58:35, 85.16it/s]  1%|         | 4217/303576 [04:03<58:06, 85.87it/s]  1%|         | 4226/303576 [04:03<57:58, 86.05it/s]  1%|         | 4235/303576 [04:04<57:28, 86.79it/s]  1%|         | 4244/303576 [04:04<57:35, 86.62it/s]  1%|         | 4253/303576 [04:04<57:11, 87.22it/s]  1%|         | 4262/303576 [04:04<57:11, 87.22it/s]  1%|         | 4271/303576 [04:04<56:55, 87.64it/s]  1%|         | 4280/303576 [04:04<57:42, 86.44it/s]  1%|         | 4289/303576 [04:04<58:46, 84.87it/s]  1%|         | 4298/303576 [04:04<59:05, 84.40it/s]                                                       1%|         | 4300/303576 [04:04<59:05, 84.40it/s]  1%|         | 4307/303576 [04:04<59:45, 83.46it/s]  1%|         | 4316/303576 [04:05<59:52, 83.31it/s]  1%|         | 4325/303576 [04:05<1:00:20, 82.66it/s]  1%|         | 4334/303576 [04:05<1:00:17, 82.71it/s]  1%|         | 4343/303576 [04:05<1:00:36, 82.30it/s]  1%|         | 4352/303576 [04:05<1:00:23, 82.58it/s]  1%|         | 4361/303576 [04:05<1:00:35, 82.29it/s]  1%|         | 4370/303576 [04:05<1:00:11, 82.84it/s]  1%|         | 4379/303576 [04:05<1:00:42, 82.15it/s]  1%|         | 4388/303576 [04:05<1:01:09, 81.54it/s]  1%|         | 4397/303576 [04:06<1:02:21, 79.97it/s]                                                         1%|         | 4400/303576 [04:06<1:02:21, 79.97it/s]  1%|         | 4406/303576 [04:06<1:02:47, 79.41it/s]  1%|         | 4414/303576 [04:06<1:03:13, 78.87it/s]  1%|         | 4423/303576 [04:06<1:02:27, 79.82it/s]  1%|         | 4431/303576 [04:06<1:02:25, 79.86it/s]  1%|         | 4440/303576 [04:06<1:01:47, 80.68it/s]  1%|         | 4449/303576 [04:06<1:01:51, 80.60it/s]  1%|         | 4458/303576 [04:06<1:02:16, 80.04it/s]  1%|         | 4467/303576 [04:06<1:02:34, 79.67it/s]  1%|         | 4475/303576 [04:07<1:02:53, 79.27it/s]  1%|         | 4483/303576 [04:07<1:02:51, 79.29it/s]  1%|         | 4492/303576 [04:07<1:01:38, 80.86it/s]                                                         1%|         | 4500/303576 [04:07<1:01:38, 80.86it/s]  1%|         | 4501/303576 [04:07<1:01:26, 81.13it/s]  1%|         | 4510/303576 [04:07<1:01:00, 81.70it/s]  1%|         | 4519/303576 [04:07<1:07:43, 73.59it/s]  1%|         | 4527/303576 [04:07<1:12:56, 68.32it/s]  1%|         | 4534/303576 [04:07<1:16:20, 65.29it/s]  1%|         | 4541/303576 [04:07<1:19:03, 63.04it/s]  1%|         | 4548/303576 [04:08<1:18:14, 63.69it/s]  2%|         | 4555/303576 [04:08<1:17:15, 64.51it/s]  2%|         | 4562/303576 [04:08<1:16:14, 65.37it/s]  2%|         | 4569/303576 [04:08<1:15:58, 65.59it/s]  2%|         | 4576/303576 [04:08<1:15:46, 65.76it/s]  2%|         | 4583/303576 [04:10<7:16:25, 11.42it/s]  2%|         | 4588/303576 [04:10<5:59:59, 13.84it/s]  2%|         | 4593/303576 [04:10<5:00:11, 16.60it/s]  2%|         | 4598/303576 [04:10<4:11:28, 19.81it/s]                                                         2%|         | 4600/303576 [04:10<4:11:28, 19.81it/s]  2%|         | 4603/303576 [04:10<3:32:03, 23.50it/s]  2%|         | 4608/303576 [04:12<10:06:55,  8.21it/s]  2%|         | 4613/303576 [04:12<7:42:06, 10.78it/s]   2%|         | 4620/303576 [04:12<5:20:40, 15.54it/s]  2%|         | 4627/303576 [04:12<3:56:29, 21.07it/s]  2%|         | 4634/303576 [04:12<3:03:16, 27.19it/s]  2%|         | 4641/303576 [04:12<2:28:41, 33.51it/s]  2%|         | 4648/303576 [04:13<2:06:12, 39.48it/s]  2%|         | 4655/303576 [04:13<1:51:01, 44.87it/s]  2%|         | 4662/303576 [04:13<1:40:15, 49.69it/s]  2%|         | 4669/303576 [04:13<1:32:34, 53.81it/s]  2%|         | 4676/303576 [04:13<1:28:19, 56.41it/s]  2%|         | 4683/303576 [04:13<1:24:48, 58.74it/s]  2%|         | 4690/303576 [04:13<1:24:15, 59.12it/s]  2%|         | 4697/303576 [04:13<1:25:11, 58.47it/s]                                                         2%|         | 4700/303576 [04:13<1:25:11, 58.47it/s]  2%|         | 4704/303576 [04:13<1:25:38, 58.16it/s]  2%|         | 4711/303576 [04:14<1:25:56, 57.96it/s]  2%|         | 4717/303576 [04:14<1:26:10, 57.80it/s]  2%|         | 4723/303576 [04:14<1:26:21, 57.68it/s]  2%|         | 4729/303576 [04:14<1:26:21, 57.67it/s]  2%|         | 4735/303576 [04:14<1:26:19, 57.69it/s]  2%|         | 4741/303576 [04:14<1:26:19, 57.70it/s]  2%|         | 4747/303576 [04:14<1:26:30, 57.58it/s]  2%|         | 4754/303576 [04:14<1:25:08, 58.50it/s]  2%|         | 4761/303576 [04:14<1:22:24, 60.43it/s]  2%|         | 4768/303576 [04:14<1:19:23, 62.73it/s]  2%|         | 4775/303576 [04:15<1:17:29, 64.27it/s]  2%|         | 4782/303576 [04:15<1:21:52, 60.82it/s]  2%|         | 4789/303576 [04:15<1:29:26, 55.68it/s]  2%|         | 4795/303576 [04:15<1:33:31, 53.25it/s]                                                         2%|         | 4800/303576 [04:15<1:33:31, 53.25it/s]  2%|         | 4801/303576 [04:15<1:37:30, 51.07it/s]  2%|         | 4807/303576 [04:15<1:33:36, 53.20it/s]  2%|         | 4813/303576 [04:15<1:34:37, 52.62it/s]  2%|         | 4819/303576 [04:15<1:33:53, 53.03it/s]  2%|         | 4825/303576 [04:16<1:34:17, 52.81it/s]  2%|         | 4831/303576 [04:16<1:34:38, 52.61it/s]  2%|         | 4837/303576 [04:16<1:33:38, 53.17it/s]  2%|         | 4843/303576 [04:16<1:30:58, 54.73it/s]  2%|         | 4849/303576 [04:16<1:30:07, 55.24it/s]  2%|         | 4855/303576 [04:16<1:28:44, 56.10it/s]  2%|         | 4861/303576 [04:16<1:28:49, 56.05it/s]  2%|         | 4867/303576 [04:16<1:28:12, 56.44it/s]  2%|         | 4873/303576 [04:16<1:30:00, 55.31it/s]  2%|         | 4879/303576 [04:17<1:28:16, 56.39it/s]  2%|         | 4885/303576 [04:17<1:27:36, 56.83it/s]  2%|         | 4893/303576 [04:17<1:21:40, 60.95it/s]                                                         2%|         | 4900/303576 [04:17<1:21:40, 60.95it/s]  2%|         | 4901/303576 [04:17<1:17:37, 64.12it/s]  2%|         | 4909/303576 [04:17<1:15:02, 66.33it/s]  2%|         | 4917/303576 [04:17<1:13:04, 68.12it/s]  2%|         | 4926/303576 [04:17<1:08:57, 72.19it/s]  2%|         | 4936/303576 [04:17<1:02:51, 79.18it/s]  2%|         | 4946/303576 [04:17<58:30, 85.07it/s]    2%|         | 4956/303576 [04:17<55:41, 89.37it/s]  2%|         | 4967/303576 [04:18<53:28, 93.05it/s]  2%|         | 4977/303576 [04:18<52:21, 95.04it/s]  2%|         | 4987/303576 [04:18<55:19, 89.96it/s]  2%|         | 4997/303576 [04:18<58:36, 84.90it/s]                                                       2%|         | 5000/303576 [04:18<58:36, 84.90it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7446279525756836, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9664, 'eval_samples_per_second': 10.779, 'eval_steps_per_second': 0.095, 'epoch': 0.04, 'timestamp': 1762964774.496046, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.786, 'grad_norm': 0.25497278571128845, 'learning_rate': 0.0006637030148401164, 'epoch': 0.04, 'timestamp': 1762964775.9653046, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7843, 'grad_norm': 0.23388466238975525, 'learning_rate': 0.0006570987309299271, 'epoch': 0.04, 'timestamp': 1762964777.1169815, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8134, 'grad_norm': 0.25404104590415955, 'learning_rate': 0.0006505601640121141, 'epoch': 0.04, 'timestamp': 1762964778.277625, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8078, 'grad_norm': 0.26574981212615967, 'learning_rate': 0.0006440866601591442, 'epoch': 0.04, 'timestamp': 1762964779.507994, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7921, 'grad_norm': 0.35347145795822144, 'learning_rate': 0.0006376775719504951, 'epoch': 0.04, 'timestamp': 1762964780.7529957, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.78, 'grad_norm': 0.1973661482334137, 'learning_rate': 0.0006313322584079068, 'epoch': 0.05, 'timestamp': 1762964784.1381736, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8094, 'grad_norm': 0.1958410143852234, 'learning_rate': 0.0006250500849312785, 'epoch': 0.05, 'timestamp': 1762964787.283342, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7778, 'grad_norm': 0.2311604768037796, 'learning_rate': 0.0006188304232351978, 'epoch': 0.05, 'timestamp': 1762964789.0391428, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7809, 'grad_norm': 0.19899873435497284, 'learning_rate': 0.0006126726512861095, 'epoch': 0.05, 'timestamp': 1762964790.7852387, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7867, 'grad_norm': 0.1968112587928772, 'learning_rate': 0.0006065761532401028, 'epoch': 0.05, 'timestamp': 1762964791.9444444, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:26:35.790754: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:26:35.801372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964795.814002 1714745 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964795.817750 1714745 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964795.828042 1714745 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964795.828056 1714745 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964795.828058 1714745 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964795.828060 1714745 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:26:35.831181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:26:38 - TensorFlow version 2.19.1 available.
  2%|         | 5000/303576 [04:30<58:36, 84.90it/s]2025-11-12 16:26:46.203718: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:26:46.214421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964806.227262 1714771 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964806.231083 1714771 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964806.241407 1714771 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964806.241424 1714771 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964806.241426 1714771 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964806.241428 1714771 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:26:46.244569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:26:48 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                     
                                             [A  2%|         | 5000/303576 [04:40<58:36, 84.90it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [A  2%|         | 5001/303576 [04:40<69:30:29,  1.19it/s]  2%|         | 5006/303576 [04:41<55:26:22,  1.50it/s]  2%|         | 5014/303576 [04:41<38:04:37,  2.18it/s]  2%|         | 5021/303576 [04:41<27:35:48,  3.01it/s]  2%|         | 5028/303576 [04:41<20:01:56,  4.14it/s]  2%|         | 5034/303576 [04:41<15:11:22,  5.46it/s]  2%|         | 5040/303576 [04:41<11:28:50,  7.22it/s]  2%|         | 5046/303576 [04:41<8:42:43,  9.52it/s]   2%|         | 5052/303576 [04:41<6:40:36, 12.42it/s]  2%|         | 5058/303576 [04:42<5:12:13, 15.93it/s]  2%|         | 5064/303576 [04:42<4:08:50, 19.99it/s]  2%|         | 5070/303576 [04:42<3:23:29, 24.45it/s]  2%|         | 5076/303576 [04:42<2:52:53, 28.77it/s]  2%|         | 5082/303576 [04:42<2:31:08, 32.92it/s]  2%|         | 5088/303576 [04:42<2:12:13, 37.63it/s]  2%|         | 5094/303576 [04:42<1:59:29, 41.63it/s]  2%|         | 5100/303576 [04:42<1:49:58, 45.23it/s]                                                         2%|         | 5100/303576 [04:42<1:49:58, 45.23it/s]  2%|         | 5106/303576 [04:42<1:42:38, 48.47it/s]  2%|         | 5112/303576 [04:43<1:38:37, 50.44it/s]  2%|         | 5118/303576 [04:43<1:35:15, 52.22it/s]  2%|         | 5124/303576 [04:43<1:33:07, 53.42it/s]  2%|         | 5130/303576 [04:43<1:31:13, 54.52it/s]  2%|         | 5136/303576 [04:43<1:30:15, 55.11it/s]  2%|         | 5142/303576 [04:43<1:29:21, 55.66it/s]  2%|         | 5148/303576 [04:43<1:28:42, 56.07it/s]  2%|         | 5154/303576 [04:43<1:29:44, 55.42it/s]  2%|         | 5160/303576 [04:43<1:30:48, 54.77it/s]  2%|         | 5166/303576 [04:44<1:30:21, 55.04it/s]  2%|         | 5172/303576 [04:44<1:31:14, 54.50it/s]  2%|         | 5178/303576 [04:44<1:31:07, 54.58it/s]  2%|         | 5184/303576 [04:44<1:31:11, 54.54it/s]  2%|         | 5190/303576 [04:44<1:31:23, 54.41it/s]  2%|         | 5196/303576 [04:44<1:31:30, 54.35it/s]                                                         2%|         | 5200/303576 [04:44<1:31:30, 54.35it/s]  2%|         | 5202/303576 [04:44<1:31:49, 54.15it/s]  2%|         | 5208/303576 [04:44<1:31:40, 54.24it/s]  2%|         | 5214/303576 [04:44<1:31:40, 54.25it/s]  2%|         | 5220/303576 [04:45<1:32:02, 54.03it/s]  2%|         | 5226/303576 [04:45<1:31:56, 54.08it/s]  2%|         | 5232/303576 [04:45<1:31:08, 54.55it/s]  2%|         | 5238/303576 [04:45<1:31:40, 54.24it/s]  2%|         | 5244/303576 [04:45<1:30:52, 54.71it/s]  2%|         | 5250/303576 [04:45<1:32:42, 53.63it/s]  2%|         | 5256/303576 [04:45<1:34:31, 52.60it/s]  2%|         | 5262/303576 [04:45<1:35:28, 52.08it/s]  2%|         | 5268/303576 [04:45<1:36:30, 51.51it/s]  2%|         | 5274/303576 [04:46<1:37:21, 51.07it/s]  2%|         | 5280/303576 [04:46<1:37:47, 50.84it/s]  2%|         | 5286/303576 [04:46<1:37:54, 50.78it/s]  2%|         | 5292/303576 [04:46<1:37:49, 50.82it/s]  2%|         | 5298/303576 [04:46<1:37:38, 50.92it/s]                                                         2%|         | 5300/303576 [04:46<1:37:38, 50.92it/s]  2%|         | 5304/303576 [04:46<1:37:37, 50.92it/s]  2%|         | 5310/303576 [04:46<1:36:20, 51.60it/s]  2%|         | 5316/303576 [04:46<1:34:45, 52.46it/s]  2%|         | 5322/303576 [04:47<1:38:16, 50.59it/s]  2%|         | 5328/303576 [04:47<1:40:56, 49.24it/s]  2%|         | 5333/303576 [04:47<1:42:22, 48.55it/s]  2%|         | 5338/303576 [04:47<1:44:27, 47.59it/s]  2%|         | 5343/303576 [04:47<1:43:50, 47.87it/s]  2%|         | 5350/303576 [04:47<1:32:14, 53.88it/s]  2%|         | 5358/303576 [04:47<1:23:23, 59.60it/s]  2%|         | 5366/303576 [04:47<1:19:31, 62.50it/s]  2%|         | 5374/303576 [04:47<1:15:59, 65.40it/s]  2%|         | 5381/303576 [04:48<1:14:41, 66.55it/s]  2%|         | 5389/303576 [04:48<1:13:15, 67.84it/s]  2%|         | 5397/303576 [04:48<1:12:19, 68.72it/s]                                                         2%|         | 5400/303576 [04:48<1:12:19, 68.72it/s]  2%|         | 5404/303576 [04:48<1:12:32, 68.51it/s]  2%|         | 5411/303576 [04:48<1:14:02, 67.12it/s]  2%|         | 5419/303576 [04:48<1:13:00, 68.06it/s]  2%|         | 5427/303576 [04:48<1:12:05, 68.93it/s]  2%|         | 5435/303576 [04:48<1:11:26, 69.55it/s]  2%|         | 5443/303576 [04:48<1:10:46, 70.20it/s]  2%|         | 5451/303576 [04:49<1:10:39, 70.32it/s]  2%|         | 5459/303576 [04:49<1:10:43, 70.26it/s]  2%|         | 5467/303576 [04:49<1:09:44, 71.25it/s]  2%|         | 5475/303576 [04:49<1:07:30, 73.60it/s]  2%|         | 5484/303576 [04:49<1:05:09, 76.25it/s]  2%|         | 5493/303576 [04:49<1:04:08, 77.45it/s]                                                         2%|         | 5500/303576 [04:49<1:04:08, 77.45it/s]  2%|         | 5502/303576 [04:49<1:02:58, 78.88it/s]  2%|         | 5511/303576 [04:49<1:02:20, 79.69it/s]  2%|         | 5520/303576 [04:49<1:01:58, 80.15it/s]  2%|         | 5529/303576 [04:50<1:01:50, 80.32it/s]  2%|         | 5538/303576 [04:50<1:01:32, 80.72it/s]  2%|         | 5547/303576 [04:50<1:01:39, 80.56it/s]  2%|         | 5556/303576 [04:50<1:02:51, 79.02it/s]  2%|         | 5564/303576 [04:50<1:02:59, 78.84it/s]  2%|         | 5573/303576 [04:50<1:02:34, 79.38it/s]  2%|         | 5581/303576 [04:50<1:02:33, 79.38it/s]  2%|         | 5590/303576 [04:50<1:02:25, 79.56it/s]  2%|         | 5598/303576 [04:50<1:05:54, 75.34it/s]                                                         2%|         | 5600/303576 [04:50<1:05:54, 75.34it/s]  2%|         | 5606/303576 [04:51<1:11:30, 69.44it/s]  2%|         | 5614/303576 [04:51<1:16:04, 65.27it/s]  2%|         | 5621/303576 [04:51<1:20:19, 61.82it/s]  2%|         | 5628/303576 [04:51<1:22:17, 60.35it/s]  2%|         | 5635/303576 [04:51<1:24:05, 59.06it/s]  2%|         | 5641/303576 [04:51<1:25:48, 57.87it/s]  2%|         | 5647/303576 [04:51<1:27:37, 56.67it/s]  2%|         | 5653/303576 [04:51<1:27:36, 56.68it/s]  2%|         | 5659/303576 [04:51<1:27:32, 56.72it/s]  2%|         | 5665/303576 [04:52<1:29:05, 55.74it/s]  2%|         | 5671/303576 [04:52<1:29:03, 55.75it/s]  2%|         | 5677/303576 [04:52<1:29:45, 55.32it/s]  2%|         | 5683/303576 [04:52<1:30:28, 54.87it/s]  2%|         | 5690/303576 [04:52<1:27:53, 56.49it/s]  2%|         | 5697/303576 [04:52<1:25:13, 58.25it/s]                                                         2%|         | 5700/303576 [04:52<1:25:13, 58.25it/s]  2%|         | 5704/303576 [04:52<1:24:35, 58.69it/s]  2%|         | 5711/303576 [04:52<1:23:06, 59.74it/s]  2%|         | 5717/303576 [04:52<1:23:13, 59.64it/s]  2%|         | 5724/303576 [04:53<1:22:06, 60.46it/s]  2%|         | 5731/303576 [04:53<1:20:11, 61.91it/s]  2%|         | 5738/303576 [04:53<1:23:24, 59.52it/s]  2%|         | 5744/303576 [04:53<1:24:41, 58.61it/s]  2%|         | 5750/303576 [04:53<1:25:41, 57.93it/s]  2%|         | 5756/303576 [04:53<1:25:45, 57.88it/s]  2%|         | 5762/303576 [04:53<1:25:20, 58.16it/s]  2%|         | 5768/303576 [04:53<1:25:04, 58.35it/s]  2%|         | 5774/303576 [04:53<1:24:43, 58.58it/s]  2%|         | 5780/303576 [04:54<1:24:42, 58.59it/s]  2%|         | 5786/303576 [04:54<1:24:21, 58.84it/s]  2%|         | 5792/303576 [04:54<1:24:28, 58.75it/s]  2%|         | 5798/303576 [04:54<1:28:52, 55.84it/s]                                                         2%|         | 5800/303576 [04:54<1:28:52, 55.84it/s]  2%|         | 5804/303576 [04:54<1:30:31, 54.83it/s]  2%|         | 5810/303576 [04:54<1:29:13, 55.62it/s]  2%|         | 5816/303576 [04:54<1:28:53, 55.82it/s]  2%|         | 5822/303576 [04:54<1:28:55, 55.81it/s]  2%|         | 5828/303576 [04:54<1:27:49, 56.51it/s]  2%|         | 5834/303576 [04:55<1:27:37, 56.63it/s]  2%|         | 5840/303576 [04:55<1:27:43, 56.56it/s]  2%|         | 5846/303576 [04:55<1:27:32, 56.68it/s]  2%|         | 5852/303576 [04:55<1:27:02, 57.01it/s]  2%|         | 5858/303576 [04:55<1:27:12, 56.89it/s]  2%|         | 5864/303576 [04:55<1:32:03, 53.90it/s]  2%|         | 5870/303576 [04:55<1:33:57, 52.81it/s]  2%|         | 5876/303576 [04:55<1:36:47, 51.26it/s]  2%|         | 5882/303576 [04:55<1:38:36, 50.32it/s]  2%|         | 5888/303576 [04:56<1:40:18, 49.46it/s]  2%|         | 5893/303576 [04:56<1:40:17, 49.47it/s]  2%|         | 5898/303576 [04:56<1:42:37, 48.34it/s]                                                         2%|         | 5900/303576 [04:56<1:42:37, 48.34it/s]  2%|         | 5903/303576 [04:56<1:42:02, 48.62it/s]  2%|         | 5908/303576 [04:56<1:44:05, 47.66it/s]  2%|         | 5913/303576 [04:56<1:43:33, 47.90it/s]  2%|         | 5918/303576 [04:56<1:45:22, 47.08it/s]  2%|         | 5923/303576 [04:56<1:44:33, 47.45it/s]  2%|         | 5928/303576 [04:56<1:46:02, 46.78it/s]  2%|         | 5933/303576 [04:57<1:44:48, 47.33it/s]  2%|         | 5938/303576 [04:57<1:46:13, 46.70it/s]  2%|         | 5943/303576 [04:57<1:45:16, 47.12it/s]  2%|         | 5948/303576 [04:57<1:46:04, 46.77it/s]  2%|         | 5953/303576 [04:57<1:44:52, 47.30it/s]  2%|         | 5959/303576 [04:57<1:41:35, 48.82it/s]  2%|         | 5966/303576 [04:57<1:30:56, 54.54it/s]  2%|         | 5977/303576 [04:57<1:12:12, 68.69it/s]  2%|         | 5988/303576 [04:57<1:02:59, 78.73it/s]  2%|         | 5997/303576 [04:57<1:02:31, 79.33it/s]                                                         2%|         | 6000/303576 [04:58<1:02:30, 79.33it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7429916262626648, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4484, 'eval_samples_per_second': 10.068, 'eval_steps_per_second': 0.089, 'epoch': 0.05, 'timestamp': 1762964814.3933816, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7803, 'grad_norm': 0.19963425397872925, 'learning_rate': 0.0006005403193813205, 'epoch': 0.05, 'timestamp': 1762964816.3193302, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7774, 'grad_norm': 0.22066619992256165, 'learning_rate': 0.0005945645460609817, 'epoch': 0.05, 'timestamp': 1762964818.1229868, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7897, 'grad_norm': 0.18646720051765442, 'learning_rate': 0.0005886482356370105, 'epoch': 0.05, 'timestamp': 1762964820.037002, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7928, 'grad_norm': 0.22397945821285248, 'learning_rate': 0.0005827907964142653, 'epoch': 0.05, 'timestamp': 1762964821.7218575, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7919, 'grad_norm': 0.23737655580043793, 'learning_rate': 0.0005769916425853603, 'epoch': 0.05, 'timestamp': 1762964823.0874279, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7874, 'grad_norm': 0.22750529646873474, 'learning_rate': 0.0005712501941720844, 'epoch': 0.06, 'timestamp': 1762964824.3682873, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8047, 'grad_norm': 0.18101230263710022, 'learning_rate': 0.0005656224392113108, 'epoch': 0.06, 'timestamp': 1762964826.1448162, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7698, 'grad_norm': 0.1956828087568283, 'learning_rate': 0.0005599941218901588, 'epoch': 0.06, 'timestamp': 1762964827.8590224, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.778, 'grad_norm': 0.20768530666828156, 'learning_rate': 0.0005544218100484076, 'epoch': 0.06, 'timestamp': 1762964829.753626, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7832, 'grad_norm': 0.2189980000257492, 'learning_rate': 0.0005489049463944995, 'epoch': 0.06, 'timestamp': 1762964831.4598303, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:27:14.755405: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:27:14.766077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964834.778721 1714817 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964834.782463 1714817 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964834.792663 1714817 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964834.792682 1714817 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964834.792684 1714817 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964834.792686 1714817 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:27:14.795809: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:27:16 - TensorFlow version 2.19.1 available.
  2%|         | 6000/303576 [05:10<1:02:30, 79.33it/s]2025-11-12 16:27:24.394364: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:27:24.404824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964844.417283 1714843 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964844.420992 1714843 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964844.431224 1714843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964844.431241 1714843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964844.431243 1714843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964844.431244 1714843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:27:24.434354: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:27:26 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                       
                                             [A  2%|         | 6000/303576 [05:18<1:02:30, 79.33it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-6000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-6000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-6000/model.safetensors
  2%|         | 6001/303576 [05:18<72:38:51,  1.14it/s]  2%|         | 6007/303576 [05:19<53:58:31,  1.53it/s]  2%|         | 6015/303576 [05:19<36:27:42,  2.27it/s]  2%|         | 6022/303576 [05:19<26:08:41,  3.16it/s]  2%|         | 6029/303576 [05:19<18:48:54,  4.39it/s]  2%|         | 6036/303576 [05:19<13:37:14,  6.07it/s]  2%|         | 6043/303576 [05:19<9:57:51,  8.29it/s]   2%|         | 6050/303576 [05:19<7:22:44, 11.20it/s]  2%|         | 6057/303576 [05:19<5:36:26, 14.74it/s]  2%|         | 6064/303576 [05:19<4:21:15, 18.98it/s]  2%|         | 6071/303576 [05:20<3:25:28, 24.13it/s]  2%|         | 6078/303576 [05:20<2:46:11, 29.83it/s]  2%|         | 6085/303576 [05:20<2:18:46, 35.73it/s]  2%|         | 6092/303576 [05:20<1:59:45, 41.40it/s]  2%|         | 6099/303576 [05:20<1:46:25, 46.59it/s]                                                         2%|         | 6100/303576 [05:20<1:46:25, 46.59it/s]  2%|         | 6106/303576 [05:20<1:38:24, 50.38it/s]  2%|         | 6113/303576 [05:20<1:32:38, 53.52it/s]  2%|         | 6120/303576 [05:20<1:28:27, 56.05it/s]  2%|         | 6127/303576 [05:20<1:25:50, 57.75it/s]  2%|         | 6134/303576 [05:21<1:24:07, 58.93it/s]  2%|         | 6141/303576 [05:21<1:23:18, 59.50it/s]  2%|         | 6148/303576 [05:21<1:22:32, 60.06it/s]  2%|         | 6155/303576 [05:21<1:21:56, 60.50it/s]  2%|         | 6162/303576 [05:21<1:21:50, 60.56it/s]  2%|         | 6169/303576 [05:21<1:21:53, 60.53it/s]  2%|         | 6176/303576 [05:21<1:21:54, 60.52it/s]  2%|         | 6183/303576 [05:21<1:23:05, 59.65it/s]  2%|         | 6189/303576 [05:21<1:25:38, 57.88it/s]  2%|         | 6195/303576 [05:22<1:27:33, 56.60it/s]                                                         2%|         | 6200/303576 [05:22<1:27:33, 56.60it/s]  2%|         | 6201/303576 [05:22<1:29:01, 55.68it/s]  2%|         | 6207/303576 [05:22<1:28:54, 55.75it/s]  2%|         | 6213/303576 [05:22<1:29:35, 55.32it/s]  2%|         | 6219/303576 [05:22<1:28:55, 55.73it/s]  2%|         | 6225/303576 [05:22<1:32:01, 53.85it/s]  2%|         | 6231/303576 [05:22<1:35:42, 51.78it/s]  2%|         | 6237/303576 [05:22<1:37:58, 50.58it/s]  2%|         | 6244/303576 [05:23<1:30:21, 54.84it/s]  2%|         | 6251/303576 [05:23<1:25:25, 58.01it/s]  2%|         | 6258/303576 [05:23<1:22:06, 60.35it/s]  2%|         | 6265/303576 [05:23<1:19:10, 62.58it/s]  2%|         | 6273/303576 [05:23<1:16:35, 64.70it/s]  2%|         | 6281/303576 [05:23<1:14:47, 66.25it/s]  2%|         | 6289/303576 [05:23<1:13:37, 67.29it/s]  2%|         | 6297/303576 [05:23<1:12:59, 67.87it/s]                                                         2%|         | 6300/303576 [05:23<1:12:59, 67.87it/s]  2%|         | 6305/303576 [05:23<1:12:08, 68.68it/s]  2%|         | 6313/303576 [05:24<1:11:36, 69.18it/s]  2%|         | 6321/303576 [05:24<1:11:26, 69.34it/s]  2%|         | 6329/303576 [05:24<1:11:24, 69.37it/s]  2%|         | 6337/303576 [05:24<1:10:54, 69.87it/s]  2%|         | 6345/303576 [05:24<1:10:47, 69.99it/s]  2%|         | 6353/303576 [05:24<1:10:23, 70.38it/s]  2%|         | 6361/303576 [05:24<1:10:03, 70.71it/s]  2%|         | 6369/303576 [05:24<1:09:51, 70.90it/s]  2%|         | 6377/303576 [05:24<1:09:41, 71.08it/s]  2%|         | 6385/303576 [05:25<1:09:38, 71.13it/s]  2%|         | 6393/303576 [05:25<1:09:37, 71.14it/s]                                                         2%|         | 6400/303576 [05:25<1:09:37, 71.14it/s]  2%|         | 6401/303576 [05:25<1:09:39, 71.10it/s]  2%|         | 6409/303576 [05:25<1:09:40, 71.09it/s]  2%|         | 6417/303576 [05:25<1:09:46, 70.98it/s]  2%|         | 6425/303576 [05:25<1:09:38, 71.12it/s]  2%|         | 6433/303576 [05:25<1:10:04, 70.68it/s]  2%|         | 6441/303576 [05:25<1:09:57, 70.79it/s]  2%|         | 6449/303576 [05:25<1:09:54, 70.83it/s]  2%|         | 6457/303576 [05:26<1:09:51, 70.88it/s]  2%|         | 6465/303576 [05:26<1:10:24, 70.33it/s]  2%|         | 6473/303576 [05:26<1:11:41, 69.07it/s]  2%|         | 6480/303576 [05:26<1:12:15, 68.52it/s]  2%|         | 6487/303576 [05:26<1:13:17, 67.56it/s]  2%|         | 6494/303576 [05:26<1:13:26, 67.42it/s]                                                         2%|         | 6500/303576 [05:26<1:13:26, 67.42it/s]  2%|         | 6501/303576 [05:26<1:14:08, 66.78it/s]  2%|         | 6508/303576 [05:26<1:14:07, 66.79it/s]  2%|         | 6515/303576 [05:26<1:14:31, 66.43it/s]  2%|         | 6522/303576 [05:27<1:14:19, 66.62it/s]  2%|         | 6529/303576 [05:27<1:14:46, 66.21it/s]  2%|         | 6536/303576 [05:27<1:14:02, 66.86it/s]  2%|         | 6543/303576 [05:27<1:13:13, 67.60it/s]  2%|         | 6551/303576 [05:27<1:12:32, 68.24it/s]  2%|         | 6559/303576 [05:27<1:11:43, 69.02it/s]  2%|         | 6566/303576 [05:27<1:11:40, 69.07it/s]  2%|         | 6575/303576 [05:27<1:07:57, 72.83it/s]  2%|         | 6584/303576 [05:27<1:04:48, 76.37it/s]  2%|         | 6593/303576 [05:27<1:02:05, 79.71it/s]                                                         2%|         | 6600/303576 [05:28<1:02:05, 79.71it/s]  2%|         | 6602/303576 [05:28<1:01:22, 80.65it/s]  2%|         | 6611/303576 [05:28<1:02:41, 78.96it/s]  2%|         | 6619/303576 [05:28<1:04:03, 77.26it/s]  2%|         | 6628/303576 [05:28<1:03:29, 77.96it/s]  2%|         | 6636/303576 [05:28<1:03:11, 78.32it/s]  2%|         | 6645/303576 [05:28<1:02:30, 79.17it/s]  2%|         | 6653/303576 [05:28<1:02:25, 79.28it/s]  2%|         | 6661/303576 [05:28<1:02:20, 79.38it/s]  2%|         | 6670/303576 [05:28<1:02:24, 79.28it/s]  2%|         | 6678/303576 [05:29<1:02:33, 79.10it/s]  2%|         | 6686/303576 [05:29<1:02:23, 79.30it/s]  2%|         | 6694/303576 [05:29<1:02:18, 79.40it/s]                                                         2%|         | 6700/303576 [05:29<1:02:18, 79.40it/s]  2%|         | 6702/303576 [05:29<1:02:23, 79.30it/s]  2%|         | 6710/303576 [05:29<1:02:21, 79.35it/s]  2%|         | 6718/303576 [05:29<1:02:24, 79.28it/s]  2%|         | 6726/303576 [05:29<1:02:23, 79.31it/s]  2%|         | 6734/303576 [05:29<1:02:19, 79.37it/s]  2%|         | 6742/303576 [05:29<1:02:20, 79.35it/s]  2%|         | 6750/303576 [05:29<1:02:21, 79.33it/s]  2%|         | 6758/303576 [05:30<1:02:26, 79.22it/s]  2%|         | 6766/303576 [05:30<1:02:27, 79.21it/s]  2%|         | 6774/303576 [05:30<1:02:30, 79.13it/s]  2%|         | 6782/303576 [05:30<1:02:31, 79.12it/s]  2%|         | 6790/303576 [05:30<1:02:44, 78.84it/s]  2%|         | 6798/303576 [05:30<1:02:48, 78.76it/s]                                                         2%|         | 6800/303576 [05:30<1:02:48, 78.76it/s]  2%|         | 6806/303576 [05:30<1:02:54, 78.63it/s]  2%|         | 6814/303576 [05:30<1:02:57, 78.57it/s]  2%|         | 6822/303576 [05:30<1:03:02, 78.46it/s]  2%|         | 6830/303576 [05:30<1:03:01, 78.47it/s]  2%|         | 6838/303576 [05:31<1:02:57, 78.54it/s]  2%|         | 6846/303576 [05:31<1:03:02, 78.45it/s]  2%|         | 6854/303576 [05:31<1:03:09, 78.30it/s]  2%|         | 6862/303576 [05:31<1:03:11, 78.25it/s]  2%|         | 6870/303576 [05:31<1:03:15, 78.17it/s]  2%|         | 6878/303576 [05:31<1:03:21, 78.04it/s]  2%|         | 6886/303576 [05:31<1:03:19, 78.09it/s]  2%|         | 6894/303576 [05:31<1:03:15, 78.17it/s]                                                         2%|         | 6900/303576 [05:31<1:03:15, 78.17it/s]  2%|         | 6902/303576 [05:31<1:03:21, 78.03it/s]  2%|         | 6910/303576 [05:32<1:03:13, 78.19it/s]  2%|         | 6918/303576 [05:32<1:03:26, 77.94it/s]  2%|         | 6926/303576 [05:32<1:03:32, 77.80it/s]  2%|         | 6934/303576 [05:32<1:03:35, 77.74it/s]  2%|         | 6942/303576 [05:32<1:03:31, 77.82it/s]  2%|         | 6950/303576 [05:32<1:03:29, 77.86it/s]  2%|         | 6958/303576 [05:32<1:03:21, 78.02it/s]  2%|         | 6966/303576 [05:32<1:03:12, 78.20it/s]  2%|         | 6974/303576 [05:32<1:03:07, 78.31it/s]  2%|         | 6982/303576 [05:32<1:03:13, 78.18it/s]  2%|         | 6990/303576 [05:33<1:03:43, 77.57it/s]  2%|         | 6998/303576 [05:33<1:05:39, 75.29it/s]                                                         2%|         | 7000/303576 [05:33<1:05:39, 75.29it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7437443137168884, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.8541, 'eval_samples_per_second': 10.837, 'eval_steps_per_second': 0.096, 'epoch': 0.06, 'timestamp': 1762964852.3143418, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7801, 'grad_norm': 0.21735747158527374, 'learning_rate': 0.0005434429791822974, 'epoch': 0.06, 'timestamp': 1762964853.9637485, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7902, 'grad_norm': 0.28237631916999817, 'learning_rate': 0.0005380353621559033, 'epoch': 0.06, 'timestamp': 1762964855.6383643, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7924, 'grad_norm': 0.20080868899822235, 'learning_rate': 0.0005326815544950249, 'epoch': 0.06, 'timestamp': 1762964857.2732499, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7903, 'grad_norm': 0.22006367146968842, 'learning_rate': 0.0005273810207608918, 'epoch': 0.06, 'timestamp': 1762964858.6850398, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7676, 'grad_norm': 0.2531987726688385, 'learning_rate': 0.000522133230842702, 'epoch': 0.06, 'timestamp': 1762964860.1353703, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7909, 'grad_norm': 0.1895364671945572, 'learning_rate': 0.0005169376599046067, 'epoch': 0.07, 'timestamp': 1762964861.508916, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7667, 'grad_norm': 0.18605855107307434, 'learning_rate': 0.0005117937883332214, 'epoch': 0.07, 'timestamp': 1762964862.7818108, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7903, 'grad_norm': 0.22939209640026093, 'learning_rate': 0.000506701101685658, 'epoch': 0.07, 'timestamp': 1762964864.0471292, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7853, 'grad_norm': 0.2294732928276062, 'learning_rate': 0.0005016590906380751, 'epoch': 0.07, 'timestamp': 1762964865.325724, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7986, 'grad_norm': 0.19100286066532135, 'learning_rate': 0.0004966672509347412, 'epoch': 0.07, 'timestamp': 1762964866.6242068, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:27:50.444306: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:27:50.455109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964870.467672 1714884 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964870.471427 1714884 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964870.481653 1714884 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964870.481667 1714884 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964870.481669 1714884 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964870.481671 1714884 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:27:50.484830: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:27:52 - TensorFlow version 2.19.1 available.
2025-11-12 16:28:00.977901: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:28:00.988812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964881.001826 1714910 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964881.005741 1714910 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964881.016351 1714910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964881.016365 1714910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964881.016367 1714910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964881.016369 1714910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:28:01.019616: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:28:02 - TensorFlow version 2.19.1 available.
  2%|         | 7000/303576 [05:50<1:05:39, 75.29it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.17it/s][A                                                       
                                             [A  2%|         | 7000/303576 [05:55<1:05:39, 75.29it/s]
100%|| 2/2 [00:01<00:00,  1.17it/s][A
                                             [A  2%|         | 7001/303576 [05:55<85:59:52,  1.04s/it]  2%|         | 7006/303576 [05:55<65:07:47,  1.26it/s]  2%|         | 7013/303576 [05:55<44:00:15,  1.87it/s]  2%|         | 7020/303576 [05:55<30:19:59,  2.72it/s]  2%|         | 7027/303576 [05:55<21:14:03,  3.88it/s]  2%|         | 7034/303576 [05:56<15:06:16,  5.45it/s]  2%|         | 7040/303576 [05:56<11:20:37,  7.26it/s]  2%|         | 7046/303576 [05:56<8:33:00,  9.63it/s]   2%|         | 7052/303576 [05:56<6:30:07, 12.67it/s]  2%|         | 7058/303576 [05:56<5:03:26, 16.29it/s]  2%|         | 7064/303576 [05:56<4:00:06, 20.58it/s]  2%|         | 7070/303576 [05:56<3:13:43, 25.51it/s]  2%|         | 7076/303576 [05:56<2:41:59, 30.51it/s]  2%|         | 7082/303576 [05:56<2:18:38, 35.64it/s]  2%|         | 7088/303576 [05:57<2:04:13, 39.78it/s]  2%|         | 7094/303576 [05:57<1:52:49, 43.79it/s]  2%|         | 7100/303576 [05:57<1:50:40, 44.65it/s]                                                         2%|         | 7100/303576 [05:57<1:50:40, 44.65it/s]  2%|         | 7106/303576 [05:57<1:47:56, 45.78it/s]  2%|         | 7112/303576 [05:57<1:41:57, 48.46it/s]  2%|         | 7118/303576 [05:57<1:38:39, 50.08it/s]  2%|         | 7124/303576 [05:57<1:36:04, 51.43it/s]  2%|         | 7130/303576 [05:57<1:34:13, 52.44it/s]  2%|         | 7136/303576 [05:57<1:31:16, 54.13it/s]  2%|         | 7142/303576 [05:58<1:30:34, 54.55it/s]  2%|         | 7148/303576 [05:58<1:31:04, 54.25it/s]  2%|         | 7155/303576 [05:58<1:25:27, 57.80it/s]  2%|         | 7161/303576 [05:58<1:26:55, 56.83it/s]  2%|         | 7167/303576 [05:58<1:26:43, 56.96it/s]  2%|         | 7173/303576 [05:58<1:26:10, 57.33it/s]  2%|         | 7179/303576 [05:58<1:26:41, 56.98it/s]  2%|         | 7185/303576 [05:58<1:26:50, 56.88it/s]  2%|         | 7191/303576 [05:58<1:26:41, 56.98it/s]  2%|         | 7197/303576 [05:59<1:26:54, 56.84it/s]                                                         2%|         | 7200/303576 [05:59<1:26:54, 56.84it/s]  2%|         | 7203/303576 [05:59<1:27:35, 56.39it/s]  2%|         | 7209/303576 [05:59<1:28:12, 56.00it/s]  2%|         | 7215/303576 [05:59<1:28:08, 56.04it/s]  2%|         | 7221/303576 [05:59<1:28:42, 55.68it/s]  2%|         | 7228/303576 [05:59<1:26:18, 57.23it/s]  2%|         | 7235/303576 [05:59<1:24:20, 58.56it/s]  2%|         | 7242/303576 [05:59<1:23:26, 59.19it/s]  2%|         | 7249/303576 [05:59<1:22:21, 59.96it/s]  2%|         | 7256/303576 [06:00<1:22:02, 60.20it/s]  2%|         | 7263/303576 [06:00<1:21:29, 60.60it/s]  2%|         | 7270/303576 [06:00<1:21:35, 60.53it/s]  2%|         | 7277/303576 [06:00<1:21:41, 60.45it/s]  2%|         | 7284/303576 [06:00<1:22:40, 59.73it/s]  2%|         | 7290/303576 [06:00<1:22:36, 59.78it/s]  2%|         | 7297/303576 [06:00<1:22:19, 59.98it/s]                                                         2%|         | 7300/303576 [06:00<1:22:19, 59.98it/s]  2%|         | 7303/303576 [06:00<1:22:22, 59.94it/s]  2%|         | 7309/303576 [06:00<1:22:21, 59.96it/s]  2%|         | 7316/303576 [06:01<1:22:25, 59.90it/s]  2%|         | 7323/303576 [06:01<1:22:13, 60.05it/s]  2%|         | 7330/303576 [06:01<1:22:24, 59.91it/s]  2%|         | 7336/303576 [06:01<1:22:25, 59.90it/s]  2%|         | 7342/303576 [06:01<1:22:23, 59.92it/s]  2%|         | 7348/303576 [06:01<1:22:39, 59.72it/s]  2%|         | 7355/303576 [06:01<1:22:34, 59.79it/s]  2%|         | 7361/303576 [06:01<1:26:07, 57.33it/s]  2%|         | 7367/303576 [06:01<1:27:05, 56.69it/s]  2%|         | 7373/303576 [06:02<1:26:32, 57.05it/s]  2%|         | 7379/303576 [06:02<1:26:00, 57.40it/s]  2%|         | 7385/303576 [06:02<1:25:23, 57.82it/s]  2%|         | 7391/303576 [06:02<1:24:52, 58.16it/s]  2%|         | 7397/303576 [06:02<1:24:13, 58.60it/s]                                                         2%|         | 7400/303576 [06:02<1:24:13, 58.60it/s]  2%|         | 7406/303576 [06:02<1:14:56, 65.87it/s]  2%|         | 7414/303576 [06:02<1:10:45, 69.76it/s]  2%|         | 7422/303576 [06:02<1:08:13, 72.34it/s]  2%|         | 7431/303576 [06:02<1:05:00, 75.92it/s]  2%|         | 7440/303576 [06:02<1:03:42, 77.48it/s]  2%|         | 7449/303576 [06:03<1:02:04, 79.50it/s]  2%|         | 7458/303576 [06:03<1:01:21, 80.44it/s]  2%|         | 7467/303576 [06:03<1:00:35, 81.45it/s]  2%|         | 7476/303576 [06:03<1:00:29, 81.59it/s]  2%|         | 7485/303576 [06:03<59:22, 83.11it/s]    2%|         | 7494/303576 [06:03<58:51, 83.84it/s]                                                       2%|         | 7500/303576 [06:03<58:51, 83.84it/s]  2%|         | 7503/303576 [06:03<1:01:23, 80.37it/s]  2%|         | 7512/303576 [06:03<1:04:31, 76.48it/s]  2%|         | 7520/303576 [06:03<1:06:18, 74.41it/s]  2%|         | 7528/303576 [06:04<1:07:34, 73.01it/s]  2%|         | 7536/303576 [06:04<1:08:27, 72.08it/s]  2%|         | 7544/303576 [06:04<1:09:13, 71.27it/s]  2%|         | 7552/303576 [06:04<1:08:50, 71.67it/s]  2%|         | 7560/303576 [06:04<1:07:11, 73.43it/s]  2%|         | 7569/303576 [06:04<1:05:19, 75.52it/s]  2%|         | 7577/303576 [06:04<1:04:26, 76.56it/s]  2%|         | 7586/303576 [06:04<1:03:20, 77.88it/s]  3%|         | 7595/303576 [06:04<1:02:01, 79.54it/s]                                                         3%|         | 7600/303576 [06:05<1:02:01, 79.54it/s]  3%|         | 7605/303576 [06:05<58:16, 84.65it/s]    3%|         | 7615/303576 [06:05<55:27, 88.96it/s]  3%|         | 7625/303576 [06:05<54:14, 90.94it/s]  3%|         | 7635/303576 [06:05<59:04, 83.50it/s]  3%|         | 7644/303576 [06:05<1:02:48, 78.52it/s]  3%|         | 7653/303576 [06:05<1:04:28, 76.50it/s]  3%|         | 7661/303576 [06:05<1:06:01, 74.69it/s]  3%|         | 7669/303576 [06:05<1:07:22, 73.21it/s]  3%|         | 7677/303576 [06:06<1:08:08, 72.37it/s]  3%|         | 7685/303576 [06:06<1:08:42, 71.77it/s]  3%|         | 7693/303576 [06:06<1:09:11, 71.27it/s]                                                         3%|         | 7700/303576 [06:06<1:09:11, 71.27it/s]  3%|         | 7701/303576 [06:06<1:09:09, 71.31it/s]  3%|         | 7709/303576 [06:06<1:09:25, 71.03it/s]  3%|         | 7717/303576 [06:06<1:09:33, 70.88it/s]  3%|         | 7725/303576 [06:06<1:09:34, 70.87it/s]  3%|         | 7733/303576 [06:06<1:09:43, 70.72it/s]  3%|         | 7741/303576 [06:06<1:09:37, 70.81it/s]  3%|         | 7749/303576 [06:07<1:09:43, 70.72it/s]  3%|         | 7757/303576 [06:07<1:09:44, 70.70it/s]  3%|         | 7765/303576 [06:07<1:10:02, 70.38it/s]  3%|         | 7773/303576 [06:07<1:10:09, 70.28it/s]  3%|         | 7781/303576 [06:07<1:09:59, 70.43it/s]  3%|         | 7789/303576 [06:07<1:10:00, 70.41it/s]  3%|         | 7797/303576 [06:07<1:10:05, 70.32it/s]                                                         3%|         | 7800/303576 [06:07<1:10:05, 70.32it/s]  3%|         | 7805/303576 [06:07<1:10:12, 70.21it/s]  3%|         | 7813/303576 [06:07<1:10:08, 70.27it/s]  3%|         | 7821/303576 [06:08<1:10:10, 70.24it/s]  3%|         | 7829/303576 [06:08<1:10:12, 70.21it/s]  3%|         | 7837/303576 [06:08<1:11:19, 69.10it/s]  3%|         | 7844/303576 [06:08<1:12:26, 68.05it/s]  3%|         | 7852/303576 [06:08<1:11:44, 68.69it/s]  3%|         | 7860/303576 [06:08<1:11:13, 69.20it/s]  3%|         | 7868/303576 [06:08<1:10:45, 69.64it/s]  3%|         | 7876/303576 [06:08<1:10:49, 69.58it/s]  3%|         | 7884/303576 [06:08<1:10:34, 69.84it/s]  3%|         | 7892/303576 [06:09<1:10:38, 69.77it/s]  3%|         | 7900/303576 [06:09<1:10:33, 69.85it/s]                                                         3%|         | 7900/303576 [06:09<1:10:33, 69.85it/s]  3%|         | 7908/303576 [06:09<1:10:29, 69.90it/s]  3%|         | 7916/303576 [06:09<1:10:19, 70.08it/s]  3%|         | 7924/303576 [06:09<1:10:27, 69.93it/s]  3%|         | 7932/303576 [06:09<1:10:12, 70.17it/s]  3%|         | 7940/303576 [06:09<1:10:07, 70.26it/s]  3%|         | 7948/303576 [06:09<1:09:32, 70.85it/s]  3%|         | 7956/303576 [06:09<1:09:13, 71.18it/s]  3%|         | 7964/303576 [06:10<1:09:05, 71.31it/s]  3%|         | 7972/303576 [06:10<1:08:57, 71.45it/s]  3%|         | 7980/303576 [06:10<1:09:11, 71.20it/s]  3%|         | 7988/303576 [06:10<1:09:53, 70.49it/s]  3%|         | 7996/303576 [06:10<1:09:58, 70.40it/s]                                                         3%|         | 8000/303576 [06:10<1:09:58, 70.40it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7441885471343994, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.3243, 'eval_samples_per_second': 10.124, 'eval_steps_per_second': 0.09, 'epoch': 0.07, 'timestamp': 1762964888.9489317, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7798, 'grad_norm': 0.22693173587322235, 'learning_rate': 0.0004917250833376024, 'epoch': 0.07, 'timestamp': 1762964890.7485118, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7798, 'grad_norm': 0.23893803358078003, 'learning_rate': 0.0004868320935763531, 'epoch': 0.07, 'timestamp': 1762964892.5302625, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7885, 'grad_norm': 0.22821708023548126, 'learning_rate': 0.00048198779229900447, 'epoch': 0.07, 'timestamp': 1762964894.216347, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7769, 'grad_norm': 0.1899714171886444, 'learning_rate': 0.0004771916950229437, 'epoch': 0.07, 'timestamp': 1762964895.9070556, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7844, 'grad_norm': 0.2474786937236786, 'learning_rate': 0.0004724433220864801, 'epoch': 0.07, 'timestamp': 1762964897.1254268, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8145, 'grad_norm': 0.22451122105121613, 'learning_rate': 0.0004677421986008745, 'epoch': 0.08, 'timestamp': 1762964898.4538133, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7847, 'grad_norm': 0.3239612579345703, 'learning_rate': 0.00046308785440284404, 'epoch': 0.08, 'timestamp': 1762964899.7780201, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7704, 'grad_norm': 0.20062962174415588, 'learning_rate': 0.0004584798240075418, 'epoch': 0.08, 'timestamp': 1762964901.197993, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7644, 'grad_norm': 0.2690044343471527, 'learning_rate': 0.0004539176465620032, 'epoch': 0.08, 'timestamp': 1762964902.63535, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7964, 'grad_norm': 0.18361122906208038, 'learning_rate': 0.00044940086579905536, 'epoch': 0.08, 'timestamp': 1762964904.0495596, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:28:27.331200: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:28:27.341814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964907.354377 1714955 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964907.358133 1714955 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964907.368457 1714955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964907.368472 1714955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964907.368474 1714955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964907.368476 1714955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:28:27.371608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:28:29 - TensorFlow version 2.19.1 available.
2025-11-12 16:28:36.899831: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:28:36.910402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964916.923145 1714982 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964916.926948 1714982 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964916.937377 1714982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964916.937393 1714982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964916.937395 1714982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964916.937396 1714982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:28:36.940572: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:28:38 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A  3%|         | 8000/303576 [06:30<1:09:58, 70.40it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                       
                                             [A  3%|         | 8000/303576 [06:31<1:09:58, 70.40it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-8000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-8000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-8000/model.safetensors
  3%|         | 8001/303576 [06:31<74:00:50,  1.11it/s]  3%|         | 8007/303576 [06:31<54:42:08,  1.50it/s]  3%|         | 8014/303576 [06:31<38:22:55,  2.14it/s]  3%|         | 8022/303576 [06:31<25:56:06,  3.17it/s]  3%|         | 8031/303576 [06:32<17:13:52,  4.76it/s]  3%|         | 8039/303576 [06:32<12:15:45,  6.69it/s]  3%|         | 8047/303576 [06:32<8:50:41,  9.28it/s]   3%|         | 8055/303576 [06:32<6:28:47, 12.67it/s]  3%|         | 8063/303576 [06:32<4:50:22, 16.96it/s]  3%|         | 8071/303576 [06:32<3:41:26, 22.24it/s]  3%|         | 8079/303576 [06:32<2:53:19, 28.42it/s]  3%|         | 8087/303576 [06:32<2:20:24, 35.08it/s]  3%|         | 8095/303576 [06:32<1:57:49, 41.80it/s]                                                         3%|         | 8100/303576 [06:32<1:57:49, 41.80it/s]  3%|         | 8103/303576 [06:33<1:41:36, 48.47it/s]  3%|         | 8111/303576 [06:33<1:29:46, 54.85it/s]  3%|         | 8119/303576 [06:33<1:22:25, 59.74it/s]  3%|         | 8127/303576 [06:33<1:17:25, 63.60it/s]  3%|         | 8135/303576 [06:33<1:13:46, 66.75it/s]  3%|         | 8143/303576 [06:33<1:11:27, 68.90it/s]  3%|         | 8151/303576 [06:33<1:09:29, 70.86it/s]  3%|         | 8160/303576 [06:33<1:05:16, 75.42it/s]  3%|         | 8169/303576 [06:33<1:02:07, 79.25it/s]  3%|         | 8178/303576 [06:33<59:51, 82.25it/s]    3%|         | 8187/303576 [06:34<1:00:11, 81.79it/s]  3%|         | 8196/303576 [06:34<59:36, 82.59it/s]                                                         3%|         | 8200/303576 [06:34<59:36, 82.59it/s]  3%|         | 8205/303576 [06:34<59:21, 82.95it/s]  3%|         | 8214/303576 [06:34<59:02, 83.37it/s]  3%|         | 8223/303576 [06:34<59:09, 83.22it/s]  3%|         | 8232/303576 [06:34<59:35, 82.60it/s]  3%|         | 8241/303576 [06:34<59:45, 82.37it/s]  3%|         | 8250/303576 [06:34<59:00, 83.40it/s]  3%|         | 8259/303576 [06:34<58:10, 84.60it/s]  3%|         | 8269/303576 [06:35<56:14, 87.51it/s]  3%|         | 8279/303576 [06:35<54:47, 89.82it/s]  3%|         | 8289/303576 [06:35<53:54, 91.29it/s]  3%|         | 8299/303576 [06:35<52:57, 92.92it/s]                                                       3%|         | 8300/303576 [06:35<52:57, 92.92it/s]  3%|         | 8309/303576 [06:35<54:18, 90.60it/s]  3%|         | 8319/303576 [06:35<56:55, 86.45it/s]  3%|         | 8328/303576 [06:35<58:17, 84.41it/s]  3%|         | 8337/303576 [06:35<59:58, 82.05it/s]  3%|         | 8346/303576 [06:35<1:00:50, 80.87it/s]  3%|         | 8355/303576 [06:36<1:03:26, 77.56it/s]  3%|         | 8363/303576 [06:36<1:05:18, 75.34it/s]  3%|         | 8371/303576 [06:36<1:06:32, 73.94it/s]  3%|         | 8379/303576 [06:36<1:06:35, 73.89it/s]  3%|         | 8388/303576 [06:36<1:04:06, 76.75it/s]  3%|         | 8398/303576 [06:36<1:00:24, 81.44it/s]                                                         3%|         | 8400/303576 [06:36<1:00:24, 81.44it/s]  3%|         | 8407/303576 [06:36<58:58, 83.41it/s]    3%|         | 8416/303576 [06:36<1:00:45, 80.97it/s]  3%|         | 8425/303576 [06:36<1:02:11, 79.09it/s]  3%|         | 8433/303576 [06:37<1:02:52, 78.23it/s]  3%|         | 8441/303576 [06:37<1:03:33, 77.38it/s]  3%|         | 8449/303576 [06:37<1:04:08, 76.69it/s]  3%|         | 8457/303576 [06:37<1:04:37, 76.12it/s]  3%|         | 8465/303576 [06:37<1:06:07, 74.38it/s]  3%|         | 8473/303576 [06:37<1:07:16, 73.11it/s]  3%|         | 8481/303576 [06:37<1:07:54, 72.43it/s]  3%|         | 8489/303576 [06:37<1:08:08, 72.17it/s]  3%|         | 8497/303576 [06:37<1:08:17, 72.01it/s]                                                         3%|         | 8500/303576 [06:37<1:08:17, 72.01it/s]  3%|         | 8505/303576 [06:38<1:08:29, 71.80it/s]  3%|         | 8513/303576 [06:38<1:08:35, 71.70it/s]  3%|         | 8521/303576 [06:38<1:09:49, 70.42it/s]  3%|         | 8529/303576 [06:38<1:07:29, 72.86it/s]  3%|         | 8538/303576 [06:38<1:03:30, 77.43it/s]  3%|         | 8546/303576 [06:38<1:03:10, 77.82it/s]  3%|         | 8555/303576 [06:38<1:00:36, 81.12it/s]  3%|         | 8566/303576 [06:38<56:17, 87.34it/s]    3%|         | 8577/303576 [06:38<52:49, 93.07it/s]  3%|         | 8588/303576 [06:38<50:26, 97.45it/s]  3%|         | 8599/303576 [06:39<49:01, 100.28it/s]                                                        3%|         | 8600/303576 [06:39<49:01, 100.28it/s]  3%|         | 8610/303576 [06:39<48:17, 101.78it/s]  3%|         | 8621/303576 [06:39<47:37, 103.23it/s]  3%|         | 8632/303576 [06:39<47:06, 104.34it/s]  3%|         | 8643/303576 [06:39<46:54, 104.77it/s]  3%|         | 8654/303576 [06:39<46:39, 105.35it/s]  3%|         | 8665/303576 [06:39<46:23, 105.95it/s]  3%|         | 8676/303576 [06:39<46:15, 106.24it/s]  3%|         | 8687/303576 [06:39<46:08, 106.52it/s]  3%|         | 8698/303576 [06:40<46:01, 106.78it/s]                                                        3%|         | 8700/303576 [06:40<46:01, 106.78it/s]  3%|         | 8709/303576 [06:40<46:13, 106.33it/s]  3%|         | 8720/303576 [06:40<46:11, 106.37it/s]  3%|         | 8731/303576 [06:40<50:05, 98.10it/s]   3%|         | 8741/303576 [06:40<52:55, 92.84it/s]  3%|         | 8751/303576 [06:40<54:31, 90.12it/s]  3%|         | 8761/303576 [06:40<56:31, 86.93it/s]  3%|         | 8770/303576 [06:40<56:48, 86.49it/s]  3%|         | 8779/303576 [06:40<57:15, 85.81it/s]  3%|         | 8788/303576 [06:41<57:09, 85.95it/s]  3%|         | 8797/303576 [06:41<57:32, 85.38it/s]                                                       3%|         | 8800/303576 [06:41<57:32, 85.38it/s]  3%|         | 8806/303576 [06:41<58:06, 84.55it/s]  3%|         | 8815/303576 [06:41<59:18, 82.83it/s]  3%|         | 8824/303576 [06:41<59:26, 82.65it/s]  3%|         | 8833/303576 [06:41<58:48, 83.53it/s]  3%|         | 8843/303576 [06:41<56:46, 86.51it/s]  3%|         | 8852/303576 [06:41<56:35, 86.81it/s]  3%|         | 8861/303576 [06:41<57:36, 85.26it/s]  3%|         | 8870/303576 [06:42<57:53, 84.84it/s]  3%|         | 8880/303576 [06:42<56:21, 87.16it/s]  3%|         | 8889/303576 [06:42<56:20, 87.17it/s]  3%|         | 8898/303576 [06:42<56:58, 86.21it/s]                                                       3%|         | 8900/303576 [06:42<56:58, 86.21it/s]  3%|         | 8907/303576 [06:42<57:04, 86.04it/s]  3%|         | 8916/303576 [06:42<56:59, 86.16it/s]  3%|         | 8925/303576 [06:42<56:59, 86.16it/s]  3%|         | 8934/303576 [06:42<56:55, 86.28it/s]  3%|         | 8943/303576 [06:42<56:50, 86.40it/s]  3%|         | 8952/303576 [06:42<56:50, 86.39it/s]  3%|         | 8961/303576 [06:43<56:51, 86.35it/s]  3%|         | 8970/303576 [06:43<56:40, 86.63it/s]  3%|         | 8979/303576 [06:43<56:48, 86.44it/s]  3%|         | 8988/303576 [06:43<56:44, 86.53it/s]  3%|         | 8997/303576 [06:43<56:45, 86.51it/s]                                                       3%|         | 9000/303576 [06:43<56:44, 86.51it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.740702211856842, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9509, 'eval_samples_per_second': 10.787, 'eval_steps_per_second': 0.095, 'epoch': 0.08, 'timestamp': 1762964925.0009966, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7817, 'grad_norm': 0.2702542841434479, 'learning_rate': 0.00044492902999168497, 'epoch': 0.08, 'timestamp': 1762964926.404356, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7862, 'grad_norm': 0.24083611369132996, 'learning_rate': 0.00044050169190786145, 'epoch': 0.08, 'timestamp': 1762964927.6449819, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7751, 'grad_norm': 0.22359691560268402, 'learning_rate': 0.00043611840876580895, 'epoch': 0.08, 'timestamp': 1762964928.7785285, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7844, 'grad_norm': 0.22251459956169128, 'learning_rate': 0.0004317787421897226, 'epoch': 0.08, 'timestamp': 1762964930.0575364, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7799, 'grad_norm': 0.24215123057365417, 'learning_rate': 0.00042748225816592703, 'epoch': 0.08, 'timestamp': 1762964931.4099827, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.792, 'grad_norm': 0.23638604581356049, 'learning_rate': 0.00042322852699947, 'epoch': 0.08, 'timestamp': 1762964932.5392218, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7884, 'grad_norm': 0.2132541984319687, 'learning_rate': 0.0004190171232711488, 'epoch': 0.09, 'timestamp': 1762964933.476393, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7835, 'grad_norm': 0.20370402932167053, 'learning_rate': 0.0004148476257949619, 'epoch': 0.09, 'timestamp': 1762964934.6237826, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7862, 'grad_norm': 0.22295546531677246, 'learning_rate': 0.00041071961757598767, 'epoch': 0.09, 'timestamp': 1762964935.7946155, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7837, 'grad_norm': 0.2361418902873993, 'learning_rate': 0.0004066326857686796, 'epoch': 0.09, 'timestamp': 1762964936.9513202, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:29:00.787487: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:29:00.798241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964940.811072 1715021 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964940.814883 1715021 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964940.825398 1715021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964940.825413 1715021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964940.825415 1715021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964940.825417 1715021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:29:00.828509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:29:03 - TensorFlow version 2.19.1 available.
2025-11-12 16:29:11.263697: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:29:11.274354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964951.287154 1715047 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964951.290884 1715047 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964951.301550 1715047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964951.301567 1715047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964951.301568 1715047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964951.301570 1715047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:29:11.304757: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:29:13 - TensorFlow version 2.19.1 available.
  3%|         | 9000/303576 [07:00<56:44, 86.51it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                     
                                             [A  3%|         | 9000/303576 [07:05<56:44, 86.51it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A  3%|         | 9001/303576 [07:06<74:30:07,  1.10it/s]  3%|         | 9006/303576 [07:06<58:22:05,  1.40it/s]  3%|         | 9014/303576 [07:06<39:11:51,  2.09it/s]  3%|         | 9021/303576 [07:06<28:06:51,  2.91it/s]  3%|         | 9028/303576 [07:06<20:12:22,  4.05it/s]  3%|         | 9034/303576 [07:06<15:12:15,  5.38it/s]  3%|         | 9040/303576 [07:06<11:23:17,  7.18it/s]  3%|         | 9046/303576 [07:06<8:33:25,  9.56it/s]   3%|         | 9052/303576 [07:06<6:29:13, 12.61it/s]  3%|         | 9058/303576 [07:07<5:03:51, 16.15it/s]  3%|         | 9064/303576 [07:07<4:03:06, 20.19it/s]  3%|         | 9070/303576 [07:07<3:19:06, 24.65it/s]  3%|         | 9076/303576 [07:07<2:48:08, 29.19it/s]  3%|         | 9082/303576 [07:07<2:26:54, 33.41it/s]  3%|         | 9088/303576 [07:07<2:10:14, 37.69it/s]  3%|         | 9094/303576 [07:07<1:57:09, 41.89it/s]  3%|         | 9100/303576 [07:07<1:47:23, 45.70it/s]                                                         3%|         | 9100/303576 [07:07<1:47:23, 45.70it/s]  3%|         | 9106/303576 [07:07<1:40:57, 48.61it/s]  3%|         | 9113/303576 [07:08<1:34:20, 52.02it/s]  3%|         | 9121/303576 [07:08<1:24:17, 58.22it/s]  3%|         | 9130/303576 [07:08<1:14:48, 65.61it/s]  3%|         | 9141/303576 [07:08<1:03:55, 76.76it/s]  3%|         | 9152/303576 [07:08<57:17, 85.66it/s]    3%|         | 9163/303576 [07:08<53:17, 92.09it/s]  3%|         | 9174/303576 [07:08<51:06, 95.99it/s]  3%|         | 9185/303576 [07:08<49:24, 99.29it/s]  3%|         | 9196/303576 [07:08<50:16, 97.59it/s]                                                       3%|         | 9200/303576 [07:08<50:16, 97.59it/s]  3%|         | 9206/303576 [07:09<51:07, 95.97it/s]  3%|         | 9216/303576 [07:09<51:09, 95.89it/s]  3%|         | 9227/303576 [07:09<50:06, 97.92it/s]  3%|         | 9238/303576 [07:09<49:27, 99.17it/s]  3%|         | 9249/303576 [07:09<48:27, 101.23it/s]  3%|         | 9260/303576 [07:09<49:10, 99.75it/s]   3%|         | 9270/303576 [07:09<54:32, 89.92it/s]  3%|         | 9280/303576 [07:09<58:31, 83.80it/s]  3%|         | 9289/303576 [07:09<1:01:28, 79.78it/s]  3%|         | 9298/303576 [07:10<1:03:28, 77.27it/s]                                                         3%|         | 9300/303576 [07:10<1:03:28, 77.27it/s]  3%|         | 9306/303576 [07:10<1:05:16, 75.14it/s]  3%|         | 9314/303576 [07:10<1:06:35, 73.65it/s]  3%|         | 9322/303576 [07:10<1:07:31, 72.63it/s]  3%|         | 9330/303576 [07:10<1:08:08, 71.98it/s]  3%|         | 9338/303576 [07:10<1:08:40, 71.40it/s]  3%|         | 9346/303576 [07:10<1:08:58, 71.09it/s]  3%|         | 9354/303576 [07:10<1:09:08, 70.92it/s]  3%|         | 9362/303576 [07:11<1:08:56, 71.13it/s]  3%|         | 9370/303576 [07:11<1:08:36, 71.48it/s]  3%|         | 9378/303576 [07:11<1:08:22, 71.72it/s]  3%|         | 9386/303576 [07:11<1:08:33, 71.51it/s]  3%|         | 9394/303576 [07:11<1:08:36, 71.47it/s]                                                         3%|         | 9400/303576 [07:11<1:08:36, 71.47it/s]  3%|         | 9402/303576 [07:11<1:08:35, 71.49it/s]  3%|         | 9410/303576 [07:11<1:09:08, 70.91it/s]  3%|         | 9418/303576 [07:11<1:07:19, 72.82it/s]  3%|         | 9427/303576 [07:11<1:04:17, 76.25it/s]  3%|         | 9436/303576 [07:12<1:02:08, 78.90it/s]  3%|         | 9445/303576 [07:12<59:49, 81.95it/s]    3%|         | 9454/303576 [07:12<1:00:10, 81.45it/s]  3%|         | 9463/303576 [07:12<1:02:03, 78.99it/s]  3%|         | 9471/303576 [07:12<1:03:04, 77.71it/s]  3%|         | 9479/303576 [07:12<1:02:39, 78.22it/s]  3%|         | 9488/303576 [07:12<1:00:50, 80.55it/s]  3%|         | 9497/303576 [07:12<1:01:20, 79.89it/s]                                                         3%|         | 9500/303576 [07:12<1:01:20, 79.89it/s]  3%|         | 9506/303576 [07:12<1:01:36, 79.55it/s]  3%|         | 9514/303576 [07:12<1:01:55, 79.15it/s]  3%|         | 9522/303576 [07:13<1:02:01, 79.02it/s]  3%|         | 9530/303576 [07:13<1:02:04, 78.96it/s]  3%|         | 9539/303576 [07:13<1:00:30, 81.00it/s]  3%|         | 9548/303576 [07:13<1:00:46, 80.62it/s]  3%|         | 9557/303576 [07:13<1:00:38, 80.81it/s]  3%|         | 9566/303576 [07:13<1:01:02, 80.26it/s]  3%|         | 9577/303576 [07:13<56:49, 86.23it/s]    3%|         | 9587/303576 [07:13<54:27, 89.97it/s]  3%|         | 9598/303576 [07:13<52:26, 93.43it/s]                                                       3%|         | 9600/303576 [07:13<52:26, 93.43it/s]  3%|         | 9608/303576 [07:14<51:26, 95.24it/s]  3%|         | 9619/303576 [07:14<50:45, 96.52it/s]  3%|         | 9630/303576 [07:14<49:58, 98.04it/s]  3%|         | 9641/303576 [07:14<49:41, 98.58it/s]  3%|         | 9651/303576 [07:14<52:56, 92.52it/s]  3%|         | 9661/303576 [07:14<57:26, 85.28it/s]  3%|         | 9670/303576 [07:14<1:00:47, 80.59it/s]  3%|         | 9679/303576 [07:14<1:02:34, 78.28it/s]  3%|         | 9687/303576 [07:14<1:03:35, 77.03it/s]  3%|         | 9696/303576 [07:15<1:00:56, 80.38it/s]                                                         3%|         | 9700/303576 [07:15<1:00:56, 80.38it/s]  3%|         | 9705/303576 [07:15<1:00:43, 80.65it/s]  3%|         | 9714/303576 [07:15<1:00:33, 80.88it/s]  3%|         | 9723/303576 [07:15<1:00:11, 81.37it/s]  3%|         | 9732/303576 [07:15<1:00:31, 80.92it/s]  3%|         | 9741/303576 [07:15<1:00:44, 80.62it/s]  3%|         | 9750/303576 [07:15<1:02:12, 78.72it/s]  3%|         | 9758/303576 [07:15<1:03:59, 76.52it/s]  3%|         | 9766/303576 [07:15<1:04:55, 75.43it/s]  3%|         | 9774/303576 [07:16<1:04:37, 75.78it/s]  3%|         | 9782/303576 [07:16<1:03:47, 76.76it/s]  3%|         | 9791/303576 [07:16<1:02:41, 78.11it/s]  3%|         | 9800/303576 [07:16<1:01:56, 79.04it/s]                                                         3%|         | 9800/303576 [07:16<1:01:56, 79.04it/s]  3%|         | 9810/303576 [07:16<58:26, 83.78it/s]    3%|         | 9819/303576 [07:16<57:19, 85.40it/s]  3%|         | 9828/303576 [07:16<56:32, 86.59it/s]  3%|         | 9837/303576 [07:16<1:00:55, 80.36it/s]  3%|         | 9846/303576 [07:16<1:02:59, 77.72it/s]  3%|         | 9854/303576 [07:17<1:04:49, 75.52it/s]  3%|         | 9862/303576 [07:17<1:06:13, 73.91it/s]  3%|         | 9870/303576 [07:17<1:07:16, 72.75it/s]  3%|         | 9878/303576 [07:17<1:07:38, 72.36it/s]  3%|         | 9886/303576 [07:17<1:07:52, 72.12it/s]  3%|         | 9894/303576 [07:17<1:08:10, 71.79it/s]                                                         3%|         | 9900/303576 [07:17<1:08:10, 71.79it/s]  3%|         | 9902/303576 [07:17<1:08:29, 71.46it/s]  3%|         | 9910/303576 [07:17<1:07:22, 72.65it/s]  3%|         | 9919/303576 [07:17<1:05:17, 74.96it/s]  3%|         | 9928/303576 [07:18<1:03:44, 76.79it/s]  3%|         | 9937/303576 [07:18<1:02:51, 77.85it/s]  3%|         | 9946/303576 [07:18<1:02:09, 78.73it/s]  3%|         | 9955/303576 [07:18<1:01:41, 79.32it/s]  3%|         | 9964/303576 [07:18<1:01:12, 79.95it/s]  3%|         | 9973/303576 [07:18<1:01:00, 80.22it/s]  3%|         | 9982/303576 [07:18<1:00:46, 80.52it/s]  3%|         | 9991/303576 [07:18<1:00:35, 80.76it/s]  3%|         | 10000/303576 [07:18<1:00:07, 81.39it/s]                                                          3%|         | 10000/303576 [07:18<1:00:07, 81.39it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7419368624687195, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.47, 'eval_samples_per_second': 10.058, 'eval_steps_per_second': 0.089, 'epoch': 0.09, 'timestamp': 1762964959.4217267, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.781, 'grad_norm': 0.23046252131462097, 'learning_rate': 0.0004025864216355775, 'epoch': 0.09, 'timestamp': 1762964961.3011692, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7746, 'grad_norm': 0.20431563258171082, 'learning_rate': 0.0003985804205064292, 'epoch': 0.09, 'timestamp': 1762964962.4102924, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7822, 'grad_norm': 0.31833890080451965, 'learning_rate': 0.00039461428173771904, 'epoch': 0.09, 'timestamp': 1762964963.5732834, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7724, 'grad_norm': 0.21691861748695374, 'learning_rate': 0.0003906876086725994, 'epoch': 0.09, 'timestamp': 1762964964.984407, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7684, 'grad_norm': 0.25825735926628113, 'learning_rate': 0.0003868000086012205, 'epoch': 0.09, 'timestamp': 1762964966.2417626, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7982, 'grad_norm': 0.21850411593914032, 'learning_rate': 0.00038295109272145565, 'epoch': 0.09, 'timestamp': 1762964967.4043567, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7756, 'grad_norm': 0.21565809845924377, 'learning_rate': 0.0003791783939394095, 'epoch': 0.1, 'timestamp': 1762964968.5872686, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7829, 'grad_norm': 0.21228115260601044, 'learning_rate': 0.000375405318165769, 'epoch': 0.1, 'timestamp': 1762964969.864279, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7728, 'grad_norm': 0.2021665871143341, 'learning_rate': 0.00037166978699124364, 'epoch': 0.1, 'timestamp': 1762964971.1893094, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7765, 'grad_norm': 0.3310887813568115, 'learning_rate': 0.0003679714268222438, 'epoch': 0.1, 'timestamp': 1762964972.4335253, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:29:35.723506: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:29:35.734170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964975.746855 1715091 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964975.750603 1715091 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964975.760898 1715091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964975.760914 1715091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964975.760916 1715091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964975.760918 1715091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:29:35.764048: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:29:37 - TensorFlow version 2.19.1 available.
  3%|         | 10000/303576 [07:30<1:00:07, 81.39it/s]2025-11-12 16:29:45.388827: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:29:45.399406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762964985.412050 1715112 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762964985.415822 1715112 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762964985.426101 1715112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964985.426114 1715112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964985.426116 1715112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762964985.426117 1715112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:29:45.429282: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:29:47 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A  3%|         | 10000/303576 [07:40<1:00:07, 81.39it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-10000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-10000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-10000/model.safetensors
  3%|         | 10001/303576 [07:40<79:52:30,  1.02it/s]  3%|         | 10007/303576 [07:40<57:52:31,  1.41it/s]  3%|         | 10015/303576 [07:40<38:12:23,  2.13it/s]  3%|         | 10022/303576 [07:40<27:02:07,  3.02it/s]  3%|         | 10029/303576 [07:40<19:16:52,  4.23it/s]  3%|         | 10036/303576 [07:40<13:53:06,  5.87it/s]  3%|         | 10043/303576 [07:40<10:07:24,  8.05it/s]  3%|         | 10050/303576 [07:41<7:29:59, 10.87it/s]   3%|         | 10056/303576 [07:41<5:51:48, 13.91it/s]  3%|         | 10062/303576 [07:41<4:37:35, 17.62it/s]  3%|         | 10068/303576 [07:41<3:43:18, 21.91it/s]  3%|         | 10074/303576 [07:41<3:09:00, 25.88it/s]  3%|         | 10080/303576 [07:41<2:44:09, 29.80it/s]  3%|         | 10086/303576 [07:41<2:24:14, 33.91it/s]  3%|         | 10093/303576 [07:41<2:03:10, 39.71it/s]  3%|         | 10100/303576 [07:41<1:49:26, 44.69it/s]                                                          3%|         | 10100/303576 [07:41<1:49:26, 44.69it/s]  3%|         | 10106/303576 [07:42<1:41:53, 48.00it/s]  3%|         | 10113/303576 [07:42<1:34:50, 51.57it/s]  3%|         | 10120/303576 [07:42<1:29:59, 54.35it/s]  3%|         | 10127/303576 [07:42<1:25:44, 57.04it/s]  3%|         | 10134/303576 [07:42<1:22:05, 59.57it/s]  3%|         | 10141/303576 [07:42<1:20:14, 60.95it/s]  3%|         | 10148/303576 [07:42<1:18:36, 62.21it/s]  3%|         | 10155/303576 [07:42<1:17:45, 62.89it/s]  3%|         | 10162/303576 [07:42<1:17:11, 63.36it/s]  3%|         | 10169/303576 [07:43<1:17:04, 63.44it/s]  3%|         | 10176/303576 [07:43<1:17:10, 63.37it/s]  3%|         | 10183/303576 [07:43<1:16:58, 63.53it/s]  3%|         | 10190/303576 [07:43<1:17:00, 63.50it/s]  3%|         | 10197/303576 [07:43<1:17:01, 63.49it/s]                                                          3%|         | 10200/303576 [07:43<1:17:01, 63.49it/s]  3%|         | 10204/303576 [07:43<1:16:57, 63.53it/s]  3%|         | 10211/303576 [07:43<1:16:44, 63.71it/s]  3%|         | 10218/303576 [07:43<1:16:45, 63.70it/s]  3%|         | 10225/303576 [07:43<1:16:35, 63.83it/s]  3%|         | 10232/303576 [07:44<1:16:38, 63.79it/s]  3%|         | 10239/303576 [07:44<1:16:30, 63.90it/s]  3%|         | 10246/303576 [07:44<1:16:53, 63.59it/s]  3%|         | 10253/303576 [07:44<1:16:55, 63.55it/s]  3%|         | 10260/303576 [07:44<1:17:00, 63.48it/s]  3%|         | 10267/303576 [07:44<1:16:49, 63.63it/s]  3%|         | 10274/303576 [07:44<1:16:43, 63.71it/s]  3%|         | 10281/303576 [07:44<1:16:42, 63.73it/s]  3%|         | 10288/303576 [07:44<1:16:55, 63.55it/s]  3%|         | 10295/303576 [07:45<1:16:54, 63.56it/s]                                                          3%|         | 10300/303576 [07:45<1:16:54, 63.56it/s]  3%|         | 10302/303576 [07:45<1:17:04, 63.42it/s]  3%|         | 10309/303576 [07:45<1:17:01, 63.46it/s]  3%|         | 10316/303576 [07:45<1:17:00, 63.47it/s]  3%|         | 10323/303576 [07:45<1:17:54, 62.73it/s]  3%|         | 10330/303576 [07:45<1:19:10, 61.73it/s]  3%|         | 10337/303576 [07:45<1:20:12, 60.93it/s]  3%|         | 10344/303576 [07:45<1:20:54, 60.41it/s]  3%|         | 10351/303576 [07:45<1:21:12, 60.18it/s]  3%|         | 10358/303576 [07:46<1:21:36, 59.89it/s]  3%|         | 10364/303576 [07:46<1:21:43, 59.80it/s]  3%|         | 10370/303576 [07:46<1:21:54, 59.66it/s]  3%|         | 10376/303576 [07:46<1:21:56, 59.64it/s]  3%|         | 10382/303576 [07:46<1:21:59, 59.59it/s]  3%|         | 10388/303576 [07:46<1:22:04, 59.54it/s]  3%|         | 10394/303576 [07:46<1:22:06, 59.51it/s]  3%|         | 10400/303576 [07:46<1:22:11, 59.45it/s]                                                          3%|         | 10400/303576 [07:46<1:22:11, 59.45it/s]  3%|         | 10406/303576 [07:46<1:22:14, 59.41it/s]  3%|         | 10412/303576 [07:47<1:22:04, 59.53it/s]  3%|         | 10418/303576 [07:47<1:22:05, 59.52it/s]  3%|         | 10424/303576 [07:47<1:21:58, 59.60it/s]  3%|         | 10430/303576 [07:47<1:22:03, 59.54it/s]  3%|         | 10436/303576 [07:47<1:22:01, 59.57it/s]  3%|         | 10442/303576 [07:47<1:26:43, 56.33it/s]  3%|         | 10448/303576 [07:47<1:30:05, 54.23it/s]  3%|         | 10454/303576 [07:47<1:29:28, 54.60it/s]  3%|         | 10460/303576 [07:47<1:28:27, 55.23it/s]  3%|         | 10466/303576 [07:47<1:28:16, 55.34it/s]  3%|         | 10472/303576 [07:48<1:28:07, 55.43it/s]  3%|         | 10478/303576 [07:48<1:27:58, 55.53it/s]  3%|         | 10484/303576 [07:48<1:27:39, 55.73it/s]  3%|         | 10490/303576 [07:48<1:27:21, 55.92it/s]  3%|         | 10496/303576 [07:48<1:27:04, 56.10it/s]                                                          3%|         | 10500/303576 [07:48<1:27:04, 56.10it/s]  3%|         | 10502/303576 [07:48<1:27:27, 55.85it/s]  3%|         | 10508/303576 [07:48<1:26:26, 56.51it/s]  3%|         | 10514/303576 [07:48<1:26:55, 56.19it/s]  3%|         | 10520/303576 [07:48<1:27:25, 55.87it/s]  3%|         | 10526/303576 [07:49<1:26:53, 56.21it/s]  3%|         | 10532/303576 [07:49<1:26:51, 56.23it/s]  3%|         | 10540/303576 [07:49<1:17:43, 62.83it/s]  3%|         | 10549/303576 [07:49<1:11:42, 68.11it/s]  3%|         | 10557/303576 [07:49<1:10:37, 69.15it/s]  3%|         | 10565/303576 [07:49<1:09:48, 69.95it/s]  3%|         | 10573/303576 [07:49<1:09:14, 70.53it/s]  3%|         | 10581/303576 [07:49<1:08:49, 70.95it/s]  3%|         | 10589/303576 [07:49<1:08:31, 71.26it/s]  3%|         | 10597/303576 [07:50<1:08:17, 71.49it/s]                                                          3%|         | 10600/303576 [07:50<1:08:17, 71.49it/s]  3%|         | 10605/303576 [07:50<1:08:54, 70.86it/s]  3%|         | 10613/303576 [07:50<1:08:39, 71.12it/s]  3%|         | 10621/303576 [07:50<1:08:26, 71.34it/s]  4%|         | 10629/303576 [07:50<1:08:20, 71.45it/s]  4%|         | 10637/303576 [07:50<1:08:14, 71.54it/s]  4%|         | 10645/303576 [07:50<1:08:11, 71.59it/s]  4%|         | 10653/303576 [07:50<1:08:11, 71.59it/s]  4%|         | 10661/303576 [07:50<1:08:13, 71.56it/s]  4%|         | 10669/303576 [07:51<1:08:07, 71.66it/s]  4%|         | 10677/303576 [07:51<1:08:12, 71.57it/s]  4%|         | 10685/303576 [07:51<1:08:20, 71.43it/s]  4%|         | 10693/303576 [07:51<1:09:00, 70.74it/s]                                                          4%|         | 10700/303576 [07:51<1:09:00, 70.74it/s]  4%|         | 10701/303576 [07:51<1:09:55, 69.81it/s]  4%|         | 10708/303576 [07:51<1:10:01, 69.70it/s]  4%|         | 10715/303576 [07:51<1:10:56, 68.80it/s]  4%|         | 10723/303576 [07:51<1:10:41, 69.05it/s]  4%|         | 10731/303576 [07:51<1:10:32, 69.19it/s]  4%|         | 10739/303576 [07:52<1:08:50, 70.89it/s]  4%|         | 10747/303576 [07:52<1:07:47, 72.00it/s]  4%|         | 10755/303576 [07:52<1:07:47, 71.99it/s]  4%|         | 10763/303576 [07:52<1:06:59, 72.84it/s]  4%|         | 10772/303576 [07:52<1:04:43, 75.40it/s]  4%|         | 10780/303576 [07:52<1:04:24, 75.77it/s]  4%|         | 10788/303576 [07:52<1:05:17, 74.74it/s]  4%|         | 10796/303576 [07:52<1:06:31, 73.35it/s]                                                          4%|         | 10800/303576 [07:52<1:06:31, 73.35it/s]  4%|         | 10804/303576 [07:52<1:06:59, 72.84it/s]  4%|         | 10812/303576 [07:53<1:07:25, 72.37it/s]  4%|         | 10820/303576 [07:53<1:07:36, 72.17it/s]  4%|         | 10828/303576 [07:53<1:07:43, 72.04it/s]  4%|         | 10836/303576 [07:53<1:08:04, 71.67it/s]  4%|         | 10844/303576 [07:53<1:08:10, 71.56it/s]  4%|         | 10852/303576 [07:53<1:08:15, 71.48it/s]  4%|         | 10860/303576 [07:53<1:08:13, 71.51it/s]  4%|         | 10868/303576 [07:53<1:08:12, 71.53it/s]  4%|         | 10876/303576 [07:53<1:08:13, 71.50it/s]  4%|         | 10884/303576 [07:54<1:08:17, 71.43it/s]  4%|         | 10892/303576 [07:54<1:08:21, 71.36it/s]  4%|         | 10900/303576 [07:54<1:08:29, 71.22it/s]                                                          4%|         | 10900/303576 [07:54<1:08:29, 71.22it/s]  4%|         | 10908/303576 [07:54<1:08:14, 71.47it/s]  4%|         | 10916/303576 [07:54<1:08:18, 71.40it/s]  4%|         | 10924/303576 [07:54<1:08:17, 71.43it/s]  4%|         | 10932/303576 [07:54<1:08:10, 71.54it/s]  4%|         | 10940/303576 [07:54<1:08:10, 71.55it/s]  4%|         | 10948/303576 [07:54<1:08:31, 71.18it/s]  4%|         | 10956/303576 [07:55<1:09:25, 70.24it/s]  4%|         | 10964/303576 [07:55<1:09:09, 70.51it/s]  4%|         | 10972/303576 [07:55<1:09:44, 69.93it/s]  4%|         | 10979/303576 [07:55<1:10:25, 69.24it/s]  4%|         | 10987/303576 [07:55<1:10:06, 69.56it/s]  4%|         | 10995/303576 [07:55<1:09:48, 69.86it/s]                                                          4%|         | 11000/303576 [07:55<1:09:47, 69.86it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7405074238777161, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.1653, 'eval_samples_per_second': 10.678, 'eval_steps_per_second': 0.094, 'epoch': 0.1, 'timestamp': 1762964993.5992594, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7728, 'grad_norm': 0.21238765120506287, 'learning_rate': 0.00036430986778268284, 'epoch': 0.1, 'timestamp': 1762964995.4411588, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7765, 'grad_norm': 0.17498533427715302, 'learning_rate': 0.0003606847436769865, 'epoch': 0.1, 'timestamp': 1762964997.016372, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7778, 'grad_norm': 0.25610747933387756, 'learning_rate': 0.0003570956919534675, 'epoch': 0.1, 'timestamp': 1762964998.587109, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7782, 'grad_norm': 0.2234114706516266, 'learning_rate': 0.00035354235366806834, 'epoch': 0.1, 'timestamp': 1762965000.2506585, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7809, 'grad_norm': 0.19991230964660645, 'learning_rate': 0.0003500243734484623, 'epoch': 0.1, 'timestamp': 1762965002.0215344, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7872, 'grad_norm': 0.20743396878242493, 'learning_rate': 0.000346541399458512, 'epoch': 0.1, 'timestamp': 1762965003.5145242, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7814, 'grad_norm': 0.26548492908477783, 'learning_rate': 0.0003430930833630824, 'epoch': 0.11, 'timestamp': 1762965004.9231503, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7848, 'grad_norm': 0.23851683735847473, 'learning_rate': 0.00033971305159836334, 'epoch': 0.11, 'timestamp': 1762965006.3035064, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.782, 'grad_norm': 0.21877627074718475, 'learning_rate': 0.0003363326820797877, 'epoch': 0.11, 'timestamp': 1762965007.7052693, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7843, 'grad_norm': 0.21743859350681305, 'learning_rate': 0.0003329859494733891, 'epoch': 0.11, 'timestamp': 1762965009.1244597, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:30:13.012343: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:30:13.022992: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965013.035764 1715157 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965013.039566 1715157 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965013.049982 1715157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965013.049997 1715157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965013.049999 1715157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965013.050000 1715157 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:30:13.053180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:30:15 - TensorFlow version 2.19.1 available.
2025-11-12 16:30:23.648225: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:30:23.658880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965023.671449 1715183 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965023.675165 1715183 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965023.685513 1715183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965023.685528 1715183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965023.685529 1715183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965023.685531 1715183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:30:23.688659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
  4%|         | 11000/303576 [08:10<1:09:47, 69.86it/s]2025-11-12T16:30:25 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.18it/s][A                                                        
                                             [A  4%|         | 11000/303576 [08:18<1:09:47, 69.86it/s]
100%|| 2/2 [00:01<00:00,  1.18it/s][A
                                             [A  4%|         | 11001/303576 [08:18<76:35:46,  1.06it/s]  4%|         | 11006/303576 [08:18<59:38:11,  1.36it/s]  4%|         | 11013/303576 [08:18<41:35:42,  1.95it/s]  4%|         | 11019/303576 [08:18<30:35:31,  2.66it/s]  4%|         | 11025/303576 [08:18<22:26:30,  3.62it/s]  4%|         | 11031/303576 [08:18<16:32:05,  4.91it/s]  4%|         | 11036/303576 [08:19<12:48:21,  6.35it/s]  4%|         | 11041/303576 [08:19<9:52:19,  8.23it/s]   4%|         | 11046/303576 [08:19<7:38:31, 10.63it/s]  4%|         | 11051/303576 [08:19<5:59:13, 13.57it/s]  4%|         | 11056/303576 [08:19<4:47:49, 16.94it/s]  4%|         | 11061/303576 [08:19<3:56:49, 20.59it/s]  4%|         | 11067/303576 [08:19<3:05:44, 26.25it/s]  4%|         | 11074/303576 [08:19<2:27:09, 33.13it/s]  4%|         | 11081/303576 [08:19<2:02:36, 39.76it/s]  4%|         | 11088/303576 [08:20<1:46:15, 45.87it/s]  4%|         | 11095/303576 [08:20<1:36:39, 50.43it/s]                                                          4%|         | 11100/303576 [08:20<1:36:39, 50.43it/s]  4%|         | 11102/303576 [08:20<1:30:49, 53.67it/s]  4%|         | 11109/303576 [08:20<1:27:10, 55.92it/s]  4%|         | 11116/303576 [08:20<1:23:50, 58.14it/s]  4%|         | 11123/303576 [08:20<1:21:14, 60.00it/s]  4%|         | 11130/303576 [08:20<1:18:43, 61.91it/s]  4%|         | 11137/303576 [08:20<1:16:55, 63.35it/s]  4%|         | 11144/303576 [08:20<1:15:20, 64.69it/s]  4%|         | 11154/303576 [08:21<1:06:33, 73.23it/s]  4%|         | 11164/303576 [08:21<1:00:45, 80.20it/s]  4%|         | 11173/303576 [08:21<1:00:49, 80.11it/s]  4%|         | 11182/303576 [08:21<1:01:06, 79.76it/s]  4%|         | 11191/303576 [08:21<1:02:25, 78.06it/s]  4%|         | 11199/303576 [08:21<1:02:57, 77.40it/s]                                                          4%|         | 11200/303576 [08:21<1:02:57, 77.40it/s]  4%|         | 11207/303576 [08:21<1:03:21, 76.91it/s]  4%|         | 11215/303576 [08:21<1:03:08, 77.18it/s]  4%|         | 11223/303576 [08:21<1:05:59, 73.84it/s]  4%|         | 11231/303576 [08:22<1:08:08, 71.51it/s]  4%|         | 11239/303576 [08:22<1:06:37, 73.12it/s]  4%|         | 11248/303576 [08:22<1:03:59, 76.14it/s]  4%|         | 11256/303576 [08:22<1:03:21, 76.89it/s]  4%|         | 11265/303576 [08:22<1:02:04, 78.49it/s]  4%|         | 11274/303576 [08:22<1:01:07, 79.69it/s]  4%|         | 11282/303576 [08:22<1:01:39, 79.02it/s]  4%|         | 11290/303576 [08:22<1:01:52, 78.72it/s]  4%|         | 11299/303576 [08:22<1:01:07, 79.69it/s]                                                          4%|         | 11300/303576 [08:22<1:01:07, 79.69it/s]  4%|         | 11307/303576 [08:22<1:01:23, 79.35it/s]  4%|         | 11315/303576 [08:23<1:01:16, 79.49it/s]  4%|         | 11324/303576 [08:23<1:00:46, 80.14it/s]  4%|         | 11333/303576 [08:23<1:00:33, 80.43it/s]  4%|         | 11342/303576 [08:23<59:53, 81.32it/s]    4%|         | 11351/303576 [08:23<59:47, 81.45it/s]  4%|         | 11360/303576 [08:23<59:40, 81.61it/s]  4%|         | 11369/303576 [08:23<1:00:03, 81.08it/s]  4%|         | 11378/303576 [08:23<59:36, 81.70it/s]    4%|         | 11387/303576 [08:23<59:38, 81.64it/s]  4%|         | 11396/303576 [08:24<59:14, 82.19it/s]                                                        4%|         | 11400/303576 [08:24<59:14, 82.19it/s]  4%|         | 11405/303576 [08:24<59:25, 81.94it/s]  4%|         | 11414/303576 [08:24<59:29, 81.84it/s]  4%|         | 11423/303576 [08:24<59:17, 82.12it/s]  4%|         | 11432/303576 [08:24<58:42, 82.94it/s]  4%|         | 11442/303576 [08:24<57:02, 85.36it/s]  4%|         | 11451/303576 [08:24<56:11, 86.64it/s]  4%|         | 11460/303576 [08:24<56:45, 85.77it/s]  4%|         | 11469/303576 [08:24<57:09, 85.18it/s]  4%|         | 11478/303576 [08:25<59:10, 82.27it/s]  4%|         | 11487/303576 [08:25<1:00:35, 80.34it/s]  4%|         | 11496/303576 [08:25<1:00:25, 80.57it/s]                                                          4%|         | 11500/303576 [08:25<1:00:25, 80.57it/s]  4%|         | 11505/303576 [08:25<1:00:21, 80.65it/s]  4%|         | 11514/303576 [08:25<1:00:43, 80.16it/s]  4%|         | 11523/303576 [08:25<1:00:38, 80.27it/s]  4%|         | 11532/303576 [08:25<1:00:08, 80.93it/s]  4%|         | 11541/303576 [08:25<1:00:21, 80.64it/s]  4%|         | 11550/303576 [08:25<1:00:36, 80.30it/s]  4%|         | 11559/303576 [08:26<1:00:40, 80.22it/s]  4%|         | 11568/303576 [08:26<1:01:06, 79.65it/s]  4%|         | 11576/303576 [08:26<1:01:41, 78.88it/s]  4%|         | 11584/303576 [08:26<1:02:01, 78.46it/s]  4%|         | 11592/303576 [08:26<1:04:06, 75.91it/s]  4%|         | 11600/303576 [08:26<1:05:41, 74.08it/s]                                                          4%|         | 11600/303576 [08:26<1:05:41, 74.08it/s]  4%|         | 11608/303576 [08:26<1:06:30, 73.17it/s]  4%|         | 11616/303576 [08:26<1:07:06, 72.50it/s]  4%|         | 11624/303576 [08:26<1:07:21, 72.24it/s]  4%|         | 11633/303576 [08:27<1:04:51, 75.01it/s]  4%|         | 11642/303576 [08:27<1:02:41, 77.61it/s]  4%|         | 11651/303576 [08:27<1:01:30, 79.09it/s]  4%|         | 11660/303576 [08:27<1:00:34, 80.32it/s]  4%|         | 11669/303576 [08:27<1:00:01, 81.05it/s]  4%|         | 11678/303576 [08:27<59:22, 81.93it/s]    4%|         | 11687/303576 [08:27<59:06, 82.30it/s]  4%|         | 11696/303576 [08:27<58:43, 82.84it/s]                                                        4%|         | 11700/303576 [08:27<58:43, 82.84it/s]  4%|         | 11705/303576 [08:27<58:29, 83.16it/s]  4%|         | 11714/303576 [08:28<58:18, 83.42it/s]  4%|         | 11723/303576 [08:28<58:33, 83.06it/s]  4%|         | 11732/303576 [08:28<59:20, 81.97it/s]  4%|         | 11741/303576 [08:28<59:33, 81.67it/s]  4%|         | 11750/303576 [08:28<1:00:35, 80.26it/s]  4%|         | 11759/303576 [08:28<1:01:50, 78.65it/s]  4%|         | 11767/303576 [08:28<1:03:43, 76.33it/s]  4%|         | 11775/303576 [08:28<1:06:32, 73.08it/s]  4%|         | 11783/303576 [08:28<1:07:40, 71.87it/s]  4%|         | 11792/303576 [08:29<1:05:03, 74.75it/s]                                                          4%|         | 11800/303576 [08:29<1:05:03, 74.75it/s]  4%|         | 11801/303576 [08:29<1:01:39, 78.87it/s]  4%|         | 11809/303576 [08:29<1:01:42, 78.80it/s]  4%|         | 11817/303576 [08:29<1:02:06, 78.30it/s]  4%|         | 11825/303576 [08:29<1:02:06, 78.28it/s]  4%|         | 11834/303576 [08:29<1:00:11, 80.78it/s]  4%|         | 11843/303576 [08:29<59:27, 81.78it/s]    4%|         | 11852/303576 [08:29<59:32, 81.66it/s]  4%|         | 11861/303576 [08:29<59:34, 81.60it/s]  4%|         | 11870/303576 [08:30<1:00:41, 80.10it/s]  4%|         | 11879/303576 [08:30<1:01:47, 78.68it/s]  4%|         | 11887/303576 [08:30<1:02:29, 77.80it/s]  4%|         | 11895/303576 [08:30<1:03:03, 77.10it/s]                                                          4%|         | 11900/303576 [08:30<1:03:03, 77.10it/s]  4%|         | 11903/303576 [08:30<1:02:31, 77.75it/s]  4%|         | 11912/303576 [08:30<1:01:42, 78.77it/s]  4%|         | 11920/303576 [08:30<1:01:26, 79.12it/s]  4%|         | 11928/303576 [08:30<1:03:45, 76.23it/s]  4%|         | 11936/303576 [08:30<1:05:22, 74.35it/s]  4%|         | 11944/303576 [08:31<1:05:40, 74.01it/s]  4%|         | 11952/303576 [08:31<1:06:44, 72.83it/s]  4%|         | 11960/303576 [08:31<1:07:32, 71.96it/s]  4%|         | 11968/303576 [08:31<1:07:33, 71.95it/s]  4%|         | 11976/303576 [08:31<1:07:24, 72.10it/s]  4%|         | 11984/303576 [08:31<1:07:38, 71.84it/s]  4%|         | 11992/303576 [08:31<1:07:30, 71.99it/s]  4%|         | 12000/303576 [08:31<1:07:23, 72.11it/s]                                                          4%|         | 12000/303576 [08:31<1:07:23, 72.11it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7401012182235718, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.5612, 'eval_samples_per_second': 10.017, 'eval_steps_per_second': 0.089, 'epoch': 0.11, 'timestamp': 1762965031.686125, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7722, 'grad_norm': 0.21092770993709564, 'learning_rate': 0.00032967251906964755, 'epoch': 0.11, 'timestamp': 1762965033.7010176, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7763, 'grad_norm': 0.21668261289596558, 'learning_rate': 0.00032639205948962346, 'epoch': 0.11, 'timestamp': 1762965035.0543363, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7849, 'grad_norm': 0.20469443500041962, 'learning_rate': 0.0003231442426518165, 'epoch': 0.11, 'timestamp': 1762965036.3481417, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7785, 'grad_norm': 0.198263481259346, 'learning_rate': 0.000319928743739355, 'epoch': 0.11, 'timestamp': 1762965037.5752227, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7648, 'grad_norm': 0.20930857956409454, 'learning_rate': 0.0003167452411675097, 'epoch': 0.11, 'timestamp': 1762965038.7837796, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7835, 'grad_norm': 0.2354438751935959, 'learning_rate': 0.00031359341655153223, 'epoch': 0.11, 'timestamp': 1762965040.0691092, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7788, 'grad_norm': 0.21862974762916565, 'learning_rate': 0.0003104729546748126, 'epoch': 0.12, 'timestamp': 1762965041.3194103, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7752, 'grad_norm': 0.19474272429943085, 'learning_rate': 0.0003073835434573546, 'epoch': 0.12, 'timestamp': 1762965042.6062775, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7815, 'grad_norm': 0.22026921808719635, 'learning_rate': 0.00030432487392456436, 'epoch': 0.12, 'timestamp': 1762965043.8680365, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7781, 'grad_norm': 0.24227002263069153, 'learning_rate': 0.0003012966401763501, 'epoch': 0.12, 'timestamp': 1762965045.237139, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:30:48.517591: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:30:48.528189: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965048.540991 1715227 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965048.544786 1715227 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965048.555256 1715227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965048.555271 1715227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965048.555273 1715227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965048.555274 1715227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:30:48.558484: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:30:50 - TensorFlow version 2.19.1 available.
2025-11-12 16:30:58.487730: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:30:58.498261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965058.510804 1715359 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965058.514533 1715359 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965058.524753 1715359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965058.524767 1715359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965058.524769 1715359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965058.524770 1715359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:30:58.527897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:31:00 - TensorFlow version 2.19.1 available.
  4%|         | 12000/303576 [08:50<1:07:23, 72.11it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A  4%|         | 12000/303576 [08:53<1:07:23, 72.11it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-12000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-12000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-12000/model.safetensors
  4%|         | 12001/303576 [08:53<89:27:31,  1.10s/it]  4%|         | 12007/303576 [08:53<62:47:53,  1.29it/s]  4%|         | 12014/303576 [08:53<42:10:37,  1.92it/s]  4%|         | 12021/303576 [08:53<28:53:55,  2.80it/s]  4%|         | 12028/303576 [08:53<20:11:42,  4.01it/s]  4%|         | 12035/303576 [08:53<14:20:16,  5.65it/s]  4%|         | 12042/303576 [08:53<10:21:33,  7.82it/s]  4%|         | 12049/303576 [08:54<7:34:44, 10.68it/s]   4%|         | 12056/303576 [08:54<5:38:27, 14.36it/s]  4%|         | 12063/303576 [08:54<4:17:47, 18.85it/s]  4%|         | 12070/303576 [08:54<3:21:52, 24.07it/s]  4%|         | 12077/303576 [08:54<2:42:49, 29.84it/s]  4%|         | 12084/303576 [08:54<2:15:26, 35.87it/s]  4%|         | 12091/303576 [08:54<1:56:40, 41.64it/s]  4%|         | 12098/303576 [08:54<1:43:31, 46.93it/s]                                                          4%|         | 12100/303576 [08:54<1:43:31, 46.93it/s]  4%|         | 12105/303576 [08:54<1:34:02, 51.65it/s]  4%|         | 12112/303576 [08:55<1:26:59, 55.84it/s]  4%|         | 12119/303576 [08:55<1:22:12, 59.08it/s]  4%|         | 12126/303576 [08:55<1:18:54, 61.56it/s]  4%|         | 12133/303576 [08:55<1:16:16, 63.69it/s]  4%|         | 12140/303576 [08:55<1:14:38, 65.07it/s]  4%|         | 12148/303576 [08:55<1:12:24, 67.07it/s]  4%|         | 12156/303576 [08:55<1:08:46, 70.62it/s]  4%|         | 12165/303576 [08:55<1:05:45, 73.86it/s]  4%|         | 12174/303576 [08:55<1:03:38, 76.31it/s]  4%|         | 12183/303576 [08:55<1:02:08, 78.15it/s]  4%|         | 12192/303576 [08:56<1:01:00, 79.60it/s]                                                          4%|         | 12200/303576 [08:56<1:01:00, 79.60it/s]  4%|         | 12201/303576 [08:56<1:00:22, 80.44it/s]  4%|         | 12210/303576 [08:56<59:55, 81.03it/s]    4%|         | 12219/303576 [08:56<59:26, 81.69it/s]  4%|         | 12228/303576 [08:56<59:20, 81.84it/s]  4%|         | 12237/303576 [08:56<58:53, 82.45it/s]  4%|         | 12246/303576 [08:56<59:03, 82.21it/s]  4%|         | 12255/303576 [08:56<59:10, 82.05it/s]  4%|         | 12264/303576 [08:56<1:00:21, 80.43it/s]  4%|         | 12273/303576 [08:57<1:03:11, 76.83it/s]  4%|         | 12281/303576 [08:57<1:04:27, 75.32it/s]  4%|         | 12290/303576 [08:57<1:02:50, 77.25it/s]  4%|         | 12299/303576 [08:57<1:01:56, 78.38it/s]                                                          4%|         | 12300/303576 [08:57<1:01:56, 78.38it/s]  4%|         | 12307/303576 [08:57<1:02:16, 77.95it/s]  4%|         | 12315/303576 [08:57<1:03:56, 75.92it/s]  4%|         | 12323/303576 [08:57<1:04:56, 74.75it/s]  4%|         | 12331/303576 [08:57<1:05:55, 73.63it/s]  4%|         | 12339/303576 [08:57<1:06:32, 72.95it/s]  4%|         | 12347/303576 [08:58<1:07:01, 72.42it/s]  4%|         | 12355/303576 [08:58<1:07:18, 72.11it/s]  4%|         | 12363/303576 [08:58<1:07:45, 71.64it/s]  4%|         | 12372/303576 [08:58<1:03:55, 75.92it/s]  4%|         | 12383/303576 [08:58<58:12, 83.37it/s]    4%|         | 12394/303576 [08:58<54:42, 88.70it/s]                                                        4%|         | 12400/303576 [08:58<54:42, 88.70it/s]  4%|         | 12405/303576 [08:58<52:15, 92.87it/s]  4%|         | 12416/303576 [08:58<50:29, 96.10it/s]  4%|         | 12427/303576 [08:58<49:22, 98.26it/s]  4%|         | 12438/303576 [08:59<48:44, 99.56it/s]  4%|         | 12449/303576 [08:59<48:27, 100.15it/s]  4%|         | 12460/303576 [08:59<48:02, 101.00it/s]  4%|         | 12471/303576 [08:59<48:36, 99.80it/s]   4%|         | 12481/303576 [08:59<50:32, 95.98it/s]  4%|         | 12491/303576 [08:59<50:47, 95.51it/s]                                                        4%|         | 12500/303576 [08:59<50:47, 95.51it/s]  4%|         | 12501/303576 [08:59<50:50, 95.43it/s]  4%|         | 12511/303576 [08:59<51:05, 94.95it/s]  4%|         | 12521/303576 [08:59<51:38, 93.94it/s]  4%|         | 12531/303576 [09:00<51:33, 94.07it/s]  4%|         | 12541/303576 [09:00<51:34, 94.06it/s]  4%|         | 12551/303576 [09:00<51:38, 93.93it/s]  4%|         | 12561/303576 [09:00<51:35, 94.00it/s]  4%|         | 12571/303576 [09:00<51:27, 94.24it/s]  4%|         | 12581/303576 [09:00<51:29, 94.18it/s]  4%|         | 12591/303576 [09:00<51:20, 94.46it/s]                                                        4%|         | 12600/303576 [09:00<51:20, 94.46it/s]  4%|         | 12601/303576 [09:00<51:23, 94.37it/s]  4%|         | 12611/303576 [09:00<51:14, 94.65it/s]  4%|         | 12621/303576 [09:01<52:45, 91.91it/s]  4%|         | 12631/303576 [09:01<53:49, 90.10it/s]  4%|         | 12641/303576 [09:01<54:24, 89.13it/s]  4%|         | 12650/303576 [09:01<54:51, 88.39it/s]  4%|         | 12659/303576 [09:01<57:12, 84.76it/s]  4%|         | 12669/303576 [09:01<55:55, 86.70it/s]  4%|         | 12680/303576 [09:01<52:29, 92.37it/s]  4%|         | 12691/303576 [09:01<50:18, 96.35it/s]                                                        4%|         | 12700/303576 [09:01<50:18, 96.35it/s]  4%|         | 12702/303576 [09:01<50:17, 96.41it/s]  4%|         | 12712/303576 [09:02<53:41, 90.30it/s]  4%|         | 12722/303576 [09:02<54:06, 89.59it/s]  4%|         | 12732/303576 [09:02<55:10, 87.86it/s]  4%|         | 12741/303576 [09:02<56:42, 85.47it/s]  4%|         | 12750/303576 [09:02<58:01, 83.53it/s]  4%|         | 12759/303576 [09:02<58:45, 82.48it/s]  4%|         | 12768/303576 [09:02<59:25, 81.55it/s]  4%|         | 12777/303576 [09:02<1:00:00, 80.76it/s]  4%|         | 12786/303576 [09:02<1:00:29, 80.12it/s]  4%|         | 12795/303576 [09:03<1:00:13, 80.47it/s]                                                          4%|         | 12800/303576 [09:03<1:00:13, 80.47it/s]  4%|         | 12804/303576 [09:03<59:32, 81.40it/s]    4%|         | 12813/303576 [09:03<59:00, 82.12it/s]  4%|         | 12822/303576 [09:03<58:40, 82.59it/s]  4%|         | 12831/303576 [09:03<58:26, 82.91it/s]  4%|         | 12840/303576 [09:03<59:12, 81.83it/s]  4%|         | 12849/303576 [09:03<58:35, 82.69it/s]  4%|         | 12859/303576 [09:03<56:44, 85.40it/s]  4%|         | 12869/303576 [09:03<55:31, 87.27it/s]  4%|         | 12878/303576 [09:04<55:32, 87.22it/s]  4%|         | 12887/303576 [09:04<57:55, 83.64it/s]  4%|         | 12896/303576 [09:04<59:43, 81.11it/s]                                                        4%|         | 12900/303576 [09:04<59:43, 81.11it/s]  4%|         | 12905/303576 [09:04<1:00:37, 79.90it/s]  4%|         | 12914/303576 [09:04<1:02:09, 77.94it/s]  4%|         | 12922/303576 [09:04<1:08:49, 70.38it/s]  4%|         | 12930/303576 [09:04<1:13:46, 65.67it/s]  4%|         | 12937/303576 [09:04<1:17:37, 62.41it/s]  4%|         | 12944/303576 [09:05<1:20:24, 60.24it/s]  4%|         | 12951/303576 [09:05<1:22:14, 58.90it/s]  4%|         | 12957/303576 [09:05<1:23:17, 58.16it/s]  4%|         | 12963/303576 [09:05<1:24:04, 57.61it/s]  4%|         | 12970/303576 [09:05<1:21:55, 59.12it/s]  4%|         | 12977/303576 [09:05<1:21:03, 59.76it/s]  4%|         | 12984/303576 [09:05<1:20:32, 60.13it/s]  4%|         | 12991/303576 [09:05<1:19:03, 61.26it/s]  4%|         | 12998/303576 [09:05<1:19:13, 61.13it/s]                                                          4%|         | 13000/303576 [09:05<1:19:13, 61.13it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7349714636802673, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.4218, 'eval_samples_per_second': 10.55, 'eval_steps_per_second': 0.093, 'epoch': 0.12, 'timestamp': 1762965066.6593773, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7784, 'grad_norm': 0.20108023285865784, 'learning_rate': 0.0002982985393565279, 'epoch': 0.12, 'timestamp': 1762965068.2983844, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.792, 'grad_norm': 0.20607174932956696, 'learning_rate': 0.0002953302716225326, 'epoch': 0.12, 'timestamp': 1762965069.6299417, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7766, 'grad_norm': 0.2555152475833893, 'learning_rate': 0.00029239154011543146, 'epoch': 0.12, 'timestamp': 1762965070.8878434, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7768, 'grad_norm': 0.2275296002626419, 'learning_rate': 0.0002894820509302345, 'epoch': 0.12, 'timestamp': 1762965072.1455407, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7817, 'grad_norm': 0.2331373244524002, 'learning_rate': 0.0002866015130865007, 'epoch': 0.12, 'timestamp': 1762965073.1565747, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7822, 'grad_norm': 0.23973381519317627, 'learning_rate': 0.00028374963849923647, 'epoch': 0.12, 'timestamp': 1762965074.2208686, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7777, 'grad_norm': 0.2340507060289383, 'learning_rate': 0.000280926141950085, 'epoch': 0.13, 'timestamp': 1762965075.308529, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7761, 'grad_norm': 0.26851189136505127, 'learning_rate': 0.0002781307410588004, 'epoch': 0.13, 'timestamp': 1762965076.547749, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7821, 'grad_norm': 0.15846502780914307, 'learning_rate': 0.00027536315625500637, 'epoch': 0.13, 'timestamp': 1762965077.749206, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7635, 'grad_norm': 0.20313093066215515, 'learning_rate': 0.0002726231107502381, 'epoch': 0.13, 'timestamp': 1762965079.4163241, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:31:23.387222: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:31:23.397933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965083.411114 1715497 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965083.414973 1715497 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965083.425671 1715497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965083.425697 1715497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965083.425699 1715497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965083.425700 1715497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:31:23.428997: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:31:25 - TensorFlow version 2.19.1 available.
  4%|         | 13000/303576 [09:20<1:19:13, 61.13it/s]2025-11-12 16:31:34.153190: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:31:34.163820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965094.176349 1715637 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965094.180000 1715637 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965094.190216 1715637 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965094.190233 1715637 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965094.190235 1715637 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965094.190237 1715637 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:31:34.193298: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:31:36 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.17it/s][A                                                        
                                             [A  4%|         | 13000/303576 [09:29<1:19:13, 61.13it/s]
100%|| 2/2 [00:01<00:00,  1.17it/s][A
                                             [A  4%|         | 13001/303576 [09:29<98:11:00,  1.22s/it]  4%|         | 13006/303576 [09:29<72:04:44,  1.12it/s]  4%|         | 13012/303576 [09:29<49:47:51,  1.62it/s]  4%|         | 13019/303576 [09:29<33:01:44,  2.44it/s]  4%|         | 13026/303576 [09:29<22:33:00,  3.58it/s]  4%|         | 13033/303576 [09:29<15:42:55,  5.14it/s]  4%|         | 13040/303576 [09:29<11:09:13,  7.24it/s]  4%|         | 13047/303576 [09:29<8:04:11, 10.00it/s]   4%|         | 13054/303576 [09:29<5:57:53, 13.53it/s]  4%|         | 13061/303576 [09:30<4:31:38, 17.82it/s]  4%|         | 13071/303576 [09:30<3:07:54, 25.77it/s]  4%|         | 13079/303576 [09:30<2:31:03, 32.05it/s]  4%|         | 13087/303576 [09:30<2:05:44, 38.50it/s]  4%|         | 13095/303576 [09:30<1:48:13, 44.73it/s]                                                          4%|         | 13100/303576 [09:30<1:48:13, 44.73it/s]  4%|         | 13103/303576 [09:30<1:36:04, 50.39it/s]  4%|         | 13111/303576 [09:30<1:27:28, 55.34it/s]  4%|         | 13119/303576 [09:30<1:21:31, 59.39it/s]  4%|         | 13127/303576 [09:30<1:17:24, 62.54it/s]  4%|         | 13135/303576 [09:31<1:12:44, 66.55it/s]  4%|         | 13143/303576 [09:31<1:09:31, 69.62it/s]  4%|         | 13151/303576 [09:31<1:09:13, 69.92it/s]  4%|         | 13159/303576 [09:31<1:08:45, 70.39it/s]  4%|         | 13167/303576 [09:31<1:08:20, 70.83it/s]  4%|         | 13175/303576 [09:31<1:07:53, 71.29it/s]  4%|         | 13183/303576 [09:31<1:07:53, 71.29it/s]  4%|         | 13191/303576 [09:31<1:07:41, 71.50it/s]  4%|         | 13199/303576 [09:31<1:07:37, 71.56it/s]                                                          4%|         | 13200/303576 [09:31<1:07:37, 71.56it/s]  4%|         | 13207/303576 [09:32<1:07:44, 71.44it/s]  4%|         | 13215/303576 [09:32<1:07:20, 71.85it/s]  4%|         | 13223/303576 [09:32<1:07:03, 72.17it/s]  4%|         | 13231/303576 [09:32<1:06:58, 72.25it/s]  4%|         | 13239/303576 [09:32<1:06:50, 72.39it/s]  4%|         | 13247/303576 [09:32<1:06:44, 72.50it/s]  4%|         | 13255/303576 [09:32<1:06:58, 72.25it/s]  4%|         | 13263/303576 [09:32<1:06:48, 72.43it/s]  4%|         | 13271/303576 [09:32<1:06:36, 72.64it/s]  4%|         | 13279/303576 [09:33<1:06:24, 72.85it/s]  4%|         | 13287/303576 [09:33<1:06:13, 73.05it/s]  4%|         | 13295/303576 [09:33<1:06:11, 73.09it/s]                                                          4%|         | 13300/303576 [09:33<1:06:11, 73.09it/s]  4%|         | 13303/303576 [09:33<1:06:16, 72.99it/s]  4%|         | 13311/303576 [09:33<1:06:20, 72.91it/s]  4%|         | 13319/303576 [09:33<1:06:29, 72.75it/s]  4%|         | 13327/303576 [09:33<1:06:35, 72.65it/s]  4%|         | 13335/303576 [09:33<1:06:40, 72.56it/s]  4%|         | 13343/303576 [09:33<1:06:43, 72.50it/s]  4%|         | 13351/303576 [09:34<1:06:46, 72.43it/s]  4%|         | 13359/303576 [09:34<1:06:54, 72.30it/s]  4%|         | 13367/303576 [09:34<1:06:46, 72.43it/s]  4%|         | 13375/303576 [09:34<1:06:41, 72.53it/s]  4%|         | 13383/303576 [09:34<1:06:39, 72.55it/s]  4%|         | 13391/303576 [09:34<1:06:20, 72.90it/s]  4%|         | 13400/303576 [09:34<1:02:36, 77.25it/s]                                                          4%|         | 13400/303576 [09:34<1:02:36, 77.25it/s]  4%|         | 13410/303576 [09:34<59:11, 81.70it/s]    4%|         | 13421/303576 [09:34<54:20, 88.99it/s]  4%|         | 13432/303576 [09:35<51:22, 94.13it/s]  4%|         | 13442/303576 [09:35<53:16, 90.77it/s]  4%|         | 13452/303576 [09:35<55:09, 87.66it/s]  4%|         | 13461/303576 [09:35<56:55, 84.95it/s]  4%|         | 13471/303576 [09:35<54:43, 88.36it/s]  4%|         | 13481/303576 [09:35<52:55, 91.35it/s]  4%|         | 13491/303576 [09:35<51:35, 93.70it/s]                                                        4%|         | 13500/303576 [09:35<51:35, 93.70it/s]  4%|         | 13501/303576 [09:35<50:51, 95.07it/s]  4%|         | 13511/303576 [09:35<51:24, 94.05it/s]  4%|         | 13521/303576 [09:35<51:47, 93.34it/s]  4%|         | 13531/303576 [09:36<52:09, 92.68it/s]  4%|         | 13541/303576 [09:36<52:26, 92.19it/s]  4%|         | 13551/303576 [09:36<52:37, 91.85it/s]  4%|         | 13561/303576 [09:36<52:58, 91.25it/s]  4%|         | 13571/303576 [09:36<53:03, 91.11it/s]  4%|         | 13581/303576 [09:36<53:03, 91.09it/s]  4%|         | 13591/303576 [09:36<53:09, 90.92it/s]                                                        4%|         | 13600/303576 [09:36<53:09, 90.92it/s]  4%|         | 13601/303576 [09:36<53:15, 90.74it/s]  4%|         | 13611/303576 [09:36<53:18, 90.65it/s]  4%|         | 13621/303576 [09:37<53:16, 90.71it/s]  4%|         | 13631/303576 [09:37<53:21, 90.57it/s]  4%|         | 13641/303576 [09:37<53:18, 90.66it/s]  4%|         | 13651/303576 [09:37<53:25, 90.46it/s]  5%|         | 13661/303576 [09:37<53:22, 90.54it/s]  5%|         | 13671/303576 [09:37<53:05, 91.00it/s]  5%|         | 13681/303576 [09:37<52:55, 91.28it/s]  5%|         | 13691/303576 [09:37<53:04, 91.04it/s]                                                        5%|         | 13700/303576 [09:37<53:04, 91.04it/s]  5%|         | 13701/303576 [09:37<53:08, 90.92it/s]  5%|         | 13711/303576 [09:38<53:12, 90.80it/s]  5%|         | 13721/303576 [09:38<53:13, 90.77it/s]  5%|         | 13731/303576 [09:38<53:12, 90.79it/s]  5%|         | 13741/303576 [09:38<53:17, 90.64it/s]  5%|         | 13751/303576 [09:38<53:22, 90.49it/s]  5%|         | 13761/303576 [09:38<53:21, 90.53it/s]  5%|         | 13771/303576 [09:38<53:16, 90.67it/s]  5%|         | 13781/303576 [09:38<53:11, 90.81it/s]  5%|         | 13791/303576 [09:38<53:11, 90.79it/s]                                                        5%|         | 13800/303576 [09:39<53:11, 90.79it/s]  5%|         | 13801/303576 [09:39<53:10, 90.84it/s]  5%|         | 13811/303576 [09:39<53:14, 90.71it/s]  5%|         | 13821/303576 [09:39<53:14, 90.71it/s]  5%|         | 13831/303576 [09:39<53:12, 90.77it/s]  5%|         | 13841/303576 [09:39<53:11, 90.77it/s]  5%|         | 13851/303576 [09:39<53:09, 90.84it/s]  5%|         | 13861/303576 [09:39<53:09, 90.83it/s]  5%|         | 13871/303576 [09:39<53:09, 90.84it/s]  5%|         | 13881/303576 [09:39<53:10, 90.81it/s]  5%|         | 13891/303576 [09:40<53:52, 89.61it/s]  5%|         | 13900/303576 [09:40<55:55, 86.32it/s]                                                        5%|         | 13900/303576 [09:40<55:55, 86.32it/s]  5%|         | 13909/303576 [09:40<57:51, 83.44it/s]  5%|         | 13918/303576 [09:40<58:20, 82.74it/s]  5%|         | 13927/303576 [09:40<59:36, 80.98it/s]  5%|         | 13936/303576 [09:40<1:00:22, 79.96it/s]  5%|         | 13945/303576 [09:40<1:02:59, 76.63it/s]  5%|         | 13953/303576 [09:40<1:04:27, 74.88it/s]  5%|         | 13961/303576 [09:41<1:06:01, 73.11it/s]  5%|         | 13969/303576 [09:41<1:08:20, 70.63it/s]  5%|         | 13977/303576 [09:41<1:08:34, 70.39it/s]  5%|         | 13985/303576 [09:41<1:08:06, 70.87it/s]  5%|         | 13993/303576 [09:41<1:10:04, 68.87it/s]                                                          5%|         | 14000/303576 [09:41<1:10:04, 68.87it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7394590377807617, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 23.0719, 'eval_samples_per_second': 9.795, 'eval_steps_per_second': 0.087, 'epoch': 0.13, 'timestamp': 1762965102.4889777, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7801, 'grad_norm': 0.27284032106399536, 'learning_rate': 0.00026991033051025756, 'epoch': 0.13, 'timestamp': 1762965104.030515, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7757, 'grad_norm': 0.23345093429088593, 'learning_rate': 0.00026722454422765024, 'epoch': 0.13, 'timestamp': 1762965105.4091475, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7796, 'grad_norm': 0.24140013754367828, 'learning_rate': 0.0002645654832946887, 'epoch': 0.13, 'timestamp': 1762965106.7837665, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7722, 'grad_norm': 0.24178704619407654, 'learning_rate': 0.0002619328817764696, 'epoch': 0.13, 'timestamp': 1762965108.1383288, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7779, 'grad_norm': 0.24030879139900208, 'learning_rate': 0.00025932647638431935, 'epoch': 0.13, 'timestamp': 1762965109.204166, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7868, 'grad_norm': 0.21759982407093048, 'learning_rate': 0.00025674600644945894, 'epoch': 0.13, 'timestamp': 1762965110.3044195, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7813, 'grad_norm': 0.25086700916290283, 'learning_rate': 0.00025419121389693745, 'epoch': 0.14, 'timestamp': 1762965111.4056084, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7631, 'grad_norm': 0.23746508359909058, 'learning_rate': 0.0002516870119210123, 'epoch': 0.14, 'timestamp': 1762965112.5083382, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.783, 'grad_norm': 0.22166213393211365, 'learning_rate': 0.00024918255970960584, 'epoch': 0.14, 'timestamp': 1762965113.6300488, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.776, 'grad_norm': 0.18688443303108215, 'learning_rate': 0.00024670302845391834, 'epoch': 0.14, 'timestamp': 1762965115.0182064, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:31:58.485855: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:31:58.496389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965118.509174 1715682 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965118.512864 1715682 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965118.523199 1715682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965118.523215 1715682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965118.523217 1715682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965118.523219 1715682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:31:58.526358: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:32:00 - TensorFlow version 2.19.1 available.
2025-11-12 16:32:08.680636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:32:08.691165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965128.703741 1715761 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965128.707497 1715761 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965128.717712 1715761 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965128.717728 1715761 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965128.717730 1715761 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965128.717732 1715761 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:32:08.720861: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:32:10 - TensorFlow version 2.19.1 available.
  5%|         | 14000/303576 [10:00<1:10:04, 68.87it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                        
                                             [A  5%|         | 14000/303576 [10:03<1:10:04, 68.87it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-14000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-14000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-14000/model.safetensors
  5%|         | 14001/303576 [10:03<67:01:49,  1.20it/s]  5%|         | 14006/303576 [10:03<53:21:50,  1.51it/s]  5%|         | 14013/303576 [10:03<38:06:00,  2.11it/s]  5%|         | 14020/303576 [10:04<27:11:31,  2.96it/s]  5%|         | 14027/303576 [10:04<19:29:12,  4.13it/s]  5%|         | 14034/303576 [10:04<14:01:23,  5.74it/s]  5%|         | 14044/303576 [10:04<9:01:54,  8.90it/s]   5%|         | 14054/303576 [10:04<6:08:42, 13.09it/s]  5%|         | 14063/303576 [10:04<4:31:19, 17.78it/s]  5%|         | 14072/303576 [10:04<3:26:10, 23.40it/s]  5%|         | 14081/303576 [10:04<2:41:33, 29.86it/s]  5%|         | 14090/303576 [10:04<2:10:42, 36.91it/s]  5%|         | 14099/303576 [10:05<1:49:06, 44.22it/s]                                                          5%|         | 14100/303576 [10:05<1:49:06, 44.22it/s]  5%|         | 14108/303576 [10:05<1:34:22, 51.12it/s]  5%|         | 14117/303576 [10:05<1:24:05, 57.37it/s]  5%|         | 14126/303576 [10:05<1:16:49, 62.79it/s]  5%|         | 14135/303576 [10:05<1:11:45, 67.23it/s]  5%|         | 14144/303576 [10:05<1:08:09, 70.78it/s]  5%|         | 14153/303576 [10:05<1:05:44, 73.38it/s]  5%|         | 14162/303576 [10:05<1:03:52, 75.52it/s]  5%|         | 14171/303576 [10:05<1:02:32, 77.12it/s]  5%|         | 14180/303576 [10:06<1:01:48, 78.04it/s]  5%|         | 14189/303576 [10:06<1:01:11, 78.82it/s]  5%|         | 14198/303576 [10:06<1:00:49, 79.28it/s]                                                          5%|         | 14200/303576 [10:06<1:00:49, 79.28it/s]  5%|         | 14207/303576 [10:06<1:00:38, 79.54it/s]  5%|         | 14216/303576 [10:06<1:00:30, 79.70it/s]  5%|         | 14225/303576 [10:06<1:00:12, 80.11it/s]  5%|         | 14234/303576 [10:06<1:00:08, 80.18it/s]  5%|         | 14243/303576 [10:06<59:59, 80.38it/s]    5%|         | 14252/303576 [10:06<1:00:14, 80.05it/s]  5%|         | 14261/303576 [10:07<1:00:03, 80.30it/s]  5%|         | 14270/303576 [10:07<1:00:03, 80.29it/s]  5%|         | 14279/303576 [10:07<1:00:02, 80.30it/s]  5%|         | 14288/303576 [10:07<1:00:05, 80.22it/s]  5%|         | 14297/303576 [10:07<1:00:05, 80.23it/s]                                                          5%|         | 14300/303576 [10:07<1:00:05, 80.23it/s]  5%|         | 14306/303576 [10:07<1:00:12, 80.08it/s]  5%|         | 14315/303576 [10:07<1:00:07, 80.18it/s]  5%|         | 14324/303576 [10:07<1:00:14, 80.03it/s]  5%|         | 14333/303576 [10:07<1:00:22, 79.84it/s]  5%|         | 14342/303576 [10:08<59:58, 80.39it/s]    5%|         | 14351/303576 [10:08<59:44, 80.69it/s]  5%|         | 14360/303576 [10:08<1:00:24, 79.80it/s]  5%|         | 14368/303576 [10:08<1:00:30, 79.67it/s]  5%|         | 14377/303576 [10:08<1:00:01, 80.31it/s]  5%|         | 14386/303576 [10:08<59:39, 80.78it/s]    5%|         | 14395/303576 [10:08<1:01:41, 78.12it/s]                                                          5%|         | 14400/303576 [10:08<1:01:41, 78.12it/s]  5%|         | 14403/303576 [10:08<1:03:18, 76.13it/s]  5%|         | 14411/303576 [10:08<1:04:22, 74.86it/s]  5%|         | 14420/303576 [10:09<1:01:38, 78.19it/s]  5%|         | 14431/303576 [10:09<55:59, 86.08it/s]    5%|         | 14442/303576 [10:09<52:40, 91.48it/s]  5%|         | 14453/303576 [10:09<49:58, 96.43it/s]  5%|         | 14463/303576 [10:09<49:41, 96.98it/s]  5%|         | 14473/303576 [10:09<50:29, 95.42it/s]  5%|         | 14483/303576 [10:09<52:12, 92.29it/s]  5%|         | 14493/303576 [10:09<54:11, 88.92it/s]                                                        5%|         | 14500/303576 [10:09<54:11, 88.92it/s]  5%|         | 14502/303576 [10:09<56:24, 85.41it/s]  5%|         | 14511/303576 [10:10<57:15, 84.13it/s]  5%|         | 14520/303576 [10:10<58:26, 82.44it/s]  5%|         | 14529/303576 [10:10<58:55, 81.75it/s]  5%|         | 14538/303576 [10:10<59:25, 81.07it/s]  5%|         | 14547/303576 [10:10<58:30, 82.33it/s]  5%|         | 14556/303576 [10:10<57:48, 83.33it/s]  5%|         | 14565/303576 [10:10<57:07, 84.31it/s]  5%|         | 14574/303576 [10:10<58:08, 82.84it/s]  5%|         | 14583/303576 [10:10<58:43, 82.03it/s]  5%|         | 14592/303576 [10:11<59:50, 80.48it/s]                                                        5%|         | 14600/303576 [10:11<59:50, 80.48it/s]  5%|         | 14601/303576 [10:11<59:45, 80.61it/s]  5%|         | 14610/303576 [10:11<1:00:20, 79.81it/s]  5%|         | 14619/303576 [10:11<59:56, 80.34it/s]    5%|         | 14628/303576 [10:11<1:00:37, 79.43it/s]  5%|         | 14636/303576 [10:11<1:00:44, 79.28it/s]  5%|         | 14644/303576 [10:11<1:00:36, 79.45it/s]  5%|         | 14652/303576 [10:11<1:00:36, 79.46it/s]  5%|         | 14660/303576 [10:11<1:00:43, 79.30it/s]  5%|         | 14668/303576 [10:11<1:00:47, 79.21it/s]  5%|         | 14678/303576 [10:12<56:58, 84.51it/s]    5%|         | 14687/303576 [10:12<56:01, 85.94it/s]  5%|         | 14696/303576 [10:12<55:27, 86.81it/s]                                                        5%|         | 14700/303576 [10:12<55:27, 86.81it/s]  5%|         | 14705/303576 [10:12<55:52, 86.16it/s]  5%|         | 14714/303576 [10:12<56:39, 84.98it/s]  5%|         | 14725/303576 [10:12<53:16, 90.36it/s]  5%|         | 14736/303576 [10:12<50:14, 95.80it/s]  5%|         | 14747/303576 [10:12<49:00, 98.21it/s]  5%|         | 14758/303576 [10:12<47:44, 100.84it/s]  5%|         | 14770/303576 [10:13<46:15, 104.05it/s]  5%|         | 14782/303576 [10:13<45:27, 105.89it/s]  5%|         | 14794/303576 [10:13<44:47, 107.46it/s]                                                         5%|         | 14800/303576 [10:13<44:47, 107.46it/s]  5%|         | 14805/303576 [10:13<44:31, 108.11it/s]  5%|         | 14816/303576 [10:13<46:44, 102.95it/s]  5%|         | 14827/303576 [10:13<49:41, 96.85it/s]   5%|         | 14839/303576 [10:13<47:24, 101.50it/s]  5%|         | 14850/303576 [10:13<46:24, 103.69it/s]  5%|         | 14861/303576 [10:13<45:46, 105.12it/s]  5%|         | 14872/303576 [10:14<45:18, 106.21it/s]  5%|         | 14883/303576 [10:14<45:17, 106.23it/s]  5%|         | 14894/303576 [10:14<45:03, 106.78it/s]                                                         5%|         | 14900/303576 [10:14<45:03, 106.78it/s]  5%|         | 14905/303576 [10:14<48:45, 98.66it/s]   5%|         | 14916/303576 [10:14<54:46, 87.82it/s]  5%|         | 14926/303576 [10:14<58:29, 82.25it/s]  5%|         | 14935/303576 [10:14<1:00:48, 79.11it/s]  5%|         | 14944/303576 [10:14<1:03:36, 75.62it/s]  5%|         | 14952/303576 [10:15<1:04:40, 74.37it/s]  5%|         | 14960/303576 [10:15<1:05:15, 73.71it/s]  5%|         | 14968/303576 [10:15<1:05:58, 72.90it/s]  5%|         | 14976/303576 [10:15<1:06:32, 72.29it/s]  5%|         | 14984/303576 [10:15<1:07:41, 71.05it/s]  5%|         | 14992/303576 [10:15<1:08:19, 70.39it/s]  5%|         | 15000/303576 [10:15<1:09:03, 69.65it/s]                                                          5%|         | 15000/303576 [10:15<1:09:03, 69.65it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7393167614936829, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.0244, 'eval_samples_per_second': 10.261, 'eval_steps_per_second': 0.091, 'epoch': 0.14, 'timestamp': 1762965137.0431266, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7844, 'grad_norm': 0.24927210807800293, 'learning_rate': 0.0002442481701739605, 'epoch': 0.14, 'timestamp': 1762965138.473437, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8096, 'grad_norm': 0.22276568412780762, 'learning_rate': 0.00024181773935730733, 'epoch': 0.14, 'timestamp': 1762965139.7152464, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7834, 'grad_norm': 0.23644718527793884, 'learning_rate': 0.00023941149293454458, 'epoch': 0.14, 'timestamp': 1762965140.9606104, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7775, 'grad_norm': 0.21053312718868256, 'learning_rate': 0.0002370291902549599, 'epoch': 0.14, 'timestamp': 1762965142.2267733, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.77, 'grad_norm': 0.19096562266349792, 'learning_rate': 0.00023467059306247443, 'epoch': 0.14, 'timestamp': 1762965143.3329673, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7874, 'grad_norm': 0.19860823452472687, 'learning_rate': 0.00023233546547181486, 'epoch': 0.14, 'timestamp': 1762965144.5665476, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7817, 'grad_norm': 0.2175687551498413, 'learning_rate': 0.00023002357394492226, 'epoch': 0.15, 'timestamp': 1762965145.7759402, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7703, 'grad_norm': 0.20318230986595154, 'learning_rate': 0.00022773468726759632, 'epoch': 0.15, 'timestamp': 1762965146.7407281, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.779, 'grad_norm': 0.2072019875049591, 'learning_rate': 0.00022546857652637023, 'epoch': 0.15, 'timestamp': 1762965147.711075, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.771, 'grad_norm': 0.1964579075574875, 'learning_rate': 0.00022322501508561783, 'epoch': 0.15, 'timestamp': 1762965149.1395462, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:32:33.161577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:32:33.172299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965153.185229 1715801 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965153.189076 1715801 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965153.199428 1715801 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965153.199444 1715801 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965153.199445 1715801 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965153.199447 1715801 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:32:33.202641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:32:35 - TensorFlow version 2.19.1 available.
2025-11-12 16:32:43.752182: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:32:43.762816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965163.775217 1715827 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965163.778917 1715827 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965163.789107 1715827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965163.789125 1715827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965163.789127 1715827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965163.789128 1715827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:32:43.792234: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
  5%|         | 15000/303576 [10:30<1:09:03, 69.65it/s]2025-11-12T16:32:45 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                        
                                             [A  5%|         | 15000/303576 [10:38<1:09:03, 69.65it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [A  5%|         | 15001/303576 [10:38<92:32:20,  1.15s/it]  5%|         | 15005/303576 [10:38<72:27:54,  1.11it/s]  5%|         | 15012/303576 [10:38<47:14:56,  1.70it/s]  5%|         | 15018/303576 [10:38<33:25:57,  2.40it/s]  5%|         | 15024/303576 [10:39<23:50:29,  3.36it/s]  5%|         | 15030/303576 [10:39<17:06:36,  4.68it/s]  5%|         | 15036/303576 [10:39<12:24:09,  6.46it/s]  5%|         | 15042/303576 [10:39<9:08:04,  8.77it/s]   5%|         | 15048/303576 [10:39<6:50:45, 11.71it/s]  5%|         | 15054/303576 [10:39<5:14:47, 15.28it/s]  5%|         | 15060/303576 [10:39<4:07:48, 19.40it/s]  5%|         | 15066/303576 [10:39<3:20:51, 23.94it/s]  5%|         | 15072/303576 [10:39<2:48:08, 28.60it/s]  5%|         | 15078/303576 [10:40<2:25:05, 33.14it/s]  5%|         | 15084/303576 [10:40<2:08:55, 37.29it/s]  5%|         | 15090/303576 [10:40<1:57:21, 40.97it/s]  5%|         | 15096/303576 [10:40<1:49:56, 43.73it/s]                                                          5%|         | 15100/303576 [10:40<1:49:56, 43.73it/s]  5%|         | 15102/303576 [10:40<1:42:05, 47.10it/s]  5%|         | 15108/303576 [10:40<1:37:03, 49.54it/s]  5%|         | 15114/303576 [10:40<1:33:59, 51.15it/s]  5%|         | 15120/303576 [10:40<1:30:52, 52.90it/s]  5%|         | 15126/303576 [10:40<1:28:51, 54.10it/s]  5%|         | 15132/303576 [10:41<1:28:15, 54.47it/s]  5%|         | 15138/303576 [10:41<1:27:52, 54.71it/s]  5%|         | 15144/303576 [10:41<1:27:38, 54.85it/s]  5%|         | 15150/303576 [10:41<1:26:25, 55.62it/s]  5%|         | 15156/303576 [10:41<1:24:43, 56.74it/s]  5%|         | 15163/303576 [10:41<1:22:46, 58.07it/s]  5%|         | 15169/303576 [10:41<1:22:22, 58.35it/s]  5%|         | 15175/303576 [10:41<1:23:10, 57.79it/s]  5%|         | 15181/303576 [10:41<1:24:33, 56.85it/s]  5%|         | 15187/303576 [10:42<1:25:31, 56.20it/s]  5%|         | 15193/303576 [10:42<1:25:55, 55.94it/s]  5%|         | 15199/303576 [10:42<1:26:33, 55.53it/s]                                                          5%|         | 15200/303576 [10:42<1:26:33, 55.53it/s]  5%|         | 15205/303576 [10:42<1:26:33, 55.52it/s]  5%|         | 15211/303576 [10:42<1:26:59, 55.25it/s]  5%|         | 15217/303576 [10:42<1:27:03, 55.21it/s]  5%|         | 15223/303576 [10:42<1:27:08, 55.15it/s]  5%|         | 15229/303576 [10:42<1:27:07, 55.16it/s]  5%|         | 15235/303576 [10:42<1:27:23, 54.99it/s]  5%|         | 15241/303576 [10:43<1:27:20, 55.02it/s]  5%|         | 15247/303576 [10:43<1:27:04, 55.19it/s]  5%|         | 15253/303576 [10:43<1:27:25, 54.97it/s]  5%|         | 15259/303576 [10:43<1:27:28, 54.93it/s]  5%|         | 15265/303576 [10:43<1:28:28, 54.31it/s]  5%|         | 15271/303576 [10:43<1:31:46, 52.36it/s]  5%|         | 15277/303576 [10:43<1:34:45, 50.70it/s]  5%|         | 15283/303576 [10:43<1:36:50, 49.61it/s]  5%|         | 15288/303576 [10:43<1:39:18, 48.38it/s]  5%|         | 15293/303576 [10:44<1:39:00, 48.53it/s]  5%|         | 15298/303576 [10:44<1:41:01, 47.56it/s]                                                          5%|         | 15300/303576 [10:44<1:41:01, 47.56it/s]  5%|         | 15303/303576 [10:44<1:40:23, 47.86it/s]  5%|         | 15308/303576 [10:44<1:42:01, 47.09it/s]  5%|         | 15313/303576 [10:44<1:41:10, 47.49it/s]  5%|         | 15318/303576 [10:44<1:42:47, 46.74it/s]  5%|         | 15323/303576 [10:44<1:41:31, 47.32it/s]  5%|         | 15328/303576 [10:44<1:42:40, 46.79it/s]  5%|         | 15333/303576 [10:44<1:42:57, 46.66it/s]  5%|         | 15338/303576 [10:45<1:41:51, 47.16it/s]  5%|         | 15343/303576 [10:45<1:40:49, 47.65it/s]  5%|         | 15348/303576 [10:45<1:42:41, 46.78it/s]  5%|         | 15353/303576 [10:45<1:41:21, 47.40it/s]  5%|         | 15360/303576 [10:45<1:32:18, 52.04it/s]  5%|         | 15368/303576 [10:45<1:23:20, 57.64it/s]  5%|         | 15376/303576 [10:45<1:18:41, 61.04it/s]  5%|         | 15383/303576 [10:45<1:15:43, 63.43it/s]  5%|         | 15390/303576 [10:45<1:14:34, 64.40it/s]  5%|         | 15398/303576 [10:45<1:12:14, 66.48it/s]                                                          5%|         | 15400/303576 [10:46<1:12:14, 66.48it/s]  5%|         | 15406/303576 [10:46<1:09:59, 68.63it/s]  5%|         | 15414/303576 [10:46<1:07:50, 70.80it/s]  5%|         | 15422/303576 [10:46<1:06:20, 72.38it/s]  5%|         | 15430/303576 [10:46<1:05:14, 73.62it/s]  5%|         | 15438/303576 [10:46<1:04:37, 74.30it/s]  5%|         | 15446/303576 [10:46<1:03:53, 75.16it/s]  5%|         | 15454/303576 [10:46<1:03:01, 76.18it/s]  5%|         | 15463/303576 [10:46<1:00:37, 79.21it/s]  5%|         | 15472/303576 [10:46<59:42, 80.42it/s]    5%|         | 15481/303576 [10:47<59:16, 81.01it/s]  5%|         | 15490/303576 [10:47<58:12, 82.50it/s]  5%|         | 15499/303576 [10:47<58:50, 81.59it/s]                                                        5%|         | 15500/303576 [10:47<58:50, 81.59it/s]  5%|         | 15508/303576 [10:47<58:47, 81.66it/s]  5%|         | 15517/303576 [10:47<59:17, 80.98it/s]  5%|         | 15526/303576 [10:47<58:59, 81.38it/s]  5%|         | 15535/303576 [10:47<59:18, 80.94it/s]  5%|         | 15544/303576 [10:47<59:04, 81.27it/s]  5%|         | 15553/303576 [10:47<59:15, 81.01it/s]  5%|         | 15562/303576 [10:48<58:53, 81.50it/s]  5%|         | 15571/303576 [10:48<59:09, 81.13it/s]  5%|         | 15580/303576 [10:48<58:45, 81.69it/s]  5%|         | 15589/303576 [10:48<59:03, 81.27it/s]  5%|         | 15598/303576 [10:48<58:50, 81.57it/s]                                                        5%|         | 15600/303576 [10:48<58:50, 81.57it/s]  5%|         | 15607/303576 [10:48<59:00, 81.35it/s]  5%|         | 15616/303576 [10:48<58:41, 81.77it/s]  5%|         | 15625/303576 [10:48<58:52, 81.52it/s]  5%|         | 15634/303576 [10:48<58:34, 81.93it/s]  5%|         | 15643/303576 [10:49<58:59, 81.36it/s]  5%|         | 15652/303576 [10:49<58:52, 81.50it/s]  5%|         | 15661/303576 [10:49<59:27, 80.70it/s]  5%|         | 15670/303576 [10:49<59:08, 81.13it/s]  5%|         | 15679/303576 [10:49<59:54, 80.10it/s]  5%|         | 15688/303576 [10:49<59:42, 80.35it/s]  5%|         | 15697/303576 [10:49<1:00:05, 79.84it/s]                                                          5%|         | 15700/303576 [10:49<1:00:05, 79.84it/s]  5%|         | 15705/303576 [10:49<1:00:09, 79.76it/s]  5%|         | 15714/303576 [10:49<59:41, 80.37it/s]    5%|         | 15723/303576 [10:50<1:00:04, 79.85it/s]  5%|         | 15732/303576 [10:50<59:45, 80.28it/s]    5%|         | 15741/303576 [10:50<1:00:15, 79.61it/s]  5%|         | 15750/303576 [10:50<58:42, 81.72it/s]    5%|         | 15760/303576 [10:50<56:28, 84.93it/s]  5%|         | 15769/303576 [10:50<56:27, 84.97it/s]  5%|         | 15778/303576 [10:50<56:44, 84.53it/s]  5%|         | 15787/303576 [10:50<57:37, 83.23it/s]  5%|         | 15796/303576 [10:50<57:37, 83.24it/s]                                                        5%|         | 15800/303576 [10:50<57:37, 83.24it/s]  5%|         | 15805/303576 [10:51<58:08, 82.48it/s]  5%|         | 15814/303576 [10:51<57:30, 83.39it/s]  5%|         | 15823/303576 [10:51<57:06, 83.97it/s]  5%|         | 15832/303576 [10:51<56:48, 84.42it/s]  5%|         | 15841/303576 [10:51<56:48, 84.41it/s]  5%|         | 15850/303576 [10:51<57:54, 82.81it/s]  5%|         | 15859/303576 [10:51<1:00:14, 79.60it/s]  5%|         | 15867/303576 [10:51<1:02:16, 77.00it/s]  5%|         | 15875/303576 [10:51<1:03:40, 75.31it/s]  5%|         | 15883/303576 [10:52<1:04:27, 74.38it/s]  5%|         | 15891/303576 [10:52<1:05:00, 73.76it/s]  5%|         | 15899/303576 [10:52<1:05:22, 73.34it/s]                                                          5%|         | 15900/303576 [10:52<1:05:22, 73.34it/s]  5%|         | 15907/303576 [10:52<1:05:41, 72.98it/s]  5%|         | 15915/303576 [10:52<1:07:04, 71.48it/s]  5%|         | 15923/303576 [10:52<1:07:54, 70.59it/s]  5%|         | 15931/303576 [10:52<1:08:54, 69.57it/s]  5%|         | 15940/303576 [10:52<1:04:33, 74.26it/s]  5%|         | 15949/303576 [10:52<1:01:03, 78.51it/s]  5%|         | 15958/303576 [10:53<58:43, 81.63it/s]    5%|         | 15967/303576 [10:53<59:05, 81.13it/s]  5%|         | 15976/303576 [10:53<58:47, 81.54it/s]  5%|         | 15985/303576 [10:53<58:58, 81.27it/s]  5%|         | 15994/303576 [10:53<58:36, 81.78it/s]                                                        5%|         | 16000/303576 [10:53<58:36, 81.78it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7365334033966064, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.816, 'eval_samples_per_second': 9.905, 'eval_steps_per_second': 0.088, 'epoch': 0.15, 'timestamp': 1762965171.9560256, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7709, 'grad_norm': 0.2274511754512787, 'learning_rate': 0.00022100377856488744, 'epoch': 0.15, 'timestamp': 1762965173.9561217, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.21222859621047974, 'learning_rate': 0.00021880464481646123, 'epoch': 0.15, 'timestamp': 1762965175.7232835, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7739, 'grad_norm': 0.26870548725128174, 'learning_rate': 0.00021662739390313805, 'epoch': 0.15, 'timestamp': 1762965177.6546724, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7742, 'grad_norm': 0.23255321383476257, 'learning_rate': 0.00021447180807623715, 'epoch': 0.15, 'timestamp': 1762965179.4685118, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7771, 'grad_norm': 0.24888332188129425, 'learning_rate': 0.00021233767175382143, 'epoch': 0.15, 'timestamp': 1762965180.7249568, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7867, 'grad_norm': 0.2164829671382904, 'learning_rate': 0.0002102247714991366, 'epoch': 0.15, 'timestamp': 1762965181.955806, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7856, 'grad_norm': 0.21348267793655396, 'learning_rate': 0.00020813289599926497, 'epoch': 0.16, 'timestamp': 1762965183.1945322, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7842, 'grad_norm': 0.24123741686344147, 'learning_rate': 0.00020606183604399245, 'epoch': 0.16, 'timestamp': 1762965184.4056962, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7772, 'grad_norm': 0.23122449219226837, 'learning_rate': 0.00020401138450488465, 'epoch': 0.16, 'timestamp': 1762965185.6980257, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7715, 'grad_norm': 0.2262452095746994, 'learning_rate': 0.00020198133631457236, 'epoch': 0.16, 'timestamp': 1762965186.9670596, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:33:10.326621: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:33:10.337085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965190.349387 1715934 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965190.353120 1715934 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965190.363293 1715934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965190.363307 1715934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965190.363309 1715934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965190.363311 1715934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:33:10.366434: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:33:12 - TensorFlow version 2.19.1 available.
2025-11-12 16:33:20.137779: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:33:20.148382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965200.161175 1715960 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965200.165003 1715960 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965200.175351 1715960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965200.175366 1715960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965200.175368 1715960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965200.175370 1715960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:33:20.178489: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:33:22 - TensorFlow version 2.19.1 available.
  5%|         | 16000/303576 [11:10<58:36, 81.78it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                      
                                             [A  5%|         | 16000/303576 [11:14<58:36, 81.78it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-16000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-16000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-16000/model.safetensors
  5%|         | 16001/303576 [11:14<62:11:44,  1.28it/s]  5%|         | 16007/303576 [11:14<47:54:04,  1.67it/s]  5%|         | 16015/303576 [11:15<33:32:13,  2.38it/s]  5%|         | 16022/303576 [11:15<24:35:47,  3.25it/s]  5%|         | 16029/303576 [11:15<18:02:04,  4.43it/s]  5%|         | 16035/303576 [11:15<13:45:51,  5.80it/s]  5%|         | 16041/303576 [11:15<10:27:17,  7.64it/s]  5%|         | 16047/303576 [11:15<7:58:12, 10.02it/s]   5%|         | 16053/303576 [11:15<6:08:30, 13.00it/s]  5%|         | 16059/303576 [11:15<4:48:49, 16.59it/s]  5%|         | 16065/303576 [11:16<3:52:03, 20.65it/s]  5%|         | 16071/303576 [11:16<3:11:02, 25.08it/s]  5%|         | 16078/303576 [11:16<2:33:07, 31.29it/s]  5%|         | 16084/303576 [11:16<2:14:52, 35.53it/s]  5%|         | 16090/303576 [11:16<2:04:55, 38.35it/s]  5%|         | 16096/303576 [11:16<1:58:27, 40.45it/s]                                                          5%|         | 16100/303576 [11:16<1:58:27, 40.45it/s]  5%|         | 16102/303576 [11:16<1:53:49, 42.09it/s]  5%|         | 16107/303576 [11:16<1:49:54, 43.59it/s]  5%|         | 16112/303576 [11:17<1:48:45, 44.05it/s]  5%|         | 16117/303576 [11:17<1:45:52, 45.25it/s]  5%|         | 16122/303576 [11:17<1:45:58, 45.21it/s]  5%|         | 16127/303576 [11:17<1:43:58, 46.07it/s]  5%|         | 16132/303576 [11:17<1:44:22, 45.90it/s]  5%|         | 16137/303576 [11:17<1:42:42, 46.65it/s]  5%|         | 16142/303576 [11:17<1:43:28, 46.30it/s]  5%|         | 16147/303576 [11:17<1:42:04, 46.93it/s]  5%|         | 16152/303576 [11:17<1:43:10, 46.43it/s]  5%|         | 16157/303576 [11:17<1:41:42, 47.10it/s]  5%|         | 16162/303576 [11:18<1:42:52, 46.57it/s]  5%|         | 16167/303576 [11:18<1:41:18, 47.28it/s]  5%|         | 16172/303576 [11:18<1:42:25, 46.76it/s]  5%|         | 16177/303576 [11:18<1:41:03, 47.39it/s]  5%|         | 16182/303576 [11:18<1:42:26, 46.76it/s]  5%|         | 16187/303576 [11:18<1:41:08, 47.36it/s]  5%|         | 16192/303576 [11:18<1:42:29, 46.73it/s]  5%|         | 16197/303576 [11:18<1:41:20, 47.26it/s]                                                          5%|         | 16200/303576 [11:18<1:41:20, 47.26it/s]  5%|         | 16202/303576 [11:18<1:42:47, 46.59it/s]  5%|         | 16207/303576 [11:19<1:41:33, 47.16it/s]  5%|         | 16212/303576 [11:19<1:42:32, 46.70it/s]  5%|         | 16217/303576 [11:19<1:44:53, 45.66it/s]  5%|         | 16223/303576 [11:19<1:41:42, 47.09it/s]  5%|         | 16229/303576 [11:19<1:39:01, 48.36it/s]  5%|         | 16235/303576 [11:19<1:35:58, 49.90it/s]  5%|         | 16241/303576 [11:19<1:31:13, 52.50it/s]  5%|         | 16247/303576 [11:19<1:28:55, 53.85it/s]  5%|         | 16253/303576 [11:19<1:27:22, 54.80it/s]  5%|         | 16259/303576 [11:20<1:26:18, 55.48it/s]  5%|         | 16265/303576 [11:20<1:25:50, 55.79it/s]  5%|         | 16271/303576 [11:20<1:25:19, 56.11it/s]  5%|         | 16277/303576 [11:20<1:25:24, 56.06it/s]  5%|         | 16283/303576 [11:20<1:25:09, 56.23it/s]  5%|         | 16289/303576 [11:20<1:24:52, 56.42it/s]  5%|         | 16295/303576 [11:20<1:24:35, 56.60it/s]                                                          5%|         | 16300/303576 [11:20<1:24:35, 56.60it/s]  5%|         | 16301/303576 [11:20<1:24:31, 56.64it/s]  5%|         | 16307/303576 [11:20<1:24:16, 56.81it/s]  5%|         | 16313/303576 [11:20<1:24:22, 56.75it/s]  5%|         | 16319/303576 [11:21<1:24:25, 56.71it/s]  5%|         | 16325/303576 [11:21<1:26:17, 55.48it/s]  5%|         | 16332/303576 [11:21<1:21:30, 58.73it/s]  5%|         | 16340/303576 [11:21<1:16:55, 62.23it/s]  5%|         | 16348/303576 [11:21<1:13:55, 64.75it/s]  5%|         | 16356/303576 [11:21<1:11:41, 66.78it/s]  5%|         | 16363/303576 [11:21<1:10:52, 67.54it/s]  5%|         | 16370/303576 [11:21<1:12:42, 65.84it/s]  5%|         | 16377/303576 [11:21<1:13:59, 64.70it/s]  5%|         | 16384/303576 [11:22<1:15:00, 63.81it/s]  5%|         | 16391/303576 [11:22<1:15:49, 63.12it/s]  5%|         | 16399/303576 [11:22<1:10:41, 67.71it/s]                                                          5%|         | 16400/303576 [11:22<1:10:41, 67.71it/s]  5%|         | 16408/303576 [11:22<1:06:35, 71.87it/s]  5%|         | 16417/303576 [11:22<1:04:00, 74.78it/s]  5%|         | 16426/303576 [11:22<1:02:21, 76.74it/s]  5%|         | 16435/303576 [11:22<1:01:09, 78.25it/s]  5%|         | 16444/303576 [11:22<1:00:23, 79.25it/s]  5%|         | 16453/303576 [11:22<59:55, 79.85it/s]    5%|         | 16462/303576 [11:23<59:32, 80.37it/s]  5%|         | 16471/303576 [11:23<59:22, 80.60it/s]  5%|         | 16480/303576 [11:23<58:19, 82.05it/s]  5%|         | 16491/303576 [11:23<54:28, 87.82it/s]                                                        5%|         | 16500/303576 [11:23<54:28, 87.82it/s]  5%|         | 16501/303576 [11:23<53:10, 89.98it/s]  5%|         | 16511/303576 [11:23<54:30, 87.78it/s]  5%|         | 16520/303576 [11:23<54:23, 87.95it/s]  5%|         | 16530/303576 [11:23<53:23, 89.60it/s]  5%|         | 16541/303576 [11:23<50:34, 94.60it/s]  5%|         | 16551/303576 [11:24<50:58, 93.84it/s]  5%|         | 16561/303576 [11:24<56:02, 85.36it/s]  5%|         | 16570/303576 [11:24<58:04, 82.38it/s]  5%|         | 16579/303576 [11:24<59:12, 80.79it/s]  5%|         | 16588/303576 [11:24<1:01:00, 78.40it/s]  5%|         | 16596/303576 [11:24<1:02:47, 76.17it/s]                                                          5%|         | 16600/303576 [11:24<1:02:47, 76.17it/s]  5%|         | 16604/303576 [11:24<1:04:14, 74.46it/s]  5%|         | 16612/303576 [11:24<1:05:49, 72.66it/s]  5%|         | 16620/303576 [11:25<1:05:53, 72.58it/s]  5%|         | 16628/303576 [11:25<1:05:59, 72.47it/s]  5%|         | 16636/303576 [11:25<1:06:08, 72.31it/s]  5%|         | 16644/303576 [11:25<1:06:30, 71.90it/s]  5%|         | 16652/303576 [11:25<1:06:30, 71.91it/s]  5%|         | 16660/303576 [11:25<1:06:31, 71.88it/s]  5%|         | 16668/303576 [11:25<1:06:38, 71.75it/s]  5%|         | 16679/303576 [11:25<59:39, 80.15it/s]    5%|         | 16691/303576 [11:25<53:38, 89.13it/s]                                                        6%|         | 16700/303576 [11:25<53:38, 89.13it/s]  6%|         | 16702/303576 [11:25<50:53, 93.95it/s]  6%|         | 16713/303576 [11:26<48:37, 98.33it/s]  6%|         | 16724/303576 [11:26<48:10, 99.23it/s]  6%|         | 16735/303576 [11:26<47:32, 100.54it/s]  6%|         | 16746/303576 [11:26<47:38, 100.34it/s]  6%|         | 16757/303576 [11:26<47:11, 101.29it/s]  6%|         | 16768/303576 [11:26<49:45, 96.07it/s]   6%|         | 16778/303576 [11:26<54:50, 87.15it/s]  6%|         | 16787/303576 [11:26<57:57, 82.47it/s]  6%|         | 16796/303576 [11:27<1:01:03, 78.28it/s]                                                          6%|         | 16800/303576 [11:27<1:01:03, 78.28it/s]  6%|         | 16804/303576 [11:27<1:02:57, 75.92it/s]  6%|         | 16812/303576 [11:27<1:04:15, 74.37it/s]  6%|         | 16820/303576 [11:27<1:05:14, 73.25it/s]  6%|         | 16828/303576 [11:27<1:06:01, 72.39it/s]  6%|         | 16839/303576 [11:27<59:00, 80.99it/s]    6%|         | 16850/303576 [11:27<55:32, 86.03it/s]  6%|         | 16859/303576 [11:27<56:31, 84.55it/s]  6%|         | 16868/303576 [11:27<56:48, 84.11it/s]  6%|         | 16877/303576 [11:28<57:21, 83.30it/s]  6%|         | 16886/303576 [11:28<57:28, 83.14it/s]  6%|         | 16895/303576 [11:28<57:56, 82.47it/s]                                                        6%|         | 16900/303576 [11:28<57:56, 82.47it/s]  6%|         | 16904/303576 [11:28<57:50, 82.61it/s]  6%|         | 16913/303576 [11:28<59:36, 80.16it/s]  6%|         | 16922/303576 [11:28<1:01:29, 77.70it/s]  6%|         | 16930/303576 [11:28<1:03:08, 75.66it/s]  6%|         | 16938/303576 [11:28<1:04:19, 74.27it/s]  6%|         | 16946/303576 [11:28<1:05:03, 73.43it/s]  6%|         | 16954/303576 [11:29<1:05:32, 72.88it/s]  6%|         | 16962/303576 [11:29<1:05:58, 72.41it/s]  6%|         | 16970/303576 [11:29<1:06:24, 71.94it/s]  6%|         | 16978/303576 [11:29<1:06:33, 71.76it/s]  6%|         | 16986/303576 [11:29<1:06:22, 71.97it/s]  6%|         | 16994/303576 [11:29<1:06:16, 72.07it/s]                                                          6%|         | 17000/303576 [11:29<1:06:16, 72.07it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7389697432518005, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.2751, 'eval_samples_per_second': 10.623, 'eval_steps_per_second': 0.094, 'epoch': 0.16, 'timestamp': 1762965208.242641, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.20012494921684265, 'learning_rate': 0.00019997148844624202, 'epoch': 0.16, 'timestamp': 1762965210.205615, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7744, 'grad_norm': 0.2075147181749344, 'learning_rate': 0.0001979816398933312, 'epoch': 0.16, 'timestamp': 1762965212.3357592, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7774, 'grad_norm': 0.22021137177944183, 'learning_rate': 0.0001960115916494258, 'epoch': 0.16, 'timestamp': 1762965214.1954558, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7667, 'grad_norm': 0.3123016655445099, 'learning_rate': 0.00019406114668835733, 'epoch': 0.16, 'timestamp': 1762965215.7550876, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7752, 'grad_norm': 0.2879011034965515, 'learning_rate': 0.00019213010994449743, 'epoch': 0.16, 'timestamp': 1762965216.9318197, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7859, 'grad_norm': 0.19496473670005798, 'learning_rate': 0.00019021828829325017, 'epoch': 0.16, 'timestamp': 1762965218.1574936, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7937, 'grad_norm': 0.2544788718223572, 'learning_rate': 0.000188325490531737, 'epoch': 0.17, 'timestamp': 1762965219.414707, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7896, 'grad_norm': 0.21459037065505981, 'learning_rate': 0.00018645152735967445, 'epoch': 0.17, 'timestamp': 1762965220.547797, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7873, 'grad_norm': 0.20638924837112427, 'learning_rate': 0.000184596211360442, 'epoch': 0.17, 'timestamp': 1762965221.7747786, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7771, 'grad_norm': 0.22878384590148926, 'learning_rate': 0.00018275935698233836, 'epoch': 0.17, 'timestamp': 1762965223.1579454, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:33:47.066018: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:33:47.076597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965227.089121 1715999 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965227.092870 1715999 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965227.103104 1715999 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965227.103119 1715999 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965227.103120 1715999 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965227.103122 1715999 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:33:47.106281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:33:49 - TensorFlow version 2.19.1 available.
  6%|         | 17000/303576 [11:40<1:06:16, 72.07it/s]2025-11-12 16:33:57.660558: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:33:57.671163: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965237.683702 1716025 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965237.687435 1716025 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965237.697583 1716025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965237.697597 1716025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965237.697599 1716025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965237.697601 1716025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:33:57.700735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:33:59 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                        
                                             [A  6%|         | 17000/303576 [11:52<1:06:16, 72.07it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [A  6%|         | 17001/303576 [11:52<70:52:40,  1.12it/s]  6%|         | 17006/303576 [11:52<55:53:44,  1.42it/s]  6%|         | 17013/303576 [11:52<39:32:28,  2.01it/s]  6%|         | 17019/303576 [11:52<29:15:43,  2.72it/s]  6%|         | 17025/303576 [11:52<21:28:37,  3.71it/s]  6%|         | 17033/303576 [11:52<14:23:40,  5.53it/s]  6%|         | 17042/303576 [11:53<9:35:19,  8.30it/s]   6%|         | 17051/303576 [11:53<6:39:25, 11.96it/s]  6%|         | 17062/303576 [11:53<4:27:43, 17.84it/s]  6%|         | 17073/303576 [11:53<3:10:54, 25.01it/s]  6%|         | 17082/303576 [11:53<2:31:16, 31.57it/s]  6%|         | 17091/303576 [11:53<2:05:27, 38.06it/s]  6%|         | 17100/303576 [11:53<1:47:06, 44.57it/s]                                                          6%|         | 17100/303576 [11:53<1:47:06, 44.57it/s]  6%|         | 17109/303576 [11:53<1:33:58, 50.80it/s]  6%|         | 17118/303576 [11:53<1:24:31, 56.48it/s]  6%|         | 17126/303576 [11:54<1:18:36, 60.73it/s]  6%|         | 17134/303576 [11:54<1:13:56, 64.57it/s]  6%|         | 17142/303576 [11:54<1:10:34, 67.65it/s]  6%|         | 17150/303576 [11:54<1:08:18, 69.88it/s]  6%|         | 17158/303576 [11:54<1:06:53, 71.37it/s]  6%|         | 17166/303576 [11:54<1:05:07, 73.30it/s]  6%|         | 17174/303576 [11:54<1:03:59, 74.60it/s]  6%|         | 17182/303576 [11:54<1:03:23, 75.29it/s]  6%|         | 17190/303576 [11:54<1:02:33, 76.29it/s]  6%|         | 17198/303576 [11:54<1:06:55, 71.32it/s]                                                          6%|         | 17200/303576 [11:55<1:06:55, 71.32it/s]  6%|         | 17206/303576 [11:55<1:12:52, 65.49it/s]  6%|         | 17213/303576 [11:55<1:16:33, 62.34it/s]  6%|         | 17220/303576 [11:55<1:19:30, 60.02it/s]  6%|         | 17227/303576 [11:55<1:20:35, 59.22it/s]  6%|         | 17233/303576 [11:55<1:20:51, 59.02it/s]  6%|         | 17240/303576 [11:55<1:19:41, 59.88it/s]  6%|         | 17247/303576 [11:55<1:21:05, 58.85it/s]  6%|         | 17253/303576 [11:55<1:20:59, 58.92it/s]  6%|         | 17259/303576 [11:56<1:21:49, 58.32it/s]  6%|         | 17265/303576 [11:56<1:22:10, 58.07it/s]  6%|         | 17271/303576 [11:56<1:22:11, 58.06it/s]  6%|         | 17277/303576 [11:56<1:22:46, 57.65it/s]  6%|         | 17283/303576 [11:56<1:22:34, 57.78it/s]  6%|         | 17289/303576 [11:56<1:21:59, 58.20it/s]  6%|         | 17295/303576 [11:56<1:21:50, 58.30it/s]                                                          6%|         | 17300/303576 [11:56<1:21:50, 58.30it/s]  6%|         | 17301/303576 [11:56<1:21:53, 58.26it/s]  6%|         | 17307/303576 [11:56<1:22:02, 58.15it/s]  6%|         | 17313/303576 [11:56<1:21:59, 58.19it/s]  6%|         | 17319/303576 [11:57<1:21:42, 58.39it/s]  6%|         | 17325/303576 [11:57<1:21:28, 58.56it/s]  6%|         | 17331/303576 [11:57<1:21:24, 58.60it/s]  6%|         | 17337/303576 [11:57<1:21:37, 58.45it/s]  6%|         | 17343/303576 [11:57<1:21:40, 58.40it/s]  6%|         | 17349/303576 [11:57<1:21:34, 58.48it/s]  6%|         | 17355/303576 [11:57<1:21:31, 58.52it/s]  6%|         | 17361/303576 [11:57<1:21:19, 58.66it/s]  6%|         | 17367/303576 [11:57<1:21:26, 58.58it/s]  6%|         | 17373/303576 [11:58<1:21:22, 58.61it/s]  6%|         | 17379/303576 [11:58<1:21:28, 58.54it/s]  6%|         | 17385/303576 [11:58<1:28:06, 54.13it/s]  6%|         | 17391/303576 [11:58<1:31:44, 51.99it/s]  6%|         | 17397/303576 [11:58<1:34:12, 50.63it/s]                                                          6%|         | 17400/303576 [11:58<1:34:12, 50.63it/s]  6%|         | 17403/303576 [11:58<1:36:04, 49.65it/s]  6%|         | 17409/303576 [11:58<1:37:09, 49.09it/s]  6%|         | 17414/303576 [11:58<1:36:53, 49.22it/s]  6%|         | 17419/303576 [11:58<1:38:42, 48.32it/s]  6%|         | 17424/303576 [11:59<1:38:14, 48.54it/s]  6%|         | 17429/303576 [11:59<1:39:45, 47.81it/s]  6%|         | 17434/303576 [11:59<1:39:00, 48.17it/s]  6%|         | 17439/303576 [11:59<1:40:21, 47.52it/s]  6%|         | 17444/303576 [11:59<1:39:06, 48.12it/s]  6%|         | 17449/303576 [11:59<1:41:06, 47.16it/s]  6%|         | 17454/303576 [11:59<1:39:36, 47.88it/s]  6%|         | 17459/303576 [11:59<1:41:00, 47.21it/s]  6%|         | 17464/303576 [11:59<1:39:41, 47.84it/s]  6%|         | 17469/303576 [12:00<1:41:02, 47.20it/s]  6%|         | 17474/303576 [12:00<1:39:49, 47.77it/s]  6%|         | 17479/303576 [12:00<1:40:56, 47.24it/s]  6%|         | 17484/303576 [12:00<1:39:31, 47.91it/s]  6%|         | 17489/303576 [12:00<1:40:37, 47.39it/s]  6%|         | 17494/303576 [12:00<1:39:13, 48.05it/s]  6%|         | 17499/303576 [12:00<1:40:39, 47.37it/s]                                                          6%|         | 17500/303576 [12:00<1:40:39, 47.37it/s]  6%|         | 17504/303576 [12:00<1:39:34, 47.89it/s]  6%|         | 17509/303576 [12:00<1:40:46, 47.31it/s]  6%|         | 17514/303576 [12:00<1:39:29, 47.92it/s]  6%|         | 17519/303576 [12:01<1:40:51, 47.27it/s]  6%|         | 17524/303576 [12:01<1:39:34, 47.88it/s]  6%|         | 17529/303576 [12:01<1:40:56, 47.23it/s]  6%|         | 17534/303576 [12:01<1:39:38, 47.85it/s]  6%|         | 17539/303576 [12:01<1:40:53, 47.25it/s]  6%|         | 17547/303576 [12:01<1:26:12, 55.29it/s]  6%|         | 17556/303576 [12:01<1:15:26, 63.19it/s]  6%|         | 17565/303576 [12:01<1:09:31, 68.56it/s]  6%|         | 17572/303576 [12:01<1:09:15, 68.82it/s]  6%|         | 17580/303576 [12:02<1:08:39, 69.43it/s]  6%|         | 17588/303576 [12:02<1:08:16, 69.82it/s]  6%|         | 17595/303576 [12:02<1:08:22, 69.71it/s]                                                          6%|         | 17600/303576 [12:02<1:08:22, 69.71it/s]  6%|         | 17602/303576 [12:02<1:10:37, 67.48it/s]  6%|         | 17610/303576 [12:02<1:10:04, 68.02it/s]  6%|         | 17618/303576 [12:02<1:09:15, 68.81it/s]  6%|         | 17626/303576 [12:02<1:08:50, 69.22it/s]  6%|         | 17634/303576 [12:02<1:08:21, 69.72it/s]  6%|         | 17642/303576 [12:02<1:07:52, 70.21it/s]  6%|         | 17650/303576 [12:03<1:07:41, 70.40it/s]  6%|         | 17658/303576 [12:03<1:07:28, 70.62it/s]  6%|         | 17666/303576 [12:03<1:07:23, 70.71it/s]  6%|         | 17674/303576 [12:03<1:07:22, 70.73it/s]  6%|         | 17682/303576 [12:03<1:07:16, 70.83it/s]  6%|         | 17690/303576 [12:03<1:07:04, 71.04it/s]  6%|         | 17698/303576 [12:03<1:07:08, 70.97it/s]                                                          6%|         | 17700/303576 [12:03<1:07:08, 70.97it/s]  6%|         | 17706/303576 [12:03<1:07:15, 70.84it/s]  6%|         | 17714/303576 [12:03<1:07:27, 70.63it/s]  6%|         | 17722/303576 [12:04<1:07:29, 70.59it/s]  6%|         | 17730/303576 [12:04<1:07:24, 70.67it/s]  6%|         | 17738/303576 [12:04<1:06:46, 71.34it/s]  6%|         | 17746/303576 [12:04<1:05:26, 72.80it/s]  6%|         | 17754/303576 [12:04<1:04:31, 73.82it/s]  6%|         | 17762/303576 [12:04<1:03:46, 74.69it/s]  6%|         | 17770/303576 [12:04<1:03:10, 75.39it/s]  6%|         | 17778/303576 [12:04<1:02:55, 75.70it/s]  6%|         | 17786/303576 [12:04<1:02:25, 76.30it/s]  6%|         | 17794/303576 [12:04<1:02:27, 76.26it/s]                                                          6%|         | 17800/303576 [12:05<1:02:27, 76.26it/s]  6%|         | 17802/303576 [12:05<1:01:59, 76.83it/s]  6%|         | 17810/303576 [12:05<1:06:59, 71.10it/s]  6%|         | 17818/303576 [12:05<1:12:29, 65.70it/s]  6%|         | 17825/303576 [12:05<1:16:35, 62.18it/s]  6%|         | 17832/303576 [12:05<1:20:24, 59.23it/s]  6%|         | 17839/303576 [12:05<1:22:02, 58.05it/s]  6%|         | 17845/303576 [12:05<1:23:01, 57.35it/s]  6%|         | 17851/303576 [12:05<1:23:07, 57.29it/s]  6%|         | 17857/303576 [12:06<1:23:37, 56.94it/s]  6%|         | 17863/303576 [12:06<1:24:13, 56.53it/s]  6%|         | 17869/303576 [12:06<1:24:40, 56.24it/s]  6%|         | 17875/303576 [12:06<1:24:48, 56.14it/s]  6%|         | 17881/303576 [12:06<1:24:52, 56.10it/s]  6%|         | 17887/303576 [12:06<1:26:17, 55.18it/s]  6%|         | 17894/303576 [12:06<1:25:00, 56.01it/s]  6%|         | 17900/303576 [12:06<1:29:58, 52.92it/s]                                                          6%|         | 17900/303576 [12:06<1:29:58, 52.92it/s]  6%|         | 17906/303576 [12:07<1:33:30, 50.92it/s]  6%|         | 17912/303576 [12:07<1:35:48, 49.69it/s]  6%|         | 17917/303576 [12:07<1:36:21, 49.41it/s]  6%|         | 17923/303576 [12:07<1:35:55, 49.63it/s]  6%|         | 17929/303576 [12:07<1:35:49, 49.69it/s]  6%|         | 17935/303576 [12:07<1:36:03, 49.56it/s]  6%|         | 17941/303576 [12:07<1:35:56, 49.62it/s]  6%|         | 17947/303576 [12:07<1:36:02, 49.57it/s]  6%|         | 17953/303576 [12:07<1:34:46, 50.23it/s]  6%|         | 17959/303576 [12:08<1:34:23, 50.43it/s]  6%|         | 17965/303576 [12:08<1:33:07, 51.12it/s]  6%|         | 17971/303576 [12:08<1:33:03, 51.15it/s]  6%|         | 17977/303576 [12:08<1:33:12, 51.07it/s]  6%|         | 17983/303576 [12:08<1:30:24, 52.65it/s]  6%|         | 17989/303576 [12:08<1:28:59, 53.49it/s]  6%|         | 17995/303576 [12:08<1:28:04, 54.04it/s]                                                          6%|         | 18000/303576 [12:08<1:28:04, 54.04it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7401971817016602, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.5767, 'eval_samples_per_second': 10.01, 'eval_steps_per_second': 0.089, 'epoch': 0.17, 'timestamp': 1762965245.7351391, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7937, 'grad_norm': 0.2453090399503708, 'learning_rate': 0.00018094078052002433, 'epoch': 0.17, 'timestamp': 1762965247.1195047, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7975, 'grad_norm': 0.21668854355812073, 'learning_rate': 0.0001791403000961507, 'epoch': 0.17, 'timestamp': 1762965248.4577003, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7788, 'grad_norm': 0.20372168719768524, 'learning_rate': 0.00017735773564316783, 'epoch': 0.17, 'timestamp': 1762965250.1949244, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7731, 'grad_norm': 0.30477219820022583, 'learning_rate': 0.00017559290888531756, 'epoch': 0.17, 'timestamp': 1762965251.9865491, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7761, 'grad_norm': 0.3019893169403076, 'learning_rate': 0.000173845643320803, 'epoch': 0.17, 'timestamp': 1762965254.0881016, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7676, 'grad_norm': 0.2371256947517395, 'learning_rate': 0.00017211576420413704, 'epoch': 0.17, 'timestamp': 1762965255.7522013, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8024, 'grad_norm': 0.2123447209596634, 'learning_rate': 0.0001704030985286659, 'epoch': 0.17, 'timestamp': 1762965257.168365, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7881, 'grad_norm': 0.23729005455970764, 'learning_rate': 0.0001687074750092664, 'epoch': 0.18, 'timestamp': 1762965258.5104918, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7694, 'grad_norm': 0.20799611508846283, 'learning_rate': 0.0001670287240652153, 'epoch': 0.18, 'timestamp': 1762965260.3132539, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7753, 'grad_norm': 0.221808522939682, 'learning_rate': 0.00016536667780323, 'epoch': 0.18, 'timestamp': 1762965262.2711673, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:34:25.623141: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:34:25.633822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965265.646434 1716070 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965265.650169 1716070 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965265.660477 1716070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965265.660493 1716070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965265.660495 1716070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965265.660496 1716070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:34:25.663570: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:34:27 - TensorFlow version 2.19.1 available.
  6%|         | 18000/303576 [12:20<1:28:04, 54.04it/s]2025-11-12 16:34:35.248628: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:34:35.259263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965275.271819 1716096 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965275.275539 1716096 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965275.285750 1716096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965275.285765 1716096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965275.285766 1716096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965275.285768 1716096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:34:35.288887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:34:37 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A  6%|         | 18000/303576 [12:29<1:28:04, 54.04it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-18000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-18000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-18000/model.safetensors
  6%|         | 18001/303576 [12:29<84:55:09,  1.07s/it]  6%|         | 18008/303576 [12:29<57:02:17,  1.39it/s]  6%|         | 18016/303576 [12:30<37:19:09,  2.13it/s]  6%|         | 18024/303576 [12:30<25:11:06,  3.15it/s]  6%|         | 18032/303576 [12:30<17:23:21,  4.56it/s]  6%|         | 18040/303576 [12:30<12:14:18,  6.48it/s]  6%|         | 18048/303576 [12:30<8:45:00,  9.06it/s]   6%|         | 18056/303576 [12:30<6:22:16, 12.45it/s]  6%|         | 18064/303576 [12:30<4:43:48, 16.77it/s]  6%|         | 18074/303576 [12:30<3:21:56, 23.56it/s]  6%|         | 18084/303576 [12:30<2:31:14, 31.46it/s]  6%|         | 18095/303576 [12:31<1:54:46, 41.46it/s]                                                          6%|         | 18100/303576 [12:31<1:54:46, 41.46it/s]  6%|         | 18105/303576 [12:31<1:34:58, 50.10it/s]  6%|         | 18116/303576 [12:31<1:19:21, 59.95it/s]  6%|         | 18126/303576 [12:31<1:11:38, 66.41it/s]  6%|         | 18137/303576 [12:31<1:03:25, 75.02it/s]  6%|         | 18148/303576 [12:31<58:21, 81.53it/s]    6%|         | 18159/303576 [12:31<54:44, 86.90it/s]  6%|         | 18170/303576 [12:31<52:27, 90.68it/s]  6%|         | 18181/303576 [12:31<50:35, 94.03it/s]  6%|         | 18192/303576 [12:32<49:46, 95.56it/s]                                                        6%|         | 18200/303576 [12:32<49:46, 95.56it/s]  6%|         | 18203/303576 [12:32<48:33, 97.95it/s]  6%|         | 18214/303576 [12:32<47:42, 99.69it/s]  6%|         | 18225/303576 [12:32<48:15, 98.57it/s]  6%|         | 18236/303576 [12:32<48:18, 98.46it/s]  6%|         | 18247/303576 [12:32<47:36, 99.89it/s]  6%|         | 18258/303576 [12:32<49:34, 95.93it/s]  6%|         | 18268/303576 [12:32<51:57, 91.50it/s]  6%|         | 18278/303576 [12:32<53:43, 88.50it/s]  6%|         | 18287/303576 [12:33<54:36, 87.07it/s]  6%|         | 18296/303576 [12:33<56:30, 84.14it/s]                                                        6%|         | 18300/303576 [12:33<56:30, 84.14it/s]  6%|         | 18305/303576 [12:33<56:35, 84.01it/s]  6%|         | 18314/303576 [12:33<56:51, 83.61it/s]  6%|         | 18323/303576 [12:33<58:07, 81.80it/s]  6%|         | 18332/303576 [12:33<58:36, 81.11it/s]  6%|         | 18341/303576 [12:33<58:40, 81.03it/s]  6%|         | 18350/303576 [12:33<58:06, 81.81it/s]  6%|         | 18359/303576 [12:33<58:02, 81.90it/s]  6%|         | 18368/303576 [12:34<57:38, 82.48it/s]  6%|         | 18377/303576 [12:34<57:41, 82.39it/s]  6%|         | 18386/303576 [12:34<56:33, 84.04it/s]  6%|         | 18395/303576 [12:34<57:02, 83.34it/s]                                                        6%|         | 18400/303576 [12:34<57:01, 83.34it/s]  6%|         | 18404/303576 [12:34<57:09, 83.14it/s]  6%|         | 18413/303576 [12:34<57:52, 82.12it/s]  6%|         | 18422/303576 [12:34<57:38, 82.44it/s]  6%|         | 18432/303576 [12:34<55:18, 85.94it/s]  6%|         | 18443/303576 [12:34<51:47, 91.75it/s]  6%|         | 18454/303576 [12:35<49:25, 96.13it/s]  6%|         | 18465/303576 [12:35<48:00, 98.98it/s]  6%|         | 18476/303576 [12:35<47:21, 100.32it/s]  6%|         | 18487/303576 [12:35<47:31, 99.99it/s]   6%|         | 18498/303576 [12:35<48:44, 97.48it/s]                                                        6%|         | 18500/303576 [12:35<48:44, 97.48it/s]  6%|         | 18508/303576 [12:35<53:41, 88.48it/s]  6%|         | 18517/303576 [12:35<56:57, 83.41it/s]  6%|         | 18526/303576 [12:35<1:00:22, 78.68it/s]  6%|         | 18534/303576 [12:35<1:02:05, 76.52it/s]  6%|         | 18542/303576 [12:36<1:03:03, 75.34it/s]  6%|         | 18550/303576 [12:36<1:03:48, 74.45it/s]  6%|         | 18558/303576 [12:36<1:04:30, 73.63it/s]  6%|         | 18566/303576 [12:36<1:05:02, 73.03it/s]  6%|         | 18574/303576 [12:36<1:05:20, 72.69it/s]  6%|         | 18582/303576 [12:36<1:05:29, 72.53it/s]  6%|         | 18590/303576 [12:36<1:05:42, 72.29it/s]  6%|         | 18598/303576 [12:36<1:06:08, 71.81it/s]                                                          6%|         | 18600/303576 [12:36<1:06:08, 71.81it/s]  6%|         | 18606/303576 [12:36<1:04:10, 74.01it/s]  6%|         | 18614/303576 [12:37<1:03:01, 75.36it/s]  6%|         | 18622/303576 [12:37<1:04:58, 73.09it/s]  6%|         | 18630/303576 [12:37<1:06:23, 71.53it/s]  6%|         | 18638/303576 [12:37<1:07:20, 70.52it/s]  6%|         | 18646/303576 [12:37<1:06:59, 70.88it/s]  6%|         | 18654/303576 [12:37<1:04:51, 73.22it/s]  6%|         | 18663/303576 [12:37<1:02:46, 75.64it/s]  6%|         | 18671/303576 [12:37<1:01:53, 76.73it/s]  6%|         | 18679/303576 [12:37<1:01:14, 77.54it/s]  6%|         | 18687/303576 [12:38<1:00:47, 78.10it/s]  6%|         | 18695/303576 [12:38<1:00:44, 78.16it/s]                                                          6%|         | 18700/303576 [12:38<1:00:44, 78.16it/s]  6%|         | 18703/303576 [12:38<1:00:33, 78.39it/s]  6%|         | 18711/303576 [12:38<1:00:20, 78.68it/s]  6%|         | 18719/303576 [12:38<1:00:16, 78.76it/s]  6%|         | 18727/303576 [12:38<1:00:08, 78.94it/s]  6%|         | 18735/303576 [12:38<1:00:00, 79.10it/s]  6%|         | 18743/303576 [12:38<1:00:05, 79.01it/s]  6%|         | 18751/303576 [12:38<1:00:02, 79.06it/s]  6%|         | 18759/303576 [12:38<1:00:05, 79.00it/s]  6%|         | 18767/303576 [12:39<1:00:42, 78.19it/s]  6%|         | 18775/303576 [12:39<1:00:50, 78.01it/s]  6%|         | 18783/303576 [12:39<1:01:13, 77.53it/s]  6%|         | 18791/303576 [12:39<1:01:26, 77.25it/s]  6%|         | 18799/303576 [12:39<1:01:30, 77.17it/s]                                                          6%|         | 18800/303576 [12:39<1:01:30, 77.17it/s]  6%|         | 18807/303576 [12:39<1:01:29, 77.18it/s]  6%|         | 18815/303576 [12:39<1:01:51, 76.71it/s]  6%|         | 18823/303576 [12:39<1:07:05, 70.74it/s]  6%|         | 18831/303576 [12:39<1:13:23, 64.66it/s]  6%|         | 18838/303576 [12:40<1:12:32, 65.42it/s]  6%|         | 18847/303576 [12:40<1:08:11, 69.58it/s]  6%|         | 18856/303576 [12:40<1:03:24, 74.83it/s]  6%|         | 18865/303576 [12:40<1:00:52, 77.96it/s]  6%|         | 18874/303576 [12:40<59:26, 79.82it/s]    6%|         | 18883/303576 [12:40<58:09, 81.59it/s]  6%|         | 18892/303576 [12:40<57:25, 82.62it/s]                                                        6%|         | 18900/303576 [12:40<57:25, 82.62it/s]  6%|         | 18901/303576 [12:40<57:23, 82.66it/s]  6%|         | 18910/303576 [12:40<56:47, 83.54it/s]  6%|         | 18919/303576 [12:41<56:16, 84.31it/s]  6%|         | 18928/303576 [12:41<56:54, 83.37it/s]  6%|         | 18937/303576 [12:41<57:15, 82.85it/s]  6%|         | 18946/303576 [12:41<57:34, 82.39it/s]  6%|         | 18955/303576 [12:41<58:05, 81.67it/s]  6%|         | 18964/303576 [12:41<57:56, 81.87it/s]  6%|         | 18973/303576 [12:41<58:05, 81.66it/s]  6%|         | 18982/303576 [12:41<58:05, 81.66it/s]  6%|         | 18991/303576 [12:41<57:05, 83.08it/s]  6%|         | 19000/303576 [12:42<56:56, 83.29it/s]                                                        6%|         | 19000/303576 [12:42<56:56, 83.29it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7405131459236145, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.996, 'eval_samples_per_second': 10.764, 'eval_steps_per_second': 0.095, 'epoch': 0.18, 'timestamp': 1762965283.2679634, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7701, 'grad_norm': 0.2428397387266159, 'learning_rate': 0.00016372117000067703, 'epoch': 0.18, 'timestamp': 1762965284.5654237, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7714, 'grad_norm': 0.21875998377799988, 'learning_rate': 0.00016209203608894796, 'epoch': 0.18, 'timestamp': 1762965285.5657065, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7906, 'grad_norm': 0.20117290318012238, 'learning_rate': 0.00016047911313700087, 'epoch': 0.18, 'timestamp': 1762965286.6754744, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8057, 'grad_norm': 0.21153391897678375, 'learning_rate': 0.00015888223983506568, 'epoch': 0.18, 'timestamp': 1762965287.8898578, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8216, 'grad_norm': 0.18839865922927856, 'learning_rate': 0.00015730125647851065, 'epoch': 0.18, 'timestamp': 1762965288.9391906, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.777, 'grad_norm': 0.25109073519706726, 'learning_rate': 0.00015573600495187128, 'epoch': 0.18, 'timestamp': 1762965290.3408642, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7731, 'grad_norm': 0.22213692963123322, 'learning_rate': 0.0001541863287130363, 'epoch': 0.18, 'timestamp': 1762965291.6562817, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7732, 'grad_norm': 0.2276192009449005, 'learning_rate': 0.00015265207277759211, 'epoch': 0.19, 'timestamp': 1762965292.9369133, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7558, 'grad_norm': 0.19986943900585175, 'learning_rate': 0.0001511330837033222, 'epoch': 0.19, 'timestamp': 1762965294.2526214, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7821, 'grad_norm': 0.3539549708366394, 'learning_rate': 0.00014962920957486194, 'epoch': 0.19, 'timestamp': 1762965295.459664, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:34:59.339632: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:34:59.350237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965299.362744 1716141 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965299.366374 1716141 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965299.376747 1716141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965299.376763 1716141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965299.376764 1716141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965299.376766 1716141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:34:59.379940: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:35:01 - TensorFlow version 2.19.1 available.
2025-11-12 16:35:09.948062: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:35:09.958791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965309.971604 1716167 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965309.975456 1716167 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965309.985777 1716167 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965309.985792 1716167 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965309.985794 1716167 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965309.985795 1716167 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:35:09.988959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:35:11 - TensorFlow version 2.19.1 available.
  6%|         | 19000/303576 [13:00<56:56, 83.29it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.17it/s][A                                                      
                                             [A  6%|         | 19000/303576 [13:04<56:56, 83.29it/s]
100%|| 2/2 [00:01<00:00,  1.17it/s][A
                                             [A  6%|         | 19001/303576 [13:04<81:45:46,  1.03s/it]  6%|         | 19006/303576 [13:04<62:08:13,  1.27it/s]  6%|         | 19014/303576 [13:04<40:26:13,  1.95it/s]  6%|         | 19021/303576 [13:04<28:25:03,  2.78it/s]  6%|         | 19027/303576 [13:05<20:59:27,  3.77it/s]  6%|         | 19033/303576 [13:05<15:28:35,  5.11it/s]  6%|         | 19039/303576 [13:05<11:26:42,  6.91it/s]  6%|         | 19045/303576 [13:05<8:32:27,  9.25it/s]   6%|         | 19052/303576 [13:05<6:10:54, 12.79it/s]  6%|         | 19059/303576 [13:05<4:38:16, 17.04it/s]  6%|         | 19065/303576 [13:05<3:43:16, 21.24it/s]  6%|         | 19072/303576 [13:05<2:56:52, 26.81it/s]  6%|         | 19079/303576 [13:05<2:25:34, 32.57it/s]  6%|         | 19086/303576 [13:06<2:03:20, 38.44it/s]  6%|         | 19093/303576 [13:06<1:47:56, 43.93it/s]  6%|         | 19100/303576 [13:06<1:36:48, 48.97it/s]                                                          6%|         | 19100/303576 [13:06<1:36:48, 48.97it/s]  6%|         | 19107/303576 [13:06<1:29:01, 53.26it/s]  6%|         | 19114/303576 [13:06<1:23:28, 56.79it/s]  6%|         | 19121/303576 [13:06<1:19:18, 59.77it/s]  6%|         | 19131/303576 [13:06<1:07:32, 70.19it/s]  6%|         | 19142/303576 [13:06<59:49, 79.25it/s]    6%|         | 19153/303576 [13:06<55:13, 85.84it/s]  6%|         | 19164/303576 [13:07<52:19, 90.58it/s]  6%|         | 19174/303576 [13:07<50:56, 93.04it/s]  6%|         | 19184/303576 [13:07<49:59, 94.81it/s]  6%|         | 19194/303576 [13:07<49:25, 95.91it/s]                                                        6%|         | 19200/303576 [13:07<49:25, 95.91it/s]  6%|         | 19204/303576 [13:07<48:54, 96.90it/s]  6%|         | 19214/303576 [13:07<48:28, 97.78it/s]  6%|         | 19224/303576 [13:07<48:19, 98.07it/s]  6%|         | 19234/303576 [13:07<48:06, 98.52it/s]  6%|         | 19244/303576 [13:07<47:53, 98.96it/s]  6%|         | 19254/303576 [13:07<47:52, 98.97it/s]  6%|         | 19264/303576 [13:08<47:55, 98.87it/s]  6%|         | 19275/303576 [13:08<47:47, 99.15it/s]  6%|         | 19286/303576 [13:08<47:37, 99.51it/s]  6%|         | 19296/303576 [13:08<47:35, 99.57it/s]                                                        6%|         | 19300/303576 [13:08<47:34, 99.57it/s]  6%|         | 19306/303576 [13:08<49:46, 95.19it/s]  6%|         | 19316/303576 [13:08<52:07, 90.89it/s]  6%|         | 19326/303576 [13:08<53:54, 87.89it/s]  6%|         | 19335/303576 [13:08<55:11, 85.83it/s]  6%|         | 19344/303576 [13:08<55:51, 84.81it/s]  6%|         | 19353/303576 [13:09<56:44, 83.49it/s]  6%|         | 19362/303576 [13:09<56:55, 83.21it/s]  6%|         | 19371/303576 [13:09<57:23, 82.53it/s]  6%|         | 19380/303576 [13:09<57:21, 82.59it/s]  6%|         | 19389/303576 [13:09<57:49, 81.92it/s]  6%|         | 19398/303576 [13:09<57:39, 82.14it/s]                                                        6%|         | 19400/303576 [13:09<57:39, 82.14it/s]  6%|         | 19407/303576 [13:09<57:59, 81.67it/s]  6%|         | 19416/303576 [13:09<57:46, 81.98it/s]  6%|         | 19425/303576 [13:09<57:56, 81.73it/s]  6%|         | 19434/303576 [13:10<57:40, 82.12it/s]  6%|         | 19443/303576 [13:10<57:06, 82.93it/s]  6%|         | 19452/303576 [13:10<55:47, 84.88it/s]  6%|         | 19461/303576 [13:10<55:29, 85.32it/s]  6%|         | 19470/303576 [13:10<56:17, 84.12it/s]  6%|         | 19479/303576 [13:10<56:23, 83.97it/s]  6%|         | 19488/303576 [13:10<57:01, 83.04it/s]  6%|         | 19497/303576 [13:10<57:04, 82.95it/s]                                                        6%|         | 19500/303576 [13:10<57:04, 82.95it/s]  6%|         | 19506/303576 [13:10<57:12, 82.75it/s]  6%|         | 19515/303576 [13:10<57:08, 82.86it/s]  6%|         | 19524/303576 [13:11<57:26, 82.43it/s]  6%|         | 19533/303576 [13:11<57:13, 82.72it/s]  6%|         | 19542/303576 [13:11<57:30, 82.31it/s]  6%|         | 19551/303576 [13:11<57:22, 82.52it/s]  6%|         | 19560/303576 [13:11<56:48, 83.33it/s]  6%|         | 19569/303576 [13:11<56:57, 83.11it/s]  6%|         | 19578/303576 [13:11<56:46, 83.37it/s]  6%|         | 19587/303576 [13:11<56:20, 84.01it/s]  6%|         | 19596/303576 [13:11<56:18, 84.06it/s]                                                        6%|         | 19600/303576 [13:12<56:18, 84.06it/s]  6%|         | 19605/303576 [13:12<56:05, 84.38it/s]  6%|         | 19615/303576 [13:12<54:26, 86.94it/s]  6%|         | 19626/303576 [13:12<51:51, 91.24it/s]  6%|         | 19637/303576 [13:12<50:12, 94.25it/s]  6%|         | 19648/303576 [13:12<48:55, 96.73it/s]  6%|         | 19658/303576 [13:12<51:04, 92.64it/s]  6%|         | 19668/303576 [13:12<53:07, 89.08it/s]  6%|         | 19677/303576 [13:12<53:16, 88.82it/s]  6%|         | 19686/303576 [13:12<53:28, 88.47it/s]  6%|         | 19695/303576 [13:13<54:37, 86.63it/s]                                                        6%|         | 19700/303576 [13:13<54:36, 86.63it/s]  6%|         | 19704/303576 [13:13<55:32, 85.18it/s]  6%|         | 19713/303576 [13:13<56:05, 84.33it/s]  6%|         | 19722/303576 [13:13<56:46, 83.32it/s]  6%|         | 19731/303576 [13:13<57:08, 82.79it/s]  7%|         | 19740/303576 [13:13<57:15, 82.61it/s]  7%|         | 19749/303576 [13:13<57:23, 82.42it/s]  7%|         | 19758/303576 [13:13<58:24, 80.98it/s]  7%|         | 19767/303576 [13:13<58:17, 81.15it/s]  7%|         | 19776/303576 [13:14<58:58, 80.20it/s]  7%|         | 19785/303576 [13:14<1:01:53, 76.42it/s]  7%|         | 19793/303576 [13:14<1:04:00, 73.89it/s]                                                          7%|         | 19800/303576 [13:14<1:04:00, 73.89it/s]  7%|         | 19801/303576 [13:14<1:05:30, 72.20it/s]  7%|         | 19809/303576 [13:14<1:04:31, 73.31it/s]  7%|         | 19817/303576 [13:14<1:03:41, 74.26it/s]  7%|         | 19825/303576 [13:14<1:03:23, 74.61it/s]  7%|         | 19833/303576 [13:14<1:05:02, 72.72it/s]  7%|         | 19841/303576 [13:14<1:06:19, 71.29it/s]  7%|         | 19849/303576 [13:15<1:06:58, 70.61it/s]  7%|         | 19857/303576 [13:15<1:07:24, 70.14it/s]  7%|         | 19865/303576 [13:15<1:07:45, 69.78it/s]  7%|         | 19873/303576 [13:15<1:08:02, 69.49it/s]  7%|         | 19882/303576 [13:15<1:04:27, 73.36it/s]  7%|         | 19891/303576 [13:15<1:02:22, 75.80it/s]  7%|         | 19900/303576 [13:15<1:00:36, 78.02it/s]                                                          7%|         | 19900/303576 [13:15<1:00:36, 78.02it/s]  7%|         | 19909/303576 [13:15<59:49, 79.02it/s]    7%|         | 19918/303576 [13:15<58:54, 80.25it/s]  7%|         | 19927/303576 [13:16<58:39, 80.60it/s]  7%|         | 19936/303576 [13:16<58:06, 81.36it/s]  7%|         | 19945/303576 [13:16<58:12, 81.20it/s]  7%|         | 19954/303576 [13:16<57:59, 81.50it/s]  7%|         | 19963/303576 [13:16<57:56, 81.57it/s]  7%|         | 19972/303576 [13:16<58:01, 81.46it/s]  7%|         | 19981/303576 [13:16<57:43, 81.87it/s]  7%|         | 19990/303576 [13:16<57:55, 81.60it/s]  7%|         | 19999/303576 [13:16<57:48, 81.75it/s]                                                        7%|         | 20000/303576 [13:16<57:48, 81.75it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7381709218025208, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4778, 'eval_samples_per_second': 10.054, 'eval_steps_per_second': 0.089, 'epoch': 0.19, 'timestamp': 1762965317.9378347, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7691, 'grad_norm': 0.20294910669326782, 'learning_rate': 0.00014814029998850477, 'epoch': 0.19, 'timestamp': 1762965319.7103617, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7829, 'grad_norm': 0.2907786965370178, 'learning_rate': 0.0001466662060371607, 'epoch': 0.19, 'timestamp': 1762965320.8124862, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7739, 'grad_norm': 0.23289038240909576, 'learning_rate': 0.0001452067802954635, 'epoch': 0.19, 'timestamp': 1762965321.8229222, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7909, 'grad_norm': 0.21062321960926056, 'learning_rate': 0.00014376187680502695, 'epoch': 0.19, 'timestamp': 1762965323.0454195, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7783, 'grad_norm': 0.26888683438301086, 'learning_rate': 0.00014233135105984714, 'epoch': 0.19, 'timestamp': 1762965324.2456515, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7811, 'grad_norm': 0.20879556238651276, 'learning_rate': 0.00014092915290714187, 'epoch': 0.19, 'timestamp': 1762965325.4445033, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7728, 'grad_norm': 0.2710871696472168, 'learning_rate': 0.00013952681463805098, 'epoch': 0.19, 'timestamp': 1762965326.5530515, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7963, 'grad_norm': 0.22408679127693176, 'learning_rate': 0.00013813843056211596, 'epoch': 0.2, 'timestamp': 1762965327.841622, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7832, 'grad_norm': 0.22957843542099, 'learning_rate': 0.00013676386182588692, 'epoch': 0.2, 'timestamp': 1762965329.1991174, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7665, 'grad_norm': 0.26314109563827515, 'learning_rate': 0.00013540297095759746, 'epoch': 0.2, 'timestamp': 1762965330.4202588, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:35:33.749861: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:35:33.760564: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965333.773427 1716206 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965333.777236 1716206 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965333.787791 1716206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965333.787807 1716206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965333.787809 1716206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965333.787810 1716206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:35:33.790987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:35:35 - TensorFlow version 2.19.1 available.
2025-11-12 16:35:43.458893: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:35:43.469606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965343.482343 1716900 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965343.486181 1716900 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965343.496423 1716900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965343.496440 1716900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965343.496442 1716900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965343.496444 1716900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:35:43.499572: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
  7%|         | 20000/303576 [13:30<57:48, 81.75it/s]2025-11-12T16:35:45 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A  7%|         | 20000/303576 [13:37<57:48, 81.75it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-20000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-20000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-20000/model.safetensors
  7%|         | 20001/303576 [13:37<72:49:44,  1.08it/s]  7%|         | 20007/303576 [13:38<53:28:21,  1.47it/s]  7%|         | 20015/303576 [13:38<35:48:14,  2.20it/s]  7%|         | 20022/303576 [13:38<25:28:05,  3.09it/s]  7%|         | 20029/303576 [13:38<18:13:28,  4.32it/s]  7%|         | 20036/303576 [13:38<13:08:31,  5.99it/s]  7%|         | 20043/303576 [13:38<9:39:46,  8.15it/s]   7%|         | 20050/303576 [13:38<7:12:32, 10.92it/s]  7%|         | 20056/303576 [13:38<5:41:18, 13.84it/s]  7%|         | 20062/303576 [13:39<4:31:49, 17.38it/s]  7%|         | 20068/303576 [13:39<3:40:44, 21.41it/s]  7%|         | 20074/303576 [13:39<3:02:45, 25.85it/s]  7%|         | 20080/303576 [13:39<2:36:03, 30.28it/s]  7%|         | 20087/303576 [13:39<2:08:34, 36.75it/s]  7%|         | 20094/303576 [13:39<1:50:15, 42.85it/s]                                                          7%|         | 20100/303576 [13:39<1:50:15, 42.85it/s]  7%|         | 20101/303576 [13:39<1:38:54, 47.77it/s]  7%|         | 20108/303576 [13:39<1:31:01, 51.91it/s]  7%|         | 20115/303576 [13:39<1:25:47, 55.07it/s]  7%|         | 20122/303576 [13:40<1:21:48, 57.74it/s]  7%|         | 20129/303576 [13:40<1:19:06, 59.72it/s]  7%|         | 20136/303576 [13:40<1:17:18, 61.11it/s]  7%|         | 20143/303576 [13:40<1:15:54, 62.24it/s]  7%|         | 20150/303576 [13:40<1:15:12, 62.81it/s]  7%|         | 20157/303576 [13:40<1:13:43, 64.07it/s]  7%|         | 20164/303576 [13:40<1:13:25, 64.33it/s]  7%|         | 20171/303576 [13:40<1:12:27, 65.18it/s]  7%|         | 20178/303576 [13:40<1:12:04, 65.53it/s]  7%|         | 20185/303576 [13:41<1:11:40, 65.89it/s]  7%|         | 20192/303576 [13:41<1:11:21, 66.19it/s]  7%|         | 20199/303576 [13:41<1:11:16, 66.26it/s]                                                          7%|         | 20200/303576 [13:41<1:11:16, 66.26it/s]  7%|         | 20206/303576 [13:41<1:11:16, 66.27it/s]  7%|         | 20213/303576 [13:41<1:11:11, 66.35it/s]  7%|         | 20220/303576 [13:41<1:11:06, 66.41it/s]  7%|         | 20227/303576 [13:41<1:10:59, 66.52it/s]  7%|         | 20234/303576 [13:41<1:10:48, 66.69it/s]  7%|         | 20241/303576 [13:41<1:10:30, 66.97it/s]  7%|         | 20248/303576 [13:41<1:11:14, 66.28it/s]  7%|         | 20255/303576 [13:42<1:11:27, 66.09it/s]  7%|         | 20264/303576 [13:42<1:05:44, 71.82it/s]  7%|         | 20275/303576 [13:42<59:21, 79.55it/s]    7%|         | 20284/303576 [13:42<59:04, 79.94it/s]  7%|         | 20293/303576 [13:42<57:08, 82.63it/s]                                                        7%|         | 20300/303576 [13:42<57:08, 82.63it/s]  7%|         | 20302/303576 [13:42<56:33, 83.47it/s]  7%|         | 20311/303576 [13:42<56:37, 83.38it/s]  7%|         | 20320/303576 [13:42<56:25, 83.67it/s]  7%|         | 20329/303576 [13:42<56:25, 83.67it/s]  7%|         | 20339/303576 [13:43<55:25, 85.17it/s]  7%|         | 20348/303576 [13:43<55:34, 84.95it/s]  7%|         | 20357/303576 [13:43<56:01, 84.26it/s]  7%|         | 20366/303576 [13:43<56:09, 84.06it/s]  7%|         | 20375/303576 [13:43<56:07, 84.11it/s]  7%|         | 20384/303576 [13:43<55:23, 85.20it/s]  7%|         | 20393/303576 [13:43<55:40, 84.78it/s]                                                        7%|         | 20400/303576 [13:43<55:40, 84.78it/s]  7%|         | 20402/303576 [13:43<55:29, 85.04it/s]  7%|         | 20411/303576 [13:43<55:34, 84.92it/s]  7%|         | 20420/303576 [13:44<56:04, 84.16it/s]  7%|         | 20429/303576 [13:44<56:55, 82.91it/s]  7%|         | 20438/303576 [13:44<56:25, 83.64it/s]  7%|         | 20447/303576 [13:44<56:40, 83.27it/s]  7%|         | 20456/303576 [13:44<56:27, 83.57it/s]  7%|         | 20467/303576 [13:44<53:06, 88.83it/s]  7%|         | 20478/303576 [13:44<51:01, 92.48it/s]  7%|         | 20489/303576 [13:44<49:36, 95.10it/s]  7%|         | 20499/303576 [13:44<53:20, 88.45it/s]                                                        7%|         | 20500/303576 [13:44<53:20, 88.45it/s]  7%|         | 20508/303576 [13:45<57:15, 82.41it/s]  7%|         | 20517/303576 [13:45<59:25, 79.39it/s]  7%|         | 20526/303576 [13:45<1:02:30, 75.47it/s]  7%|         | 20536/303576 [13:45<58:29, 80.64it/s]    7%|         | 20546/303576 [13:45<56:19, 83.74it/s]  7%|         | 20555/303576 [13:45<56:12, 83.92it/s]  7%|         | 20564/303576 [13:45<57:13, 82.42it/s]  7%|         | 20573/303576 [13:45<56:59, 82.76it/s]  7%|         | 20582/303576 [13:45<56:56, 82.84it/s]  7%|         | 20591/303576 [13:46<57:19, 82.28it/s]  7%|         | 20600/303576 [13:46<57:15, 82.36it/s]                                                        7%|         | 20600/303576 [13:46<57:15, 82.36it/s]  7%|         | 20609/303576 [13:46<57:24, 82.14it/s]  7%|         | 20619/303576 [13:46<55:29, 84.99it/s]  7%|         | 20628/303576 [13:46<55:21, 85.18it/s]  7%|         | 20637/303576 [13:46<55:10, 85.47it/s]  7%|         | 20646/303576 [13:46<55:02, 85.67it/s]  7%|         | 20655/303576 [13:46<54:53, 85.90it/s]  7%|         | 20664/303576 [13:46<55:23, 85.13it/s]  7%|         | 20673/303576 [13:47<56:25, 83.55it/s]  7%|         | 20682/303576 [13:47<56:40, 83.20it/s]  7%|         | 20691/303576 [13:47<55:59, 84.20it/s]  7%|         | 20700/303576 [13:47<56:34, 83.32it/s]                                                        7%|         | 20700/303576 [13:47<56:34, 83.32it/s]  7%|         | 20709/303576 [13:47<56:58, 82.75it/s]  7%|         | 20718/303576 [13:47<56:42, 83.12it/s]  7%|         | 20727/303576 [13:47<56:16, 83.77it/s]  7%|         | 20736/303576 [13:47<56:24, 83.56it/s]  7%|         | 20745/303576 [13:47<56:33, 83.35it/s]  7%|         | 20754/303576 [13:47<56:31, 83.40it/s]  7%|         | 20763/303576 [13:48<56:38, 83.21it/s]  7%|         | 20772/303576 [13:48<56:29, 83.43it/s]  7%|         | 20781/303576 [13:48<56:45, 83.05it/s]  7%|         | 20790/303576 [13:48<55:54, 84.29it/s]  7%|         | 20799/303576 [13:48<56:02, 84.09it/s]                                                        7%|         | 20800/303576 [13:48<56:02, 84.09it/s]  7%|         | 20808/303576 [13:48<55:40, 84.64it/s]  7%|         | 20817/303576 [13:48<56:16, 83.75it/s]  7%|         | 20826/303576 [13:48<57:25, 82.07it/s]  7%|         | 20835/303576 [13:48<57:17, 82.26it/s]  7%|         | 20844/303576 [13:49<56:49, 82.92it/s]  7%|         | 20853/303576 [13:49<57:11, 82.39it/s]  7%|         | 20862/303576 [13:49<57:24, 82.09it/s]  7%|         | 20871/303576 [13:49<58:29, 80.55it/s]  7%|         | 20880/303576 [13:49<59:33, 79.10it/s]  7%|         | 20888/303576 [13:49<1:00:06, 78.39it/s]  7%|         | 20896/303576 [13:49<1:00:28, 77.91it/s]                                                          7%|         | 20900/303576 [13:49<1:00:28, 77.91it/s]  7%|         | 20904/303576 [13:49<1:00:56, 77.30it/s]  7%|         | 20912/303576 [13:49<1:01:30, 76.59it/s]  7%|         | 20920/303576 [13:50<1:03:20, 74.36it/s]  7%|         | 20928/303576 [13:50<1:04:10, 73.41it/s]  7%|         | 20936/303576 [13:50<1:04:50, 72.64it/s]  7%|         | 20944/303576 [13:50<1:06:23, 70.95it/s]  7%|         | 20954/303576 [13:50<1:00:55, 77.31it/s]  7%|         | 20963/303576 [13:50<58:26, 80.61it/s]    7%|         | 20974/303576 [13:50<53:57, 87.29it/s]  7%|         | 20985/303576 [13:50<51:03, 92.26it/s]  7%|         | 20996/303576 [13:50<48:46, 96.55it/s]                                                        7%|         | 21000/303576 [13:50<48:46, 96.55it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7369913458824158, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9324, 'eval_samples_per_second': 10.797, 'eval_steps_per_second': 0.096, 'epoch': 0.2, 'timestamp': 1762965351.353016, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.784, 'grad_norm': 0.21757270395755768, 'learning_rate': 0.0001340556218534163, 'epoch': 0.2, 'timestamp': 1762965353.1732337, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7703, 'grad_norm': 0.19606706500053406, 'learning_rate': 0.0001327216797638355, 'epoch': 0.2, 'timestamp': 1762965354.6993895, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7739, 'grad_norm': 0.2298913449048996, 'learning_rate': 0.00013140101128019332, 'epoch': 0.2, 'timestamp': 1762965356.0408108, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7715, 'grad_norm': 0.22557392716407776, 'learning_rate': 0.00013009348432133297, 'epoch': 0.2, 'timestamp': 1762965357.2217498, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8014, 'grad_norm': 0.2203439474105835, 'learning_rate': 0.00012879896812039213, 'epoch': 0.2, 'timestamp': 1762965358.3694422, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7797, 'grad_norm': 0.22341026365756989, 'learning_rate': 0.00012751733321172536, 'epoch': 0.2, 'timestamp': 1762965359.6114807, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7706, 'grad_norm': 0.20962123572826385, 'learning_rate': 0.00012624845141795619, 'epoch': 0.2, 'timestamp': 1762965360.7929761, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7633, 'grad_norm': 0.2493453472852707, 'learning_rate': 0.00012499219583715727, 'epoch': 0.21, 'timestamp': 1762965361.9875643, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7608, 'grad_norm': 0.2243219017982483, 'learning_rate': 0.0001237484408301601, 'epoch': 0.21, 'timestamp': 1762965363.2396739, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7886, 'grad_norm': 0.2526293396949768, 'learning_rate': 0.00012251706200798842, 'epoch': 0.21, 'timestamp': 1762965364.4260545, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:36:08.319901: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:36:08.330484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965368.343112 1719982 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965368.346876 1719982 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965368.357327 1719982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965368.357344 1719982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965368.357346 1719982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965368.357348 1719982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:36:08.360468: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:36:10 - TensorFlow version 2.19.1 available.
2025-11-12 16:36:18.965491: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:36:18.976278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965378.989250 1721328 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965378.993091 1721328 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965379.003712 1721328 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965379.003727 1721328 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965379.003729 1721328 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965379.003731 1721328 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:36:19.006907: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:36:20 - TensorFlow version 2.19.1 available.
  7%|         | 21000/303576 [14:10<48:46, 96.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.12it/s][A                                                      
                                             [A  7%|         | 21000/303576 [14:13<48:46, 96.55it/s]
100%|| 2/2 [00:01<00:00,  1.12it/s][A
                                             [A  7%|         | 21001/303576 [14:13<62:05:22,  1.26it/s]  7%|         | 21007/303576 [14:13<48:11:38,  1.63it/s]  7%|         | 21016/303576 [14:13<32:46:37,  2.39it/s]  7%|         | 21024/303576 [14:13<23:36:30,  3.32it/s]  7%|         | 21031/303576 [14:14<17:41:31,  4.44it/s]  7%|         | 21038/303576 [14:14<13:14:45,  5.92it/s]  7%|         | 21044/303576 [14:14<10:18:04,  7.62it/s]  7%|         | 21050/303576 [14:14<7:59:52,  9.81it/s]   7%|         | 21056/303576 [14:14<6:11:56, 12.66it/s]  7%|         | 21062/303576 [14:14<4:50:32, 16.21it/s]  7%|         | 21068/303576 [14:14<3:51:05, 20.37it/s]  7%|         | 21074/303576 [14:14<3:08:01, 25.04it/s]  7%|         | 21080/303576 [14:15<2:37:22, 29.92it/s]  7%|         | 21086/303576 [14:15<2:15:30, 34.74it/s]  7%|         | 21093/303576 [14:15<1:56:11, 40.52it/s]  7%|         | 21099/303576 [14:15<1:45:40, 44.55it/s]                                                          7%|         | 21100/303576 [14:15<1:45:40, 44.55it/s]  7%|         | 21105/303576 [14:15<1:37:59, 48.04it/s]  7%|         | 21112/303576 [14:15<1:31:12, 51.62it/s]  7%|         | 21119/303576 [14:15<1:26:54, 54.17it/s]  7%|         | 21125/303576 [14:15<1:24:48, 55.51it/s]  7%|         | 21131/303576 [14:15<1:23:01, 56.70it/s]  7%|         | 21138/303576 [14:16<1:21:25, 57.81it/s]  7%|         | 21145/303576 [14:16<1:20:13, 58.68it/s]  7%|         | 21152/303576 [14:16<1:21:52, 57.49it/s]  7%|         | 21159/303576 [14:16<1:19:05, 59.51it/s]  7%|         | 21166/303576 [14:16<1:19:24, 59.27it/s]  7%|         | 21173/303576 [14:16<1:18:50, 59.70it/s]  7%|         | 21180/303576 [14:16<1:18:27, 59.99it/s]  7%|         | 21187/303576 [14:16<1:18:52, 59.66it/s]  7%|         | 21194/303576 [14:16<1:18:20, 60.07it/s]                                                          7%|         | 21200/303576 [14:17<1:18:20, 60.07it/s]  7%|         | 21201/303576 [14:17<1:18:08, 60.23it/s]  7%|         | 21208/303576 [14:17<1:17:40, 60.59it/s]  7%|         | 21215/303576 [14:17<1:17:45, 60.52it/s]  7%|         | 21222/303576 [14:17<1:17:13, 60.94it/s]  7%|         | 21229/303576 [14:17<1:17:22, 60.82it/s]  7%|         | 21236/303576 [14:17<1:18:45, 59.75it/s]  7%|         | 21243/303576 [14:17<1:18:02, 60.30it/s]  7%|         | 21250/303576 [14:17<1:17:29, 60.72it/s]  7%|         | 21259/303576 [14:17<1:10:16, 66.96it/s]  7%|         | 21267/303576 [14:18<1:06:48, 70.43it/s]  7%|         | 21275/303576 [14:18<1:04:56, 72.44it/s]  7%|         | 21283/303576 [14:18<1:03:17, 74.33it/s]  7%|         | 21291/303576 [14:18<1:02:11, 75.66it/s]  7%|         | 21299/303576 [14:18<1:01:38, 76.32it/s]                                                          7%|         | 21300/303576 [14:18<1:01:38, 76.32it/s]  7%|         | 21307/303576 [14:18<1:01:07, 76.97it/s]  7%|         | 21315/303576 [14:18<1:00:37, 77.60it/s]  7%|         | 21323/303576 [14:18<1:00:23, 77.91it/s]  7%|         | 21331/303576 [14:18<1:00:18, 78.00it/s]  7%|         | 21339/303576 [14:19<1:00:13, 78.10it/s]  7%|         | 21347/303576 [14:19<1:00:06, 78.26it/s]  7%|         | 21355/303576 [14:19<1:00:24, 77.86it/s]  7%|         | 21363/303576 [14:19<1:00:39, 77.55it/s]  7%|         | 21371/303576 [14:19<1:00:16, 78.03it/s]  7%|         | 21379/303576 [14:19<59:57, 78.44it/s]    7%|         | 21388/303576 [14:19<59:29, 79.05it/s]  7%|         | 21396/303576 [14:19<59:33, 78.97it/s]                                                        7%|         | 21400/303576 [14:19<59:33, 78.97it/s]  7%|         | 21404/303576 [14:19<59:35, 78.92it/s]  7%|         | 21412/303576 [14:19<59:21, 79.22it/s]  7%|         | 21420/303576 [14:20<59:20, 79.25it/s]  7%|         | 21428/303576 [14:20<59:26, 79.11it/s]  7%|         | 21436/303576 [14:20<59:31, 79.00it/s]  7%|         | 21444/303576 [14:20<59:33, 78.95it/s]  7%|         | 21453/303576 [14:20<59:16, 79.32it/s]  7%|         | 21461/303576 [14:20<59:21, 79.20it/s]  7%|         | 21469/303576 [14:20<59:32, 78.97it/s]  7%|         | 21477/303576 [14:20<59:34, 78.91it/s]  7%|         | 21485/303576 [14:20<59:41, 78.77it/s]  7%|         | 21493/303576 [14:20<59:34, 78.91it/s]                                                        7%|         | 21500/303576 [14:21<59:34, 78.91it/s]  7%|         | 21501/303576 [14:21<59:43, 78.71it/s]  7%|         | 21509/303576 [14:21<59:40, 78.79it/s]  7%|         | 21518/303576 [14:21<58:51, 79.86it/s]  7%|         | 21527/303576 [14:21<57:58, 81.09it/s]  7%|         | 21536/303576 [14:21<58:23, 80.50it/s]  7%|         | 21545/303576 [14:21<59:16, 79.30it/s]  7%|         | 21553/303576 [14:21<59:28, 79.03it/s]  7%|         | 21561/303576 [14:21<59:30, 78.99it/s]  7%|         | 21569/303576 [14:21<59:35, 78.88it/s]  7%|         | 21577/303576 [14:22<59:33, 78.92it/s]  7%|         | 21585/303576 [14:22<59:28, 79.03it/s]  7%|         | 21593/303576 [14:22<59:27, 79.04it/s]                                                        7%|         | 21600/303576 [14:22<59:27, 79.04it/s]  7%|         | 21601/303576 [14:22<59:31, 78.94it/s]  7%|         | 21610/303576 [14:22<59:05, 79.53it/s]  7%|         | 21619/303576 [14:22<58:18, 80.60it/s]  7%|         | 21628/303576 [14:22<57:42, 81.43it/s]  7%|         | 21637/303576 [14:22<57:17, 82.01it/s]  7%|         | 21646/303576 [14:22<56:45, 82.79it/s]  7%|         | 21655/303576 [14:22<59:26, 79.04it/s]  7%|         | 21663/303576 [14:23<1:01:27, 76.45it/s]  7%|         | 21671/303576 [14:23<1:03:02, 74.53it/s]  7%|         | 21679/303576 [14:23<1:04:38, 72.68it/s]  7%|         | 21687/303576 [14:23<1:05:41, 71.52it/s]  7%|         | 21695/303576 [14:23<1:05:37, 71.59it/s]                                                          7%|         | 21700/303576 [14:23<1:05:37, 71.59it/s]  7%|         | 21703/303576 [14:23<1:05:20, 71.89it/s]  7%|         | 21711/303576 [14:23<1:05:43, 71.48it/s]  7%|         | 21719/303576 [14:23<1:05:23, 71.84it/s]  7%|         | 21727/303576 [14:23<1:03:38, 73.82it/s]  7%|         | 21735/303576 [14:24<1:02:55, 74.65it/s]  7%|         | 21744/303576 [14:24<1:00:39, 77.45it/s]  7%|         | 21752/303576 [14:24<1:00:16, 77.93it/s]  7%|         | 21761/303576 [14:24<59:31, 78.90it/s]    7%|         | 21769/303576 [14:24<1:00:04, 78.18it/s]  7%|         | 21778/303576 [14:24<58:59, 79.62it/s]    7%|         | 21787/303576 [14:24<57:51, 81.17it/s]  7%|         | 21796/303576 [14:24<56:53, 82.54it/s]                                                        7%|         | 21800/303576 [14:24<56:53, 82.54it/s]  7%|         | 21805/303576 [14:24<56:16, 83.44it/s]  7%|         | 21814/303576 [14:25<55:38, 84.40it/s]  7%|         | 21823/303576 [14:25<55:23, 84.79it/s]  7%|         | 21832/303576 [14:25<55:13, 85.02it/s]  7%|         | 21841/303576 [14:25<55:05, 85.23it/s]  7%|         | 21850/303576 [14:25<55:02, 85.31it/s]  7%|         | 21859/303576 [14:25<54:38, 85.93it/s]  7%|         | 21868/303576 [14:25<54:23, 86.31it/s]  7%|         | 21877/303576 [14:25<54:38, 85.93it/s]  7%|         | 21886/303576 [14:25<54:46, 85.70it/s]  7%|         | 21895/303576 [14:25<54:47, 85.69it/s]                                                        7%|         | 21900/303576 [14:26<54:47, 85.69it/s]  7%|         | 21904/303576 [14:26<54:44, 85.76it/s]  7%|         | 21913/303576 [14:26<54:20, 86.38it/s]  7%|         | 21922/303576 [14:26<53:42, 87.39it/s]  7%|         | 21931/303576 [14:26<53:16, 88.12it/s]  7%|         | 21940/303576 [14:26<53:00, 88.56it/s]  7%|         | 21949/303576 [14:26<53:04, 88.43it/s]  7%|         | 21959/303576 [14:26<52:41, 89.07it/s]  7%|         | 21968/303576 [14:26<52:49, 88.86it/s]  7%|         | 21977/303576 [14:26<52:51, 88.78it/s]  7%|         | 21986/303576 [14:27<53:32, 87.66it/s]  7%|         | 21995/303576 [14:27<53:47, 87.24it/s]                                                        7%|         | 22000/303576 [14:27<53:47, 87.24it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7388125658035278, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.5095, 'eval_samples_per_second': 10.04, 'eval_steps_per_second': 0.089, 'epoch': 0.21, 'timestamp': 1762965386.9360135, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7768, 'grad_norm': 0.25207191705703735, 'learning_rate': 0.00012129793621941879, 'epoch': 0.21, 'timestamp': 1762965388.8260937, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7812, 'grad_norm': 0.22591327130794525, 'learning_rate': 0.0001200909415386638, 'epoch': 0.21, 'timestamp': 1762965390.4917874, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7972, 'grad_norm': 0.2304999828338623, 'learning_rate': 0.00011889595725317829, 'epoch': 0.21, 'timestamp': 1762965391.9472086, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7529, 'grad_norm': 0.2534821033477783, 'learning_rate': 0.00011771286385158671, 'epoch': 0.21, 'timestamp': 1762965393.2197762, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.771, 'grad_norm': 0.2381424456834793, 'learning_rate': 0.00011654154301173091, 'epoch': 0.21, 'timestamp': 1762965394.4859638, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7774, 'grad_norm': 0.21707317233085632, 'learning_rate': 0.00011538187758883626, 'epoch': 0.21, 'timestamp': 1762965395.744828, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7764, 'grad_norm': 0.2471468299627304, 'learning_rate': 0.0001142337516037962, 'epoch': 0.21, 'timestamp': 1762965397.0629952, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7673, 'grad_norm': 0.2727890908718109, 'learning_rate': 0.00011309705023157288, 'epoch': 0.22, 'timestamp': 1762965398.3268692, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.767, 'grad_norm': 0.19777700304985046, 'learning_rate': 0.00011197165978971358, 'epoch': 0.22, 'timestamp': 1762965399.4907677, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7567, 'grad_norm': 0.24038606882095337, 'learning_rate': 0.00011085746772698126, 'epoch': 0.22, 'timestamp': 1762965400.6252484, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:36:43.976919: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:36:43.987467: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965404.000225 1723880 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965404.003998 1723880 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965404.014291 1723880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965404.014306 1723880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965404.014309 1723880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965404.014311 1723880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:36:44.017470: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:36:45 - TensorFlow version 2.19.1 available.
2025-11-12 16:36:53.499014: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:36:53.509772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965413.522511 1724699 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965413.526303 1724699 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965413.536668 1724699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965413.536687 1724699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965413.536689 1724699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965413.536691 1724699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:36:53.539855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
  7%|         | 22000/303576 [14:40<53:47, 87.24it/s]2025-11-12T16:36:55 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A  7%|         | 22000/303576 [14:48<53:47, 87.24it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-22000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-22000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-22000/model.safetensors
  7%|         | 22001/303576 [14:48<61:16:12,  1.28it/s]  7%|         | 22008/303576 [14:48<45:08:03,  1.73it/s]  7%|         | 22016/303576 [14:48<31:47:59,  2.46it/s]  7%|         | 22024/303576 [14:48<22:32:19,  3.47it/s]  7%|         | 22031/303576 [14:48<16:42:47,  4.68it/s]  7%|         | 22038/303576 [14:48<12:23:04,  6.31it/s]  7%|         | 22045/303576 [14:48<9:12:47,  8.49it/s]   7%|         | 22052/303576 [14:49<6:56:18, 11.27it/s]  7%|         | 22058/303576 [14:49<5:28:26, 14.29it/s]  7%|         | 22064/303576 [14:49<4:21:06, 17.97it/s]  7%|         | 22070/303576 [14:49<3:31:14, 22.21it/s]  7%|         | 22076/303576 [14:49<2:54:21, 26.91it/s]  7%|         | 22082/303576 [14:49<2:27:07, 31.89it/s]  7%|         | 22088/303576 [14:49<2:08:29, 36.51it/s]  7%|         | 22094/303576 [14:49<1:54:50, 40.85it/s]  7%|         | 22100/303576 [14:49<1:45:05, 44.64it/s]                                                          7%|         | 22100/303576 [14:49<1:45:05, 44.64it/s]  7%|         | 22106/303576 [14:49<1:38:08, 47.80it/s]  7%|         | 22112/303576 [14:50<1:33:06, 50.38it/s]  7%|         | 22118/303576 [14:50<1:29:40, 52.31it/s]  7%|         | 22124/303576 [14:50<1:28:21, 53.09it/s]  7%|         | 22130/303576 [14:50<1:26:41, 54.11it/s]  7%|         | 22136/303576 [14:50<1:24:46, 55.33it/s]  7%|         | 22142/303576 [14:50<1:24:53, 55.25it/s]  7%|         | 22149/303576 [14:50<1:19:25, 59.05it/s]  7%|         | 22156/303576 [14:50<1:15:36, 62.03it/s]  7%|         | 22163/303576 [14:50<1:13:42, 63.64it/s]  7%|         | 22170/303576 [14:51<1:17:06, 60.82it/s]  7%|         | 22177/303576 [14:51<1:17:31, 60.50it/s]  7%|         | 22184/303576 [14:51<1:17:38, 60.40it/s]  7%|         | 22191/303576 [14:51<1:17:02, 60.87it/s]  7%|         | 22198/303576 [14:51<1:16:14, 61.51it/s]                                                          7%|         | 22200/303576 [14:51<1:16:14, 61.51it/s]  7%|         | 22205/303576 [14:51<1:15:04, 62.46it/s]  7%|         | 22212/303576 [14:51<1:16:24, 61.38it/s]  7%|         | 22219/303576 [14:51<1:18:59, 59.37it/s]  7%|         | 22225/303576 [14:51<1:19:22, 59.08it/s]  7%|         | 22232/303576 [14:52<1:18:18, 59.88it/s]  7%|         | 22238/303576 [14:52<1:21:09, 57.77it/s]  7%|         | 22244/303576 [14:52<1:23:36, 56.09it/s]  7%|         | 22250/303576 [14:52<1:25:12, 55.03it/s]  7%|         | 22256/303576 [14:52<1:25:04, 55.11it/s]  7%|         | 22262/303576 [14:52<1:24:18, 55.61it/s]  7%|         | 22268/303576 [14:52<1:24:21, 55.58it/s]  7%|         | 22274/303576 [14:52<1:23:27, 56.18it/s]  7%|         | 22280/303576 [14:52<1:22:29, 56.84it/s]  7%|         | 22286/303576 [14:53<1:22:10, 57.05it/s]  7%|         | 22294/303576 [14:53<1:14:59, 62.52it/s]                                                          7%|         | 22300/303576 [14:53<1:14:59, 62.52it/s]  7%|         | 22303/303576 [14:53<1:07:40, 69.27it/s]  7%|         | 22312/303576 [14:53<1:03:36, 73.70it/s]  7%|         | 22321/303576 [14:53<1:00:44, 77.17it/s]  7%|         | 22330/303576 [14:53<59:05, 79.33it/s]    7%|         | 22339/303576 [14:53<57:22, 81.69it/s]  7%|         | 22348/303576 [14:53<56:53, 82.37it/s]  7%|         | 22357/303576 [14:53<56:36, 82.81it/s]  7%|         | 22366/303576 [14:54<58:21, 80.31it/s]  7%|         | 22375/303576 [14:54<1:00:16, 77.75it/s]  7%|         | 22383/303576 [14:54<1:01:32, 76.14it/s]  7%|         | 22391/303576 [14:54<1:02:26, 75.05it/s]  7%|         | 22399/303576 [14:54<1:03:01, 74.35it/s]                                                          7%|         | 22400/303576 [14:54<1:03:01, 74.35it/s]  7%|         | 22407/303576 [14:54<1:03:34, 73.71it/s]  7%|         | 22415/303576 [14:54<1:04:38, 72.50it/s]  7%|         | 22423/303576 [14:54<1:06:02, 70.96it/s]  7%|         | 22431/303576 [14:54<1:06:49, 70.12it/s]  7%|         | 22439/303576 [14:55<1:07:08, 69.79it/s]  7%|         | 22446/303576 [14:55<1:08:01, 68.88it/s]  7%|         | 22454/303576 [14:55<1:07:07, 69.79it/s]  7%|         | 22462/303576 [14:55<1:06:25, 70.53it/s]  7%|         | 22470/303576 [14:55<1:05:59, 70.99it/s]  7%|         | 22478/303576 [14:55<1:05:33, 71.46it/s]  7%|         | 22486/303576 [14:55<1:05:23, 71.64it/s]  7%|         | 22494/303576 [14:55<1:05:08, 71.92it/s]                                                          7%|         | 22500/303576 [14:55<1:05:07, 71.92it/s]  7%|         | 22502/303576 [14:55<1:05:03, 72.00it/s]  7%|         | 22510/303576 [14:56<1:04:56, 72.13it/s]  7%|         | 22518/303576 [14:56<1:04:58, 72.09it/s]  7%|         | 22526/303576 [14:56<1:04:58, 72.09it/s]  7%|         | 22534/303576 [14:56<1:05:12, 71.83it/s]  7%|         | 22542/303576 [14:56<1:05:15, 71.78it/s]  7%|         | 22550/303576 [14:56<1:05:22, 71.64it/s]  7%|         | 22558/303576 [14:56<1:04:19, 72.82it/s]  7%|         | 22567/303576 [14:56<1:02:27, 74.98it/s]  7%|         | 22575/303576 [14:56<1:01:42, 75.89it/s]  7%|         | 22583/303576 [14:57<1:01:30, 76.13it/s]  7%|         | 22591/303576 [14:57<1:01:16, 76.42it/s]  7%|         | 22599/303576 [14:57<1:01:30, 76.14it/s]                                                          7%|         | 22600/303576 [14:57<1:01:30, 76.14it/s]  7%|         | 22608/303576 [14:57<1:00:20, 77.60it/s]  7%|         | 22617/303576 [14:57<59:37, 78.54it/s]    7%|         | 22626/303576 [14:57<58:24, 80.17it/s]  7%|         | 22635/303576 [14:57<58:12, 80.45it/s]  7%|         | 22644/303576 [14:57<57:27, 81.50it/s]  7%|         | 22653/303576 [14:57<57:00, 82.12it/s]  7%|         | 22662/303576 [14:58<56:33, 82.77it/s]  7%|         | 22671/303576 [14:58<56:21, 83.08it/s]  7%|         | 22680/303576 [14:58<56:35, 82.73it/s]  7%|         | 22689/303576 [14:58<56:30, 82.84it/s]  7%|         | 22698/303576 [14:58<56:11, 83.31it/s]                                                        7%|         | 22700/303576 [14:58<56:11, 83.31it/s]  7%|         | 22707/303576 [14:58<56:03, 83.50it/s]  7%|         | 22716/303576 [14:58<56:03, 83.49it/s]  7%|         | 22725/303576 [14:58<56:09, 83.36it/s]  7%|         | 22734/303576 [14:58<55:59, 83.59it/s]  7%|         | 22743/303576 [14:58<55:58, 83.61it/s]  7%|         | 22752/303576 [14:59<56:01, 83.54it/s]  7%|         | 22761/303576 [14:59<55:49, 83.83it/s]  8%|         | 22770/303576 [14:59<54:54, 85.25it/s]  8%|         | 22780/303576 [14:59<53:48, 86.97it/s]  8%|         | 22790/303576 [14:59<53:10, 88.01it/s]  8%|         | 22800/303576 [14:59<52:36, 88.96it/s]                                                        8%|         | 22800/303576 [14:59<52:36, 88.96it/s]  8%|         | 22809/303576 [14:59<52:26, 89.22it/s]  8%|         | 22819/303576 [14:59<52:14, 89.58it/s]  8%|         | 22829/303576 [14:59<52:04, 89.86it/s]  8%|         | 22839/303576 [15:00<51:54, 90.12it/s]  8%|         | 22849/303576 [15:00<51:45, 90.40it/s]  8%|         | 22859/303576 [15:00<55:55, 83.67it/s]  8%|         | 22868/303576 [15:00<58:50, 79.51it/s]  8%|         | 22877/303576 [15:00<1:01:16, 76.36it/s]  8%|         | 22885/303576 [15:00<1:02:06, 75.32it/s]  8%|         | 22893/303576 [15:00<1:02:43, 74.59it/s]                                                          8%|         | 22900/303576 [15:00<1:02:43, 74.59it/s]  8%|         | 22901/303576 [15:00<1:03:34, 73.58it/s]  8%|         | 22909/303576 [15:01<1:03:53, 73.22it/s]  8%|         | 22917/303576 [15:01<1:04:17, 72.75it/s]  8%|         | 22925/303576 [15:01<1:05:28, 71.44it/s]  8%|         | 22933/303576 [15:01<1:06:39, 70.16it/s]  8%|         | 22941/303576 [15:01<1:07:19, 69.46it/s]  8%|         | 22948/303576 [15:01<1:07:26, 69.35it/s]  8%|         | 22955/303576 [15:01<1:08:15, 68.52it/s]  8%|         | 22962/303576 [15:01<1:08:04, 68.70it/s]  8%|         | 22969/303576 [15:01<1:08:58, 67.80it/s]  8%|         | 22976/303576 [15:01<1:08:41, 68.08it/s]  8%|         | 22983/303576 [15:02<1:08:51, 67.92it/s]  8%|         | 22990/303576 [15:02<1:08:40, 68.09it/s]  8%|         | 22997/303576 [15:02<1:08:55, 67.85it/s]                                                          8%|         | 23000/303576 [15:02<1:08:55, 67.85it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.736488938331604, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9339, 'eval_samples_per_second': 10.796, 'eval_steps_per_second': 0.096, 'epoch': 0.22, 'timestamp': 1762965421.5596392, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7675, 'grad_norm': 0.3087121546268463, 'learning_rate': 0.0001097543626120979, 'epoch': 0.22, 'timestamp': 1762965423.3351796, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.77, 'grad_norm': 0.24426470696926117, 'learning_rate': 0.00010866223412260052, 'epoch': 0.22, 'timestamp': 1762965424.9966116, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7742, 'grad_norm': 0.25276124477386475, 'learning_rate': 0.00010758097303380771, 'epoch': 0.22, 'timestamp': 1762965426.6883626, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.774, 'grad_norm': 0.21041239798069, 'learning_rate': 0.00010652112332022768, 'epoch': 0.22, 'timestamp': 1762965427.9511058, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7668, 'grad_norm': 0.23505569994449615, 'learning_rate': 0.00010546116769985338, 'epoch': 0.22, 'timestamp': 1762965429.3648503, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.20560289919376373, 'learning_rate': 0.00010441175933885978, 'epoch': 0.22, 'timestamp': 1762965430.70878, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7705, 'grad_norm': 0.2643105983734131, 'learning_rate': 0.00010337279328504075, 'epoch': 0.22, 'timestamp': 1762965431.9147437, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7704, 'grad_norm': 0.21622909605503082, 'learning_rate': 0.0001023441656305344, 'epoch': 0.23, 'timestamp': 1762965433.0751798, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7747, 'grad_norm': 0.23245297372341156, 'learning_rate': 0.00010132577350143082, 'epoch': 0.23, 'timestamp': 1762965434.3305082, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7679, 'grad_norm': 0.27888092398643494, 'learning_rate': 0.00010031751504748327, 'epoch': 0.23, 'timestamp': 1762965435.7906005, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:37:19.696819: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:37:19.707386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965439.720007 1726851 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965439.723736 1726851 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965439.734040 1726851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965439.734054 1726851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965439.734056 1726851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965439.734058 1726851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:37:19.737201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:37:22 - TensorFlow version 2.19.1 available.
2025-11-12 16:37:30.068350: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:37:30.078932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965450.091431 1727806 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965450.095139 1727806 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965450.105309 1727806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965450.105327 1727806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965450.105328 1727806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965450.105330 1727806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:37:30.108427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:37:32 - TensorFlow version 2.19.1 available.
  8%|         | 23000/303576 [15:20<1:08:55, 67.85it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.16it/s][A                                                        
                                             [A  8%|         | 23000/303576 [15:24<1:08:55, 67.85it/s]
100%|| 2/2 [00:01<00:00,  1.16it/s][A
                                             [A  8%|         | 23001/303576 [15:24<86:16:40,  1.11s/it]  8%|         | 23006/303576 [15:24<64:24:48,  1.21it/s]  8%|         | 23013/303576 [15:25<43:03:00,  1.81it/s]  8%|         | 23019/303576 [15:25<30:52:17,  2.52it/s]  8%|         | 23025/303576 [15:25<22:14:18,  3.50it/s]  8%|         | 23031/303576 [15:25<16:02:53,  4.86it/s]  8%|         | 23037/303576 [15:25<11:43:20,  6.65it/s]  8%|         | 23043/303576 [15:25<8:42:50,  8.94it/s]   8%|         | 23049/303576 [15:25<6:35:36, 11.82it/s]  8%|         | 23054/303576 [15:25<5:16:48, 14.76it/s]  8%|         | 23059/303576 [15:25<4:18:18, 18.10it/s]  8%|         | 23065/303576 [15:26<3:23:49, 22.94it/s]  8%|         | 23071/303576 [15:26<2:47:09, 27.97it/s]  8%|         | 23077/303576 [15:26<2:24:09, 32.43it/s]  8%|         | 23083/303576 [15:26<2:10:12, 35.90it/s]  8%|         | 23090/303576 [15:26<1:50:58, 42.13it/s]  8%|         | 23096/303576 [15:26<1:41:51, 45.89it/s]                                                          8%|         | 23100/303576 [15:26<1:41:51, 45.89it/s]  8%|         | 23103/303576 [15:26<1:32:18, 50.64it/s]  8%|         | 23109/303576 [15:26<1:30:55, 51.41it/s]  8%|         | 23115/303576 [15:26<1:31:47, 50.93it/s]  8%|         | 23121/303576 [15:27<1:34:00, 49.72it/s]  8%|         | 23127/303576 [15:27<1:35:33, 48.91it/s]  8%|         | 23134/303576 [15:27<1:27:56, 53.15it/s]  8%|         | 23145/303576 [15:27<1:09:57, 66.82it/s]  8%|         | 23156/303576 [15:27<1:00:12, 77.64it/s]  8%|         | 23167/303576 [15:27<54:26, 85.83it/s]    8%|         | 23178/303576 [15:27<51:17, 91.12it/s]  8%|         | 23188/303576 [15:27<52:33, 88.92it/s]  8%|         | 23198/303576 [15:27<52:39, 88.74it/s]                                                        8%|         | 23200/303576 [15:28<52:39, 88.74it/s]  8%|         | 23207/303576 [15:28<53:36, 87.16it/s]  8%|         | 23216/303576 [15:28<55:05, 84.82it/s]  8%|         | 23225/303576 [15:28<56:13, 83.09it/s]  8%|         | 23234/303576 [15:28<59:06, 79.04it/s]  8%|         | 23242/303576 [15:28<1:00:42, 76.96it/s]  8%|         | 23250/303576 [15:28<1:01:54, 75.48it/s]  8%|         | 23258/303576 [15:28<1:02:46, 74.43it/s]  8%|         | 23266/303576 [15:28<1:03:27, 73.63it/s]  8%|         | 23274/303576 [15:29<1:03:52, 73.13it/s]  8%|         | 23282/303576 [15:29<1:04:23, 72.54it/s]  8%|         | 23290/303576 [15:29<1:04:30, 72.41it/s]  8%|         | 23298/303576 [15:29<1:04:30, 72.41it/s]                                                          8%|         | 23300/303576 [15:29<1:04:30, 72.41it/s]  8%|         | 23306/303576 [15:29<1:04:43, 72.18it/s]  8%|         | 23314/303576 [15:29<1:04:57, 71.90it/s]  8%|         | 23322/303576 [15:29<1:04:52, 71.99it/s]  8%|         | 23330/303576 [15:29<1:04:58, 71.89it/s]  8%|         | 23338/303576 [15:29<1:05:29, 71.31it/s]  8%|         | 23346/303576 [15:30<1:06:05, 70.67it/s]  8%|         | 23354/303576 [15:30<1:06:15, 70.49it/s]  8%|         | 23362/303576 [15:30<1:06:45, 69.96it/s]  8%|         | 23369/303576 [15:30<1:07:23, 69.30it/s]  8%|         | 23376/303576 [15:30<1:09:17, 67.40it/s]  8%|         | 23383/303576 [15:30<1:08:35, 68.08it/s]  8%|         | 23391/303576 [15:30<1:06:00, 70.75it/s]  8%|         | 23399/303576 [15:30<1:03:40, 73.34it/s]                                                          8%|         | 23400/303576 [15:30<1:03:40, 73.34it/s]  8%|         | 23407/303576 [15:30<1:02:26, 74.79it/s]  8%|         | 23415/303576 [15:30<1:01:33, 75.86it/s]  8%|         | 23423/303576 [15:31<1:01:03, 76.47it/s]  8%|         | 23432/303576 [15:31<1:00:04, 77.73it/s]  8%|         | 23441/303576 [15:31<59:26, 78.55it/s]    8%|         | 23450/303576 [15:31<58:41, 79.54it/s]  8%|         | 23459/303576 [15:31<58:22, 79.98it/s]  8%|         | 23468/303576 [15:31<58:04, 80.39it/s]  8%|         | 23477/303576 [15:31<57:56, 80.58it/s]  8%|         | 23486/303576 [15:31<57:50, 80.71it/s]  8%|         | 23495/303576 [15:31<57:49, 80.74it/s]                                                        8%|         | 23500/303576 [15:32<57:48, 80.74it/s]  8%|         | 23504/303576 [15:32<57:49, 80.72it/s]  8%|         | 23513/303576 [15:32<57:46, 80.79it/s]  8%|         | 23522/303576 [15:32<57:26, 81.25it/s]  8%|         | 23531/303576 [15:32<57:09, 81.65it/s]  8%|         | 23540/303576 [15:32<56:56, 81.96it/s]  8%|         | 23549/303576 [15:32<56:47, 82.18it/s]  8%|         | 23558/303576 [15:32<56:29, 82.62it/s]  8%|         | 23567/303576 [15:32<56:42, 82.29it/s]  8%|         | 23576/303576 [15:32<56:25, 82.70it/s]  8%|         | 23585/303576 [15:33<56:29, 82.61it/s]  8%|         | 23594/303576 [15:33<56:18, 82.88it/s]                                                        8%|         | 23600/303576 [15:33<56:18, 82.88it/s]  8%|         | 23603/303576 [15:33<56:37, 82.41it/s]  8%|         | 23612/303576 [15:33<56:28, 82.61it/s]  8%|         | 23622/303576 [15:33<54:40, 85.33it/s]  8%|         | 23631/303576 [15:33<57:12, 81.56it/s]  8%|         | 23640/303576 [15:33<58:48, 79.33it/s]  8%|         | 23648/303576 [15:33<1:00:28, 77.15it/s]  8%|         | 23656/303576 [15:33<1:01:44, 75.56it/s]  8%|         | 23664/303576 [15:34<1:02:53, 74.18it/s]  8%|         | 23672/303576 [15:34<1:03:40, 73.26it/s]  8%|         | 23680/303576 [15:34<1:03:56, 72.95it/s]  8%|         | 23688/303576 [15:34<1:04:17, 72.57it/s]  8%|         | 23696/303576 [15:34<1:05:27, 71.26it/s]                                                          8%|         | 23700/303576 [15:34<1:05:27, 71.26it/s]  8%|         | 23704/303576 [15:34<1:05:44, 70.95it/s]  8%|         | 23712/303576 [15:34<1:05:07, 71.63it/s]  8%|         | 23720/303576 [15:34<1:05:15, 71.48it/s]  8%|         | 23728/303576 [15:34<1:05:09, 71.58it/s]  8%|         | 23736/303576 [15:35<1:05:14, 71.49it/s]  8%|         | 23744/303576 [15:35<1:04:56, 71.82it/s]  8%|         | 23752/303576 [15:35<1:04:51, 71.90it/s]  8%|         | 23760/303576 [15:35<1:05:21, 71.35it/s]  8%|         | 23768/303576 [15:35<1:06:15, 70.38it/s]  8%|         | 23776/303576 [15:35<1:06:07, 70.53it/s]  8%|         | 23784/303576 [15:35<1:05:40, 71.00it/s]  8%|         | 23792/303576 [15:35<1:05:44, 70.93it/s]  8%|         | 23800/303576 [15:35<1:05:38, 71.03it/s]                                                          8%|         | 23800/303576 [15:35<1:05:38, 71.03it/s]  8%|         | 23808/303576 [15:36<1:03:51, 73.03it/s]  8%|         | 23818/303576 [15:36<58:08, 80.19it/s]    8%|         | 23828/303576 [15:36<54:38, 85.32it/s]  8%|         | 23839/303576 [15:36<51:45, 90.07it/s]  8%|         | 23850/303576 [15:36<50:12, 92.86it/s]  8%|         | 23860/303576 [15:36<49:09, 94.84it/s]  8%|         | 23871/303576 [15:36<48:14, 96.65it/s]  8%|         | 23881/303576 [15:36<47:46, 97.58it/s]  8%|         | 23891/303576 [15:36<47:35, 97.93it/s]                                                        8%|         | 23900/303576 [15:37<47:35, 97.93it/s]  8%|         | 23901/303576 [15:37<47:21, 98.44it/s]  8%|         | 23911/303576 [15:37<49:38, 93.88it/s]  8%|         | 23921/303576 [15:37<51:36, 90.31it/s]  8%|         | 23931/303576 [15:37<53:12, 87.60it/s]  8%|         | 23940/303576 [15:37<53:57, 86.37it/s]  8%|         | 23949/303576 [15:37<54:56, 84.83it/s]  8%|         | 23958/303576 [15:37<55:10, 84.46it/s]  8%|         | 23967/303576 [15:37<55:47, 83.54it/s]  8%|         | 23976/303576 [15:37<55:53, 83.38it/s]  8%|         | 23985/303576 [15:38<56:07, 83.02it/s]  8%|         | 23994/303576 [15:38<56:06, 83.05it/s]                                                        8%|         | 24000/303576 [15:38<56:06, 83.05it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7397294640541077, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.3639, 'eval_samples_per_second': 10.106, 'eval_steps_per_second': 0.089, 'epoch': 0.23, 'timestamp': 1762965458.154974, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7733, 'grad_norm': 0.20444150269031525, 'learning_rate': 9.931928943192264e-05, 'epoch': 0.23, 'timestamp': 1762965460.1487222, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.20974871516227722, 'learning_rate': 9.833099682137192e-05, 'epoch': 0.23, 'timestamp': 1762965461.4597383, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7652, 'grad_norm': 0.23965592682361603, 'learning_rate': 9.735253837586268e-05, 'epoch': 0.23, 'timestamp': 1762965462.8171704, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8026, 'grad_norm': 0.20881567895412445, 'learning_rate': 9.638381623894928e-05, 'epoch': 0.23, 'timestamp': 1762965464.2262502, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7754, 'grad_norm': 0.2320290207862854, 'learning_rate': 9.542473352792247e-05, 'epoch': 0.23, 'timestamp': 1762965465.4728796, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7867, 'grad_norm': 0.43314218521118164, 'learning_rate': 9.447519432412002e-05, 'epoch': 0.23, 'timestamp': 1762965466.6856048, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7784, 'grad_norm': 0.22304575145244598, 'learning_rate': 9.353510366333385e-05, 'epoch': 0.23, 'timestamp': 1762965468.0286007, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7718, 'grad_norm': 0.25086134672164917, 'learning_rate': 9.260436752631266e-05, 'epoch': 0.24, 'timestamp': 1762965469.4317596, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.773, 'grad_norm': 0.22997000813484192, 'learning_rate': 9.168289282935866e-05, 'epoch': 0.24, 'timestamp': 1762965470.4593678, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7891, 'grad_norm': 0.24879823625087738, 'learning_rate': 9.077058741501852e-05, 'epoch': 0.24, 'timestamp': 1762965471.6667683, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:37:54.992967: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:37:55.003737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965475.016441 1729822 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965475.020223 1729822 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965475.030542 1729822 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965475.030558 1729822 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965475.030560 1729822 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965475.030561 1729822 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:37:55.033748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:37:56 - TensorFlow version 2.19.1 available.
  8%|         | 24000/303576 [15:50<56:06, 83.05it/s]2025-11-12 16:38:04.805064: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:38:04.815663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965484.828087 1730249 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965484.831728 1730249 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965484.842032 1730249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965484.842049 1730249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965484.842050 1730249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965484.842052 1730249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:38:04.845085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:38:06 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A  8%|         | 24000/303576 [15:59<56:06, 83.05it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-24000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-24000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-24000/model.safetensors
  8%|         | 24001/303576 [15:59<59:08:30,  1.31it/s]  8%|         | 24009/303576 [15:59<42:24:26,  1.83it/s]  8%|         | 24017/303576 [15:59<30:26:59,  2.55it/s]  8%|         | 24025/303576 [15:59<21:53:36,  3.55it/s]  8%|         | 24032/303576 [15:59<16:23:21,  4.74it/s]  8%|         | 24039/303576 [16:00<12:13:28,  6.35it/s]  8%|         | 24046/303576 [16:00<9:08:50,  8.49it/s]   8%|         | 24052/303576 [16:00<7:08:11, 10.88it/s]  8%|         | 24058/303576 [16:00<5:34:34, 13.92it/s]  8%|         | 24064/303576 [16:00<4:23:54, 17.65it/s]  8%|         | 24070/303576 [16:00<3:31:42, 22.00it/s]  8%|         | 24076/303576 [16:00<2:53:43, 26.81it/s]  8%|         | 24082/303576 [16:00<2:26:24, 31.82it/s]  8%|         | 24088/303576 [16:00<2:07:01, 36.67it/s]  8%|         | 24094/303576 [16:00<1:52:59, 41.22it/s]  8%|         | 24100/303576 [16:01<1:43:00, 45.22it/s]                                                          8%|         | 24100/303576 [16:01<1:43:00, 45.22it/s]  8%|         | 24106/303576 [16:01<1:36:24, 48.31it/s]  8%|         | 24113/303576 [16:01<1:30:03, 51.72it/s]  8%|         | 24119/303576 [16:01<1:26:47, 53.66it/s]  8%|         | 24126/303576 [16:01<1:24:02, 55.41it/s]  8%|         | 24132/303576 [16:01<1:23:51, 55.54it/s]  8%|         | 24138/303576 [16:01<1:22:41, 56.32it/s]  8%|         | 24144/303576 [16:01<1:22:21, 56.54it/s]  8%|         | 24150/303576 [16:01<1:21:20, 57.26it/s]  8%|         | 24156/303576 [16:02<1:21:36, 57.07it/s]  8%|         | 24162/303576 [16:02<1:22:07, 56.71it/s]  8%|         | 24169/303576 [16:02<1:20:15, 58.02it/s]  8%|         | 24176/303576 [16:02<1:17:01, 60.45it/s]  8%|         | 24183/303576 [16:02<1:14:35, 62.43it/s]  8%|         | 24191/303576 [16:02<1:11:40, 64.96it/s]  8%|         | 24199/303576 [16:02<1:09:36, 66.89it/s]                                                          8%|         | 24200/303576 [16:02<1:09:36, 66.89it/s]  8%|         | 24207/303576 [16:02<1:08:39, 67.82it/s]  8%|         | 24215/303576 [16:02<1:08:11, 68.27it/s]  8%|         | 24223/303576 [16:03<1:07:48, 68.66it/s]  8%|         | 24231/303576 [16:03<1:07:39, 68.81it/s]  8%|         | 24238/303576 [16:03<1:07:34, 68.90it/s]  8%|         | 24245/303576 [16:03<1:08:03, 68.40it/s]  8%|         | 24253/303576 [16:03<1:07:04, 69.41it/s]  8%|         | 24261/303576 [16:03<1:06:22, 70.14it/s]  8%|         | 24269/303576 [16:03<1:05:58, 70.56it/s]  8%|         | 24277/303576 [16:03<1:03:54, 72.85it/s]  8%|         | 24285/303576 [16:03<1:04:25, 72.26it/s]  8%|         | 24293/303576 [16:04<1:04:53, 71.73it/s]                                                          8%|         | 24300/303576 [16:04<1:04:53, 71.73it/s]  8%|         | 24301/303576 [16:04<1:05:12, 71.38it/s]  8%|         | 24309/303576 [16:04<1:05:11, 71.39it/s]  8%|         | 24317/303576 [16:04<1:05:16, 71.30it/s]  8%|         | 24326/303576 [16:04<1:01:02, 76.24it/s]  8%|         | 24336/303576 [16:04<56:37, 82.18it/s]    8%|         | 24345/303576 [16:04<56:04, 82.99it/s]  8%|         | 24354/303576 [16:04<56:11, 82.82it/s]  8%|         | 24363/303576 [16:04<56:14, 82.73it/s]  8%|         | 24374/303576 [16:05<52:15, 89.05it/s]  8%|         | 24385/303576 [16:05<50:09, 92.78it/s]  8%|         | 24396/303576 [16:05<48:11, 96.54it/s]                                                        8%|         | 24400/303576 [16:05<48:11, 96.54it/s]  8%|         | 24406/303576 [16:05<51:11, 90.90it/s]  8%|         | 24416/303576 [16:05<52:39, 88.36it/s]  8%|         | 24425/303576 [16:05<53:40, 86.68it/s]  8%|         | 24434/303576 [16:05<54:48, 84.88it/s]  8%|         | 24443/303576 [16:05<55:13, 84.24it/s]  8%|         | 24452/303576 [16:05<57:04, 81.50it/s]  8%|         | 24461/303576 [16:06<1:00:06, 77.38it/s]  8%|         | 24470/303576 [16:06<58:13, 79.89it/s]    8%|         | 24479/303576 [16:06<58:17, 79.79it/s]  8%|         | 24488/303576 [16:06<58:10, 79.96it/s]  8%|         | 24497/303576 [16:06<58:21, 79.71it/s]                                                        8%|         | 24500/303576 [16:06<58:21, 79.71it/s]  8%|         | 24505/303576 [16:06<59:06, 78.70it/s]  8%|         | 24514/303576 [16:06<58:45, 79.16it/s]  8%|         | 24522/303576 [16:06<58:36, 79.36it/s]  8%|         | 24530/303576 [16:06<58:33, 79.43it/s]  8%|         | 24538/303576 [16:07<58:56, 78.89it/s]  8%|         | 24546/303576 [16:07<59:08, 78.63it/s]  8%|         | 24554/303576 [16:07<1:03:50, 72.85it/s]  8%|         | 24562/303576 [16:07<1:09:06, 67.30it/s]  8%|         | 24569/303576 [16:07<1:13:06, 63.61it/s]  8%|         | 24576/303576 [16:07<1:15:39, 61.46it/s]  8%|         | 24583/303576 [16:07<1:18:14, 59.43it/s]  8%|         | 24590/303576 [16:07<1:16:35, 60.71it/s]  8%|         | 24597/303576 [16:07<1:15:35, 61.51it/s]                                                          8%|         | 24600/303576 [16:08<1:15:35, 61.51it/s]  8%|         | 24605/303576 [16:08<1:12:30, 64.13it/s]  8%|         | 24613/303576 [16:08<1:11:16, 65.23it/s]  8%|         | 24621/303576 [16:08<1:09:57, 66.46it/s]  8%|         | 24629/303576 [16:08<1:09:08, 67.24it/s]  8%|         | 24638/303576 [16:08<1:04:26, 72.15it/s]  8%|         | 24646/303576 [16:08<1:02:42, 74.13it/s]  8%|         | 24654/303576 [16:08<1:03:19, 73.40it/s]  8%|         | 24662/303576 [16:08<1:03:51, 72.80it/s]  8%|         | 24670/303576 [16:08<1:04:11, 72.42it/s]  8%|         | 24678/303576 [16:09<1:03:44, 72.92it/s]  8%|         | 24687/303576 [16:09<1:01:40, 75.37it/s]  8%|         | 24696/303576 [16:09<1:00:19, 77.05it/s]                                                          8%|         | 24700/303576 [16:09<1:00:19, 77.05it/s]  8%|         | 24705/303576 [16:09<59:46, 77.75it/s]    8%|         | 24714/303576 [16:09<58:54, 78.90it/s]  8%|         | 24722/303576 [16:09<58:44, 79.12it/s]  8%|         | 24731/303576 [16:09<57:49, 80.37it/s]  8%|         | 24740/303576 [16:09<57:24, 80.95it/s]  8%|         | 24749/303576 [16:09<57:41, 80.55it/s]  8%|         | 24758/303576 [16:10<57:32, 80.77it/s]  8%|         | 24767/303576 [16:10<57:43, 80.50it/s]  8%|         | 24776/303576 [16:10<57:56, 80.19it/s]  8%|         | 24785/303576 [16:10<57:49, 80.36it/s]  8%|         | 24794/303576 [16:10<57:36, 80.65it/s]                                                        8%|         | 24800/303576 [16:10<57:36, 80.65it/s]  8%|         | 24803/303576 [16:10<58:09, 79.88it/s]  8%|         | 24811/303576 [16:10<58:33, 79.33it/s]  8%|         | 24819/303576 [16:10<58:46, 79.04it/s]  8%|         | 24827/303576 [16:10<59:02, 78.69it/s]  8%|         | 24835/303576 [16:11<59:01, 78.70it/s]  8%|         | 24843/303576 [16:11<59:08, 78.54it/s]  8%|         | 24851/303576 [16:11<59:00, 78.73it/s]  8%|         | 24860/303576 [16:11<58:44, 79.08it/s]  8%|         | 24869/303576 [16:11<58:23, 79.55it/s]  8%|         | 24877/303576 [16:11<59:00, 78.72it/s]  8%|         | 24885/303576 [16:11<59:27, 78.12it/s]  8%|         | 24893/303576 [16:11<59:51, 77.59it/s]                                                        8%|         | 24900/303576 [16:11<59:51, 77.59it/s]  8%|         | 24901/303576 [16:11<59:23, 78.21it/s]  8%|         | 24909/303576 [16:11<59:07, 78.54it/s]  8%|         | 24917/303576 [16:12<59:12, 78.44it/s]  8%|         | 24925/303576 [16:12<59:39, 77.86it/s]  8%|         | 24933/303576 [16:12<59:57, 77.45it/s]  8%|         | 24941/303576 [16:12<59:43, 77.76it/s]  8%|         | 24949/303576 [16:12<59:45, 77.70it/s]  8%|         | 24957/303576 [16:12<1:00:07, 77.23it/s]  8%|         | 24965/303576 [16:12<1:00:29, 76.77it/s]  8%|         | 24973/303576 [16:12<1:00:38, 76.57it/s]  8%|         | 24982/303576 [16:12<59:35, 77.92it/s]    8%|         | 24991/303576 [16:13<59:08, 78.52it/s]  8%|         | 24999/303576 [16:13<58:49, 78.93it/s]                                                        8%|         | 25000/303576 [16:13<58:49, 78.93it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7395371794700623, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.0864, 'eval_samples_per_second': 10.718, 'eval_steps_per_second': 0.095, 'epoch': 0.24, 'timestamp': 1762965492.7537036, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7783, 'grad_norm': 0.2257111370563507, 'learning_rate': 8.986736004286652e-05, 'epoch': 0.24, 'timestamp': 1762965494.525385, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7706, 'grad_norm': 0.2352501004934311, 'learning_rate': 8.897312038037944e-05, 'epoch': 0.24, 'timestamp': 1762965496.1577024, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7994, 'grad_norm': 0.28930214047431946, 'learning_rate': 8.808777899390253e-05, 'epoch': 0.24, 'timestamp': 1762965497.571215, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7706, 'grad_norm': 0.2528441846370697, 'learning_rate': 8.721124733970489e-05, 'epoch': 0.24, 'timestamp': 1762965498.7102847, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7717, 'grad_norm': 0.195548877120018, 'learning_rate': 8.634343775512445e-05, 'epoch': 0.24, 'timestamp': 1762965499.96376, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7615, 'grad_norm': 0.20277662575244904, 'learning_rate': 8.548426344980056e-05, 'epoch': 0.24, 'timestamp': 1762965501.458282, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7743, 'grad_norm': 0.19941243529319763, 'learning_rate': 8.463363849699399e-05, 'epoch': 0.24, 'timestamp': 1762965502.8031802, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7605, 'grad_norm': 0.21150793135166168, 'learning_rate': 8.37914778249935e-05, 'epoch': 0.25, 'timestamp': 1762965504.0426753, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7946, 'grad_norm': 0.2109992653131485, 'learning_rate': 8.296599380798841e-05, 'epoch': 0.25, 'timestamp': 1762965505.3197074, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7826, 'grad_norm': 0.1975754052400589, 'learning_rate': 8.21404273034714e-05, 'epoch': 0.25, 'timestamp': 1762965506.6010761, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:38:30.486650: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:38:30.497086: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965510.509444 1731344 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965510.513209 1731344 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965510.523470 1731344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965510.523484 1731344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965510.523487 1731344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965510.523489 1731344 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:38:30.526594: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:38:32 - TensorFlow version 2.19.1 available.
2025-11-12 16:38:40.945044: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:38:40.955927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965520.968872 1731903 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965520.972738 1731903 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965520.983242 1731903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965520.983255 1731903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965520.983257 1731903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965520.983259 1731903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:38:40.986563: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:38:42 - TensorFlow version 2.19.1 available.
  8%|         | 25000/303576 [16:30<58:49, 78.93it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A  8%|         | 25000/303576 [16:35<58:49, 78.93it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A  8%|         | 25001/303576 [16:35<81:44:38,  1.06s/it]  8%|         | 25006/303576 [16:35<61:45:02,  1.25it/s]  8%|         | 25014/303576 [16:35<39:45:47,  1.95it/s]  8%|         | 25021/303576 [16:35<27:43:19,  2.79it/s]  8%|         | 25028/303576 [16:36<19:32:04,  3.96it/s]  8%|         | 25035/303576 [16:36<13:55:32,  5.56it/s]  8%|         | 25042/303576 [16:36<10:03:14,  7.70it/s]  8%|         | 25049/303576 [16:36<7:21:51, 10.51it/s]   8%|         | 25056/303576 [16:36<5:30:12, 14.06it/s]  8%|         | 25063/303576 [16:36<4:11:53, 18.43it/s]  8%|         | 25070/303576 [16:36<3:16:39, 23.60it/s]  8%|         | 25077/303576 [16:36<2:37:55, 29.39it/s]  8%|         | 25084/303576 [16:36<2:10:45, 35.50it/s]  8%|         | 25091/303576 [16:37<1:52:56, 41.09it/s]  8%|         | 25098/303576 [16:37<1:40:17, 46.28it/s]                                                          8%|         | 25100/303576 [16:37<1:40:17, 46.28it/s]  8%|         | 25105/303576 [16:37<1:30:54, 51.06it/s]  8%|         | 25112/303576 [16:37<1:24:07, 55.17it/s]  8%|         | 25119/303576 [16:37<1:18:59, 58.75it/s]  8%|         | 25128/303576 [16:37<1:11:20, 65.04it/s]  8%|         | 25136/303576 [16:37<1:10:37, 65.71it/s]  8%|         | 25145/303576 [16:37<1:06:05, 70.22it/s]  8%|         | 25154/303576 [16:37<1:03:00, 73.65it/s]  8%|         | 25163/303576 [16:37<1:01:28, 75.49it/s]  8%|         | 25171/303576 [16:38<1:00:38, 76.51it/s]  8%|         | 25180/303576 [16:38<58:19, 79.55it/s]    8%|         | 25189/303576 [16:38<58:45, 78.97it/s]  8%|         | 25197/303576 [16:38<1:00:23, 76.82it/s]                                                          8%|         | 25200/303576 [16:38<1:00:23, 76.82it/s]  8%|         | 25205/303576 [16:38<1:01:42, 75.19it/s]  8%|         | 25213/303576 [16:38<1:02:38, 74.06it/s]  8%|         | 25221/303576 [16:38<1:03:28, 73.08it/s]  8%|         | 25229/303576 [16:38<1:04:29, 71.93it/s]  8%|         | 25237/303576 [16:38<1:04:55, 71.45it/s]  8%|         | 25245/303576 [16:39<1:04:17, 72.16it/s]  8%|         | 25254/303576 [16:39<1:02:10, 74.61it/s]  8%|         | 25263/303576 [16:39<59:30, 77.96it/s]    8%|         | 25272/303576 [16:39<58:31, 79.26it/s]  8%|         | 25280/303576 [16:39<59:01, 78.59it/s]  8%|         | 25288/303576 [16:39<59:34, 77.85it/s]  8%|         | 25296/303576 [16:39<1:00:11, 77.05it/s]                                                          8%|         | 25300/303576 [16:39<1:00:11, 77.05it/s]  8%|         | 25304/303576 [16:39<1:03:57, 72.51it/s]  8%|         | 25312/303576 [16:40<1:09:32, 66.70it/s]  8%|         | 25319/303576 [16:40<1:14:18, 62.42it/s]  8%|         | 25326/303576 [16:40<1:17:04, 60.17it/s]  8%|         | 25333/303576 [16:40<1:16:50, 60.34it/s]  8%|         | 25340/303576 [16:40<1:17:49, 59.59it/s]  8%|         | 25346/303576 [16:40<1:18:56, 58.74it/s]  8%|         | 25353/303576 [16:40<1:17:52, 59.55it/s]  8%|         | 25359/303576 [16:40<1:17:44, 59.65it/s]  8%|         | 25366/303576 [16:40<1:17:50, 59.57it/s]  8%|         | 25372/303576 [16:41<1:17:59, 59.45it/s]  8%|         | 25378/303576 [16:41<1:18:29, 59.08it/s]  8%|         | 25384/303576 [16:41<1:18:41, 58.92it/s]  8%|         | 25390/303576 [16:41<1:19:25, 58.37it/s]  8%|         | 25399/303576 [16:41<1:10:56, 65.35it/s]                                                          8%|         | 25400/303576 [16:41<1:10:56, 65.35it/s]  8%|         | 25408/303576 [16:41<1:05:12, 71.10it/s]  8%|         | 25417/303576 [16:41<1:01:54, 74.89it/s]  8%|         | 25426/303576 [16:41<59:23, 78.04it/s]    8%|         | 25435/303576 [16:41<57:45, 80.26it/s]  8%|         | 25445/303576 [16:41<55:06, 84.12it/s]  8%|         | 25454/303576 [16:42<54:16, 85.41it/s]  8%|         | 25463/303576 [16:42<53:40, 86.36it/s]  8%|         | 25472/303576 [16:42<53:24, 86.79it/s]  8%|         | 25481/303576 [16:42<53:16, 87.01it/s]  8%|         | 25490/303576 [16:42<54:08, 85.61it/s]  8%|         | 25499/303576 [16:42<57:08, 81.12it/s]                                                        8%|         | 25500/303576 [16:42<57:08, 81.12it/s]  8%|         | 25508/303576 [16:42<57:40, 80.36it/s]  8%|         | 25517/303576 [16:42<57:18, 80.87it/s]  8%|         | 25526/303576 [16:42<57:12, 81.01it/s]  8%|         | 25535/303576 [16:43<56:52, 81.48it/s]  8%|         | 25544/303576 [16:43<57:01, 81.27it/s]  8%|         | 25553/303576 [16:43<56:59, 81.30it/s]  8%|         | 25562/303576 [16:43<56:31, 81.97it/s]  8%|         | 25572/303576 [16:43<54:40, 84.75it/s]  8%|         | 25583/303576 [16:43<51:06, 90.65it/s]  8%|         | 25594/303576 [16:43<49:01, 94.52it/s]                                                        8%|         | 25600/303576 [16:43<49:01, 94.52it/s]  8%|         | 25605/303576 [16:43<47:31, 97.50it/s]  8%|         | 25616/303576 [16:43<46:40, 99.27it/s]  8%|         | 25627/303576 [16:44<46:21, 99.93it/s]  8%|         | 25638/303576 [16:44<48:39, 95.19it/s]  8%|         | 25648/303576 [16:44<49:57, 92.73it/s]  8%|         | 25658/303576 [16:44<52:02, 89.00it/s]  8%|         | 25667/303576 [16:44<53:17, 86.92it/s]  8%|         | 25676/303576 [16:44<54:55, 84.32it/s]  8%|         | 25685/303576 [16:44<55:32, 83.39it/s]  8%|         | 25694/303576 [16:44<56:38, 81.77it/s]                                                        8%|         | 25700/303576 [16:44<56:38, 81.77it/s]  8%|         | 25703/303576 [16:44<56:38, 81.76it/s]  8%|         | 25712/303576 [16:45<56:37, 81.77it/s]  8%|         | 25721/303576 [16:45<56:34, 81.86it/s]  8%|         | 25730/303576 [16:45<56:21, 82.16it/s]  8%|         | 25739/303576 [16:45<55:58, 82.72it/s]  8%|         | 25748/303576 [16:45<57:33, 80.44it/s]  8%|         | 25757/303576 [16:45<58:44, 78.84it/s]  8%|         | 25765/303576 [16:45<58:59, 78.50it/s]  8%|         | 25773/303576 [16:45<59:30, 77.81it/s]  8%|         | 25781/303576 [16:45<1:00:04, 77.08it/s]  8%|         | 25789/303576 [16:46<1:00:13, 76.88it/s]  8%|         | 25797/303576 [16:46<1:00:11, 76.91it/s]                                                          8%|         | 25800/303576 [16:46<1:00:11, 76.91it/s]  9%|         | 25805/303576 [16:46<1:00:43, 76.23it/s]  9%|         | 25813/303576 [16:46<1:00:13, 76.86it/s]  9%|         | 25822/303576 [16:46<59:14, 78.14it/s]    9%|         | 25830/303576 [16:46<59:23, 77.94it/s]  9%|         | 25838/303576 [16:46<59:35, 77.67it/s]  9%|         | 25846/303576 [16:46<59:43, 77.51it/s]  9%|         | 25854/303576 [16:46<59:53, 77.29it/s]  9%|         | 25862/303576 [16:47<1:00:00, 77.13it/s]  9%|         | 25870/303576 [16:47<1:00:11, 76.90it/s]  9%|         | 25878/303576 [16:47<1:00:08, 76.95it/s]  9%|         | 25886/303576 [16:47<1:00:05, 77.02it/s]  9%|         | 25894/303576 [16:47<1:00:22, 76.65it/s]                                                          9%|         | 25900/303576 [16:47<1:00:22, 76.65it/s]  9%|         | 25902/303576 [16:47<1:00:20, 76.69it/s]  9%|         | 25910/303576 [16:47<1:00:17, 76.76it/s]  9%|         | 25918/303576 [16:47<1:00:14, 76.83it/s]  9%|         | 25926/303576 [16:47<1:00:03, 77.04it/s]  9%|         | 25934/303576 [16:47<1:00:14, 76.82it/s]  9%|         | 25942/303576 [16:48<1:00:22, 76.64it/s]  9%|         | 25950/303576 [16:48<1:00:17, 76.74it/s]  9%|         | 25958/303576 [16:48<1:00:13, 76.83it/s]  9%|         | 25966/303576 [16:48<1:00:37, 76.31it/s]  9%|         | 25974/303576 [16:48<1:01:59, 74.63it/s]  9%|         | 25982/303576 [16:48<1:03:08, 73.27it/s]  9%|         | 25990/303576 [16:48<1:03:55, 72.38it/s]  9%|         | 25998/303576 [16:48<1:04:57, 71.22it/s]                                                          9%|         | 26000/303576 [16:48<1:04:57, 71.22it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7375516891479492, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4406, 'eval_samples_per_second': 10.071, 'eval_steps_per_second': 0.089, 'epoch': 0.25, 'timestamp': 1762965529.0420794, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8059, 'grad_norm': 0.2249760627746582, 'learning_rate': 8.132307573162851e-05, 'epoch': 0.25, 'timestamp': 1762965530.585613, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7763, 'grad_norm': 0.2494094967842102, 'learning_rate': 8.05138573484472e-05, 'epoch': 0.25, 'timestamp': 1762965531.8981538, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.766, 'grad_norm': 0.2500236928462982, 'learning_rate': 7.971269122332151e-05, 'epoch': 0.25, 'timestamp': 1762965533.2308311, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7671, 'grad_norm': 0.246943399310112, 'learning_rate': 7.891949723095897e-05, 'epoch': 0.25, 'timestamp': 1762965534.912236, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7662, 'grad_norm': 0.2447679489850998, 'learning_rate': 7.813419604336651e-05, 'epoch': 0.25, 'timestamp': 1762965536.0897267, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7761, 'grad_norm': 0.21497483551502228, 'learning_rate': 7.735670912191703e-05, 'epoch': 0.25, 'timestamp': 1762965537.2245479, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7924, 'grad_norm': 0.23056864738464355, 'learning_rate': 7.658695870949484e-05, 'epoch': 0.25, 'timestamp': 1762965538.3779192, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7754, 'grad_norm': 0.2669678330421448, 'learning_rate': 7.582486782271882e-05, 'epoch': 0.25, 'timestamp': 1762965539.6529648, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.779, 'grad_norm': 0.2465738207101822, 'learning_rate': 7.507036024424346e-05, 'epoch': 0.26, 'timestamp': 1762965540.9471636, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7844, 'grad_norm': 0.1998242288827896, 'learning_rate': 7.432336051513631e-05, 'epoch': 0.26, 'timestamp': 1762965542.2952847, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:39:05.680037: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:39:05.690727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965545.703411 1732998 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965545.707130 1732998 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965545.717579 1732998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965545.717598 1732998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965545.717600 1732998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965545.717602 1732998 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:39:05.720646: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:39:07 - TensorFlow version 2.19.1 available.
  9%|         | 26000/303576 [17:00<1:04:57, 71.22it/s]2025-11-12 16:39:15.333071: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:39:15.343573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965555.356201 1733420 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965555.359983 1733420 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965555.370273 1733420 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965555.370287 1733420 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965555.370289 1733420 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965555.370291 1733420 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:39:15.373416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:39:17 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                        
                                             [A  9%|         | 26000/303576 [17:09<1:04:57, 71.22it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-26000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-26000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-26000/model.safetensors
  9%|         | 26001/303576 [17:09<75:38:06,  1.02it/s]  9%|         | 26008/303576 [17:09<52:08:01,  1.48it/s]  9%|         | 26016/303576 [17:10<34:46:32,  2.22it/s]  9%|         | 26025/303576 [17:10<22:48:57,  3.38it/s]  9%|         | 26035/303576 [17:10<14:54:50,  5.17it/s]  9%|         | 26043/303576 [17:10<10:51:18,  7.10it/s]  9%|         | 26052/303576 [17:10<7:41:58, 10.01it/s]   9%|         | 26060/303576 [17:10<5:45:44, 13.38it/s]  9%|         | 26069/303576 [17:10<4:13:45, 18.23it/s]  9%|         | 26078/303576 [17:10<3:12:19, 24.05it/s]  9%|         | 26087/303576 [17:10<2:30:25, 30.75it/s]  9%|         | 26096/303576 [17:11<2:01:58, 37.92it/s]                                                          9%|         | 26100/303576 [17:11<2:01:58, 37.92it/s]  9%|         | 26105/303576 [17:11<1:41:47, 45.43it/s]  9%|         | 26114/303576 [17:11<1:28:03, 52.51it/s]  9%|         | 26124/303576 [17:11<1:16:15, 60.64it/s]  9%|         | 26134/303576 [17:11<1:08:49, 67.18it/s]  9%|         | 26143/303576 [17:11<1:04:48, 71.35it/s]  9%|         | 26152/303576 [17:11<1:02:23, 74.11it/s]  9%|         | 26161/303576 [17:11<1:00:13, 76.78it/s]  9%|         | 26170/303576 [17:11<1:00:18, 76.67it/s]  9%|         | 26179/303576 [17:12<59:58, 77.10it/s]    9%|         | 26188/303576 [17:12<59:31, 77.68it/s]  9%|         | 26197/303576 [17:12<59:01, 78.33it/s]                                                        9%|         | 26200/303576 [17:12<59:01, 78.33it/s]  9%|         | 26206/303576 [17:12<57:50, 79.92it/s]  9%|         | 26215/303576 [17:12<57:46, 80.00it/s]  9%|         | 26224/303576 [17:12<57:46, 80.02it/s]  9%|         | 26233/303576 [17:12<57:36, 80.25it/s]  9%|         | 26242/303576 [17:12<57:43, 80.07it/s]  9%|         | 26251/303576 [17:12<57:12, 80.80it/s]  9%|         | 26260/303576 [17:13<57:55, 79.79it/s]  9%|         | 26269/303576 [17:13<57:47, 79.98it/s]  9%|         | 26278/303576 [17:13<57:57, 79.75it/s]  9%|         | 26286/303576 [17:13<58:05, 79.56it/s]  9%|         | 26294/303576 [17:13<58:01, 79.64it/s]                                                        9%|         | 26300/303576 [17:13<58:01, 79.64it/s]  9%|         | 26302/303576 [17:13<58:00, 79.66it/s]  9%|         | 26311/303576 [17:13<57:43, 80.04it/s]  9%|         | 26320/303576 [17:13<57:31, 80.33it/s]  9%|         | 26329/303576 [17:13<57:01, 81.04it/s]  9%|         | 26338/303576 [17:13<57:18, 80.62it/s]  9%|         | 26347/303576 [17:14<57:04, 80.95it/s]  9%|         | 26356/303576 [17:14<56:38, 81.56it/s]  9%|         | 26365/303576 [17:14<56:24, 81.91it/s]  9%|         | 26374/303576 [17:14<55:23, 83.40it/s]  9%|         | 26384/303576 [17:14<52:32, 87.91it/s]  9%|         | 26394/303576 [17:14<50:40, 91.17it/s]                                                        9%|         | 26400/303576 [17:14<50:40, 91.17it/s]  9%|         | 26405/303576 [17:14<48:10, 95.91it/s]  9%|         | 26416/303576 [17:14<47:01, 98.25it/s]  9%|         | 26427/303576 [17:14<45:40, 101.14it/s]  9%|         | 26439/303576 [17:15<44:21, 104.14it/s]  9%|         | 26451/303576 [17:15<43:30, 106.17it/s]  9%|         | 26462/303576 [17:15<44:14, 104.38it/s]  9%|         | 26473/303576 [17:15<48:48, 94.63it/s]   9%|         | 26483/303576 [17:15<51:19, 89.97it/s]  9%|         | 26493/303576 [17:15<53:36, 86.13it/s]                                                        9%|         | 26500/303576 [17:15<53:36, 86.13it/s]  9%|         | 26502/303576 [17:15<54:28, 84.76it/s]  9%|         | 26511/303576 [17:15<56:03, 82.37it/s]  9%|         | 26520/303576 [17:16<56:48, 81.28it/s]  9%|         | 26529/303576 [17:16<57:22, 80.48it/s]  9%|         | 26538/303576 [17:16<58:37, 78.77it/s]  9%|         | 26546/303576 [17:16<59:33, 77.52it/s]  9%|         | 26555/303576 [17:16<57:38, 80.10it/s]  9%|         | 26564/303576 [17:16<55:53, 82.60it/s]  9%|         | 26573/303576 [17:16<55:33, 83.09it/s]  9%|         | 26582/303576 [17:16<55:49, 82.69it/s]  9%|         | 26591/303576 [17:16<55:32, 83.13it/s]  9%|         | 26600/303576 [17:16<55:18, 83.47it/s]                                                        9%|         | 26600/303576 [17:16<55:18, 83.47it/s]  9%|         | 26609/303576 [17:17<55:14, 83.56it/s]  9%|         | 26618/303576 [17:17<55:06, 83.76it/s]  9%|         | 26627/303576 [17:17<54:54, 84.06it/s]  9%|         | 26636/303576 [17:17<54:52, 84.11it/s]  9%|         | 26645/303576 [17:17<54:51, 84.13it/s]  9%|         | 26654/303576 [17:17<53:50, 85.71it/s]  9%|         | 26663/303576 [17:17<54:34, 84.57it/s]  9%|         | 26672/303576 [17:17<54:44, 84.30it/s]  9%|         | 26681/303576 [17:17<55:20, 83.38it/s]  9%|         | 26690/303576 [17:18<55:27, 83.21it/s]  9%|         | 26699/303576 [17:18<55:29, 83.16it/s]                                                        9%|         | 26700/303576 [17:18<55:29, 83.16it/s]  9%|         | 26708/303576 [17:18<55:32, 83.08it/s]  9%|         | 26717/303576 [17:18<56:21, 81.87it/s]  9%|         | 26726/303576 [17:18<57:15, 80.57it/s]  9%|         | 26735/303576 [17:18<57:45, 79.87it/s]  9%|         | 26744/303576 [17:18<57:21, 80.45it/s]  9%|         | 26753/303576 [17:18<56:42, 81.35it/s]  9%|         | 26762/303576 [17:18<55:48, 82.67it/s]  9%|         | 26773/303576 [17:19<52:33, 87.79it/s]  9%|         | 26782/303576 [17:19<56:23, 81.82it/s]  9%|         | 26791/303576 [17:19<1:00:12, 76.62it/s]  9%|         | 26799/303576 [17:19<1:02:58, 73.26it/s]                                                          9%|         | 26800/303576 [17:19<1:02:57, 73.26it/s]  9%|         | 26807/303576 [17:19<1:05:00, 70.96it/s]  9%|         | 26815/303576 [17:19<1:06:27, 69.40it/s]  9%|         | 26822/303576 [17:19<1:07:39, 68.18it/s]  9%|         | 26829/303576 [17:19<1:07:59, 67.84it/s]  9%|         | 26836/303576 [17:19<1:08:30, 67.32it/s]  9%|         | 26844/303576 [17:20<1:05:40, 70.22it/s]  9%|         | 26853/303576 [17:20<1:02:15, 74.09it/s]  9%|         | 26862/303576 [17:20<1:00:19, 76.45it/s]  9%|         | 26871/303576 [17:20<59:31, 77.47it/s]    9%|         | 26879/303576 [17:20<59:01, 78.12it/s]  9%|         | 26889/303576 [17:20<55:58, 82.37it/s]  9%|         | 26899/303576 [17:20<52:53, 87.18it/s]                                                        9%|         | 26900/303576 [17:20<52:53, 87.18it/s]  9%|         | 26909/303576 [17:20<51:02, 90.33it/s]  9%|         | 26919/303576 [17:20<49:40, 92.83it/s]  9%|         | 26929/303576 [17:21<48:50, 94.42it/s]  9%|         | 26939/303576 [17:21<48:01, 95.99it/s]  9%|         | 26949/303576 [17:21<47:40, 96.71it/s]  9%|         | 26959/303576 [17:21<47:19, 97.41it/s]  9%|         | 26969/303576 [17:21<47:01, 98.03it/s]  9%|         | 26979/303576 [17:21<48:58, 94.13it/s]  9%|         | 26989/303576 [17:21<51:06, 90.19it/s]  9%|         | 26999/303576 [17:21<52:43, 87.43it/s]                                                        9%|         | 27000/303576 [17:21<52:43, 87.43it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7389926910400391, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9118, 'eval_samples_per_second': 10.807, 'eval_steps_per_second': 0.096, 'epoch': 0.26, 'timestamp': 1762965563.207594, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.792, 'grad_norm': 0.21563249826431274, 'learning_rate': 7.35837939273311e-05, 'epoch': 0.26, 'timestamp': 1762965564.5021064, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7894, 'grad_norm': 0.22600433230400085, 'learning_rate': 7.285158651615636e-05, 'epoch': 0.26, 'timestamp': 1762965565.712147, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.762, 'grad_norm': 0.24362410604953766, 'learning_rate': 7.212666505293788e-05, 'epoch': 0.26, 'timestamp': 1762965566.964378, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7818, 'grad_norm': 0.23309345543384552, 'learning_rate': 7.140895703767521e-05, 'epoch': 0.26, 'timestamp': 1762965568.1232746, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7661, 'grad_norm': 0.22293531894683838, 'learning_rate': 7.069839069179088e-05, 'epoch': 0.26, 'timestamp': 1762965569.184903, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7761, 'grad_norm': 0.2010411024093628, 'learning_rate': 6.999489495095181e-05, 'epoch': 0.26, 'timestamp': 1762965570.4196715, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7762, 'grad_norm': 0.24935540556907654, 'learning_rate': 6.929839945796185e-05, 'epoch': 0.26, 'timestamp': 1762965571.6106968, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7822, 'grad_norm': 0.2999800443649292, 'learning_rate': 6.86088345557257e-05, 'epoch': 0.26, 'timestamp': 1762965572.887646, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7679, 'grad_norm': 0.2662942409515381, 'learning_rate': 6.7926131280282e-05, 'epoch': 0.27, 'timestamp': 1762965574.1876414, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7665, 'grad_norm': 0.21391817927360535, 'learning_rate': 6.725022135390647e-05, 'epoch': 0.27, 'timestamp': 1762965575.2576542, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:39:39.158818: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:39:39.169437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965579.181982 1734515 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965579.185725 1734515 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965579.196038 1734515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965579.196054 1734515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965579.196056 1734515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965579.196058 1734515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:39:39.199206: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:39:41 - TensorFlow version 2.19.1 available.
2025-11-12 16:39:49.717129: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:39:49.727697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965589.740473 1735069 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965589.744255 1735069 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965589.754662 1735069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965589.754684 1735069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965589.754686 1735069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965589.754687 1735069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:39:49.757871: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:39:51 - TensorFlow version 2.19.1 available.
  9%|         | 27000/303576 [17:40<52:43, 87.43it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A  9%|         | 27000/303576 [17:44<52:43, 87.43it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A  9%|         | 27001/303576 [17:44<69:40:19,  1.10it/s]  9%|         | 27007/303576 [17:44<52:24:05,  1.47it/s]  9%|         | 27015/303576 [17:44<35:49:34,  2.14it/s]  9%|         | 27022/303576 [17:44<25:49:10,  2.98it/s]  9%|         | 27029/303576 [17:44<18:39:36,  4.12it/s]  9%|         | 27036/303576 [17:45<13:34:09,  5.66it/s]  9%|         | 27043/303576 [17:45<9:55:56,  7.73it/s]   9%|         | 27050/303576 [17:45<7:23:25, 10.39it/s]  9%|         | 27056/303576 [17:45<5:47:18, 13.27it/s]  9%|         | 27062/303576 [17:45<4:33:17, 16.86it/s]  9%|         | 27068/303576 [17:45<3:38:13, 21.12it/s]  9%|         | 27074/303576 [17:45<2:58:41, 25.79it/s]  9%|         | 27080/303576 [17:45<2:29:42, 30.78it/s]  9%|         | 27086/303576 [17:45<2:08:41, 35.81it/s]  9%|         | 27092/303576 [17:46<1:53:55, 40.45it/s]  9%|         | 27098/303576 [17:46<1:44:20, 44.16it/s]                                                          9%|         | 27100/303576 [17:46<1:44:20, 44.16it/s]  9%|         | 27104/303576 [17:46<1:36:58, 47.52it/s]  9%|         | 27110/303576 [17:46<1:32:22, 49.88it/s]  9%|         | 27116/303576 [17:46<1:29:23, 51.54it/s]  9%|         | 27122/303576 [17:46<1:28:07, 52.28it/s]  9%|         | 27128/303576 [17:46<1:26:26, 53.30it/s]  9%|         | 27134/303576 [17:46<1:25:08, 54.11it/s]  9%|         | 27140/303576 [17:46<1:23:47, 54.99it/s]  9%|         | 27146/303576 [17:47<1:22:58, 55.52it/s]  9%|         | 27152/303576 [17:47<1:22:07, 56.10it/s]  9%|         | 27158/303576 [17:47<1:26:52, 53.03it/s]  9%|         | 27164/303576 [17:47<1:30:19, 51.00it/s]  9%|         | 27170/303576 [17:47<1:28:11, 52.23it/s]  9%|         | 27177/303576 [17:47<1:24:18, 54.64it/s]  9%|         | 27183/303576 [17:47<1:22:20, 55.95it/s]  9%|         | 27189/303576 [17:47<1:20:45, 57.04it/s]  9%|         | 27195/303576 [17:47<1:19:42, 57.79it/s]                                                          9%|         | 27200/303576 [17:47<1:19:42, 57.79it/s]  9%|         | 27201/303576 [17:48<1:19:32, 57.92it/s]  9%|         | 27207/303576 [17:48<1:19:25, 57.99it/s]  9%|         | 27213/303576 [17:48<1:20:28, 57.24it/s]  9%|         | 27219/303576 [17:48<1:19:44, 57.76it/s]  9%|         | 27225/303576 [17:48<1:19:22, 58.03it/s]  9%|         | 27231/303576 [17:48<1:19:12, 58.14it/s]  9%|         | 27237/303576 [17:48<1:18:53, 58.38it/s]  9%|         | 27244/303576 [17:48<1:15:15, 61.20it/s]  9%|         | 27252/303576 [17:48<1:11:30, 64.40it/s]  9%|         | 27260/303576 [17:48<1:09:20, 66.41it/s]  9%|         | 27268/303576 [17:49<1:07:53, 67.83it/s]  9%|         | 27276/303576 [17:49<1:05:53, 69.88it/s]  9%|         | 27284/303576 [17:49<1:03:40, 72.31it/s]  9%|         | 27292/303576 [17:49<1:02:36, 73.55it/s]  9%|         | 27300/303576 [17:49<1:01:28, 74.90it/s]                                                          9%|         | 27300/303576 [17:49<1:01:28, 74.90it/s]  9%|         | 27308/303576 [17:49<1:00:34, 76.02it/s]  9%|         | 27317/303576 [17:49<59:59, 76.74it/s]    9%|         | 27325/303576 [17:49<59:29, 77.39it/s]  9%|         | 27333/303576 [17:49<59:39, 77.18it/s]  9%|         | 27341/303576 [17:50<59:46, 77.02it/s]  9%|         | 27349/303576 [17:50<1:00:02, 76.68it/s]  9%|         | 27357/303576 [17:50<1:00:13, 76.44it/s]  9%|         | 27365/303576 [17:50<1:00:17, 76.35it/s]  9%|         | 27373/303576 [17:50<1:00:31, 76.05it/s]  9%|         | 27381/303576 [17:50<1:00:37, 75.93it/s]  9%|         | 27389/303576 [17:50<1:00:40, 75.87it/s]  9%|         | 27397/303576 [17:50<1:00:08, 76.53it/s]                                                          9%|         | 27400/303576 [17:50<1:00:08, 76.53it/s]  9%|         | 27408/303576 [17:50<54:32, 84.40it/s]    9%|         | 27419/303576 [17:50<50:45, 90.68it/s]  9%|         | 27430/303576 [17:51<48:35, 94.73it/s]  9%|         | 27441/303576 [17:51<47:09, 97.60it/s]  9%|         | 27452/303576 [17:51<46:05, 99.85it/s]  9%|         | 27462/303576 [17:51<47:39, 96.55it/s]  9%|         | 27472/303576 [17:51<50:06, 91.85it/s]  9%|         | 27482/303576 [17:51<52:10, 88.19it/s]  9%|         | 27491/303576 [17:51<53:23, 86.19it/s]  9%|         | 27500/303576 [17:51<54:28, 84.46it/s]                                                        9%|         | 27500/303576 [17:51<54:28, 84.46it/s]  9%|         | 27509/303576 [17:51<55:24, 83.05it/s]  9%|         | 27518/303576 [17:52<55:46, 82.50it/s]  9%|         | 27527/303576 [17:52<56:18, 81.71it/s]  9%|         | 27537/303576 [17:52<54:26, 84.51it/s]  9%|         | 27546/303576 [17:52<53:28, 86.02it/s]  9%|         | 27555/303576 [17:52<54:22, 84.60it/s]  9%|         | 27564/303576 [17:52<55:48, 82.43it/s]  9%|         | 27573/303576 [17:52<55:41, 82.59it/s]  9%|         | 27582/303576 [17:52<54:39, 84.17it/s]  9%|         | 27591/303576 [17:54<4:41:28, 16.34it/s]  9%|         | 27598/303576 [17:54<3:51:35, 19.86it/s]                                                          9%|         | 27600/303576 [17:54<3:51:35, 19.86it/s]  9%|         | 27604/303576 [17:54<3:16:09, 23.45it/s]  9%|         | 27610/303576 [17:54<2:47:23, 27.48it/s]  9%|         | 27618/303576 [17:54<2:13:26, 34.47it/s]  9%|         | 27626/303576 [17:54<1:51:30, 41.24it/s]  9%|         | 27633/303576 [17:56<6:45:36, 11.34it/s]  9%|         | 27640/303576 [17:56<5:09:38, 14.85it/s]  9%|         | 27648/303576 [17:56<3:51:36, 19.86it/s]  9%|         | 27655/303576 [17:57<3:04:23, 24.94it/s]  9%|         | 27662/303576 [17:57<2:31:07, 30.43it/s]  9%|         | 27670/303576 [17:57<2:03:16, 37.30it/s]  9%|         | 27678/303576 [17:57<1:44:59, 43.80it/s]  9%|         | 27686/303576 [17:57<1:32:36, 49.65it/s]  9%|         | 27694/303576 [17:57<1:24:11, 54.61it/s]                                                          9%|         | 27700/303576 [17:57<1:24:11, 54.61it/s]  9%|         | 27702/303576 [17:57<1:18:25, 58.63it/s]  9%|         | 27710/303576 [17:57<1:14:15, 61.92it/s]  9%|         | 27718/303576 [17:57<1:11:28, 64.33it/s]  9%|         | 27726/303576 [17:58<1:09:31, 66.12it/s]  9%|         | 27734/303576 [17:58<1:08:11, 67.42it/s]  9%|         | 27742/303576 [17:58<1:07:07, 68.49it/s]  9%|         | 27750/303576 [17:58<1:06:45, 68.86it/s]  9%|         | 27758/303576 [17:58<1:06:11, 69.44it/s]  9%|         | 27766/303576 [17:58<1:05:51, 69.81it/s]  9%|         | 27774/303576 [17:58<1:05:37, 70.04it/s]  9%|         | 27782/303576 [17:58<1:05:28, 70.21it/s]  9%|         | 27790/303576 [17:58<1:05:08, 70.57it/s]  9%|         | 27798/303576 [17:59<1:05:02, 70.67it/s]                                                          9%|         | 27800/303576 [17:59<1:05:02, 70.67it/s]  9%|         | 27806/303576 [17:59<1:05:27, 70.21it/s]  9%|         | 27814/303576 [17:59<1:05:49, 69.81it/s]  9%|         | 27822/303576 [17:59<1:05:12, 70.48it/s]  9%|         | 27830/303576 [17:59<1:05:05, 70.61it/s]  9%|         | 27838/303576 [17:59<1:04:54, 70.81it/s]  9%|         | 27846/303576 [17:59<1:04:42, 71.02it/s]  9%|         | 27854/303576 [17:59<1:04:29, 71.26it/s]  9%|         | 27862/303576 [17:59<1:04:23, 71.36it/s]  9%|         | 27870/303576 [18:00<1:04:18, 71.46it/s]  9%|         | 27878/303576 [18:00<1:04:12, 71.56it/s]  9%|         | 27886/303576 [18:00<1:05:17, 70.37it/s]  9%|         | 27894/303576 [18:00<1:06:15, 69.35it/s]                                                          9%|         | 27900/303576 [18:00<1:06:15, 69.35it/s]  9%|         | 27901/303576 [18:00<1:06:30, 69.07it/s]  9%|         | 27908/303576 [18:00<1:07:25, 68.15it/s]  9%|         | 27915/303576 [18:00<1:07:00, 68.57it/s]  9%|         | 27922/303576 [18:00<1:08:00, 67.55it/s]  9%|         | 27929/303576 [18:00<1:07:42, 67.86it/s]  9%|         | 27936/303576 [18:01<1:07:30, 68.05it/s]  9%|         | 27944/303576 [18:01<1:06:08, 69.45it/s]  9%|         | 27952/303576 [18:01<1:05:40, 69.95it/s]  9%|         | 27960/303576 [18:01<1:05:04, 70.59it/s]  9%|         | 27968/303576 [18:01<1:04:54, 70.77it/s]  9%|         | 27976/303576 [18:01<1:04:51, 70.83it/s]  9%|         | 27984/303576 [18:01<1:04:37, 71.07it/s]  9%|         | 27992/303576 [18:01<1:04:18, 71.43it/s]  9%|         | 28000/303576 [18:01<1:03:54, 71.86it/s]                                                          9%|         | 28000/303576 [18:01<1:03:54, 71.86it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7379512190818787, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.6378, 'eval_samples_per_second': 9.983, 'eval_steps_per_second': 0.088, 'epoch': 0.27, 'timestamp': 1762965597.8959892, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7781, 'grad_norm': 0.22144968807697296, 'learning_rate': 6.658103717828343e-05, 'epoch': 0.27, 'timestamp': 1762965599.6403239, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7556, 'grad_norm': 0.199233740568161, 'learning_rate': 6.591851182774513e-05, 'epoch': 0.27, 'timestamp': 1762965601.4324522, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7841, 'grad_norm': 0.2461816817522049, 'learning_rate': 6.526257904257843e-05, 'epoch': 0.27, 'timestamp': 1762965602.927119, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7684, 'grad_norm': 0.20650151371955872, 'learning_rate': 6.461963518591678e-05, 'epoch': 0.27, 'timestamp': 1762965604.2184799, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7791, 'grad_norm': 0.22314482927322388, 'learning_rate': 6.397662708229465e-05, 'epoch': 0.27, 'timestamp': 1762965605.2977083, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.776, 'grad_norm': 0.1902817338705063, 'learning_rate': 6.334001733453035e-05, 'epoch': 0.27, 'timestamp': 1762965608.0344512, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7823, 'grad_norm': 0.24731844663619995, 'learning_rate': 6.270974227475178e-05, 'epoch': 0.27, 'timestamp': 1762965611.1483912, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.20413777232170105, 'learning_rate': 6.208573886862439e-05, 'epoch': 0.27, 'timestamp': 1762965612.5623503, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7712, 'grad_norm': 0.27922630310058594, 'learning_rate': 6.14679447090467e-05, 'epoch': 0.28, 'timestamp': 1762965613.987057, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7758, 'grad_norm': 0.27141380310058594, 'learning_rate': 6.0856298009909476e-05, 'epoch': 0.28, 'timestamp': 1762965615.4092422, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:40:18.744233: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:40:18.754821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965618.767438 1736302 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965618.771189 1736302 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965618.781541 1736302 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965618.781557 1736302 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965618.781559 1736302 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965618.781561 1736302 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:40:18.784831: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:40:20 - TensorFlow version 2.19.1 available.
2025-11-12 16:40:28.333060: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:40:28.343515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965628.356389 1736788 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965628.360300 1736788 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965628.370462 1736788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965628.370477 1736788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965628.370479 1736788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965628.370481 1736788 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:40:28.373585: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:40:30 - TensorFlow version 2.19.1 available.
  9%|         | 28000/303576 [18:20<1:03:54, 71.86it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                        
                                             [A  9%|         | 28000/303576 [18:23<1:03:54, 71.86it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-28000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-28000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-28000/model.safetensors
  9%|         | 28001/303576 [18:23<84:02:48,  1.10s/it]  9%|         | 28008/303576 [18:23<56:01:34,  1.37it/s]  9%|         | 28015/303576 [18:23<38:19:11,  2.00it/s]  9%|         | 28022/303576 [18:23<26:38:45,  2.87it/s]  9%|         | 28028/303576 [18:23<19:38:03,  3.90it/s]  9%|         | 28034/303576 [18:23<14:29:00,  5.28it/s]  9%|         | 28040/303576 [18:23<10:42:43,  7.15it/s]  9%|         | 28046/303576 [18:24<7:57:29,  9.62it/s]   9%|         | 28052/303576 [18:24<5:59:26, 12.78it/s]  9%|         | 28058/303576 [18:24<4:37:02, 16.57it/s]  9%|         | 28064/303576 [18:24<3:40:16, 20.85it/s]  9%|         | 28070/303576 [18:24<2:58:35, 25.71it/s]  9%|         | 28076/303576 [18:24<2:30:05, 30.59it/s]  9%|         | 28082/303576 [18:24<2:10:57, 35.06it/s]  9%|         | 28088/303576 [18:24<1:57:32, 39.06it/s]  9%|         | 28094/303576 [18:24<1:46:59, 42.92it/s]  9%|         | 28100/303576 [18:25<1:39:37, 46.08it/s]                                                          9%|         | 28100/303576 [18:25<1:39:37, 46.08it/s]  9%|         | 28107/303576 [18:25<1:31:06, 50.39it/s]  9%|         | 28113/303576 [18:25<1:28:06, 52.11it/s]  9%|         | 28119/303576 [18:25<1:26:13, 53.24it/s]  9%|         | 28125/303576 [18:25<1:23:54, 54.71it/s]  9%|         | 28131/303576 [18:25<1:21:55, 56.03it/s]  9%|         | 28137/303576 [18:25<1:20:32, 56.99it/s]  9%|         | 28143/303576 [18:25<1:19:25, 57.79it/s]  9%|         | 28149/303576 [18:25<1:19:56, 57.42it/s]  9%|         | 28155/303576 [18:25<1:19:34, 57.69it/s]  9%|         | 28161/303576 [18:26<1:21:04, 56.62it/s]  9%|         | 28167/303576 [18:26<1:22:06, 55.91it/s]  9%|         | 28173/303576 [18:26<1:22:48, 55.43it/s]  9%|         | 28179/303576 [18:26<1:23:47, 54.78it/s]  9%|         | 28185/303576 [18:26<1:24:57, 54.02it/s]  9%|         | 28191/303576 [18:26<1:24:40, 54.21it/s]  9%|         | 28197/303576 [18:26<1:24:57, 54.02it/s]                                                          9%|         | 28200/303576 [18:26<1:24:57, 54.02it/s]  9%|         | 28203/303576 [18:26<1:24:54, 54.05it/s]  9%|         | 28209/303576 [18:26<1:25:15, 53.83it/s]  9%|         | 28215/303576 [18:27<1:25:35, 53.62it/s]  9%|         | 28221/303576 [18:27<1:25:52, 53.44it/s]  9%|         | 28227/303576 [18:27<1:24:32, 54.28it/s]  9%|         | 28233/303576 [18:27<1:24:12, 54.49it/s]  9%|         | 28239/303576 [18:27<1:23:30, 54.95it/s]  9%|         | 28246/303576 [18:27<1:21:03, 56.61it/s]  9%|         | 28253/303576 [18:27<1:19:29, 57.73it/s]  9%|         | 28259/303576 [18:27<1:19:38, 57.62it/s]  9%|         | 28265/303576 [18:27<1:21:47, 56.10it/s]  9%|         | 28271/303576 [18:28<1:22:35, 55.55it/s]  9%|         | 28277/303576 [18:28<1:23:42, 54.81it/s]  9%|         | 28283/303576 [18:28<1:22:05, 55.89it/s]  9%|         | 28289/303576 [18:28<1:23:02, 55.25it/s]  9%|         | 28295/303576 [18:28<1:23:41, 54.82it/s]                                                          9%|         | 28300/303576 [18:28<1:23:41, 54.82it/s]  9%|         | 28301/303576 [18:28<1:23:22, 55.02it/s]  9%|         | 28307/303576 [18:28<1:24:23, 54.36it/s]  9%|         | 28313/303576 [18:28<1:24:42, 54.16it/s]  9%|         | 28319/303576 [18:28<1:23:42, 54.80it/s]  9%|         | 28325/303576 [18:29<1:22:32, 55.57it/s]  9%|         | 28331/303576 [18:29<1:23:12, 55.13it/s]  9%|         | 28337/303576 [18:29<1:23:33, 54.90it/s]  9%|         | 28343/303576 [18:29<1:24:01, 54.59it/s]  9%|         | 28350/303576 [18:29<1:19:37, 57.60it/s]  9%|         | 28357/303576 [18:29<1:17:31, 59.16it/s]  9%|         | 28364/303576 [18:29<1:15:39, 60.63it/s]  9%|         | 28371/303576 [18:29<1:13:54, 62.06it/s]  9%|         | 28378/303576 [18:29<1:12:26, 63.32it/s]  9%|         | 28385/303576 [18:30<1:11:52, 63.81it/s]  9%|         | 28392/303576 [18:30<1:11:19, 64.30it/s]  9%|         | 28399/303576 [18:30<1:10:44, 64.83it/s]                                                          9%|         | 28400/303576 [18:30<1:10:44, 64.83it/s]  9%|         | 28406/303576 [18:30<1:10:33, 65.01it/s]  9%|         | 28413/303576 [18:30<1:09:48, 65.69it/s]  9%|         | 28420/303576 [18:30<1:10:52, 64.71it/s]  9%|         | 28427/303576 [18:30<1:15:12, 60.97it/s]  9%|         | 28434/303576 [18:30<1:16:58, 59.58it/s]  9%|         | 28440/303576 [18:30<1:18:36, 58.34it/s]  9%|         | 28446/303576 [18:31<1:22:53, 55.32it/s]  9%|         | 28452/303576 [18:31<1:24:27, 54.29it/s]  9%|         | 28458/303576 [18:31<1:24:35, 54.20it/s]  9%|         | 28464/303576 [18:31<1:24:21, 54.36it/s]  9%|         | 28470/303576 [18:31<1:25:06, 53.88it/s]  9%|         | 28476/303576 [18:31<1:26:01, 53.30it/s]  9%|         | 28482/303576 [18:31<1:27:20, 52.50it/s]  9%|         | 28488/303576 [18:31<1:30:08, 50.86it/s]  9%|         | 28494/303576 [18:32<1:31:16, 50.23it/s]  9%|         | 28500/303576 [18:32<1:31:20, 50.19it/s]                                                          9%|         | 28500/303576 [18:32<1:31:20, 50.19it/s]  9%|         | 28506/303576 [18:32<1:30:53, 50.44it/s]  9%|         | 28514/303576 [18:32<1:20:47, 56.74it/s]  9%|         | 28521/303576 [18:32<1:17:11, 59.39it/s]  9%|         | 28528/303576 [18:32<1:14:54, 61.19it/s]  9%|         | 28535/303576 [18:32<1:13:47, 62.12it/s]  9%|         | 28542/303576 [18:32<1:13:10, 62.64it/s]  9%|         | 28549/303576 [18:32<1:12:25, 63.29it/s]  9%|         | 28556/303576 [18:32<1:11:45, 63.88it/s]  9%|         | 28563/303576 [18:33<1:11:19, 64.26it/s]  9%|         | 28570/303576 [18:33<1:10:28, 65.04it/s]  9%|         | 28577/303576 [18:33<1:10:35, 64.92it/s]  9%|         | 28584/303576 [18:33<1:09:56, 65.53it/s]  9%|         | 28592/303576 [18:33<1:08:33, 66.85it/s]  9%|         | 28599/303576 [18:33<1:08:42, 66.71it/s]                                                          9%|         | 28600/303576 [18:33<1:08:41, 66.71it/s]  9%|         | 28606/303576 [18:33<1:09:17, 66.14it/s]  9%|         | 28613/303576 [18:33<1:09:23, 66.04it/s]  9%|         | 28620/303576 [18:33<1:09:50, 65.61it/s]  9%|         | 28627/303576 [18:34<1:09:56, 65.51it/s]  9%|         | 28634/303576 [18:34<1:09:51, 65.60it/s]  9%|         | 28641/303576 [18:34<1:12:51, 62.89it/s]  9%|         | 28648/303576 [18:34<1:15:56, 60.33it/s]  9%|         | 28655/303576 [18:34<1:16:32, 59.87it/s]  9%|         | 28662/303576 [18:34<1:16:48, 59.65it/s]  9%|         | 28668/303576 [18:34<1:17:09, 59.38it/s]  9%|         | 28674/303576 [18:34<1:17:27, 59.15it/s]  9%|         | 28680/303576 [18:34<1:17:53, 58.81it/s]  9%|         | 28686/303576 [18:35<1:17:53, 58.81it/s]  9%|         | 28694/303576 [18:35<1:11:48, 63.81it/s]                                                          9%|         | 28700/303576 [18:35<1:11:47, 63.81it/s]  9%|         | 28703/303576 [18:35<1:06:36, 68.78it/s]  9%|         | 28712/303576 [18:35<1:01:55, 73.98it/s]  9%|         | 28721/303576 [18:35<59:49, 76.57it/s]    9%|         | 28730/303576 [18:35<58:15, 78.62it/s]  9%|         | 28739/303576 [18:35<57:37, 79.50it/s]  9%|         | 28748/303576 [18:35<56:46, 80.69it/s]  9%|         | 28757/303576 [18:35<56:41, 80.79it/s]  9%|         | 28766/303576 [18:36<56:06, 81.63it/s]  9%|         | 28775/303576 [18:36<56:14, 81.43it/s]  9%|         | 28784/303576 [18:36<55:19, 82.78it/s]  9%|         | 28793/303576 [18:36<56:07, 81.61it/s]                                                        9%|         | 28800/303576 [18:36<56:07, 81.61it/s]  9%|         | 28802/303576 [18:36<57:08, 80.15it/s]  9%|         | 28811/303576 [18:36<57:35, 79.52it/s]  9%|         | 28819/303576 [18:36<57:57, 79.01it/s]  9%|         | 28827/303576 [18:36<58:12, 78.66it/s]  9%|         | 28835/303576 [18:36<58:17, 78.55it/s] 10%|         | 28843/303576 [18:37<58:20, 78.48it/s] 10%|         | 28851/303576 [18:37<58:31, 78.23it/s] 10%|         | 28860/303576 [18:37<57:40, 79.38it/s] 10%|         | 28869/303576 [18:37<55:42, 82.19it/s] 10%|         | 28878/303576 [18:37<56:38, 80.82it/s] 10%|         | 28887/303576 [18:37<57:18, 79.88it/s] 10%|         | 28896/303576 [18:37<56:48, 80.59it/s]                                                       10%|         | 28900/303576 [18:37<56:48, 80.59it/s] 10%|         | 28906/303576 [18:37<54:32, 83.93it/s] 10%|         | 28917/303576 [18:37<51:31, 88.85it/s] 10%|         | 28928/303576 [18:38<49:35, 92.29it/s] 10%|         | 28938/303576 [18:38<48:31, 94.31it/s] 10%|         | 28948/303576 [18:38<47:53, 95.57it/s] 10%|         | 28958/303576 [18:38<48:11, 94.99it/s] 10%|         | 28968/303576 [18:38<51:20, 89.14it/s] 10%|         | 28979/303576 [18:38<49:32, 92.37it/s] 10%|         | 28989/303576 [18:38<49:57, 91.59it/s] 10%|         | 28999/303576 [18:38<50:27, 90.68it/s]                                                       10%|         | 29000/303576 [18:38<50:27, 90.68it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.73878413438797, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.1401, 'eval_samples_per_second': 10.691, 'eval_steps_per_second': 0.095, 'epoch': 0.28, 'timestamp': 1762965636.5498772, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7743, 'grad_norm': 0.25860336422920227, 'learning_rate': 6.025073759991592e-05, 'epoch': 0.28, 'timestamp': 1762965638.4736133, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7772, 'grad_norm': 0.23144882917404175, 'learning_rate': 5.965120291646414e-05, 'epoch': 0.28, 'timestamp': 1762965640.2494698, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7747, 'grad_norm': 0.26242899894714355, 'learning_rate': 5.905763399959016e-05, 'epoch': 0.28, 'timestamp': 1762965642.056561, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.777, 'grad_norm': 0.289794385433197, 'learning_rate': 5.8469971485971345e-05, 'epoch': 0.28, 'timestamp': 1762965643.7186387, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7693, 'grad_norm': 0.261139452457428, 'learning_rate': 5.7888156602989296e-05, 'epoch': 0.28, 'timestamp': 1762965645.5655487, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.20063771307468414, 'learning_rate': 5.731213116285212e-05, 'epoch': 0.28, 'timestamp': 1762965647.0992823, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.766, 'grad_norm': 0.21766899526119232, 'learning_rate': 5.674183755677492e-05, 'epoch': 0.28, 'timestamp': 1762965648.6979706, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7733, 'grad_norm': 0.2509414255619049, 'learning_rate': 5.617721874921829e-05, 'epoch': 0.28, 'timestamp': 1762965649.9148524, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7621, 'grad_norm': 0.2297086864709854, 'learning_rate': 5.561821827218414e-05, 'epoch': 0.29, 'timestamp': 1762965651.164579, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7697, 'grad_norm': 0.1983662247657776, 'learning_rate': 5.507028724829312e-05, 'epoch': 0.29, 'timestamp': 1762965652.23102, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:40:56.136955: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:40:56.147545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965656.159917 1738084 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965656.163572 1738084 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965656.173849 1738084 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965656.173862 1738084 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965656.173864 1738084 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965656.173865 1738084 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:40:56.176980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:40:58 - TensorFlow version 2.19.1 available.
 10%|         | 29000/303576 [18:50<50:27, 90.68it/s]2025-11-12 16:41:06.589548: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:41:06.600214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965666.613020 1738512 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965666.616862 1738512 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965666.627359 1738512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965666.627376 1738512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965666.627379 1738512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965666.627380 1738512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:41:06.630493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:41:08 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 10%|         | 29000/303576 [19:01<50:27, 90.68it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 10%|         | 29001/303576 [19:01<67:35:51,  1.13it/s] 10%|         | 29006/303576 [19:01<53:15:38,  1.43it/s] 10%|         | 29014/303576 [19:01<36:05:54,  2.11it/s] 10%|         | 29021/303576 [19:01<25:51:51,  2.95it/s] 10%|         | 29028/303576 [19:01<18:35:43,  4.10it/s] 10%|         | 29035/303576 [19:01<13:25:29,  5.68it/s] 10%|         | 29042/303576 [19:02<9:47:10,  7.79it/s]  10%|         | 29049/303576 [19:02<7:12:58, 10.57it/s] 10%|         | 29058/303576 [19:02<4:59:05, 15.30it/s] 10%|         | 29069/303576 [19:02<3:22:03, 22.64it/s] 10%|         | 29080/303576 [19:02<2:26:41, 31.19it/s] 10%|         | 29091/303576 [19:02<1:52:42, 40.59it/s]                                                         10%|         | 29100/303576 [19:02<1:52:42, 40.59it/s] 10%|         | 29102/303576 [19:02<1:30:54, 50.32it/s] 10%|         | 29113/303576 [19:02<1:16:24, 59.86it/s] 10%|         | 29123/303576 [19:02<1:08:06, 67.16it/s] 10%|         | 29134/303576 [19:02<59:59, 76.24it/s]   10%|         | 29144/303576 [19:03<56:51, 80.45it/s] 10%|         | 29154/303576 [19:03<55:18, 82.70it/s] 10%|         | 29164/303576 [19:03<54:39, 83.68it/s] 10%|         | 29174/303576 [19:03<55:41, 82.13it/s] 10%|         | 29183/303576 [19:03<56:14, 81.31it/s] 10%|         | 29192/303576 [19:03<59:45, 76.52it/s] 10%|         | 29200/303576 [19:03<1:04:01, 71.43it/s]                                                         10%|         | 29200/303576 [19:03<1:04:01, 71.43it/s] 10%|         | 29208/303576 [19:03<1:07:33, 67.68it/s] 10%|         | 29215/303576 [19:04<1:10:56, 64.46it/s] 10%|         | 29222/303576 [19:04<1:14:39, 61.25it/s] 10%|         | 29229/303576 [19:04<1:17:11, 59.24it/s] 10%|         | 29235/303576 [19:04<1:19:15, 57.69it/s] 10%|         | 29241/303576 [19:04<1:20:34, 56.75it/s] 10%|         | 29248/303576 [19:04<1:17:57, 58.65it/s] 10%|         | 29254/303576 [19:04<1:22:59, 55.09it/s] 10%|         | 29260/303576 [19:04<1:26:50, 52.64it/s] 10%|         | 29266/303576 [19:05<1:29:41, 50.98it/s] 10%|         | 29272/303576 [19:05<1:31:50, 49.78it/s] 10%|         | 29277/303576 [19:05<1:34:06, 48.58it/s] 10%|         | 29283/303576 [19:05<1:33:35, 48.85it/s] 10%|         | 29293/303576 [19:05<1:14:36, 61.27it/s]                                                         10%|         | 29300/303576 [19:05<1:14:36, 61.27it/s] 10%|         | 29304/303576 [19:05<1:02:50, 72.75it/s] 10%|         | 29315/303576 [19:05<55:35, 82.21it/s]   10%|         | 29326/303576 [19:05<51:54, 88.04it/s] 10%|         | 29338/303576 [19:05<48:22, 94.48it/s] 10%|         | 29348/303576 [19:06<50:41, 90.17it/s] 10%|         | 29358/303576 [19:06<53:37, 85.23it/s] 10%|         | 29367/303576 [19:06<55:47, 81.90it/s] 10%|         | 29376/303576 [19:06<57:17, 79.76it/s] 10%|         | 29385/303576 [19:06<57:55, 78.89it/s] 10%|         | 29393/303576 [19:06<58:15, 78.43it/s]                                                       10%|         | 29400/303576 [19:06<58:15, 78.43it/s] 10%|         | 29401/303576 [19:06<57:59, 78.80it/s] 10%|         | 29409/303576 [19:06<58:07, 78.61it/s] 10%|         | 29417/303576 [19:06<59:01, 77.41it/s] 10%|         | 29425/303576 [19:07<59:47, 76.42it/s] 10%|         | 29433/303576 [19:07<59:36, 76.65it/s] 10%|         | 29442/303576 [19:07<58:10, 78.53it/s] 10%|         | 29450/303576 [19:07<58:10, 78.53it/s] 10%|         | 29458/303576 [19:07<59:04, 77.33it/s] 10%|         | 29466/303576 [19:07<59:42, 76.51it/s] 10%|         | 29474/303576 [19:07<1:00:15, 75.81it/s] 10%|         | 29482/303576 [19:07<1:00:43, 75.23it/s] 10%|         | 29490/303576 [19:07<1:01:02, 74.83it/s] 10%|         | 29498/303576 [19:08<1:01:12, 74.63it/s]                                                         10%|         | 29500/303576 [19:08<1:01:12, 74.63it/s] 10%|         | 29506/303576 [19:08<1:00:50, 75.08it/s] 10%|         | 29515/303576 [19:08<58:38, 77.89it/s]   10%|         | 29525/303576 [19:08<55:16, 82.64it/s] 10%|         | 29535/303576 [19:08<53:27, 85.44it/s] 10%|         | 29545/303576 [19:08<51:19, 88.98it/s] 10%|         | 29555/303576 [19:08<49:42, 91.86it/s] 10%|         | 29565/303576 [19:08<48:42, 93.77it/s] 10%|         | 29575/303576 [19:08<48:09, 94.82it/s] 10%|         | 29585/303576 [19:08<47:38, 95.86it/s] 10%|         | 29595/303576 [19:09<47:16, 96.59it/s]                                                       10%|         | 29600/303576 [19:09<47:16, 96.59it/s] 10%|         | 29605/303576 [19:09<47:07, 96.90it/s] 10%|         | 29615/303576 [19:09<47:09, 96.83it/s] 10%|         | 29625/303576 [19:09<46:55, 97.31it/s] 10%|         | 29635/303576 [19:09<47:04, 96.98it/s] 10%|         | 29645/303576 [19:09<46:54, 97.34it/s] 10%|         | 29655/303576 [19:09<46:45, 97.65it/s] 10%|         | 29665/303576 [19:09<46:47, 97.57it/s] 10%|         | 29675/303576 [19:09<46:46, 97.59it/s] 10%|         | 29685/303576 [19:10<46:39, 97.82it/s] 10%|         | 29695/303576 [19:10<46:36, 97.94it/s]                                                       10%|         | 29700/303576 [19:10<46:36, 97.94it/s] 10%|         | 29705/303576 [19:10<46:39, 97.82it/s] 10%|         | 29715/303576 [19:10<46:51, 97.41it/s] 10%|         | 29725/303576 [19:10<47:03, 96.98it/s] 10%|         | 29735/303576 [19:10<47:06, 96.88it/s] 10%|         | 29745/303576 [19:10<47:11, 96.72it/s] 10%|         | 29755/303576 [19:10<46:48, 97.51it/s] 10%|         | 29766/303576 [19:10<46:15, 98.66it/s] 10%|         | 29777/303576 [19:10<45:54, 99.40it/s] 10%|         | 29787/303576 [19:11<47:05, 96.89it/s] 10%|         | 29797/303576 [19:11<50:41, 90.00it/s]                                                       10%|         | 29800/303576 [19:11<50:41, 90.00it/s] 10%|         | 29807/303576 [19:11<53:18, 85.58it/s] 10%|         | 29816/303576 [19:11<55:22, 82.40it/s] 10%|         | 29825/303576 [19:11<56:45, 80.39it/s] 10%|         | 29834/303576 [19:11<57:36, 79.19it/s] 10%|         | 29842/303576 [19:11<58:47, 77.60it/s] 10%|         | 29850/303576 [19:11<59:20, 76.87it/s] 10%|         | 29858/303576 [19:11<59:46, 76.32it/s] 10%|         | 29866/303576 [19:12<59:24, 76.79it/s] 10%|         | 29874/303576 [19:12<59:23, 76.81it/s] 10%|         | 29882/303576 [19:12<59:33, 76.59it/s] 10%|         | 29890/303576 [19:12<59:28, 76.69it/s] 10%|         | 29898/303576 [19:12<59:31, 76.62it/s]                                                       10%|         | 29900/303576 [19:12<59:31, 76.62it/s] 10%|         | 29906/303576 [19:12<59:01, 77.28it/s] 10%|         | 29914/303576 [19:12<59:06, 77.17it/s] 10%|         | 29922/303576 [19:12<59:05, 77.18it/s] 10%|         | 29930/303576 [19:12<59:12, 77.02it/s] 10%|         | 29938/303576 [19:13<59:12, 77.03it/s] 10%|         | 29946/303576 [19:13<59:17, 76.92it/s] 10%|         | 29954/303576 [19:13<59:21, 76.83it/s] 10%|         | 29962/303576 [19:13<1:01:11, 74.52it/s] 10%|         | 29970/303576 [19:13<1:02:20, 73.14it/s] 10%|         | 29978/303576 [19:13<1:03:36, 71.69it/s] 10%|         | 29986/303576 [19:13<1:04:12, 71.02it/s] 10%|         | 29994/303576 [19:13<1:04:42, 70.47it/s]                                                         10%|         | 30000/303576 [19:13<1:04:42, 70.47it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7377486824989319, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4828, 'eval_samples_per_second': 10.052, 'eval_steps_per_second': 0.089, 'epoch': 0.29, 'timestamp': 1762965674.71424, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7683, 'grad_norm': 0.20743171870708466, 'learning_rate': 5.4522301471716485e-05, 'epoch': 0.29, 'timestamp': 1762965676.0854523, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7708, 'grad_norm': 0.20848332345485687, 'learning_rate': 5.397976851600452e-05, 'epoch': 0.29, 'timestamp': 1762965677.265489, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7535, 'grad_norm': 0.2449813038110733, 'learning_rate': 5.344263412198365e-05, 'epoch': 0.29, 'timestamp': 1762965679.030795, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7834, 'grad_norm': 0.30531904101371765, 'learning_rate': 5.291084457039482e-05, 'epoch': 0.29, 'timestamp': 1762965680.1925206, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7826, 'grad_norm': 0.21427056193351746, 'learning_rate': 5.2384346676521324e-05, 'epoch': 0.29, 'timestamp': 1762965681.5129018, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7755, 'grad_norm': 0.2776484787464142, 'learning_rate': 5.186308778486951e-05, 'epoch': 0.29, 'timestamp': 1762965682.5755727, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7888, 'grad_norm': 0.23842450976371765, 'learning_rate': 5.134701576390264e-05, 'epoch': 0.29, 'timestamp': 1762965683.6005025, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7671, 'grad_norm': 0.29305300116539, 'learning_rate': 5.0836079000827235e-05, 'epoch': 0.29, 'timestamp': 1762965684.6634963, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.773, 'grad_norm': 0.26332715153694153, 'learning_rate': 5.0330226396431334e-05, 'epoch': 0.3, 'timestamp': 1762965685.9797616, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7814, 'grad_norm': 0.2464243769645691, 'learning_rate': 4.982940735997388e-05, 'epoch': 0.3, 'timestamp': 1762965687.3432298, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:41:30.702574: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:41:30.713275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965690.725959 1739624 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965690.729746 1739624 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965690.740165 1739624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965690.740181 1739624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965690.740183 1739624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965690.740184 1739624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:41:30.743399: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:41:32 - TensorFlow version 2.19.1 available.
2025-11-12 16:41:40.379963: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:41:40.390512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965700.403211 1740066 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965700.406895 1740066 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965700.417101 1740066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965700.417116 1740066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965700.417118 1740066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965700.417119 1740066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:41:40.420250: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:41:42 - TensorFlow version 2.19.1 available.
 10%|         | 30000/303576 [19:30<1:04:42, 70.47it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                        
                                             [A 10%|         | 30000/303576 [19:34<1:04:42, 70.47it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-30000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-30000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-30000/model.safetensors
 10%|         | 30001/303576 [19:35<63:35:23,  1.20it/s] 10%|         | 30007/303576 [19:35<47:59:30,  1.58it/s] 10%|         | 30014/303576 [19:35<34:14:14,  2.22it/s] 10%|         | 30021/303576 [19:35<24:29:09,  3.10it/s] 10%|         | 30028/303576 [19:35<17:35:22,  4.32it/s] 10%|         | 30035/303576 [19:35<12:44:06,  5.97it/s] 10%|         | 30042/303576 [19:35<9:17:43,  8.17it/s]  10%|         | 30049/303576 [19:35<6:54:00, 11.01it/s] 10%|         | 30056/303576 [19:35<5:12:59, 14.56it/s] 10%|         | 30063/303576 [19:36<4:03:16, 18.74it/s] 10%|         | 30070/303576 [19:36<3:12:00, 23.74it/s] 10%|         | 30077/303576 [19:36<2:36:41, 29.09it/s] 10%|         | 30084/303576 [19:36<2:17:07, 33.24it/s] 10%|         | 30090/303576 [19:36<2:06:03, 36.16it/s] 10%|         | 30096/303576 [19:36<1:58:28, 38.47it/s]                                                         10%|         | 30100/303576 [19:36<1:58:28, 38.47it/s] 10%|         | 30102/303576 [19:36<1:52:09, 40.64it/s] 10%|         | 30108/303576 [19:36<1:47:23, 42.44it/s] 10%|         | 30113/303576 [19:37<1:45:30, 43.19it/s] 10%|         | 30118/303576 [19:37<1:41:49, 44.76it/s] 10%|         | 30124/303576 [19:37<1:35:47, 47.58it/s] 10%|         | 30130/303576 [19:37<1:30:05, 50.58it/s] 10%|         | 30136/303576 [19:37<1:27:53, 51.85it/s] 10%|         | 30142/303576 [19:37<1:25:43, 53.16it/s] 10%|         | 30148/303576 [19:37<1:23:24, 54.63it/s] 10%|         | 30155/303576 [19:37<1:20:13, 56.81it/s] 10%|         | 30162/303576 [19:37<1:17:08, 59.07it/s] 10%|         | 30169/303576 [19:38<1:14:07, 61.48it/s] 10%|         | 30176/303576 [19:38<1:13:04, 62.36it/s] 10%|         | 30183/303576 [19:38<1:12:01, 63.26it/s] 10%|         | 30190/303576 [19:38<1:11:33, 63.68it/s] 10%|         | 30197/303576 [19:38<1:11:07, 64.06it/s]                                                         10%|         | 30200/303576 [19:38<1:11:07, 64.06it/s] 10%|         | 30204/303576 [19:38<1:11:45, 63.49it/s] 10%|         | 30211/303576 [19:38<1:11:36, 63.62it/s] 10%|         | 30218/303576 [19:38<1:14:15, 61.35it/s] 10%|         | 30225/303576 [19:38<1:16:02, 59.91it/s] 10%|         | 30232/303576 [19:39<1:17:20, 58.90it/s] 10%|         | 30238/303576 [19:39<1:18:01, 58.39it/s] 10%|         | 30244/303576 [19:39<1:18:33, 57.99it/s] 10%|         | 30250/303576 [19:39<1:19:03, 57.62it/s] 10%|         | 30256/303576 [19:39<1:19:30, 57.29it/s] 10%|         | 30262/303576 [19:39<1:19:37, 57.21it/s] 10%|         | 30268/303576 [19:39<1:19:10, 57.53it/s] 10%|         | 30275/303576 [19:39<1:16:10, 59.79it/s] 10%|         | 30282/303576 [19:39<1:14:56, 60.77it/s] 10%|         | 30289/303576 [19:40<1:14:29, 61.14it/s] 10%|         | 30296/303576 [19:40<1:13:39, 61.83it/s]                                                         10%|         | 30300/303576 [19:40<1:13:39, 61.83it/s] 10%|         | 30303/303576 [19:40<1:18:50, 57.77it/s] 10%|         | 30309/303576 [19:40<1:20:22, 56.66it/s] 10%|         | 30315/303576 [19:40<1:19:34, 57.24it/s] 10%|         | 30321/303576 [19:40<1:19:41, 57.15it/s] 10%|         | 30327/303576 [19:40<1:22:05, 55.48it/s] 10%|         | 30336/303576 [19:40<1:11:52, 63.36it/s] 10%|         | 30345/303576 [19:40<1:06:00, 68.99it/s] 10%|         | 30354/303576 [19:41<1:01:59, 73.45it/s] 10%|         | 30363/303576 [19:41<59:33, 76.46it/s]   10%|         | 30372/303576 [19:41<58:07, 78.34it/s] 10%|         | 30381/303576 [19:41<57:13, 79.56it/s] 10%|         | 30390/303576 [19:41<56:32, 80.54it/s] 10%|         | 30399/303576 [19:41<56:02, 81.24it/s]                                                       10%|         | 30400/303576 [19:41<56:02, 81.24it/s] 10%|         | 30408/303576 [19:41<56:01, 81.27it/s] 10%|         | 30417/303576 [19:41<56:02, 81.23it/s] 10%|         | 30426/303576 [19:41<56:06, 81.14it/s] 10%|         | 30435/303576 [19:42<56:08, 81.08it/s] 10%|         | 30444/303576 [19:42<56:07, 81.12it/s] 10%|         | 30453/303576 [19:42<56:03, 81.21it/s] 10%|         | 30462/303576 [19:42<56:50, 80.09it/s] 10%|         | 30471/303576 [19:42<57:39, 78.95it/s] 10%|         | 30479/303576 [19:42<58:08, 78.28it/s] 10%|         | 30487/303576 [19:42<58:23, 77.94it/s] 10%|         | 30495/303576 [19:42<58:30, 77.80it/s]                                                       10%|         | 30500/303576 [19:42<58:29, 77.80it/s] 10%|         | 30503/303576 [19:42<58:46, 77.44it/s] 10%|         | 30511/303576 [19:42<58:51, 77.32it/s] 10%|         | 30519/303576 [19:43<58:54, 77.25it/s] 10%|         | 30527/303576 [19:43<58:58, 77.15it/s] 10%|         | 30535/303576 [19:43<59:22, 76.63it/s] 10%|         | 30543/303576 [19:43<59:16, 76.77it/s] 10%|         | 30551/303576 [19:43<59:18, 76.72it/s] 10%|         | 30559/303576 [19:43<59:25, 76.58it/s] 10%|         | 30567/303576 [19:43<59:26, 76.55it/s] 10%|         | 30575/303576 [19:43<59:24, 76.59it/s] 10%|         | 30583/303576 [19:43<59:20, 76.66it/s] 10%|         | 30591/303576 [19:44<58:48, 77.36it/s] 10%|         | 30599/303576 [19:44<58:23, 77.91it/s]                                                       10%|         | 30600/303576 [19:44<58:23, 77.91it/s] 10%|         | 30608/303576 [19:44<57:39, 78.90it/s] 10%|         | 30617/303576 [19:44<57:36, 78.97it/s] 10%|         | 30626/303576 [19:44<57:09, 79.58it/s] 10%|         | 30634/303576 [19:44<57:08, 79.61it/s] 10%|         | 30642/303576 [19:44<57:09, 79.59it/s] 10%|         | 30651/303576 [19:44<56:34, 80.40it/s] 10%|         | 30660/303576 [19:44<58:40, 77.53it/s] 10%|         | 30668/303576 [19:44<59:16, 76.74it/s] 10%|         | 30677/303576 [19:45<56:57, 79.85it/s] 10%|         | 30686/303576 [19:45<56:16, 80.82it/s] 10%|         | 30695/303576 [19:45<58:17, 78.03it/s]                                                       10%|         | 30700/303576 [19:45<58:16, 78.03it/s] 10%|         | 30703/303576 [19:45<58:20, 77.96it/s] 10%|         | 30712/303576 [19:45<57:38, 78.90it/s] 10%|         | 30720/303576 [19:45<57:27, 79.14it/s] 10%|         | 30728/303576 [19:45<57:23, 79.23it/s] 10%|         | 30736/303576 [19:45<57:39, 78.87it/s] 10%|         | 30744/303576 [19:45<57:32, 79.02it/s] 10%|         | 30753/303576 [19:46<56:45, 80.11it/s] 10%|         | 30762/303576 [19:46<56:16, 80.80it/s] 10%|         | 30771/303576 [19:46<55:16, 82.26it/s] 10%|         | 30780/303576 [19:46<56:27, 80.54it/s] 10%|         | 30789/303576 [19:46<56:52, 79.94it/s] 10%|         | 30798/303576 [19:46<1:00:48, 74.77it/s]                                                         10%|         | 30800/303576 [19:46<1:00:48, 74.77it/s] 10%|         | 30806/303576 [19:46<1:01:40, 73.72it/s] 10%|         | 30815/303576 [19:46<58:21, 77.89it/s]   10%|         | 30824/303576 [19:46<57:23, 79.20it/s] 10%|         | 30832/303576 [19:47<57:44, 78.72it/s] 10%|         | 30840/303576 [19:47<1:03:01, 72.12it/s] 10%|         | 30848/303576 [19:47<1:09:02, 65.84it/s] 10%|         | 30856/303576 [19:47<1:07:43, 67.12it/s] 10%|         | 30865/303576 [19:47<1:03:46, 71.27it/s] 10%|         | 30874/303576 [19:47<1:01:28, 73.94it/s] 10%|         | 30882/303576 [19:47<1:00:26, 75.20it/s] 10%|         | 30891/303576 [19:47<59:13, 76.73it/s]   10%|         | 30900/303576 [19:48<57:19, 79.27it/s]                                                       10%|         | 30900/303576 [19:48<57:19, 79.27it/s] 10%|         | 30909/303576 [19:48<57:44, 78.71it/s] 10%|         | 30917/303576 [19:48<1:00:50, 74.69it/s] 10%|         | 30925/303576 [19:48<1:01:17, 74.14it/s] 10%|         | 30934/303576 [19:48<59:21, 76.56it/s]   10%|         | 30943/303576 [19:48<57:39, 78.80it/s] 10%|         | 30951/303576 [19:48<58:17, 77.95it/s] 10%|         | 30960/303576 [19:48<56:34, 80.31it/s] 10%|         | 30969/303576 [19:48<58:02, 78.28it/s] 10%|         | 30978/303576 [19:49<56:51, 79.90it/s] 10%|         | 30987/303576 [19:49<55:38, 81.66it/s] 10%|         | 30996/303576 [19:49<55:23, 82.02it/s]                                                       10%|         | 31000/303576 [19:49<55:23, 82.02it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366914749145508, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.0741, 'eval_samples_per_second': 10.724, 'eval_steps_per_second': 0.095, 'epoch': 0.3, 'timestamp': 1762965708.4177933, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7699, 'grad_norm': 0.24519065022468567, 'learning_rate': 4.9333571804125116e-05, 'epoch': 0.3, 'timestamp': 1762965710.2248168, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7754, 'grad_norm': 0.25328442454338074, 'learning_rate': 4.8842670139957345e-05, 'epoch': 0.3, 'timestamp': 1762965711.9386914, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7637, 'grad_norm': 0.25853657722473145, 'learning_rate': 4.835665327198557e-05, 'epoch': 0.3, 'timestamp': 1762965713.634139, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7837, 'grad_norm': 0.29384908080101013, 'learning_rate': 4.78754725932573e-05, 'epoch': 0.3, 'timestamp': 1762965715.0102513, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7724, 'grad_norm': 0.24083444476127625, 'learning_rate': 4.7399079980491297e-05, 'epoch': 0.3, 'timestamp': 1762965716.2733738, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7659, 'grad_norm': 0.23768341541290283, 'learning_rate': 4.692742778926486e-05, 'epoch': 0.3, 'timestamp': 1762965717.5707004, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7799, 'grad_norm': 0.2149989902973175, 'learning_rate': 4.646046884924878e-05, 'epoch': 0.3, 'timestamp': 1762965718.839343, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7805, 'grad_norm': 0.22701388597488403, 'learning_rate': 4.599815645948983e-05, 'epoch': 0.3, 'timestamp': 1762965720.117928, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.779, 'grad_norm': 0.22853797674179077, 'learning_rate': 4.5540444383740154e-05, 'epoch': 0.31, 'timestamp': 1762965721.4465346, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7765, 'grad_norm': 0.24831444025039673, 'learning_rate': 4.5087286845833175e-05, 'epoch': 0.31, 'timestamp': 1762965722.7143693, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:42:06.636880: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:42:06.647651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965726.661025 1740813 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965726.665037 1740813 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965726.675593 1740813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965726.675608 1740813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965726.675610 1740813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965726.675612 1740813 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:42:06.679019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:42:08 - TensorFlow version 2.19.1 available.
 10%|         | 31000/303576 [20:00<55:23, 82.02it/s]2025-11-12 16:42:17.115133: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:42:17.125823: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965737.138706 1741140 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965737.142554 1741140 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965737.152962 1741140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965737.152979 1741140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965737.152980 1741140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965737.152982 1741140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:42:17.156192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:42:19 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 10%|         | 31000/303576 [20:12<55:23, 82.02it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [A 10%|         | 31001/303576 [20:12<67:44:41,  1.12it/s] 10%|         | 31006/303576 [20:12<53:25:38,  1.42it/s] 10%|         | 31014/303576 [20:12<36:17:53,  2.09it/s] 10%|         | 31021/303576 [20:12<26:10:17,  2.89it/s] 10%|         | 31027/303576 [20:12<19:42:51,  3.84it/s] 10%|         | 31033/303576 [20:12<14:47:31,  5.12it/s] 10%|         | 31039/303576 [20:12<11:06:45,  6.81it/s] 10%|         | 31044/303576 [20:13<8:45:32,  8.64it/s]  10%|         | 31049/303576 [20:13<6:54:13, 10.97it/s] 10%|         | 31054/303576 [20:13<5:29:01, 13.80it/s] 10%|         | 31059/303576 [20:13<4:25:45, 17.09it/s] 10%|         | 31064/303576 [20:13<3:39:04, 20.73it/s] 10%|         | 31069/303576 [20:13<3:02:22, 24.90it/s] 10%|         | 31074/303576 [20:13<2:38:35, 28.64it/s] 10%|         | 31079/303576 [20:13<2:19:37, 32.53it/s] 10%|         | 31084/303576 [20:13<2:07:46, 35.54it/s] 10%|         | 31090/303576 [20:14<1:55:00, 39.49it/s] 10%|         | 31096/303576 [20:14<1:45:39, 42.98it/s]                                                         10%|         | 31100/303576 [20:14<1:45:39, 42.98it/s] 10%|         | 31102/303576 [20:14<1:39:10, 45.79it/s] 10%|         | 31108/303576 [20:14<1:34:16, 48.17it/s] 10%|         | 31114/303576 [20:14<1:31:28, 49.65it/s] 10%|         | 31121/303576 [20:14<1:26:15, 52.64it/s] 10%|         | 31128/303576 [20:14<1:21:51, 55.47it/s] 10%|         | 31135/303576 [20:14<1:19:07, 57.39it/s] 10%|         | 31142/303576 [20:14<1:16:32, 59.32it/s] 10%|         | 31149/303576 [20:15<1:14:53, 60.63it/s] 10%|         | 31156/303576 [20:15<1:13:30, 61.77it/s] 10%|         | 31163/303576 [20:15<1:12:13, 62.87it/s] 10%|         | 31170/303576 [20:15<1:11:26, 63.55it/s] 10%|         | 31177/303576 [20:15<1:10:59, 63.96it/s] 10%|         | 31184/303576 [20:15<1:10:30, 64.38it/s] 10%|         | 31191/303576 [20:15<1:10:17, 64.58it/s] 10%|         | 31198/303576 [20:15<1:10:10, 64.69it/s]                                                         10%|         | 31200/303576 [20:15<1:10:10, 64.69it/s] 10%|         | 31205/303576 [20:15<1:10:09, 64.71it/s] 10%|         | 31212/303576 [20:16<1:10:06, 64.76it/s] 10%|         | 31219/303576 [20:16<1:10:42, 64.20it/s] 10%|         | 31226/303576 [20:16<1:10:27, 64.43it/s] 10%|         | 31233/303576 [20:16<1:10:15, 64.61it/s] 10%|         | 31240/303576 [20:16<1:10:46, 64.14it/s] 10%|         | 31247/303576 [20:16<1:11:47, 63.22it/s] 10%|         | 31254/303576 [20:16<1:12:03, 62.98it/s] 10%|         | 31261/303576 [20:16<1:11:49, 63.20it/s] 10%|         | 31268/303576 [20:16<1:11:18, 63.65it/s] 10%|         | 31275/303576 [20:16<1:10:23, 64.47it/s] 10%|         | 31282/303576 [20:17<1:10:37, 64.26it/s] 10%|         | 31289/303576 [20:17<1:10:21, 64.50it/s] 10%|         | 31296/303576 [20:17<1:10:11, 64.66it/s]                                                         10%|         | 31300/303576 [20:17<1:10:10, 64.66it/s] 10%|         | 31303/303576 [20:17<1:09:38, 65.16it/s] 10%|         | 31310/303576 [20:17<1:09:30, 65.28it/s] 10%|         | 31317/303576 [20:17<1:09:06, 65.66it/s] 10%|         | 31324/303576 [20:17<1:08:56, 65.81it/s] 10%|         | 31331/303576 [20:17<1:09:26, 65.34it/s] 10%|         | 31338/303576 [20:17<1:09:26, 65.34it/s] 10%|         | 31345/303576 [20:18<1:09:09, 65.60it/s] 10%|         | 31352/303576 [20:18<1:09:10, 65.58it/s] 10%|         | 31359/303576 [20:18<1:09:01, 65.74it/s] 10%|         | 31366/303576 [20:18<1:09:08, 65.62it/s] 10%|         | 31373/303576 [20:18<1:08:51, 65.88it/s] 10%|         | 31380/303576 [20:18<1:08:55, 65.82it/s] 10%|         | 31387/303576 [20:18<1:11:24, 63.53it/s] 10%|         | 31394/303576 [20:18<1:13:30, 61.71it/s]                                                         10%|         | 31400/303576 [20:18<1:13:30, 61.71it/s] 10%|         | 31401/303576 [20:18<1:14:16, 61.07it/s] 10%|         | 31408/303576 [20:19<1:13:07, 62.04it/s] 10%|         | 31415/303576 [20:19<1:11:08, 63.76it/s] 10%|         | 31422/303576 [20:19<1:10:24, 64.42it/s] 10%|         | 31429/303576 [20:19<1:10:25, 64.40it/s] 10%|         | 31436/303576 [20:19<1:12:51, 62.25it/s] 10%|         | 31443/303576 [20:19<1:12:54, 62.21it/s] 10%|         | 31450/303576 [20:19<1:12:29, 62.56it/s] 10%|         | 31457/303576 [20:19<1:13:11, 61.96it/s] 10%|         | 31464/303576 [20:19<1:14:44, 60.67it/s] 10%|         | 31471/303576 [20:20<1:15:02, 60.43it/s] 10%|         | 31478/303576 [20:20<1:15:39, 59.94it/s] 10%|         | 31485/303576 [20:20<1:17:02, 58.87it/s] 10%|         | 31491/303576 [20:20<1:17:09, 58.77it/s] 10%|         | 31497/303576 [20:20<1:16:48, 59.03it/s]                                                         10%|         | 31500/303576 [20:20<1:16:48, 59.03it/s] 10%|         | 31504/303576 [20:20<1:15:52, 59.76it/s] 10%|         | 31511/303576 [20:20<1:14:24, 60.94it/s] 10%|         | 31518/303576 [20:20<1:12:46, 62.30it/s] 10%|         | 31525/303576 [20:20<1:12:17, 62.73it/s] 10%|         | 31532/303576 [20:21<1:12:33, 62.49it/s] 10%|         | 31539/303576 [20:21<1:12:08, 62.84it/s] 10%|         | 31547/303576 [20:21<1:08:12, 66.47it/s] 10%|         | 31556/303576 [20:21<1:03:54, 70.95it/s] 10%|         | 31566/303576 [20:21<58:23, 77.64it/s]   10%|         | 31575/303576 [20:21<56:02, 80.90it/s] 10%|         | 31584/303576 [20:21<55:39, 81.46it/s] 10%|         | 31593/303576 [20:21<54:41, 82.90it/s]                                                       10%|         | 31600/303576 [20:21<54:40, 82.90it/s] 10%|         | 31602/303576 [20:21<54:04, 83.82it/s] 10%|         | 31611/303576 [20:22<53:47, 84.25it/s] 10%|         | 31620/303576 [20:22<53:27, 84.78it/s] 10%|         | 31631/303576 [20:22<50:47, 89.24it/s] 10%|         | 31640/303576 [20:22<51:49, 87.44it/s] 10%|         | 31649/303576 [20:22<51:43, 87.61it/s] 10%|         | 31658/303576 [20:22<51:39, 87.74it/s] 10%|         | 31667/303576 [20:22<51:28, 88.05it/s] 10%|         | 31676/303576 [20:22<51:28, 88.03it/s] 10%|         | 31685/303576 [20:22<51:30, 87.98it/s] 10%|         | 31694/303576 [20:22<51:27, 88.06it/s]                                                       10%|         | 31700/303576 [20:23<51:27, 88.06it/s] 10%|         | 31703/303576 [20:23<51:22, 88.21it/s] 10%|         | 31712/303576 [20:23<51:22, 88.19it/s] 10%|         | 31721/303576 [20:23<51:21, 88.21it/s] 10%|         | 31730/303576 [20:23<51:19, 88.28it/s] 10%|         | 31740/303576 [20:23<49:27, 91.61it/s] 10%|         | 31751/303576 [20:23<47:55, 94.52it/s] 10%|         | 31761/303576 [20:23<48:33, 93.31it/s] 10%|         | 31771/303576 [20:23<49:56, 90.70it/s] 10%|         | 31781/303576 [20:23<49:29, 91.52it/s] 10%|         | 31791/303576 [20:24<48:24, 93.56it/s]                                                       10%|         | 31800/303576 [20:24<48:24, 93.56it/s] 10%|         | 31801/303576 [20:24<48:28, 93.44it/s] 10%|         | 31811/303576 [20:24<47:50, 94.67it/s] 10%|         | 31821/303576 [20:24<47:13, 95.91it/s] 10%|         | 31832/303576 [20:24<46:32, 97.31it/s] 10%|         | 31842/303576 [20:24<46:26, 97.53it/s] 10%|         | 31852/303576 [20:24<46:10, 98.08it/s] 10%|         | 31863/303576 [20:24<45:32, 99.42it/s] 10%|         | 31873/303576 [20:24<46:36, 97.14it/s] 11%|         | 31883/303576 [20:24<49:01, 92.38it/s] 11%|         | 31893/303576 [20:25<51:07, 88.58it/s]                                                       11%|         | 31900/303576 [20:25<51:07, 88.58it/s] 11%|         | 31902/303576 [20:25<52:34, 86.11it/s] 11%|         | 31911/303576 [20:25<53:54, 83.99it/s] 11%|         | 31920/303576 [20:25<54:41, 82.79it/s] 11%|         | 31929/303576 [20:25<55:11, 82.04it/s] 11%|         | 31938/303576 [20:25<56:20, 80.35it/s] 11%|         | 31947/303576 [20:25<58:11, 77.79it/s] 11%|         | 31955/303576 [20:25<59:40, 75.87it/s] 11%|         | 31963/303576 [20:26<1:00:54, 74.33it/s] 11%|         | 31971/303576 [20:26<1:01:30, 73.60it/s] 11%|         | 31980/303576 [20:26<59:33, 76.01it/s]   11%|         | 31988/303576 [20:26<59:12, 76.45it/s] 11%|         | 31996/303576 [20:26<59:12, 76.45it/s]                                                       11%|         | 32000/303576 [20:26<59:12, 76.45it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366805076599121, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.746, 'eval_samples_per_second': 9.936, 'eval_steps_per_second': 0.088, 'epoch': 0.31, 'timestamp': 1762965745.4608836, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7678, 'grad_norm': 0.25846362113952637, 'learning_rate': 4.463863852510533e-05, 'epoch': 0.31, 'timestamp': 1762965747.6626632, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.77, 'grad_norm': 0.227248415350914, 'learning_rate': 4.419445455186378e-05, 'epoch': 0.31, 'timestamp': 1762965749.2682595, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.779, 'grad_norm': 0.31019285321235657, 'learning_rate': 4.375469050289864e-05, 'epoch': 0.31, 'timestamp': 1762965750.8255475, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7775, 'grad_norm': 0.22945116460323334, 'learning_rate': 4.331930239704044e-05, 'epoch': 0.31, 'timestamp': 1762965752.3836966, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.761, 'grad_norm': 0.2104867845773697, 'learning_rate': 4.2888246690761446e-05, 'epoch': 0.31, 'timestamp': 1762965754.0203893, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.76, 'grad_norm': 0.22534653544425964, 'learning_rate': 4.2461480273820814e-05, 'epoch': 0.31, 'timestamp': 1762965755.3521283, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7818, 'grad_norm': 0.2627427577972412, 'learning_rate': 4.2038960464953e-05, 'epoch': 0.31, 'timestamp': 1762965756.4852104, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7781, 'grad_norm': 0.28151965141296387, 'learning_rate': 4.162064500759945e-05, 'epoch': 0.31, 'timestamp': 1762965757.564701, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7645, 'grad_norm': 0.2652498185634613, 'learning_rate': 4.1206492065682205e-05, 'epoch': 0.32, 'timestamp': 1762965758.6406655, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7646, 'grad_norm': 0.21668344736099243, 'learning_rate': 4.079646021941996e-05, 'epoch': 0.32, 'timestamp': 1762965759.958777, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:42:43.370264: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:42:43.381049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965763.394316 1741851 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965763.398442 1741851 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965763.409183 1741851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965763.409200 1741851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965763.409202 1741851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965763.409203 1741851 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:42:43.412667: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:42:45 - TensorFlow version 2.19.1 available.
2025-11-12 16:42:53.273319: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:42:53.284276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965773.297645 1742249 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965773.301564 1742249 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965773.312223 1742249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965773.312238 1742249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965773.312240 1742249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965773.312241 1742249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:42:53.315387: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 11%|         | 32000/303576 [20:40<59:12, 76.45it/s]2025-11-12T16:42:55 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 11%|         | 32000/303576 [20:47<59:12, 76.45it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-32000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-32000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-32000/model.safetensors
 11%|         | 32001/303576 [20:47<67:24:45,  1.12it/s] 11%|         | 32009/303576 [20:48<46:12:28,  1.63it/s] 11%|         | 32017/303576 [20:48<32:03:24,  2.35it/s] 11%|         | 32025/303576 [20:48<22:28:22,  3.36it/s] 11%|         | 32033/303576 [20:48<15:55:21,  4.74it/s] 11%|         | 32041/303576 [20:48<11:25:03,  6.61it/s] 11%|         | 32048/303576 [20:48<8:34:23,  8.80it/s]  11%|         | 32055/303576 [20:48<6:28:48, 11.64it/s] 11%|         | 32062/303576 [20:48<4:56:16, 15.27it/s] 11%|         | 32069/303576 [20:48<3:49:39, 19.70it/s] 11%|         | 32076/303576 [20:49<3:01:32, 24.93it/s] 11%|         | 32083/303576 [20:49<2:28:39, 30.44it/s] 11%|         | 32091/303576 [20:49<2:01:55, 37.11it/s] 11%|         | 32099/303576 [20:49<1:43:33, 43.69it/s]                                                         11%|         | 32100/303576 [20:49<1:43:33, 43.69it/s] 11%|         | 32107/303576 [20:49<1:31:02, 49.70it/s] 11%|         | 32115/303576 [20:49<1:22:29, 54.84it/s] 11%|         | 32123/303576 [20:49<1:16:33, 59.10it/s] 11%|         | 32131/303576 [20:49<1:12:23, 62.49it/s] 11%|         | 32139/303576 [20:49<1:09:34, 65.02it/s] 11%|         | 32147/303576 [20:50<1:07:40, 66.84it/s] 11%|         | 32155/303576 [20:50<1:06:17, 68.25it/s] 11%|         | 32163/303576 [20:50<1:05:30, 69.05it/s] 11%|         | 32171/303576 [20:50<1:05:07, 69.46it/s] 11%|         | 32179/303576 [20:50<1:04:34, 70.06it/s] 11%|         | 32187/303576 [20:50<1:04:13, 70.42it/s] 11%|         | 32195/303576 [20:50<1:04:04, 70.59it/s]                                                         11%|         | 32200/303576 [20:50<1:04:04, 70.59it/s] 11%|         | 32203/303576 [20:50<1:03:53, 70.78it/s] 11%|         | 32211/303576 [20:50<1:03:41, 71.02it/s] 11%|         | 32219/303576 [20:51<1:03:34, 71.13it/s] 11%|         | 32227/303576 [20:51<1:03:31, 71.20it/s] 11%|         | 32235/303576 [20:51<1:03:22, 71.36it/s] 11%|         | 32243/303576 [20:51<1:01:27, 73.59it/s] 11%|         | 32252/303576 [20:51<59:32, 75.95it/s]   11%|         | 32261/303576 [20:51<58:33, 77.22it/s] 11%|         | 32270/303576 [20:51<57:30, 78.63it/s] 11%|         | 32279/303576 [20:51<57:07, 79.15it/s] 11%|         | 32287/303576 [20:51<56:57, 79.37it/s] 11%|         | 32296/303576 [20:52<56:30, 80.01it/s]                                                       11%|         | 32300/303576 [20:52<56:30, 80.01it/s] 11%|         | 32305/303576 [20:52<56:25, 80.12it/s] 11%|         | 32314/303576 [20:52<55:24, 81.60it/s] 11%|         | 32325/303576 [20:52<51:19, 88.08it/s] 11%|         | 32336/303576 [20:52<48:14, 93.71it/s] 11%|         | 32347/303576 [20:52<46:11, 97.85it/s] 11%|         | 32359/303576 [20:52<44:20, 101.95it/s] 11%|         | 32370/303576 [20:52<43:57, 102.84it/s] 11%|         | 32381/303576 [20:52<43:26, 104.06it/s] 11%|         | 32392/303576 [20:52<43:32, 103.82it/s]                                                        11%|         | 32400/303576 [20:53<43:32, 103.82it/s] 11%|         | 32403/303576 [20:53<43:34, 103.72it/s] 11%|         | 32414/303576 [20:53<43:43, 103.35it/s] 11%|         | 32425/303576 [20:53<44:09, 102.32it/s] 11%|         | 32436/303576 [20:53<44:15, 102.09it/s] 11%|         | 32447/303576 [20:53<44:27, 101.64it/s] 11%|         | 32458/303576 [20:53<44:26, 101.68it/s] 11%|         | 32469/303576 [20:53<44:14, 102.13it/s] 11%|         | 32480/303576 [20:53<44:21, 101.86it/s] 11%|         | 32491/303576 [20:53<44:06, 102.45it/s]                                                        11%|         | 32500/303576 [20:54<44:05, 102.45it/s] 11%|         | 32502/303576 [20:54<46:09, 97.86it/s]  11%|         | 32512/303576 [20:54<48:46, 92.63it/s] 11%|         | 32522/303576 [20:54<50:48, 88.91it/s] 11%|         | 32531/303576 [20:54<52:27, 86.12it/s] 11%|         | 32540/303576 [20:54<53:16, 84.79it/s] 11%|         | 32549/303576 [20:54<54:25, 83.00it/s] 11%|         | 32558/303576 [20:54<54:41, 82.58it/s] 11%|         | 32567/303576 [20:54<55:19, 81.64it/s] 11%|         | 32576/303576 [20:55<55:42, 81.08it/s] 11%|         | 32585/303576 [20:55<56:03, 80.57it/s] 11%|         | 32594/303576 [20:55<55:54, 80.77it/s]                                                       11%|         | 32600/303576 [20:55<55:54, 80.77it/s] 11%|         | 32603/303576 [20:55<55:41, 81.08it/s] 11%|         | 32612/303576 [20:55<56:07, 80.47it/s] 11%|         | 32621/303576 [20:55<55:50, 80.86it/s] 11%|         | 32630/303576 [20:55<56:16, 80.24it/s] 11%|         | 32639/303576 [20:55<56:05, 80.50it/s] 11%|         | 32648/303576 [20:55<55:56, 80.72it/s] 11%|         | 32657/303576 [20:56<54:54, 82.23it/s] 11%|         | 32666/303576 [20:56<55:41, 81.08it/s] 11%|         | 32675/303576 [20:56<55:29, 81.36it/s] 11%|         | 32684/303576 [20:56<57:32, 78.46it/s] 11%|         | 32692/303576 [20:56<58:24, 77.30it/s] 11%|         | 32700/303576 [20:56<59:21, 76.05it/s]                                                       11%|         | 32700/303576 [20:56<59:21, 76.05it/s] 11%|         | 32708/303576 [20:56<1:00:14, 74.94it/s] 11%|         | 32716/303576 [20:56<1:00:54, 74.11it/s] 11%|         | 32724/303576 [20:56<1:01:26, 73.48it/s] 11%|         | 32732/303576 [20:57<1:01:46, 73.08it/s] 11%|         | 32740/303576 [20:57<1:02:08, 72.64it/s] 11%|         | 32748/303576 [20:57<1:02:33, 72.16it/s] 11%|         | 32756/303576 [20:57<1:02:53, 71.77it/s] 11%|         | 32764/303576 [20:57<1:03:10, 71.44it/s] 11%|         | 32772/303576 [20:57<1:03:10, 71.44it/s] 11%|         | 32780/303576 [20:57<1:03:15, 71.34it/s] 11%|         | 32788/303576 [20:57<1:03:20, 71.24it/s] 11%|         | 32796/303576 [20:57<1:03:21, 71.23it/s]                                                         11%|         | 32800/303576 [20:57<1:03:21, 71.23it/s] 11%|         | 32804/303576 [20:58<1:03:18, 71.28it/s] 11%|         | 32812/303576 [20:58<1:02:55, 71.72it/s] 11%|         | 32820/303576 [20:58<1:02:50, 71.80it/s] 11%|         | 32828/303576 [20:58<1:02:45, 71.89it/s] 11%|         | 32836/303576 [20:58<1:02:45, 71.90it/s] 11%|         | 32844/303576 [20:58<1:02:36, 72.06it/s] 11%|         | 32852/303576 [20:58<1:02:32, 72.15it/s] 11%|         | 32860/303576 [20:58<1:02:34, 72.11it/s] 11%|         | 32868/303576 [20:58<1:02:42, 71.95it/s] 11%|         | 32876/303576 [20:59<1:02:45, 71.88it/s] 11%|         | 32884/303576 [20:59<1:02:45, 71.89it/s] 11%|         | 32892/303576 [20:59<1:02:51, 71.76it/s] 11%|         | 32900/303576 [20:59<1:02:50, 71.78it/s]                                                         11%|         | 32900/303576 [20:59<1:02:50, 71.78it/s] 11%|         | 32908/303576 [20:59<1:01:41, 73.13it/s] 11%|         | 32916/303576 [20:59<1:01:07, 73.81it/s] 11%|         | 32924/303576 [20:59<1:04:26, 70.01it/s] 11%|         | 32932/303576 [20:59<1:08:12, 66.14it/s] 11%|         | 32939/303576 [20:59<1:12:19, 62.36it/s] 11%|         | 32946/303576 [21:00<1:15:34, 59.68it/s] 11%|         | 32953/303576 [21:00<1:14:21, 60.65it/s] 11%|         | 32961/303576 [21:00<1:10:56, 63.58it/s] 11%|         | 32968/303576 [21:00<1:12:46, 61.98it/s] 11%|         | 32975/303576 [21:00<1:16:10, 59.21it/s] 11%|         | 32981/303576 [21:00<1:17:37, 58.10it/s] 11%|         | 32987/303576 [21:00<1:19:28, 56.75it/s] 11%|         | 32993/303576 [21:00<1:20:52, 55.77it/s] 11%|         | 32999/303576 [21:01<1:21:41, 55.21it/s]                                                         11%|         | 33000/303576 [21:01<1:21:41, 55.21it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7360073924064636, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.3699, 'eval_samples_per_second': 10.576, 'eval_steps_per_second': 0.094, 'epoch': 0.32, 'timestamp': 1762965781.329189, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7642, 'grad_norm': 0.18538154661655426, 'learning_rate': 4.03905084611856e-05, 'epoch': 0.32, 'timestamp': 1762965782.8349862, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.775, 'grad_norm': 0.28938162326812744, 'learning_rate': 3.9988596191405086e-05, 'epoch': 0.32, 'timestamp': 1762965784.236368, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7585, 'grad_norm': 0.2203807681798935, 'learning_rate': 3.959068321449691e-05, 'epoch': 0.32, 'timestamp': 1762965785.5332184, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.769, 'grad_norm': 0.24179349839687347, 'learning_rate': 3.9196729734852266e-05, 'epoch': 0.32, 'timestamp': 1762965786.5111084, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7766, 'grad_norm': 0.20107601583003998, 'learning_rate': 3.8806696352854896e-05, 'epoch': 0.32, 'timestamp': 1762965787.505331, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8005, 'grad_norm': 0.2278587818145752, 'learning_rate': 3.842054406094084e-05, 'epoch': 0.32, 'timestamp': 1762965788.747414, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7714, 'grad_norm': 0.24686376750469208, 'learning_rate': 3.80382342396972e-05, 'epoch': 0.32, 'timestamp': 1762965790.0139334, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.21630440652370453, 'learning_rate': 3.765972865399969e-05, 'epoch': 0.32, 'timestamp': 1762965791.413422, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7731, 'grad_norm': 0.22769951820373535, 'learning_rate': 3.728498944918891e-05, 'epoch': 0.33, 'timestamp': 1762965792.8025424, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7707, 'grad_norm': 0.22008384764194489, 'learning_rate': 3.691397914728428e-05, 'epoch': 0.33, 'timestamp': 1762965794.4764614, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:43:18.592760: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:43:18.603490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965798.616595 1742821 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965798.620664 1742821 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965798.631196 1742821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965798.631213 1742821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965798.631216 1742821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965798.631217 1742821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:43:18.634639: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:43:20 - TensorFlow version 2.19.1 available.
2025-11-12 16:43:29.255364: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:43:29.266034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965809.278838 1743112 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965809.282697 1743112 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965809.293031 1743112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965809.293046 1743112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965809.293048 1743112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965809.293049 1743112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:43:29.296264: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:43:31 - TensorFlow version 2.19.1 available.
 11%|         | 33000/303576 [21:20<1:21:41, 55.21it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                        
                                             [A 11%|         | 33000/303576 [21:23<1:21:41, 55.21it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [A 11%|         | 33001/303576 [21:23<104:18:36,  1.39s/it] 11%|         | 33005/303576 [21:24<78:13:04,  1.04s/it]  11%|         | 33011/303576 [21:24<51:14:19,  1.47it/s] 11%|         | 33016/303576 [21:24<36:37:18,  2.05it/s] 11%|         | 33022/303576 [21:24<24:46:10,  3.03it/s] 11%|         | 33028/303576 [21:24<17:08:18,  4.38it/s] 11%|         | 33034/303576 [21:24<12:06:38,  6.21it/s] 11%|         | 33040/303576 [21:24<8:43:41,  8.61it/s]  11%|         | 33046/303576 [21:24<6:25:45, 11.69it/s] 11%|         | 33053/303576 [21:24<4:40:13, 16.09it/s] 11%|         | 33059/303576 [21:25<3:40:09, 20.48it/s] 11%|         | 33065/303576 [21:25<2:57:47, 25.36it/s] 11%|         | 33071/303576 [21:25<2:27:40, 30.53it/s] 11%|         | 33077/303576 [21:25<2:06:16, 35.70it/s] 11%|         | 33084/303576 [21:25<1:48:50, 41.42it/s] 11%|         | 33091/303576 [21:25<1:38:05, 45.96it/s] 11%|         | 33098/303576 [21:25<1:30:28, 49.82it/s]                                                         11%|         | 33100/303576 [21:25<1:30:28, 49.82it/s] 11%|         | 33105/303576 [21:25<1:25:57, 52.44it/s] 11%|         | 33112/303576 [21:25<1:22:47, 54.45it/s] 11%|         | 33118/303576 [21:26<1:22:05, 54.91it/s] 11%|         | 33124/303576 [21:26<1:22:00, 54.96it/s] 11%|         | 33130/303576 [21:26<1:21:07, 55.56it/s] 11%|         | 33137/303576 [21:26<1:19:23, 56.77it/s] 11%|         | 33144/303576 [21:26<1:17:48, 57.92it/s] 11%|         | 33150/303576 [21:26<1:17:05, 58.47it/s] 11%|         | 33156/303576 [21:26<1:16:50, 58.65it/s] 11%|         | 33164/303576 [21:26<1:11:05, 63.39it/s] 11%|         | 33174/303576 [21:26<1:02:02, 72.64it/s] 11%|         | 33183/303576 [21:27<58:52, 76.55it/s]   11%|         | 33192/303576 [21:27<56:50, 79.28it/s]                                                       11%|         | 33200/303576 [21:27<56:50, 79.28it/s] 11%|         | 33201/303576 [21:27<56:26, 79.83it/s] 11%|         | 33209/303576 [21:27<58:43, 76.73it/s] 11%|         | 33217/303576 [21:27<59:33, 75.66it/s] 11%|         | 33228/303576 [21:27<53:44, 83.84it/s] 11%|         | 33239/303576 [21:27<50:39, 88.93it/s] 11%|         | 33250/303576 [21:27<48:41, 92.54it/s] 11%|         | 33260/303576 [21:27<48:03, 93.75it/s] 11%|         | 33270/303576 [21:27<47:47, 94.28it/s] 11%|         | 33280/303576 [21:28<48:31, 92.83it/s] 11%|         | 33290/303576 [21:28<50:38, 88.95it/s] 11%|         | 33299/303576 [21:28<51:47, 86.96it/s]                                                       11%|         | 33300/303576 [21:28<51:47, 86.96it/s] 11%|         | 33308/303576 [21:28<52:43, 85.44it/s] 11%|         | 33317/303576 [21:28<52:52, 85.20it/s] 11%|         | 33326/303576 [21:28<52:57, 85.05it/s] 11%|         | 33335/303576 [21:28<53:13, 84.62it/s] 11%|         | 33344/303576 [21:28<53:35, 84.05it/s] 11%|         | 33353/303576 [21:28<53:37, 83.99it/s] 11%|         | 33362/303576 [21:29<53:47, 83.72it/s] 11%|         | 33371/303576 [21:29<54:07, 83.19it/s] 11%|         | 33380/303576 [21:29<54:26, 82.72it/s] 11%|         | 33389/303576 [21:29<54:06, 83.22it/s] 11%|         | 33398/303576 [21:29<54:12, 83.07it/s]                                                       11%|         | 33400/303576 [21:29<54:12, 83.07it/s] 11%|         | 33407/303576 [21:29<54:22, 82.81it/s] 11%|         | 33416/303576 [21:29<54:38, 82.41it/s] 11%|         | 33425/303576 [21:29<54:52, 82.06it/s] 11%|         | 33434/303576 [21:29<54:29, 82.61it/s] 11%|         | 33443/303576 [21:30<54:37, 82.43it/s] 11%|         | 33452/303576 [21:30<54:17, 82.91it/s] 11%|         | 33461/303576 [21:30<55:04, 81.74it/s] 11%|         | 33470/303576 [21:30<56:24, 79.80it/s] 11%|         | 33478/303576 [21:30<57:22, 78.46it/s] 11%|         | 33486/303576 [21:30<57:56, 77.69it/s] 11%|         | 33494/303576 [21:30<58:24, 77.08it/s]                                                       11%|         | 33500/303576 [21:30<58:23, 77.08it/s] 11%|         | 33502/303576 [21:30<58:44, 76.63it/s] 11%|         | 33510/303576 [21:30<59:08, 76.11it/s] 11%|         | 33520/303576 [21:31<54:45, 82.20it/s] 11%|         | 33531/303576 [21:31<51:28, 87.43it/s] 11%|         | 33540/303576 [21:31<52:48, 85.22it/s] 11%|         | 33550/303576 [21:31<51:55, 86.66it/s] 11%|         | 33559/303576 [21:31<51:25, 87.50it/s] 11%|         | 33569/303576 [21:31<50:58, 88.29it/s] 11%|         | 33579/303576 [21:31<50:38, 88.85it/s] 11%|         | 33588/303576 [21:31<50:29, 89.11it/s] 11%|         | 33597/303576 [21:31<50:24, 89.27it/s]                                                       11%|         | 33600/303576 [21:31<50:24, 89.27it/s] 11%|         | 33606/303576 [21:31<50:27, 89.16it/s] 11%|         | 33615/303576 [21:32<50:20, 89.39it/s] 11%|         | 33624/303576 [21:32<50:15, 89.53it/s] 11%|         | 33633/303576 [21:32<50:20, 89.36it/s] 11%|         | 33642/303576 [21:32<50:41, 88.75it/s] 11%|         | 33652/303576 [21:32<50:16, 89.48it/s] 11%|         | 33661/303576 [21:32<51:04, 88.07it/s] 11%|         | 33670/303576 [21:32<51:59, 86.52it/s] 11%|         | 33679/303576 [21:32<52:30, 85.67it/s] 11%|         | 33688/303576 [21:32<53:10, 84.59it/s] 11%|         | 33697/303576 [21:33<53:31, 84.04it/s]                                                       11%|         | 33700/303576 [21:33<53:31, 84.04it/s] 11%|         | 33706/303576 [21:33<53:42, 83.76it/s] 11%|         | 33715/303576 [21:33<53:38, 83.84it/s] 11%|         | 33724/303576 [21:33<53:47, 83.61it/s] 11%|         | 33734/303576 [21:33<51:37, 87.11it/s] 11%|         | 33745/303576 [21:33<48:47, 92.17it/s] 11%|         | 33756/303576 [21:33<46:39, 96.40it/s] 11%|         | 33766/303576 [21:33<46:35, 96.51it/s] 11%|         | 33776/303576 [21:33<46:44, 96.19it/s] 11%|         | 33786/303576 [21:33<46:47, 96.10it/s] 11%|         | 33796/303576 [21:34<46:52, 95.92it/s]                                                       11%|         | 33800/303576 [21:34<46:52, 95.92it/s] 11%|         | 33806/303576 [21:34<47:39, 94.33it/s] 11%|         | 33816/303576 [21:34<49:00, 91.73it/s] 11%|         | 33826/303576 [21:34<50:26, 89.12it/s] 11%|         | 33835/303576 [21:34<51:39, 87.01it/s] 11%|         | 33844/303576 [21:34<52:02, 86.39it/s] 11%|         | 33853/303576 [21:34<51:47, 86.81it/s] 11%|         | 33862/303576 [21:34<51:22, 87.50it/s] 11%|         | 33871/303576 [21:34<51:03, 88.03it/s] 11%|         | 33880/303576 [21:35<51:06, 87.94it/s] 11%|         | 33889/303576 [21:35<50:50, 88.40it/s] 11%|         | 33899/303576 [21:35<50:27, 89.07it/s]                                                       11%|         | 33900/303576 [21:35<50:27, 89.07it/s] 11%|         | 33908/303576 [21:35<51:57, 86.49it/s] 11%|         | 33917/303576 [21:35<54:52, 81.89it/s] 11%|         | 33926/303576 [21:35<56:57, 78.91it/s] 11%|         | 33934/303576 [21:35<58:27, 76.88it/s] 11%|         | 33942/303576 [21:35<59:45, 75.20it/s] 11%|         | 33950/303576 [21:35<1:00:57, 73.72it/s] 11%|         | 33958/303576 [21:36<1:01:45, 72.77it/s] 11%|         | 33966/303576 [21:36<1:02:11, 72.26it/s] 11%|         | 33974/303576 [21:36<1:02:32, 71.84it/s] 11%|         | 33982/303576 [21:36<1:02:45, 71.59it/s] 11%|         | 33990/303576 [21:36<1:03:04, 71.23it/s] 11%|         | 33998/303576 [21:36<1:03:28, 70.78it/s]                                                         11%|         | 34000/303576 [21:36<1:03:28, 70.78it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7352466583251953, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.8814, 'eval_samples_per_second': 9.877, 'eval_steps_per_second': 0.087, 'epoch': 0.33, 'timestamp': 1762965817.358416, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7797, 'grad_norm': 0.246749609708786, 'learning_rate': 3.654666064323588e-05, 'epoch': 0.33, 'timestamp': 1762965819.1715755, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7624, 'grad_norm': 0.21651558578014374, 'learning_rate': 3.618299720121364e-05, 'epoch': 0.33, 'timestamp': 1762965820.6463335, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7698, 'grad_norm': 0.31258273124694824, 'learning_rate': 3.582295245093333e-05, 'epoch': 0.33, 'timestamp': 1762965821.775687, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.775, 'grad_norm': 0.24143831431865692, 'learning_rate': 3.5466490384019005e-05, 'epoch': 0.33, 'timestamp': 1762965822.9779782, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7643, 'grad_norm': 0.22043341398239136, 'learning_rate': 3.511357535040193e-05, 'epoch': 0.33, 'timestamp': 1762965824.23829, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7676, 'grad_norm': 0.23662303388118744, 'learning_rate': 3.476417205475509e-05, 'epoch': 0.33, 'timestamp': 1762965825.3653998, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7659, 'grad_norm': 0.30196037888526917, 'learning_rate': 3.441824555296334e-05, 'epoch': 0.33, 'timestamp': 1762965826.5241404, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7695, 'grad_norm': 0.22492311894893646, 'learning_rate': 3.4075761248628575e-05, 'epoch': 0.33, 'timestamp': 1762965827.5841188, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7657, 'grad_norm': 0.2294163703918457, 'learning_rate': 3.3736684889609805e-05, 'epoch': 0.34, 'timestamp': 1762965828.7325377, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7631, 'grad_norm': 0.2697966694831848, 'learning_rate': 3.340098256459739e-05, 'epoch': 0.34, 'timestamp': 1762965830.1263623, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:43:53.570471: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:43:53.581192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965833.594243 1743682 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965833.598240 1743682 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965833.608880 1743682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965833.608898 1743682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965833.608900 1743682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965833.608902 1743682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:43:53.612279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:43:55 - TensorFlow version 2.19.1 available.
2025-11-12 16:44:03.117340: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:44:03.128241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965843.141024 1743969 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965843.144737 1743969 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965843.155199 1743969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965843.155213 1743969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965843.155215 1743969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965843.155217 1743969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:44:03.158287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 11%|         | 34000/303576 [21:50<1:03:28, 70.78it/s]2025-11-12T16:44:05 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                        
                                             [A 11%|         | 34000/303576 [21:57<1:03:28, 70.78it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-34000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-34000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-34000/model.safetensors
 11%|         | 34001/303576 [21:57<73:51:24,  1.01it/s] 11%|         | 34007/303576 [21:57<53:22:37,  1.40it/s] 11%|         | 34014/303576 [21:58<36:44:43,  2.04it/s] 11%|         | 34021/303576 [21:58<25:40:57,  2.92it/s] 11%|         | 34027/303576 [21:58<18:54:54,  3.96it/s] 11%|         | 34033/303576 [21:58<13:55:03,  5.38it/s] 11%|         | 34039/303576 [21:58<10:16:09,  7.29it/s] 11%|         | 34045/303576 [21:58<7:39:04,  9.79it/s]  11%|         | 34051/303576 [21:58<5:47:03, 12.94it/s] 11%|         | 34057/303576 [21:58<4:27:48, 16.77it/s] 11%|         | 34063/303576 [21:58<3:31:19, 21.26it/s] 11%|         | 34069/303576 [21:59<2:51:30, 26.19it/s] 11%|         | 34075/303576 [21:59<2:23:11, 31.37it/s] 11%|         | 34081/303576 [21:59<2:03:35, 36.34it/s] 11%|         | 34087/303576 [21:59<1:49:28, 41.03it/s] 11%|         | 34093/303576 [21:59<1:40:15, 44.80it/s] 11%|         | 34099/303576 [21:59<1:33:42, 47.93it/s]                                                         11%|         | 34100/303576 [21:59<1:33:42, 47.93it/s] 11%|         | 34105/303576 [21:59<1:29:28, 50.19it/s] 11%|         | 34111/303576 [21:59<1:25:53, 52.29it/s] 11%|         | 34117/303576 [21:59<1:23:27, 53.82it/s] 11%|         | 34123/303576 [22:00<1:21:39, 54.99it/s] 11%|         | 34129/303576 [22:00<1:20:30, 55.78it/s] 11%|         | 34135/303576 [22:00<1:20:03, 56.09it/s] 11%|         | 34141/303576 [22:00<1:19:18, 56.63it/s] 11%|         | 34147/303576 [22:00<1:19:25, 56.54it/s] 11%|        | 34153/303576 [22:00<1:19:19, 56.61it/s] 11%|        | 34159/303576 [22:00<1:18:41, 57.06it/s] 11%|        | 34165/303576 [22:00<1:18:48, 56.98it/s] 11%|        | 34171/303576 [22:00<1:18:23, 57.27it/s] 11%|        | 34177/303576 [22:00<1:18:39, 57.09it/s] 11%|        | 34183/303576 [22:01<1:18:44, 57.02it/s] 11%|        | 34189/303576 [22:01<1:18:22, 57.28it/s] 11%|        | 34195/303576 [22:01<1:18:17, 57.35it/s]                                                         11%|        | 34200/303576 [22:01<1:18:17, 57.35it/s] 11%|        | 34201/303576 [22:01<1:18:44, 57.01it/s] 11%|        | 34207/303576 [22:01<1:18:46, 57.00it/s] 11%|        | 34213/303576 [22:01<1:19:01, 56.81it/s] 11%|        | 34219/303576 [22:01<1:18:40, 57.07it/s] 11%|        | 34225/303576 [22:01<1:18:19, 57.31it/s] 11%|        | 34231/303576 [22:01<1:18:17, 57.34it/s] 11%|        | 34237/303576 [22:02<1:18:32, 57.15it/s] 11%|        | 34243/303576 [22:02<1:18:14, 57.38it/s] 11%|        | 34249/303576 [22:02<1:18:01, 57.53it/s] 11%|        | 34255/303576 [22:02<1:18:06, 57.46it/s] 11%|        | 34261/303576 [22:02<1:18:24, 57.24it/s] 11%|        | 34267/303576 [22:02<1:19:03, 56.78it/s] 11%|        | 34273/303576 [22:02<1:18:38, 57.07it/s] 11%|        | 34279/303576 [22:02<1:18:57, 56.84it/s] 11%|        | 34285/303576 [22:02<1:19:10, 56.68it/s] 11%|        | 34291/303576 [22:02<1:19:16, 56.62it/s] 11%|        | 34297/303576 [22:03<1:19:11, 56.67it/s]                                                         11%|        | 34300/303576 [22:03<1:19:11, 56.67it/s] 11%|        | 34303/303576 [22:03<1:19:19, 56.57it/s] 11%|        | 34309/303576 [22:03<1:19:21, 56.56it/s] 11%|        | 34315/303576 [22:03<1:19:15, 56.62it/s] 11%|        | 34321/303576 [22:03<1:19:20, 56.56it/s] 11%|        | 34327/303576 [22:03<1:19:17, 56.59it/s] 11%|        | 34333/303576 [22:03<1:18:34, 57.10it/s] 11%|        | 34339/303576 [22:03<1:21:10, 55.28it/s] 11%|        | 34345/303576 [22:03<1:22:19, 54.51it/s] 11%|        | 34351/303576 [22:04<1:23:04, 54.01it/s] 11%|        | 34357/303576 [22:04<1:23:50, 53.51it/s] 11%|        | 34363/303576 [22:04<1:23:50, 53.51it/s] 11%|        | 34369/303576 [22:04<1:24:29, 53.11it/s] 11%|        | 34375/303576 [22:04<1:24:42, 52.96it/s] 11%|        | 34381/303576 [22:04<1:25:01, 52.76it/s] 11%|        | 34387/303576 [22:04<1:24:53, 52.85it/s] 11%|        | 34393/303576 [22:04<1:25:08, 52.69it/s] 11%|        | 34399/303576 [22:04<1:26:29, 51.87it/s]                                                         11%|        | 34400/303576 [22:04<1:26:29, 51.87it/s] 11%|        | 34405/303576 [22:05<1:26:09, 52.07it/s] 11%|        | 34411/303576 [22:05<1:25:46, 52.30it/s] 11%|        | 34417/303576 [22:05<1:25:51, 52.25it/s] 11%|        | 34423/303576 [22:05<1:25:55, 52.21it/s] 11%|        | 34429/303576 [22:05<1:25:51, 52.25it/s] 11%|        | 34435/303576 [22:05<1:25:48, 52.28it/s] 11%|        | 34441/303576 [22:05<1:25:31, 52.45it/s] 11%|        | 34447/303576 [22:05<1:26:05, 52.10it/s] 11%|        | 34453/303576 [22:05<1:25:42, 52.33it/s] 11%|        | 34459/303576 [22:06<1:24:50, 52.87it/s] 11%|        | 34465/303576 [22:06<1:23:40, 53.60it/s] 11%|        | 34471/303576 [22:06<1:22:24, 54.42it/s] 11%|        | 34477/303576 [22:06<1:21:28, 55.04it/s] 11%|        | 34483/303576 [22:06<1:19:35, 56.34it/s] 11%|        | 34490/303576 [22:06<1:17:57, 57.53it/s] 11%|        | 34496/303576 [22:06<1:17:01, 58.22it/s]                                                         11%|        | 34500/303576 [22:06<1:17:01, 58.22it/s] 11%|        | 34502/303576 [22:06<1:16:38, 58.51it/s] 11%|        | 34508/303576 [22:06<1:16:15, 58.80it/s] 11%|        | 34514/303576 [22:07<1:16:02, 58.97it/s] 11%|        | 34520/303576 [22:07<1:16:39, 58.50it/s] 11%|        | 34528/303576 [22:07<1:09:23, 64.62it/s] 11%|        | 34537/303576 [22:07<1:03:42, 70.38it/s] 11%|        | 34546/303576 [22:07<1:00:20, 74.30it/s] 11%|        | 34555/303576 [22:07<58:08, 77.11it/s]   11%|        | 34564/303576 [22:07<56:07, 79.88it/s] 11%|        | 34573/303576 [22:07<55:21, 80.99it/s] 11%|        | 34582/303576 [22:07<54:38, 82.05it/s] 11%|        | 34591/303576 [22:07<53:46, 83.38it/s] 11%|        | 34600/303576 [22:08<53:02, 84.52it/s]                                                       11%|        | 34600/303576 [22:08<53:02, 84.52it/s] 11%|        | 34609/303576 [22:08<52:53, 84.76it/s] 11%|        | 34618/303576 [22:08<52:29, 85.40it/s] 11%|        | 34627/303576 [22:08<52:42, 85.04it/s] 11%|        | 34636/303576 [22:08<52:05, 86.06it/s] 11%|        | 34645/303576 [22:08<52:58, 84.60it/s] 11%|        | 34654/303576 [22:08<52:56, 84.66it/s] 11%|        | 34663/303576 [22:08<53:22, 83.98it/s] 11%|        | 34672/303576 [22:08<53:12, 84.24it/s] 11%|        | 34681/303576 [22:09<53:22, 83.97it/s] 11%|        | 34690/303576 [22:09<53:14, 84.17it/s] 11%|        | 34699/303576 [22:09<53:17, 84.10it/s]                                                       11%|        | 34700/303576 [22:09<53:17, 84.10it/s] 11%|        | 34708/303576 [22:09<52:50, 84.82it/s] 11%|        | 34717/303576 [22:09<52:52, 84.74it/s] 11%|        | 34726/303576 [22:09<52:25, 85.47it/s] 11%|        | 34735/303576 [22:09<52:18, 85.67it/s] 11%|        | 34744/303576 [22:09<52:07, 85.97it/s] 11%|        | 34753/303576 [22:09<52:16, 85.72it/s] 11%|        | 34762/303576 [22:10<52:09, 85.89it/s] 11%|        | 34771/303576 [22:10<52:13, 85.79it/s] 11%|        | 34780/303576 [22:10<52:12, 85.82it/s] 11%|        | 34789/303576 [22:10<52:00, 86.13it/s] 11%|        | 34798/303576 [22:10<51:55, 86.27it/s]                                                       11%|        | 34800/303576 [22:10<51:55, 86.27it/s] 11%|        | 34807/303576 [22:10<51:46, 86.52it/s] 11%|        | 34816/303576 [22:10<51:25, 87.10it/s] 11%|        | 34825/303576 [22:10<51:00, 87.80it/s] 11%|        | 34834/303576 [22:10<51:08, 87.58it/s] 11%|        | 34843/303576 [22:10<51:18, 87.29it/s] 11%|        | 34852/303576 [22:11<51:46, 86.50it/s] 11%|        | 34861/303576 [22:11<51:57, 86.19it/s] 11%|        | 34870/303576 [22:11<52:25, 85.42it/s] 11%|        | 34879/303576 [22:11<53:13, 84.13it/s] 11%|        | 34888/303576 [22:11<53:59, 82.95it/s] 11%|        | 34897/303576 [22:11<55:35, 80.54it/s]                                                       11%|        | 34900/303576 [22:11<55:35, 80.54it/s] 11%|        | 34906/303576 [22:11<56:42, 78.96it/s] 12%|        | 34914/303576 [22:11<56:37, 79.07it/s] 12%|        | 34922/303576 [22:11<56:43, 78.94it/s] 12%|        | 34931/303576 [22:12<55:24, 80.81it/s] 12%|        | 34940/303576 [22:12<54:40, 81.89it/s] 12%|        | 34949/303576 [22:12<54:04, 82.79it/s] 12%|        | 34958/303576 [22:12<54:15, 82.52it/s] 12%|        | 34967/303576 [22:12<55:12, 81.10it/s] 12%|        | 34976/303576 [22:12<56:04, 79.83it/s] 12%|        | 34984/303576 [22:12<56:55, 78.64it/s] 12%|        | 34992/303576 [22:12<57:36, 77.70it/s] 12%|        | 35000/303576 [22:12<58:05, 77.05it/s]                                                       12%|        | 35000/303576 [22:12<58:05, 77.05it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7359920144081116, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.1178, 'eval_samples_per_second': 10.702, 'eval_steps_per_second': 0.095, 'epoch': 0.34, 'timestamp': 1762965851.2446394, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7651, 'grad_norm': 0.23069095611572266, 'learning_rate': 3.3071927892510944e-05, 'epoch': 0.34, 'timestamp': 1762965853.0597875, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7645, 'grad_norm': 0.20420671999454498, 'learning_rate': 3.2742840339229205e-05, 'epoch': 0.34, 'timestamp': 1762965854.8047354, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7729, 'grad_norm': 0.311044305562973, 'learning_rate': 3.2417027424731036e-05, 'epoch': 0.34, 'timestamp': 1762965856.560053, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7725, 'grad_norm': 0.2188156098127365, 'learning_rate': 3.2094456564195035e-05, 'epoch': 0.34, 'timestamp': 1762965858.423208, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7795, 'grad_norm': 0.25300273299217224, 'learning_rate': 3.177509549704028e-05, 'epoch': 0.34, 'timestamp': 1762965860.2489014, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7666, 'grad_norm': 0.21153582632541656, 'learning_rate': 3.145891228369993e-05, 'epoch': 0.34, 'timestamp': 1762965861.5401483, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7639, 'grad_norm': 0.22431211173534393, 'learning_rate': 3.1145875302426976e-05, 'epoch': 0.34, 'timestamp': 1762965862.7222302, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7701, 'grad_norm': 0.24139802157878876, 'learning_rate': 3.0835953246131795e-05, 'epoch': 0.34, 'timestamp': 1762965863.8831391, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7724, 'grad_norm': 0.2175307273864746, 'learning_rate': 3.0529115119250834e-05, 'epoch': 0.34, 'timestamp': 1762965865.0743268, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7614, 'grad_norm': 0.22219538688659668, 'learning_rate': 3.022533023464706e-05, 'epoch': 0.35, 'timestamp': 1762965866.3344831, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:44:30.181399: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:44:30.192498: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965870.205871 1744541 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965870.209967 1744541 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965870.220695 1744541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965870.220713 1744541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965870.220715 1744541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965870.220716 1744541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:44:30.224140: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:44:32 - TensorFlow version 2.19.1 available.
2025-11-12 16:44:40.786161: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:44:40.796797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965880.809536 1744831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965880.813340 1744831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965880.823708 1744831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965880.823727 1744831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965880.823729 1744831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965880.823731 1744831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:44:40.826951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:44:42 - TensorFlow version 2.19.1 available.
 12%|        | 35000/303576 [22:30<58:05, 77.05it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 12%|        | 35000/303576 [22:35<58:05, 77.05it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [A 12%|        | 35001/303576 [22:35<83:11:36,  1.12s/it] 12%|        | 35006/303576 [22:35<62:07:28,  1.20it/s] 12%|        | 35013/303576 [22:35<41:22:37,  1.80it/s] 12%|        | 35020/303576 [22:35<28:13:19,  2.64it/s] 12%|        | 35027/303576 [22:35<19:40:13,  3.79it/s] 12%|        | 35033/303576 [22:36<14:35:16,  5.11it/s] 12%|        | 35039/303576 [22:36<10:51:35,  6.87it/s] 12%|        | 35045/303576 [22:36<8:05:37,  9.22it/s]  12%|        | 35051/303576 [22:36<6:05:27, 12.25it/s] 12%|        | 35057/303576 [22:36<4:40:08, 15.98it/s] 12%|        | 35063/303576 [22:36<3:39:16, 20.41it/s] 12%|        | 35070/303576 [22:36<2:51:18, 26.12it/s] 12%|        | 35076/303576 [22:36<2:23:31, 31.18it/s] 12%|        | 35082/303576 [22:36<2:03:48, 36.14it/s] 12%|        | 35088/303576 [22:36<1:49:34, 40.83it/s] 12%|        | 35094/303576 [22:37<1:40:04, 44.71it/s] 12%|        | 35100/303576 [22:37<1:33:39, 47.78it/s]                                                         12%|        | 35100/303576 [22:37<1:33:39, 47.78it/s] 12%|        | 35106/303576 [22:37<1:28:30, 50.56it/s] 12%|        | 35112/303576 [22:37<1:26:21, 51.81it/s] 12%|        | 35119/303576 [22:37<1:19:15, 56.46it/s] 12%|        | 35126/303576 [22:37<1:14:43, 59.88it/s] 12%|        | 35134/303576 [22:37<1:11:07, 62.90it/s] 12%|        | 35142/303576 [22:37<1:08:44, 65.08it/s] 12%|        | 35150/303576 [22:37<1:07:21, 66.42it/s] 12%|        | 35157/303576 [22:38<1:06:33, 67.21it/s] 12%|        | 35164/303576 [22:38<1:07:02, 66.74it/s] 12%|        | 35171/303576 [22:38<1:06:17, 67.48it/s] 12%|        | 35178/303576 [22:38<1:06:30, 67.27it/s] 12%|        | 35185/303576 [22:38<1:06:24, 67.36it/s] 12%|        | 35192/303576 [22:38<1:06:37, 67.13it/s] 12%|        | 35199/303576 [22:38<1:06:35, 67.16it/s]                                                         12%|        | 35200/303576 [22:38<1:06:35, 67.16it/s] 12%|        | 35206/303576 [22:38<1:06:44, 67.01it/s] 12%|        | 35214/303576 [22:38<1:05:08, 68.66it/s] 12%|        | 35222/303576 [22:39<1:04:17, 69.56it/s] 12%|        | 35230/303576 [22:39<1:03:56, 69.94it/s] 12%|        | 35238/303576 [22:39<1:01:41, 72.49it/s] 12%|        | 35247/303576 [22:39<59:10, 75.57it/s]   12%|        | 35256/303576 [22:39<57:47, 77.39it/s] 12%|        | 35265/303576 [22:39<56:36, 78.99it/s] 12%|        | 35274/303576 [22:39<55:49, 80.09it/s] 12%|        | 35283/303576 [22:39<55:19, 80.82it/s] 12%|        | 35292/303576 [22:39<55:08, 81.08it/s]                                                       12%|        | 35300/303576 [22:39<55:08, 81.08it/s] 12%|        | 35301/303576 [22:40<54:55, 81.41it/s] 12%|        | 35310/303576 [22:40<54:38, 81.82it/s] 12%|        | 35319/303576 [22:40<54:01, 82.75it/s] 12%|        | 35328/303576 [22:40<53:18, 83.86it/s] 12%|        | 35337/303576 [22:40<52:53, 84.52it/s] 12%|        | 35346/303576 [22:40<53:40, 83.28it/s] 12%|        | 35355/303576 [22:40<53:40, 83.28it/s] 12%|        | 35364/303576 [22:40<57:10, 78.18it/s] 12%|        | 35372/303576 [22:40<58:10, 76.84it/s] 12%|        | 35381/303576 [22:40<56:34, 79.02it/s] 12%|        | 35390/303576 [22:41<55:43, 80.22it/s] 12%|        | 35399/303576 [22:41<54:42, 81.69it/s]                                                       12%|        | 35400/303576 [22:41<54:42, 81.69it/s] 12%|        | 35408/303576 [22:41<54:23, 82.18it/s] 12%|        | 35417/303576 [22:41<54:27, 82.07it/s] 12%|        | 35426/303576 [22:41<54:51, 81.46it/s] 12%|        | 35435/303576 [22:41<54:34, 81.88it/s] 12%|        | 35444/303576 [22:41<54:45, 81.61it/s] 12%|        | 35453/303576 [22:41<54:01, 82.72it/s] 12%|        | 35462/303576 [22:41<54:13, 82.40it/s] 12%|        | 35471/303576 [22:42<53:25, 83.63it/s] 12%|        | 35481/303576 [22:42<51:03, 87.51it/s] 12%|        | 35492/303576 [22:42<48:20, 92.43it/s]                                                       12%|        | 35500/303576 [22:42<48:20, 92.43it/s] 12%|        | 35502/303576 [22:42<47:17, 94.47it/s] 12%|        | 35512/303576 [22:42<50:49, 87.90it/s] 12%|        | 35521/303576 [22:42<52:40, 84.81it/s] 12%|        | 35530/303576 [22:42<53:11, 83.98it/s] 12%|        | 35539/303576 [22:42<53:08, 84.05it/s] 12%|        | 35548/303576 [22:42<52:56, 84.39it/s] 12%|        | 35557/303576 [22:43<52:51, 84.51it/s] 12%|        | 35566/303576 [22:43<52:41, 84.78it/s] 12%|        | 35575/303576 [22:43<52:26, 85.16it/s] 12%|        | 35584/303576 [22:43<53:22, 83.68it/s] 12%|        | 35593/303576 [22:43<54:02, 82.66it/s]                                                       12%|        | 35600/303576 [22:43<54:01, 82.66it/s] 12%|        | 35602/303576 [22:43<54:05, 82.57it/s] 12%|        | 35611/303576 [22:43<54:34, 81.84it/s] 12%|        | 35620/303576 [22:43<54:32, 81.88it/s] 12%|        | 35629/303576 [22:43<54:52, 81.39it/s] 12%|        | 35638/303576 [22:44<54:44, 81.57it/s] 12%|        | 35647/303576 [22:44<55:01, 81.14it/s] 12%|        | 35656/303576 [22:44<54:28, 81.96it/s] 12%|        | 35665/303576 [22:44<54:35, 81.80it/s] 12%|        | 35674/303576 [22:44<55:03, 81.10it/s] 12%|        | 35683/303576 [22:44<54:46, 81.50it/s] 12%|        | 35692/303576 [22:44<55:13, 80.84it/s]                                                       12%|        | 35700/303576 [22:44<55:13, 80.84it/s] 12%|        | 35701/303576 [22:44<54:57, 81.24it/s] 12%|        | 35710/303576 [22:44<55:11, 80.89it/s] 12%|        | 35719/303576 [22:45<54:52, 81.35it/s] 12%|        | 35728/303576 [22:45<55:08, 80.95it/s] 12%|        | 35737/303576 [22:45<54:56, 81.24it/s] 12%|        | 35746/303576 [22:45<55:19, 80.67it/s] 12%|        | 35755/303576 [22:45<55:02, 81.09it/s] 12%|        | 35764/303576 [22:45<55:18, 80.70it/s] 12%|        | 35773/303576 [22:45<54:57, 81.21it/s] 12%|        | 35782/303576 [22:45<55:17, 80.71it/s] 12%|        | 35791/303576 [22:45<54:46, 81.49it/s]                                                       12%|        | 35800/303576 [22:46<54:46, 81.49it/s] 12%|        | 35801/303576 [22:46<52:48, 84.51it/s] 12%|        | 35811/303576 [22:46<50:53, 87.70it/s] 12%|        | 35821/303576 [22:46<49:53, 89.44it/s] 12%|        | 35830/303576 [22:46<51:17, 86.99it/s] 12%|        | 35839/303576 [22:46<52:08, 85.59it/s] 12%|        | 35848/303576 [22:46<53:05, 84.04it/s] 12%|        | 35857/303576 [22:46<53:15, 83.77it/s] 12%|        | 35866/303576 [22:46<54:00, 82.62it/s] 12%|        | 35875/303576 [22:46<54:01, 82.58it/s] 12%|        | 35884/303576 [22:47<55:16, 80.72it/s] 12%|        | 35893/303576 [22:47<57:11, 78.02it/s]                                                       12%|        | 35900/303576 [22:47<57:11, 78.02it/s] 12%|        | 35901/303576 [22:47<58:55, 75.72it/s] 12%|        | 35909/303576 [22:47<1:00:09, 74.16it/s] 12%|        | 35917/303576 [22:47<1:00:08, 74.17it/s] 12%|        | 35927/303576 [22:47<55:41, 80.10it/s]   12%|        | 35936/303576 [22:47<54:00, 82.59it/s] 12%|        | 35945/303576 [22:47<53:35, 83.24it/s] 12%|        | 35954/303576 [22:47<54:35, 81.70it/s] 12%|        | 35963/303576 [22:48<54:40, 81.59it/s] 12%|        | 35972/303576 [22:48<54:47, 81.39it/s] 12%|        | 35981/303576 [22:48<54:57, 81.15it/s] 12%|        | 35990/303576 [22:48<55:52, 79.82it/s] 12%|        | 35998/303576 [22:48<56:45, 78.57it/s]                                                       12%|        | 36000/303576 [22:48<56:45, 78.57it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7376421093940735, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4962, 'eval_samples_per_second': 10.046, 'eval_steps_per_second': 0.089, 'epoch': 0.35, 'timestamp': 1762965888.831117, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7545, 'grad_norm': 0.27143916487693787, 'learning_rate': 2.992456821054065e-05, 'epoch': 0.35, 'timestamp': 1762965890.6494782, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7648, 'grad_norm': 0.21951182186603546, 'learning_rate': 2.962679896747061e-05, 'epoch': 0.35, 'timestamp': 1762965892.1506872, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7563, 'grad_norm': 0.21887041628360748, 'learning_rate': 2.93319927252865e-05, 'epoch': 0.35, 'timestamp': 1762965893.4305882, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7614, 'grad_norm': 0.2515031099319458, 'learning_rate': 2.904012000017004e-05, 'epoch': 0.35, 'timestamp': 1762965894.6595023, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7674, 'grad_norm': 0.22390487790107727, 'learning_rate': 2.8751151601686438e-05, 'epoch': 0.35, 'timestamp': 1762965895.8030984, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7741, 'grad_norm': 0.2644447982311249, 'learning_rate': 2.8465058629865048e-05, 'epoch': 0.35, 'timestamp': 1762965897.0202913, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7672, 'grad_norm': 0.22459891438484192, 'learning_rate': 2.818181247230903e-05, 'epoch': 0.35, 'timestamp': 1762965898.2531564, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7735, 'grad_norm': 0.20961228013038635, 'learning_rate': 2.7901384801333805e-05, 'epoch': 0.35, 'timestamp': 1762965899.4728942, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7818, 'grad_norm': 0.22396832704544067, 'learning_rate': 2.762374757113401e-05, 'epoch': 0.35, 'timestamp': 1762965900.6994293, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7793, 'grad_norm': 0.2697199583053589, 'learning_rate': 2.7348873014978613e-05, 'epoch': 0.36, 'timestamp': 1762965901.9434688, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:45:05.266939: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:45:05.278046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965905.291626 1745404 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965905.295818 1745404 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965905.306672 1745404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965905.306700 1745404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965905.306703 1745404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965905.306705 1745404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:45:05.310194: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:45:07 - TensorFlow version 2.19.1 available.
 12%|        | 36000/303576 [23:00<56:45, 78.57it/s]2025-11-12 16:45:14.846337: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:45:14.857040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965914.869762 1745694 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965914.873544 1745694 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965914.883882 1745694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965914.883900 1745694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965914.883901 1745694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965914.883903 1745694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:45:14.887075: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:45:16 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 12%|        | 36000/303576 [23:09<56:45, 78.57it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-36000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-36000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-36000/model.safetensors
 12%|        | 36001/303576 [23:09<67:56:53,  1.09it/s] 12%|        | 36006/303576 [23:09<52:21:33,  1.42it/s] 12%|        | 36013/303576 [23:09<36:07:05,  2.06it/s] 12%|        | 36020/303576 [23:09<25:09:12,  2.95it/s] 12%|        | 36027/303576 [23:09<17:43:41,  4.19it/s] 12%|        | 36034/303576 [23:10<12:38:49,  5.88it/s] 12%|        | 36041/303576 [23:10<9:08:42,  8.13it/s]  12%|        | 36048/303576 [23:10<6:42:08, 11.09it/s] 12%|        | 36055/303576 [23:10<5:00:22, 14.84it/s] 12%|        | 36062/303576 [23:10<3:49:31, 19.43it/s] 12%|        | 36069/303576 [23:10<3:00:05, 24.76it/s] 12%|        | 36076/303576 [23:10<2:25:39, 30.61it/s] 12%|        | 36083/303576 [23:10<2:01:35, 36.66it/s] 12%|        | 36090/303576 [23:10<1:44:59, 42.46it/s] 12%|        | 36097/303576 [23:11<1:33:22, 47.74it/s]                                                         12%|        | 36100/303576 [23:11<1:33:22, 47.74it/s] 12%|        | 36104/303576 [23:11<1:25:04, 52.40it/s] 12%|        | 36111/303576 [23:11<1:19:02, 56.40it/s] 12%|        | 36118/303576 [23:11<1:14:56, 59.48it/s] 12%|        | 36125/303576 [23:11<1:12:19, 61.63it/s] 12%|        | 36132/303576 [23:11<1:11:01, 62.75it/s] 12%|        | 36139/303576 [23:11<1:09:05, 64.51it/s] 12%|        | 36147/303576 [23:11<1:07:00, 66.52it/s] 12%|        | 36155/303576 [23:11<1:05:40, 67.86it/s] 12%|        | 36163/303576 [23:11<1:04:54, 68.66it/s] 12%|        | 36171/303576 [23:12<1:04:17, 69.33it/s] 12%|        | 36179/303576 [23:12<1:03:59, 69.64it/s] 12%|        | 36187/303576 [23:12<1:03:56, 69.70it/s] 12%|        | 36196/303576 [23:12<1:00:48, 73.29it/s]                                                         12%|        | 36200/303576 [23:12<1:00:47, 73.29it/s] 12%|        | 36205/303576 [23:12<58:45, 75.83it/s]   12%|        | 36213/303576 [23:12<58:04, 76.73it/s] 12%|        | 36221/303576 [23:12<58:23, 76.32it/s] 12%|        | 36229/303576 [23:12<58:25, 76.26it/s] 12%|        | 36237/303576 [23:12<58:12, 76.55it/s] 12%|        | 36245/303576 [23:13<58:21, 76.36it/s] 12%|        | 36253/303576 [23:13<58:22, 76.31it/s] 12%|        | 36261/303576 [23:13<58:13, 76.52it/s] 12%|        | 36269/303576 [23:13<57:53, 76.96it/s] 12%|        | 36278/303576 [23:13<56:21, 79.06it/s] 12%|        | 36288/303576 [23:13<52:56, 84.14it/s] 12%|        | 36297/303576 [23:13<52:09, 85.42it/s]                                                       12%|        | 36300/303576 [23:13<52:09, 85.42it/s] 12%|        | 36306/303576 [23:13<53:36, 83.09it/s] 12%|        | 36315/303576 [23:13<54:48, 81.27it/s] 12%|        | 36324/303576 [23:14<55:35, 80.12it/s] 12%|        | 36333/303576 [23:14<57:08, 77.94it/s] 12%|        | 36341/303576 [23:14<58:48, 75.75it/s] 12%|        | 36349/303576 [23:14<59:54, 74.35it/s] 12%|        | 36357/303576 [23:14<1:00:47, 73.26it/s] 12%|        | 36365/303576 [23:14<1:01:23, 72.54it/s] 12%|        | 36373/303576 [23:14<1:01:51, 72.00it/s] 12%|        | 36381/303576 [23:14<1:02:09, 71.64it/s] 12%|        | 36389/303576 [23:14<1:02:20, 71.43it/s] 12%|        | 36397/303576 [23:15<1:01:46, 72.08it/s]                                                         12%|        | 36400/303576 [23:15<1:01:46, 72.08it/s] 12%|        | 36405/303576 [23:15<1:02:12, 71.58it/s] 12%|        | 36413/303576 [23:15<1:03:05, 70.58it/s] 12%|        | 36421/303576 [23:15<1:03:42, 69.89it/s] 12%|        | 36428/303576 [23:15<1:03:48, 69.78it/s] 12%|        | 36435/303576 [23:15<1:04:34, 68.95it/s] 12%|        | 36442/303576 [23:15<1:04:28, 69.05it/s] 12%|        | 36449/303576 [23:15<1:05:01, 68.46it/s] 12%|        | 36457/303576 [23:15<1:04:40, 68.85it/s] 12%|        | 36465/303576 [23:16<1:04:20, 69.20it/s] 12%|        | 36473/303576 [23:16<1:04:04, 69.48it/s] 12%|        | 36481/303576 [23:16<1:04:17, 69.24it/s] 12%|        | 36489/303576 [23:16<1:04:20, 69.18it/s] 12%|        | 36497/303576 [23:16<1:04:07, 69.42it/s]                                                         12%|        | 36500/303576 [23:16<1:04:07, 69.42it/s] 12%|        | 36505/303576 [23:16<1:04:06, 69.43it/s] 12%|        | 36513/303576 [23:16<1:04:06, 69.44it/s] 12%|        | 36521/303576 [23:16<1:04:01, 69.52it/s] 12%|        | 36529/303576 [23:16<1:02:25, 71.30it/s] 12%|        | 36538/303576 [23:17<59:51, 74.35it/s]   12%|        | 36546/303576 [23:17<1:00:52, 73.10it/s] 12%|        | 36554/303576 [23:17<1:01:47, 72.03it/s] 12%|        | 36562/303576 [23:17<1:02:27, 71.24it/s] 12%|        | 36570/303576 [23:17<1:02:44, 70.93it/s] 12%|        | 36578/303576 [23:17<1:03:03, 70.57it/s] 12%|        | 36586/303576 [23:17<1:03:16, 70.33it/s] 12%|        | 36594/303576 [23:17<1:03:48, 69.73it/s]                                                         12%|        | 36600/303576 [23:17<1:03:48, 69.73it/s] 12%|        | 36601/303576 [23:17<1:04:12, 69.31it/s] 12%|        | 36609/303576 [23:18<1:03:47, 69.75it/s] 12%|        | 36617/303576 [23:18<1:03:22, 70.20it/s] 12%|        | 36625/303576 [23:18<1:03:07, 70.48it/s] 12%|        | 36633/303576 [23:18<1:03:01, 70.59it/s] 12%|        | 36641/303576 [23:18<1:03:02, 70.57it/s] 12%|        | 36649/303576 [23:18<1:03:10, 70.43it/s] 12%|        | 36657/303576 [23:18<1:03:02, 70.56it/s] 12%|        | 36665/303576 [23:18<1:03:17, 70.29it/s] 12%|        | 36673/303576 [23:18<1:03:42, 69.82it/s] 12%|        | 36680/303576 [23:19<1:03:50, 69.68it/s] 12%|        | 36687/303576 [23:19<1:04:45, 68.69it/s] 12%|        | 36694/303576 [23:19<1:04:36, 68.85it/s]                                                         12%|        | 36700/303576 [23:19<1:04:36, 68.85it/s] 12%|        | 36701/303576 [23:19<1:04:30, 68.96it/s] 12%|        | 36709/303576 [23:19<1:04:12, 69.27it/s] 12%|        | 36717/303576 [23:19<1:03:51, 69.64it/s] 12%|        | 36725/303576 [23:19<1:03:27, 70.08it/s] 12%|        | 36733/303576 [23:19<1:03:18, 70.25it/s] 12%|        | 36741/303576 [23:19<1:02:57, 70.63it/s] 12%|        | 36749/303576 [23:20<1:03:01, 70.55it/s] 12%|        | 36757/303576 [23:20<1:03:10, 70.39it/s] 12%|        | 36765/303576 [23:20<1:03:01, 70.56it/s] 12%|        | 36773/303576 [23:20<1:03:00, 70.58it/s] 12%|        | 36781/303576 [23:20<1:02:10, 71.52it/s] 12%|        | 36789/303576 [23:20<1:02:36, 71.02it/s] 12%|        | 36797/303576 [23:20<1:02:50, 70.75it/s]                                                         12%|        | 36800/303576 [23:20<1:02:50, 70.75it/s] 12%|        | 36805/303576 [23:20<1:02:45, 70.84it/s] 12%|        | 36813/303576 [23:20<1:02:42, 70.90it/s] 12%|        | 36821/303576 [23:21<1:02:38, 70.97it/s] 12%|        | 36829/303576 [23:21<1:03:07, 70.43it/s] 12%|        | 36837/303576 [23:21<1:01:34, 72.20it/s] 12%|        | 36846/303576 [23:21<58:04, 76.54it/s]   12%|        | 36855/303576 [23:21<55:33, 80.02it/s] 12%|        | 36864/303576 [23:21<54:04, 82.20it/s] 12%|        | 36873/303576 [23:21<53:17, 83.41it/s] 12%|        | 36882/303576 [23:21<52:37, 84.45it/s] 12%|        | 36891/303576 [23:21<52:16, 85.04it/s] 12%|        | 36900/303576 [23:22<51:57, 85.53it/s]                                                       12%|        | 36900/303576 [23:22<51:57, 85.53it/s] 12%|        | 36909/303576 [23:22<51:47, 85.80it/s] 12%|        | 36918/303576 [23:22<51:36, 86.13it/s] 12%|        | 36927/303576 [23:22<51:27, 86.35it/s] 12%|        | 36936/303576 [23:22<51:21, 86.52it/s] 12%|        | 36945/303576 [23:22<51:22, 86.51it/s] 12%|        | 36954/303576 [23:22<51:31, 86.23it/s] 12%|        | 36963/303576 [23:22<51:26, 86.38it/s] 12%|        | 36972/303576 [23:22<51:18, 86.59it/s] 12%|        | 36981/303576 [23:22<51:18, 86.59it/s] 12%|        | 36990/303576 [23:23<51:16, 86.66it/s] 12%|        | 36999/303576 [23:23<51:17, 86.63it/s]                                                       12%|        | 37000/303576 [23:23<51:17, 86.63it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7379710078239441, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9324, 'eval_samples_per_second': 10.797, 'eval_steps_per_second': 0.096, 'epoch': 0.36, 'timestamp': 1762965922.876336, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7711, 'grad_norm': 0.2716801166534424, 'learning_rate': 2.7079441586592528e-05, 'epoch': 0.36, 'timestamp': 1762965924.4899268, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.783, 'grad_norm': 0.2621545195579529, 'learning_rate': 2.680998323493757e-05, 'epoch': 0.36, 'timestamp': 1762965925.904403, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7686, 'grad_norm': 0.22725674510002136, 'learning_rate': 2.654320617207669e-05, 'epoch': 0.36, 'timestamp': 1762965927.1503236, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7578, 'grad_norm': 0.2705584764480591, 'learning_rate': 2.6279083717413258e-05, 'epoch': 0.36, 'timestamp': 1762965928.5196185, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7695, 'grad_norm': 0.25935232639312744, 'learning_rate': 2.6017589455840213e-05, 'epoch': 0.36, 'timestamp': 1762965929.9714046, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.27112770080566406, 'learning_rate': 2.5758697235098223e-05, 'epoch': 0.36, 'timestamp': 1762965931.381448, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.2768622934818268, 'learning_rate': 2.550238116316026e-05, 'epoch': 0.36, 'timestamp': 1762965932.8129156, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7686, 'grad_norm': 0.23274223506450653, 'learning_rate': 2.524861560564214e-05, 'epoch': 0.36, 'timestamp': 1762965934.2264094, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8, 'grad_norm': 0.24624231457710266, 'learning_rate': 2.499737518323865e-05, 'epoch': 0.36, 'timestamp': 1762965935.4668183, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.26980334520339966, 'learning_rate': 2.4748634769185546e-05, 'epoch': 0.37, 'timestamp': 1762965936.6211243, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:45:40.439720: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:45:40.450464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965940.463544 1746261 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965940.467561 1746261 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965940.478143 1746261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965940.478159 1746261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965940.478161 1746261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965940.478162 1746261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:45:40.481553: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:45:42 - TensorFlow version 2.19.1 available.
2025-11-12 16:45:51.074771: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:45:51.085300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965951.098081 1746551 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965951.101901 1746551 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965951.112218 1746551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965951.112233 1746551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965951.112235 1746551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965951.112237 1746551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:45:51.115438: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:45:53 - TensorFlow version 2.19.1 available.
 12%|        | 37000/303576 [23:40<51:17, 86.63it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 12%|        | 37000/303576 [23:45<51:17, 86.63it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [A 12%|        | 37001/303576 [23:45<72:59:49,  1.01it/s] 12%|        | 37005/303576 [23:45<58:50:34,  1.26it/s] 12%|        | 37013/303576 [23:45<38:05:35,  1.94it/s] 12%|        | 37020/303576 [23:46<26:39:05,  2.78it/s] 12%|        | 37027/303576 [23:46<18:50:36,  3.93it/s] 12%|        | 37033/303576 [23:46<14:02:47,  5.27it/s] 12%|        | 37039/303576 [23:46<10:28:00,  7.07it/s] 12%|        | 37045/303576 [23:46<7:50:12,  9.45it/s]  12%|        | 37052/303576 [23:46<5:41:24, 13.01it/s] 12%|        | 37059/303576 [23:46<4:16:43, 17.30it/s] 12%|        | 37066/303576 [23:46<3:19:18, 22.29it/s] 12%|        | 37073/303576 [23:46<2:40:25, 27.69it/s] 12%|        | 37080/303576 [23:47<2:13:22, 33.30it/s] 12%|        | 37087/303576 [23:47<1:55:03, 38.60it/s] 12%|        | 37094/303576 [23:47<1:42:11, 43.46it/s]                                                         12%|        | 37100/303576 [23:47<1:42:11, 43.46it/s] 12%|        | 37101/303576 [23:47<1:33:27, 47.52it/s] 12%|        | 37108/303576 [23:47<1:27:07, 50.98it/s] 12%|        | 37115/303576 [23:47<1:22:51, 53.60it/s] 12%|        | 37122/303576 [23:47<1:19:27, 55.88it/s] 12%|        | 37129/303576 [23:47<1:17:33, 57.25it/s] 12%|        | 37136/303576 [23:47<1:15:49, 58.57it/s] 12%|        | 37143/303576 [23:48<1:14:54, 59.28it/s] 12%|        | 37150/303576 [23:48<1:11:51, 61.79it/s] 12%|        | 37157/303576 [23:48<1:14:36, 59.52it/s] 12%|        | 37164/303576 [23:48<1:17:03, 57.63it/s] 12%|        | 37170/303576 [23:48<1:18:34, 56.51it/s] 12%|        | 37176/303576 [23:48<1:19:35, 55.78it/s] 12%|        | 37182/303576 [23:48<1:20:43, 55.00it/s] 12%|        | 37188/303576 [23:48<1:20:51, 54.90it/s] 12%|        | 37194/303576 [23:48<1:21:29, 54.48it/s] 12%|        | 37200/303576 [23:49<1:21:38, 54.38it/s]                                                         12%|        | 37200/303576 [23:49<1:21:38, 54.38it/s] 12%|        | 37206/303576 [23:49<1:20:52, 54.90it/s] 12%|        | 37212/303576 [23:49<1:21:32, 54.44it/s] 12%|        | 37218/303576 [23:49<1:21:53, 54.21it/s] 12%|        | 37224/303576 [23:49<1:22:09, 54.03it/s] 12%|        | 37230/303576 [23:49<1:24:37, 52.46it/s] 12%|        | 37236/303576 [23:49<1:27:15, 50.87it/s] 12%|        | 37242/303576 [23:49<1:29:05, 49.82it/s] 12%|        | 37247/303576 [23:50<1:31:01, 48.77it/s] 12%|        | 37252/303576 [23:50<1:30:40, 48.95it/s] 12%|        | 37257/303576 [23:50<1:32:23, 48.04it/s] 12%|        | 37263/303576 [23:50<1:26:55, 51.06it/s] 12%|        | 37270/303576 [23:50<1:20:34, 55.08it/s] 12%|        | 37277/303576 [23:50<1:15:51, 58.51it/s] 12%|        | 37284/303576 [23:50<1:13:16, 60.57it/s] 12%|        | 37291/303576 [23:50<1:10:48, 62.68it/s] 12%|        | 37298/303576 [23:50<1:09:51, 63.53it/s]                                                         12%|        | 37300/303576 [23:50<1:09:51, 63.53it/s] 12%|        | 37305/303576 [23:50<1:09:02, 64.28it/s] 12%|        | 37312/303576 [23:51<1:08:54, 64.40it/s] 12%|        | 37319/303576 [23:51<1:08:11, 65.07it/s] 12%|        | 37326/303576 [23:51<1:08:00, 65.26it/s] 12%|        | 37333/303576 [23:51<1:07:55, 65.33it/s] 12%|        | 37340/303576 [23:51<1:08:55, 64.38it/s] 12%|        | 37347/303576 [23:51<1:12:46, 60.96it/s] 12%|        | 37354/303576 [23:51<1:10:48, 62.67it/s] 12%|        | 37362/303576 [23:51<1:06:12, 67.01it/s] 12%|        | 37370/303576 [23:51<1:03:10, 70.23it/s] 12%|        | 37378/303576 [23:52<1:00:47, 72.97it/s] 12%|        | 37386/303576 [23:52<59:46, 74.22it/s]   12%|        | 37394/303576 [23:52<58:48, 75.43it/s]                                                       12%|        | 37400/303576 [23:52<58:48, 75.43it/s] 12%|        | 37402/303576 [23:52<58:12, 76.22it/s] 12%|        | 37410/303576 [23:52<58:10, 76.25it/s] 12%|        | 37418/303576 [23:52<59:18, 74.80it/s] 12%|        | 37426/303576 [23:52<59:09, 74.98it/s] 12%|        | 37434/303576 [23:52<58:36, 75.68it/s] 12%|        | 37443/303576 [23:52<57:14, 77.48it/s] 12%|        | 37452/303576 [23:52<56:02, 79.15it/s] 12%|        | 37461/303576 [23:53<55:30, 79.91it/s] 12%|        | 37470/303576 [23:53<54:53, 80.79it/s] 12%|        | 37479/303576 [23:53<54:47, 80.95it/s] 12%|        | 37488/303576 [23:53<54:14, 81.75it/s] 12%|        | 37497/303576 [23:53<54:17, 81.68it/s]                                                       12%|        | 37500/303576 [23:53<54:17, 81.68it/s] 12%|        | 37506/303576 [23:53<54:05, 81.97it/s] 12%|        | 37515/303576 [23:53<54:09, 81.87it/s] 12%|        | 37524/303576 [23:53<53:54, 82.26it/s] 12%|        | 37533/303576 [23:53<54:06, 81.95it/s] 12%|        | 37542/303576 [23:54<53:48, 82.41it/s] 12%|        | 37551/303576 [23:54<53:54, 82.23it/s] 12%|        | 37560/303576 [23:54<53:42, 82.54it/s] 12%|        | 37569/303576 [23:54<54:00, 82.08it/s] 12%|        | 37578/303576 [23:54<56:04, 79.05it/s] 12%|        | 37586/303576 [23:54<56:53, 77.93it/s] 12%|        | 37594/303576 [23:54<56:58, 77.82it/s]                                                       12%|        | 37600/303576 [23:54<56:58, 77.82it/s] 12%|        | 37603/303576 [23:54<56:14, 78.82it/s] 12%|        | 37612/303576 [23:54<55:36, 79.71it/s] 12%|        | 37621/303576 [23:55<55:34, 79.76it/s] 12%|        | 37629/303576 [23:55<55:36, 79.72it/s] 12%|        | 37637/303576 [23:55<55:38, 79.66it/s] 12%|        | 37645/303576 [23:55<55:47, 79.44it/s] 12%|        | 37653/303576 [23:55<55:52, 79.32it/s] 12%|        | 37661/303576 [23:55<55:54, 79.28it/s] 12%|        | 37669/303576 [23:55<56:17, 78.73it/s] 12%|        | 37677/303576 [23:55<58:06, 76.27it/s] 12%|        | 37685/303576 [23:55<1:03:36, 69.66it/s] 12%|        | 37693/303576 [23:56<1:07:51, 65.31it/s] 12%|        | 37700/303576 [23:56<1:10:47, 62.60it/s]                                                         12%|        | 37700/303576 [23:56<1:10:47, 62.60it/s] 12%|        | 37707/303576 [23:56<1:16:08, 58.20it/s] 12%|        | 37713/303576 [23:56<1:18:21, 56.55it/s] 12%|        | 37719/303576 [23:56<1:20:01, 55.37it/s] 12%|        | 37725/303576 [23:56<1:20:07, 55.29it/s] 12%|        | 37731/303576 [23:56<1:18:58, 56.10it/s] 12%|        | 37737/303576 [23:56<1:17:43, 57.00it/s] 12%|        | 37743/303576 [23:56<1:17:12, 57.38it/s] 12%|        | 37749/303576 [23:57<1:16:23, 58.00it/s] 12%|        | 37755/303576 [23:57<1:16:10, 58.15it/s] 12%|        | 37761/303576 [23:57<1:16:01, 58.28it/s] 12%|        | 37767/303576 [23:57<1:15:46, 58.46it/s] 12%|        | 37774/303576 [23:57<1:14:55, 59.13it/s] 12%|        | 37781/303576 [23:57<1:14:01, 59.84it/s] 12%|        | 37788/303576 [23:57<1:13:40, 60.13it/s] 12%|        | 37795/303576 [23:57<1:13:12, 60.51it/s]                                                         12%|        | 37800/303576 [23:57<1:13:12, 60.51it/s] 12%|        | 37802/303576 [23:57<1:13:17, 60.43it/s] 12%|        | 37809/303576 [23:58<1:12:40, 60.95it/s] 12%|        | 37816/303576 [23:58<1:11:33, 61.90it/s] 12%|        | 37825/303576 [23:58<1:03:43, 69.51it/s] 12%|        | 37834/303576 [23:58<1:01:01, 72.58it/s] 12%|        | 37843/303576 [23:58<58:44, 75.40it/s]   12%|        | 37852/303576 [23:58<57:16, 77.33it/s] 12%|        | 37861/303576 [23:58<55:58, 79.11it/s] 12%|        | 37870/303576 [23:58<55:31, 79.76it/s] 12%|        | 37879/303576 [23:58<54:29, 81.26it/s] 12%|        | 37888/303576 [23:59<54:40, 80.98it/s] 12%|        | 37897/303576 [23:59<54:35, 81.12it/s]                                                       12%|        | 37900/303576 [23:59<54:34, 81.12it/s] 12%|        | 37906/303576 [23:59<55:05, 80.38it/s] 12%|        | 37915/303576 [23:59<55:26, 79.86it/s] 12%|        | 37923/303576 [23:59<55:36, 79.62it/s] 12%|        | 37931/303576 [23:59<55:52, 79.24it/s] 12%|        | 37939/303576 [23:59<55:58, 79.10it/s] 12%|        | 37947/303576 [23:59<55:51, 79.26it/s] 13%|        | 37955/303576 [23:59<55:58, 79.10it/s] 13%|        | 37963/303576 [24:00<56:01, 79.01it/s] 13%|        | 37971/303576 [24:00<55:56, 79.12it/s] 13%|        | 37979/303576 [24:00<55:59, 79.05it/s] 13%|        | 37987/303576 [24:00<57:39, 76.77it/s] 13%|        | 37995/303576 [24:00<59:11, 74.79it/s]                                                       13%|        | 38000/303576 [24:00<59:10, 74.79it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7372040152549744, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.3806, 'eval_samples_per_second': 10.098, 'eval_steps_per_second': 0.089, 'epoch': 0.37, 'timestamp': 1762965959.0021653, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7789, 'grad_norm': 0.24648238718509674, 'learning_rate': 2.4502369486746446e-05, 'epoch': 0.37, 'timestamp': 1762965960.7875679, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7826, 'grad_norm': 0.2209559828042984, 'learning_rate': 2.4258554706724988e-05, 'epoch': 0.37, 'timestamp': 1762965962.5196996, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7764, 'grad_norm': 0.30916154384613037, 'learning_rate': 2.4017166045001524e-05, 'epoch': 0.37, 'timestamp': 1762965964.3179088, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7635, 'grad_norm': 0.24737076461315155, 'learning_rate': 2.377817936009463e-05, 'epoch': 0.37, 'timestamp': 1762965965.7548647, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7873, 'grad_norm': 0.257068932056427, 'learning_rate': 2.3541570750746514e-05, 'epoch': 0.37, 'timestamp': 1762965967.0083783, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.769, 'grad_norm': 0.24610105156898499, 'learning_rate': 2.3307316553532728e-05, 'epoch': 0.37, 'timestamp': 1762965968.254397, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7713, 'grad_norm': 0.29454973340034485, 'learning_rate': 2.3075393340495525e-05, 'epoch': 0.37, 'timestamp': 1762965969.6388595, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7598, 'grad_norm': 0.29478752613067627, 'learning_rate': 2.2845777916800887e-05, 'epoch': 0.37, 'timestamp': 1762965971.3752759, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7742, 'grad_norm': 0.28403499722480774, 'learning_rate': 2.261844731841865e-05, 'epoch': 0.37, 'timestamp': 1762965972.6488461, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.25947096943855286, 'learning_rate': 2.2393378809826017e-05, 'epoch': 0.38, 'timestamp': 1762965973.9444225, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:46:17.330173: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:46:17.341002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965977.354214 1747258 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965977.358271 1747258 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965977.369095 1747258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965977.369114 1747258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965977.369116 1747258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965977.369117 1747258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:46:17.372264: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:46:19 - TensorFlow version 2.19.1 available.
2025-11-12 16:46:26.996906: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:46:27.007529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762965987.020269 1747416 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762965987.024102 1747416 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762965987.034450 1747416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965987.034465 1747416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965987.034467 1747416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762965987.034469 1747416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:46:27.037673: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:46:28 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A 13%|        | 38000/303576 [24:20<59:10, 74.79it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 13%|        | 38000/303576 [24:21<59:10, 74.79it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-38000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-38000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-38000/model.safetensors
 13%|        | 38001/303576 [24:21<64:24:17,  1.15it/s] 13%|        | 38007/303576 [24:21<48:10:34,  1.53it/s] 13%|        | 38014/303576 [24:22<34:08:31,  2.16it/s] 13%|        | 38021/303576 [24:22<24:18:23,  3.03it/s] 13%|        | 38028/303576 [24:22<17:26:37,  4.23it/s] 13%|        | 38034/303576 [24:22<13:07:55,  5.62it/s] 13%|        | 38040/303576 [24:22<9:53:43,  7.45it/s]  13%|        | 38046/303576 [24:22<7:28:28,  9.87it/s] 13%|        | 38052/303576 [24:22<5:44:02, 12.86it/s] 13%|        | 38058/303576 [24:22<4:29:16, 16.43it/s] 13%|        | 38064/303576 [24:22<3:36:16, 20.46it/s] 13%|        | 38070/303576 [24:23<2:58:00, 24.86it/s] 13%|        | 38076/303576 [24:23<2:30:44, 29.36it/s] 13%|        | 38082/303576 [24:23<2:09:37, 34.14it/s] 13%|        | 38088/303576 [24:23<1:54:43, 38.57it/s] 13%|        | 38094/303576 [24:23<1:44:06, 42.50it/s] 13%|        | 38100/303576 [24:23<1:36:38, 45.78it/s]                                                         13%|        | 38100/303576 [24:23<1:36:38, 45.78it/s] 13%|        | 38106/303576 [24:23<1:31:06, 48.56it/s] 13%|        | 38112/303576 [24:23<1:27:29, 50.57it/s] 13%|        | 38118/303576 [24:23<1:25:10, 51.94it/s] 13%|        | 38124/303576 [24:24<1:23:15, 53.14it/s] 13%|        | 38130/303576 [24:24<1:24:11, 52.55it/s] 13%|        | 38136/303576 [24:24<1:24:38, 52.26it/s] 13%|        | 38142/303576 [24:24<1:24:56, 52.09it/s] 13%|        | 38148/303576 [24:24<1:22:26, 53.66it/s] 13%|        | 38154/303576 [24:24<1:21:52, 54.03it/s] 13%|        | 38160/303576 [24:24<1:26:25, 51.18it/s] 13%|        | 38166/303576 [24:24<1:28:36, 49.92it/s] 13%|        | 38172/303576 [24:25<1:29:57, 49.17it/s] 13%|        | 38177/303576 [24:25<1:31:37, 48.27it/s] 13%|        | 38182/303576 [24:25<1:31:09, 48.53it/s] 13%|        | 38187/303576 [24:25<1:32:35, 47.77it/s] 13%|        | 38192/303576 [24:25<1:32:01, 48.07it/s] 13%|        | 38197/303576 [24:25<1:33:21, 47.37it/s]                                                         13%|        | 38200/303576 [24:25<1:33:21, 47.37it/s] 13%|        | 38202/303576 [24:25<1:32:21, 47.89it/s] 13%|        | 38207/303576 [24:25<1:33:21, 47.37it/s] 13%|        | 38212/303576 [24:25<1:32:24, 47.86it/s] 13%|        | 38217/303576 [24:25<1:33:38, 47.23it/s] 13%|        | 38222/303576 [24:26<1:32:36, 47.76it/s] 13%|        | 38227/303576 [24:26<1:33:52, 47.11it/s] 13%|        | 38232/303576 [24:26<1:32:58, 47.56it/s] 13%|        | 38237/303576 [24:26<1:34:12, 46.94it/s] 13%|        | 38242/303576 [24:26<1:33:05, 47.50it/s] 13%|        | 38247/303576 [24:26<1:34:14, 46.92it/s] 13%|        | 38252/303576 [24:26<1:33:02, 47.53it/s] 13%|        | 38257/303576 [24:26<1:34:19, 46.88it/s] 13%|        | 38262/303576 [24:26<1:33:02, 47.52it/s] 13%|        | 38267/303576 [24:27<1:34:07, 46.98it/s] 13%|        | 38272/303576 [24:27<1:33:41, 47.19it/s] 13%|        | 38278/303576 [24:27<1:29:11, 49.58it/s] 13%|        | 38284/303576 [24:27<1:27:55, 50.29it/s] 13%|        | 38290/303576 [24:27<1:24:47, 52.14it/s] 13%|        | 38296/303576 [24:27<1:22:45, 53.43it/s]                                                         13%|        | 38300/303576 [24:27<1:22:45, 53.43it/s] 13%|        | 38302/303576 [24:27<1:21:14, 54.42it/s] 13%|        | 38308/303576 [24:27<1:19:52, 55.35it/s] 13%|        | 38314/303576 [24:27<1:19:07, 55.87it/s] 13%|        | 38320/303576 [24:28<1:18:28, 56.34it/s] 13%|        | 38326/303576 [24:28<1:18:06, 56.59it/s] 13%|        | 38332/303576 [24:28<1:18:34, 56.26it/s] 13%|        | 38338/303576 [24:28<1:18:35, 56.25it/s] 13%|        | 38345/303576 [24:28<1:14:27, 59.37it/s] 13%|        | 38355/303576 [24:28<1:03:42, 69.38it/s] 13%|        | 38364/303576 [24:28<59:56, 73.73it/s]   13%|        | 38373/303576 [24:28<57:06, 77.40it/s] 13%|        | 38382/303576 [24:28<55:36, 79.48it/s] 13%|        | 38391/303576 [24:28<54:43, 80.76it/s] 13%|        | 38400/303576 [24:29<54:29, 81.10it/s]                                                       13%|        | 38400/303576 [24:29<54:29, 81.10it/s] 13%|        | 38409/303576 [24:29<54:02, 81.79it/s] 13%|        | 38418/303576 [24:29<53:47, 82.17it/s] 13%|        | 38427/303576 [24:29<53:51, 82.04it/s] 13%|        | 38436/303576 [24:29<53:36, 82.43it/s] 13%|        | 38445/303576 [24:29<53:47, 82.15it/s] 13%|        | 38454/303576 [24:29<53:54, 81.98it/s] 13%|        | 38463/303576 [24:29<53:42, 82.28it/s] 13%|        | 38472/303576 [24:29<53:16, 82.93it/s] 13%|        | 38481/303576 [24:30<53:08, 83.15it/s] 13%|        | 38490/303576 [24:30<53:20, 82.82it/s] 13%|        | 38499/303576 [24:30<53:15, 82.96it/s]                                                       13%|        | 38500/303576 [24:30<53:15, 82.96it/s] 13%|        | 38508/303576 [24:30<53:25, 82.68it/s] 13%|        | 38517/303576 [24:30<53:18, 82.88it/s] 13%|        | 38526/303576 [24:30<53:29, 82.58it/s] 13%|        | 38535/303576 [24:30<53:18, 82.87it/s] 13%|        | 38544/303576 [24:30<53:28, 82.61it/s] 13%|        | 38553/303576 [24:30<53:15, 82.94it/s] 13%|        | 38562/303576 [24:31<53:28, 82.59it/s] 13%|        | 38571/303576 [24:31<53:15, 82.94it/s] 13%|        | 38580/303576 [24:31<52:45, 83.72it/s] 13%|        | 38589/303576 [24:31<52:44, 83.75it/s] 13%|        | 38598/303576 [24:31<53:06, 83.17it/s]                                                       13%|        | 38600/303576 [24:31<53:06, 83.17it/s] 13%|        | 38607/303576 [24:31<52:58, 83.37it/s] 13%|        | 38616/303576 [24:31<53:17, 82.86it/s] 13%|        | 38625/303576 [24:31<53:07, 83.13it/s] 13%|        | 38635/303576 [24:31<51:40, 85.45it/s] 13%|        | 38644/303576 [24:32<52:04, 84.78it/s] 13%|        | 38653/303576 [24:32<52:16, 84.48it/s] 13%|        | 38662/303576 [24:32<52:43, 83.74it/s] 13%|        | 38671/303576 [24:32<52:49, 83.59it/s] 13%|        | 38680/303576 [24:32<53:10, 83.03it/s] 13%|        | 38689/303576 [24:32<53:03, 83.21it/s] 13%|        | 38698/303576 [24:32<53:03, 83.21it/s]                                                       13%|        | 38700/303576 [24:32<53:03, 83.21it/s] 13%|        | 38707/303576 [24:32<52:57, 83.35it/s] 13%|        | 38716/303576 [24:32<53:14, 82.91it/s] 13%|        | 38725/303576 [24:32<53:06, 83.11it/s] 13%|        | 38734/303576 [24:33<53:18, 82.80it/s] 13%|        | 38743/303576 [24:33<53:10, 83.01it/s] 13%|        | 38752/303576 [24:33<53:24, 82.65it/s] 13%|        | 38761/303576 [24:33<53:08, 83.06it/s] 13%|        | 38770/303576 [24:33<53:20, 82.74it/s] 13%|        | 38779/303576 [24:33<53:07, 83.06it/s] 13%|        | 38788/303576 [24:33<53:15, 82.87it/s] 13%|        | 38797/303576 [24:33<53:05, 83.12it/s]                                                       13%|        | 38800/303576 [24:33<53:05, 83.12it/s] 13%|        | 38806/303576 [24:33<53:02, 83.18it/s] 13%|        | 38815/303576 [24:34<52:52, 83.45it/s] 13%|        | 38824/303576 [24:34<52:53, 83.42it/s] 13%|        | 38833/303576 [24:34<52:51, 83.47it/s] 13%|        | 38842/303576 [24:34<52:56, 83.34it/s] 13%|        | 38851/303576 [24:34<52:49, 83.51it/s] 13%|        | 38860/303576 [24:34<52:53, 83.41it/s] 13%|        | 38869/303576 [24:34<52:52, 83.43it/s] 13%|        | 38878/303576 [24:34<53:02, 83.16it/s] 13%|        | 38887/303576 [24:34<52:55, 83.36it/s] 13%|        | 38897/303576 [24:35<50:59, 86.51it/s]                                                       13%|        | 38900/303576 [24:35<50:59, 86.51it/s] 13%|        | 38907/303576 [24:35<48:53, 90.22it/s] 13%|        | 38917/303576 [24:35<47:47, 92.30it/s] 13%|        | 38927/303576 [24:35<49:09, 89.74it/s] 13%|        | 38937/303576 [24:35<50:28, 87.38it/s] 13%|        | 38946/303576 [24:35<51:31, 85.61it/s] 13%|        | 38955/303576 [24:35<52:16, 84.36it/s] 13%|        | 38964/303576 [24:35<52:55, 83.32it/s] 13%|        | 38973/303576 [24:35<52:54, 83.36it/s] 13%|        | 38982/303576 [24:36<54:15, 81.28it/s] 13%|        | 38991/303576 [24:36<56:57, 77.41it/s] 13%|        | 38999/303576 [24:36<58:20, 75.58it/s]                                                       13%|        | 39000/303576 [24:36<58:20, 75.58it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7372477054595947, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.2179, 'eval_samples_per_second': 10.651, 'eval_steps_per_second': 0.094, 'epoch': 0.38, 'timestamp': 1762965995.1627746, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7681, 'grad_norm': 0.2729848623275757, 'learning_rate': 2.2170549881733635e-05, 'epoch': 0.38, 'timestamp': 1762965997.0966628, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.788, 'grad_norm': 0.25199756026268005, 'learning_rate': 2.194993824883447e-05, 'epoch': 0.38, 'timestamp': 1762965999.0627005, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7588, 'grad_norm': 0.23349590599536896, 'learning_rate': 2.1733695217096717e-05, 'epoch': 0.38, 'timestamp': 1762966001.0953944, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7784, 'grad_norm': 0.29786211252212524, 'learning_rate': 2.151743057700643e-05, 'epoch': 0.38, 'timestamp': 1762966002.5140836, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7685, 'grad_norm': 0.2584274709224701, 'learning_rate': 2.1303317913102716e-05, 'epoch': 0.38, 'timestamp': 1762966003.7225242, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7753, 'grad_norm': 0.2574816346168518, 'learning_rate': 2.1091335811799394e-05, 'epoch': 0.38, 'timestamp': 1762966004.9260004, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7719, 'grad_norm': 0.27122944593429565, 'learning_rate': 2.0881463072589635e-05, 'epoch': 0.38, 'timestamp': 1762966006.1201816, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7741, 'grad_norm': 0.27283576130867004, 'learning_rate': 2.0673678705925676e-05, 'epoch': 0.38, 'timestamp': 1762966007.3274868, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7753, 'grad_norm': 0.21632079780101776, 'learning_rate': 2.0467961931119627e-05, 'epoch': 0.38, 'timestamp': 1762966008.505879, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.2418314665555954, 'learning_rate': 2.0264292174265157e-05, 'epoch': 0.39, 'timestamp': 1762966009.7296116, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:46:53.523909: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:46:53.534607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966013.547810 1748116 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966013.551825 1748116 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966013.562345 1748116 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966013.562361 1748116 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966013.562363 1748116 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966013.562364 1748116 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:46:53.565769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:46:55 - TensorFlow version 2.19.1 available.
 13%|        | 39000/303576 [24:50<58:20, 75.58it/s]2025-11-12 16:47:04.029813: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:47:04.040489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966024.053289 1748406 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966024.057122 1748406 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966024.067497 1748406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966024.067516 1748406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966024.067518 1748406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966024.067519 1748406 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:47:04.070734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:47:05 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 13%|        | 39000/303576 [24:58<58:20, 75.58it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 13%|        | 39001/303576 [24:58<74:34:31,  1.01s/it] 13%|        | 39006/303576 [24:58<56:58:42,  1.29it/s] 13%|        | 39013/303576 [24:59<38:58:24,  1.89it/s] 13%|        | 39019/303576 [24:59<28:14:58,  2.60it/s] 13%|        | 39025/303576 [24:59<20:27:59,  3.59it/s] 13%|        | 39031/303576 [24:59<14:52:24,  4.94it/s] 13%|        | 39037/303576 [24:59<10:53:37,  6.75it/s] 13%|        | 39043/303576 [24:59<8:04:12,  9.11it/s]  13%|        | 39049/303576 [24:59<6:02:49, 12.15it/s] 13%|        | 39055/303576 [24:59<4:41:11, 15.68it/s] 13%|        | 39061/303576 [24:59<3:44:57, 19.60it/s] 13%|        | 39067/303576 [25:00<3:05:20, 23.78it/s] 13%|        | 39073/303576 [25:00<2:37:37, 27.97it/s] 13%|        | 39078/303576 [25:00<2:19:39, 31.57it/s] 13%|        | 39084/303576 [25:00<2:02:41, 35.93it/s] 13%|        | 39090/303576 [25:00<1:52:34, 39.16it/s] 13%|        | 39095/303576 [25:00<1:48:11, 40.74it/s] 13%|        | 39100/303576 [25:00<1:43:16, 42.68it/s]                                                         13%|        | 39100/303576 [25:00<1:43:16, 42.68it/s] 13%|        | 39105/303576 [25:00<1:41:32, 43.41it/s] 13%|        | 39110/303576 [25:00<1:38:09, 44.90it/s] 13%|        | 39115/303576 [25:01<1:37:37, 45.15it/s] 13%|        | 39120/303576 [25:01<1:35:05, 46.35it/s] 13%|        | 39126/303576 [25:01<1:29:04, 49.48it/s] 13%|        | 39132/303576 [25:01<1:25:06, 51.79it/s] 13%|        | 39138/303576 [25:01<1:21:54, 53.81it/s] 13%|        | 39144/303576 [25:01<1:23:11, 52.98it/s] 13%|        | 39150/303576 [25:01<1:25:05, 51.80it/s] 13%|        | 39156/303576 [25:01<1:27:29, 50.37it/s] 13%|        | 39162/303576 [25:01<1:25:29, 51.55it/s] 13%|        | 39168/303576 [25:02<1:22:55, 53.14it/s] 13%|        | 39174/303576 [25:02<1:20:59, 54.41it/s] 13%|        | 39180/303576 [25:02<1:19:26, 55.46it/s] 13%|        | 39186/303576 [25:02<1:18:17, 56.29it/s] 13%|        | 39192/303576 [25:02<1:17:39, 56.75it/s] 13%|        | 39198/303576 [25:02<1:17:36, 56.78it/s]                                                         13%|        | 39200/303576 [25:02<1:17:36, 56.78it/s] 13%|        | 39204/303576 [25:02<1:19:49, 55.20it/s] 13%|        | 39210/303576 [25:02<1:22:10, 53.62it/s] 13%|        | 39216/303576 [25:02<1:23:44, 52.62it/s] 13%|        | 39222/303576 [25:03<1:22:42, 53.27it/s] 13%|        | 39228/303576 [25:03<1:22:12, 53.59it/s] 13%|        | 39234/303576 [25:03<1:20:16, 54.89it/s] 13%|        | 39240/303576 [25:03<1:18:44, 55.95it/s] 13%|        | 39247/303576 [25:03<1:15:55, 58.03it/s] 13%|        | 39254/303576 [25:03<1:13:52, 59.63it/s] 13%|        | 39261/303576 [25:03<1:12:31, 60.74it/s] 13%|        | 39268/303576 [25:03<1:11:43, 61.41it/s] 13%|        | 39275/303576 [25:03<1:10:40, 62.33it/s] 13%|        | 39282/303576 [25:04<1:09:10, 63.68it/s] 13%|        | 39289/303576 [25:04<1:08:09, 64.62it/s] 13%|        | 39296/303576 [25:04<1:08:24, 64.39it/s]                                                         13%|        | 39300/303576 [25:04<1:08:24, 64.39it/s] 13%|        | 39303/303576 [25:04<1:07:45, 65.01it/s] 13%|        | 39310/303576 [25:04<1:06:58, 65.76it/s] 13%|        | 39317/303576 [25:04<1:06:40, 66.06it/s] 13%|        | 39324/303576 [25:04<1:06:09, 66.57it/s] 13%|        | 39331/303576 [25:04<1:05:54, 66.83it/s] 13%|        | 39338/303576 [25:04<1:05:51, 66.87it/s] 13%|        | 39345/303576 [25:04<1:05:48, 66.92it/s] 13%|        | 39352/303576 [25:05<1:05:34, 67.15it/s] 13%|        | 39359/303576 [25:05<1:06:44, 65.98it/s] 13%|        | 39366/303576 [25:05<1:09:15, 63.58it/s] 13%|        | 39373/303576 [25:05<1:12:08, 61.04it/s] 13%|        | 39380/303576 [25:05<1:13:20, 60.04it/s] 13%|        | 39387/303576 [25:05<1:13:54, 59.57it/s] 13%|        | 39393/303576 [25:05<1:14:14, 59.30it/s] 13%|        | 39399/303576 [25:05<1:14:40, 58.97it/s]                                                         13%|        | 39400/303576 [25:05<1:14:40, 58.97it/s] 13%|        | 39405/303576 [25:05<1:14:36, 59.01it/s] 13%|        | 39411/303576 [25:06<1:15:36, 58.24it/s] 13%|        | 39417/303576 [25:06<1:18:47, 55.88it/s] 13%|        | 39423/303576 [25:06<1:23:01, 53.02it/s] 13%|        | 39429/303576 [25:06<1:26:09, 51.10it/s] 13%|        | 39435/303576 [25:06<1:29:26, 49.22it/s] 13%|        | 39440/303576 [25:06<1:30:04, 48.87it/s] 13%|        | 39445/303576 [25:06<1:32:17, 47.69it/s] 13%|        | 39450/303576 [25:06<1:32:07, 47.79it/s] 13%|        | 39455/303576 [25:07<1:33:37, 47.02it/s] 13%|        | 39460/303576 [25:07<1:32:50, 47.41it/s] 13%|        | 39465/303576 [25:07<1:33:15, 47.20it/s] 13%|        | 39472/303576 [25:07<1:25:30, 51.47it/s] 13%|        | 39478/303576 [25:07<1:21:45, 53.83it/s] 13%|        | 39484/303576 [25:07<1:21:50, 53.78it/s] 13%|        | 39490/303576 [25:07<1:22:33, 53.31it/s] 13%|        | 39496/303576 [25:07<1:21:34, 53.95it/s]                                                         13%|        | 39500/303576 [25:07<1:21:34, 53.95it/s] 13%|        | 39502/303576 [25:07<1:20:32, 54.64it/s] 13%|        | 39508/303576 [25:08<1:19:59, 55.02it/s] 13%|        | 39514/303576 [25:08<1:18:37, 55.98it/s] 13%|        | 39520/303576 [25:08<1:18:35, 56.00it/s] 13%|        | 39526/303576 [25:08<1:18:11, 56.28it/s] 13%|        | 39532/303576 [25:08<1:18:55, 55.76it/s] 13%|        | 39538/303576 [25:08<1:17:55, 56.47it/s] 13%|        | 39544/303576 [25:08<1:18:11, 56.28it/s] 13%|        | 39550/303576 [25:08<1:17:52, 56.51it/s] 13%|        | 39556/303576 [25:08<1:16:58, 57.17it/s] 13%|        | 39562/303576 [25:08<1:17:02, 57.12it/s] 13%|        | 39568/303576 [25:09<1:17:11, 57.01it/s] 13%|        | 39574/303576 [25:09<1:16:23, 57.60it/s] 13%|        | 39580/303576 [25:09<1:16:43, 57.35it/s] 13%|        | 39586/303576 [25:09<1:17:15, 56.96it/s] 13%|        | 39592/303576 [25:09<1:17:38, 56.66it/s] 13%|        | 39599/303576 [25:09<1:15:49, 58.03it/s]                                                         13%|        | 39600/303576 [25:09<1:15:49, 58.03it/s] 13%|        | 39606/303576 [25:09<1:14:03, 59.40it/s] 13%|        | 39613/303576 [25:09<1:12:41, 60.52it/s] 13%|        | 39620/303576 [25:09<1:11:34, 61.46it/s] 13%|        | 39627/303576 [25:10<1:10:06, 62.75it/s] 13%|        | 39634/303576 [25:10<1:11:14, 61.74it/s] 13%|        | 39642/303576 [25:10<1:06:06, 66.54it/s] 13%|        | 39649/303576 [25:10<1:06:00, 66.64it/s] 13%|        | 39656/303576 [25:10<1:05:55, 66.72it/s] 13%|        | 39663/303576 [25:10<1:06:20, 66.31it/s] 13%|        | 39672/303576 [25:10<1:02:31, 70.35it/s] 13%|        | 39681/303576 [25:10<58:58, 74.58it/s]   13%|        | 39691/303576 [25:10<55:35, 79.11it/s] 13%|        | 39700/303576 [25:11<53:39, 81.97it/s]                                                       13%|        | 39700/303576 [25:11<53:39, 81.97it/s] 13%|        | 39710/303576 [25:11<51:48, 84.90it/s] 13%|        | 39719/303576 [25:11<51:07, 86.02it/s] 13%|        | 39728/303576 [25:11<51:11, 85.90it/s] 13%|        | 39737/303576 [25:11<51:39, 85.13it/s] 13%|        | 39746/303576 [25:11<51:58, 84.61it/s] 13%|        | 39755/303576 [25:11<52:59, 82.97it/s] 13%|        | 39764/303576 [25:11<52:59, 82.98it/s] 13%|        | 39773/303576 [25:11<53:29, 82.20it/s] 13%|        | 39782/303576 [25:11<52:50, 83.20it/s] 13%|        | 39791/303576 [25:12<52:20, 84.00it/s]                                                       13%|        | 39800/303576 [25:12<52:20, 84.00it/s] 13%|        | 39801/303576 [25:12<51:09, 85.92it/s] 13%|        | 39810/303576 [25:12<50:48, 86.52it/s] 13%|        | 39819/303576 [25:12<51:53, 84.72it/s] 13%|        | 39828/303576 [25:12<52:33, 83.63it/s] 13%|        | 39837/303576 [25:12<53:06, 82.78it/s] 13%|        | 39846/303576 [25:12<52:51, 83.16it/s] 13%|        | 39855/303576 [25:12<53:15, 82.52it/s] 13%|        | 39864/303576 [25:12<53:01, 82.88it/s] 13%|        | 39873/303576 [25:13<53:30, 82.13it/s] 13%|        | 39882/303576 [25:13<53:39, 81.90it/s] 13%|        | 39891/303576 [25:13<53:39, 81.91it/s] 13%|        | 39900/303576 [25:13<53:00, 82.91it/s]                                                       13%|        | 39900/303576 [25:13<53:00, 82.91it/s] 13%|        | 39909/303576 [25:13<51:55, 84.62it/s] 13%|        | 39918/303576 [25:13<51:11, 85.84it/s] 13%|        | 39927/303576 [25:13<50:47, 86.52it/s] 13%|        | 39936/303576 [25:13<50:20, 87.29it/s] 13%|        | 39945/303576 [25:13<50:00, 87.85it/s] 13%|        | 39954/303576 [25:14<50:00, 87.86it/s] 13%|        | 39963/303576 [25:14<49:49, 88.17it/s] 13%|        | 39972/303576 [25:14<49:54, 88.04it/s] 13%|        | 39981/303576 [25:14<49:56, 87.97it/s] 13%|        | 39990/303576 [25:14<49:43, 88.34it/s] 13%|        | 39999/303576 [25:14<49:30, 88.73it/s]                                                       13%|        | 40000/303576 [25:14<49:30, 88.73it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7361196279525757, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4951, 'eval_samples_per_second': 10.047, 'eval_steps_per_second': 0.089, 'epoch': 0.39, 'timestamp': 1762966032.2251775, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7808, 'grad_norm': 0.24156436324119568, 'learning_rate': 2.006264906617996e-05, 'epoch': 0.39, 'timestamp': 1762966034.2158034, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7743, 'grad_norm': 0.28293171525001526, 'learning_rate': 1.986301244036852e-05, 'epoch': 0.39, 'timestamp': 1762966036.088362, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7815, 'grad_norm': 0.2507842779159546, 'learning_rate': 1.9665362331005354e-05, 'epoch': 0.39, 'timestamp': 1762966037.7603915, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7696, 'grad_norm': 0.27278614044189453, 'learning_rate': 1.946967897093807e-05, 'epoch': 0.39, 'timestamp': 1762966039.3523831, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.772, 'grad_norm': 0.23981887102127075, 'learning_rate': 1.9275942789710553e-05, 'epoch': 0.39, 'timestamp': 1762966041.3068206, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7658, 'grad_norm': 0.2269841730594635, 'learning_rate': 1.908413441160565e-05, 'epoch': 0.39, 'timestamp': 1762966043.0599952, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7663, 'grad_norm': 0.23096665740013123, 'learning_rate': 1.889423465370742e-05, 'epoch': 0.39, 'timestamp': 1762966044.4506922, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7658, 'grad_norm': 0.29911428689956665, 'learning_rate': 1.8706224523982628e-05, 'epoch': 0.39, 'timestamp': 1762966045.6249063, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7869, 'grad_norm': 0.2356499582529068, 'learning_rate': 1.8520085219381315e-05, 'epoch': 0.39, 'timestamp': 1762966046.8360045, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7878, 'grad_norm': 0.2744620144367218, 'learning_rate': 1.833579812395633e-05, 'epoch': 0.4, 'timestamp': 1762966047.9625208, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:47:31.318333: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:47:31.329484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966051.342566 1749111 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966051.346333 1749111 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966051.357130 1749111 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966051.357147 1749111 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966051.357150 1749111 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966051.357152 1749111 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:47:31.360360: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:47:33 - TensorFlow version 2.19.1 available.
2025-11-12 16:47:40.815015: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:47:40.825632: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966060.838357 1749269 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966060.842159 1749269 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966060.852506 1749269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966060.852522 1749269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966060.852523 1749269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966060.852525 1749269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:47:40.855731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:47:42 - TensorFlow version 2.19.1 available.
 13%|        | 40000/303576 [25:30<49:30, 88.73it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 13%|        | 40000/303576 [25:35<49:30, 88.73it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-40000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-40000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-40000/model.safetensors
 13%|        | 40001/303576 [25:35<67:37:28,  1.08it/s] 13%|        | 40008/303576 [25:35<47:29:59,  1.54it/s] 13%|        | 40017/303576 [25:35<30:59:06,  2.36it/s] 13%|        | 40025/303576 [25:35<21:43:37,  3.37it/s] 13%|        | 40032/303576 [25:36<15:59:19,  4.58it/s] 13%|        | 40039/303576 [25:36<11:46:30,  6.22it/s] 13%|        | 40046/303576 [25:36<8:44:49,  8.37it/s]  13%|        | 40052/303576 [25:36<6:47:42, 10.77it/s] 13%|        | 40058/303576 [25:36<5:21:25, 13.66it/s] 13%|        | 40064/303576 [25:36<4:17:11, 17.08it/s] 13%|        | 40070/303576 [25:36<3:30:18, 20.88it/s] 13%|        | 40076/303576 [25:36<2:56:09, 24.93it/s] 13%|        | 40082/303576 [25:37<2:31:40, 28.95it/s] 13%|        | 40087/303576 [25:37<2:15:28, 32.41it/s] 13%|        | 40092/303576 [25:37<2:04:52, 35.17it/s] 13%|        | 40097/303576 [25:37<1:55:02, 38.17it/s]                                                         13%|        | 40100/303576 [25:37<1:55:02, 38.17it/s] 13%|        | 40102/303576 [25:37<1:49:35, 40.07it/s] 13%|        | 40107/303576 [25:37<1:43:41, 42.35it/s] 13%|        | 40112/303576 [25:37<1:41:31, 43.25it/s] 13%|        | 40117/303576 [25:37<1:37:45, 44.92it/s] 13%|        | 40122/303576 [25:37<1:37:21, 45.10it/s] 13%|        | 40127/303576 [25:37<1:34:48, 46.31it/s] 13%|        | 40132/303576 [25:38<1:35:11, 46.13it/s] 13%|        | 40137/303576 [25:38<1:33:21, 47.03it/s] 13%|        | 40145/303576 [25:38<1:18:52, 55.67it/s] 13%|        | 40153/303576 [25:38<1:10:15, 62.49it/s] 13%|        | 40161/303576 [25:38<1:05:52, 66.64it/s] 13%|        | 40168/303576 [25:38<1:05:10, 67.36it/s] 13%|        | 40176/303576 [25:38<1:04:09, 68.42it/s] 13%|        | 40184/303576 [25:38<1:03:27, 69.18it/s] 13%|        | 40192/303576 [25:38<1:02:46, 69.93it/s] 13%|        | 40199/303576 [25:39<1:02:46, 69.92it/s]                                                         13%|        | 40200/303576 [25:39<1:02:46, 69.92it/s] 13%|        | 40207/303576 [25:39<1:01:48, 71.01it/s] 13%|        | 40215/303576 [25:39<1:01:47, 71.04it/s] 13%|        | 40223/303576 [25:39<1:01:37, 71.22it/s] 13%|        | 40231/303576 [25:39<1:01:37, 71.22it/s] 13%|        | 40239/303576 [25:39<1:01:41, 71.15it/s] 13%|        | 40247/303576 [25:39<1:01:31, 71.33it/s] 13%|        | 40255/303576 [25:39<1:01:12, 71.70it/s] 13%|        | 40263/303576 [25:39<1:00:58, 71.98it/s] 13%|        | 40271/303576 [25:40<1:01:00, 71.93it/s] 13%|        | 40279/303576 [25:40<1:01:04, 71.85it/s] 13%|        | 40287/303576 [25:40<1:01:13, 71.66it/s] 13%|        | 40295/303576 [25:40<1:01:11, 71.70it/s]                                                         13%|        | 40300/303576 [25:40<1:01:11, 71.70it/s] 13%|        | 40303/303576 [25:40<1:01:16, 71.61it/s] 13%|        | 40311/303576 [25:40<1:01:16, 71.62it/s] 13%|        | 40319/303576 [25:40<1:01:21, 71.51it/s] 13%|        | 40327/303576 [25:40<1:00:57, 71.97it/s] 13%|        | 40335/303576 [25:40<1:01:26, 71.42it/s] 13%|        | 40343/303576 [25:41<1:01:37, 71.18it/s] 13%|        | 40351/303576 [25:41<1:01:47, 70.99it/s] 13%|        | 40359/303576 [25:41<1:01:09, 71.73it/s] 13%|        | 40368/303576 [25:41<59:27, 73.77it/s]   13%|        | 40376/303576 [25:41<59:47, 73.37it/s] 13%|        | 40384/303576 [25:41<59:57, 73.16it/s] 13%|        | 40392/303576 [25:41<1:00:44, 72.21it/s] 13%|        | 40400/303576 [25:41<1:01:27, 71.38it/s]                                                         13%|        | 40400/303576 [25:41<1:01:27, 71.38it/s] 13%|        | 40408/303576 [25:41<1:01:50, 70.93it/s] 13%|        | 40416/303576 [25:42<1:02:12, 70.51it/s] 13%|        | 40424/303576 [25:42<1:02:29, 70.18it/s] 13%|        | 40432/303576 [25:42<1:02:41, 69.96it/s] 13%|        | 40440/303576 [25:42<1:03:10, 69.43it/s] 13%|        | 40447/303576 [25:42<1:03:08, 69.46it/s] 13%|        | 40454/303576 [25:42<1:04:10, 68.34it/s] 13%|        | 40461/303576 [25:42<1:04:13, 68.27it/s] 13%|        | 40468/303576 [25:42<1:05:21, 67.10it/s] 13%|        | 40475/303576 [25:42<1:04:58, 67.50it/s] 13%|        | 40482/303576 [25:43<1:04:49, 67.64it/s] 13%|        | 40489/303576 [25:43<1:04:14, 68.26it/s] 13%|        | 40496/303576 [25:43<1:04:40, 67.79it/s]                                                         13%|        | 40500/303576 [25:43<1:04:40, 67.79it/s] 13%|        | 40503/303576 [25:43<1:04:19, 68.17it/s] 13%|        | 40510/303576 [25:43<1:04:16, 68.22it/s] 13%|        | 40517/303576 [25:43<1:03:54, 68.61it/s] 13%|        | 40524/303576 [25:43<1:04:13, 68.27it/s] 13%|        | 40531/303576 [25:43<1:04:11, 68.29it/s] 13%|        | 40538/303576 [25:43<1:04:19, 68.15it/s] 13%|        | 40545/303576 [25:43<1:04:03, 68.43it/s] 13%|        | 40554/303576 [25:44<59:43, 73.39it/s]   13%|        | 40562/303576 [25:44<58:53, 74.44it/s] 13%|        | 40570/303576 [25:44<58:19, 75.16it/s] 13%|        | 40578/303576 [25:44<58:20, 75.13it/s] 13%|        | 40586/303576 [25:44<58:03, 75.51it/s] 13%|        | 40594/303576 [25:44<57:49, 75.81it/s]                                                       13%|        | 40600/303576 [25:44<57:49, 75.81it/s] 13%|        | 40602/303576 [25:44<57:34, 76.13it/s] 13%|        | 40610/303576 [25:44<57:30, 76.22it/s] 13%|        | 40618/303576 [25:44<57:23, 76.36it/s] 13%|        | 40626/303576 [25:45<57:22, 76.37it/s] 13%|        | 40634/303576 [25:45<57:15, 76.54it/s] 13%|        | 40642/303576 [25:45<57:24, 76.33it/s] 13%|        | 40650/303576 [25:45<57:25, 76.31it/s] 13%|        | 40658/303576 [25:45<57:38, 76.02it/s] 13%|        | 40666/303576 [25:45<57:48, 75.79it/s] 13%|        | 40674/303576 [25:45<57:56, 75.63it/s] 13%|        | 40682/303576 [25:45<58:06, 75.41it/s] 13%|        | 40690/303576 [25:45<58:17, 75.17it/s] 13%|        | 40698/303576 [25:45<57:43, 75.90it/s]                                                       13%|        | 40700/303576 [25:45<57:43, 75.90it/s] 13%|        | 40707/303576 [25:46<56:29, 77.56it/s] 13%|        | 40716/303576 [25:46<55:44, 78.59it/s] 13%|        | 40724/303576 [25:46<55:27, 78.99it/s] 13%|        | 40733/303576 [25:46<55:04, 79.53it/s] 13%|        | 40742/303576 [25:46<54:21, 80.60it/s] 13%|        | 40751/303576 [25:46<54:08, 80.90it/s] 13%|        | 40760/303576 [25:46<53:45, 81.48it/s] 13%|        | 40769/303576 [25:46<54:03, 81.02it/s] 13%|        | 40778/303576 [25:46<52:43, 83.08it/s] 13%|        | 40789/303576 [25:47<49:23, 88.66it/s] 13%|        | 40800/303576 [25:47<46:47, 93.59it/s]                                                       13%|        | 40800/303576 [25:47<46:47, 93.59it/s] 13%|        | 40811/303576 [25:47<44:38, 98.10it/s] 13%|        | 40821/303576 [25:47<44:29, 98.45it/s] 13%|        | 40831/303576 [25:47<48:13, 90.79it/s] 13%|        | 40841/303576 [25:47<50:05, 87.43it/s] 13%|        | 40850/303576 [25:47<51:10, 85.57it/s] 13%|        | 40859/303576 [25:47<52:17, 83.74it/s] 13%|        | 40868/303576 [25:47<52:44, 83.01it/s] 13%|        | 40877/303576 [25:48<53:42, 81.52it/s] 13%|        | 40886/303576 [25:48<53:38, 81.63it/s] 13%|        | 40896/303576 [25:48<51:04, 85.71it/s]                                                       13%|        | 40900/303576 [25:48<51:04, 85.71it/s] 13%|        | 40907/303576 [25:48<48:37, 90.04it/s] 13%|        | 40918/303576 [25:48<47:03, 93.04it/s] 13%|        | 40928/303576 [25:48<46:08, 94.85it/s] 13%|        | 40938/303576 [25:48<45:31, 96.16it/s] 13%|        | 40949/303576 [25:48<44:58, 97.33it/s] 13%|        | 40959/303576 [25:48<44:48, 97.68it/s] 13%|        | 40969/303576 [25:49<44:42, 97.89it/s] 13%|        | 40979/303576 [25:49<44:42, 97.88it/s] 14%|        | 40990/303576 [25:49<44:19, 98.75it/s]                                                       14%|        | 41000/303576 [25:49<44:19, 98.75it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366189360618591, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9423, 'eval_samples_per_second': 10.792, 'eval_steps_per_second': 0.096, 'epoch': 0.4, 'timestamp': 1762966068.90531, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7733, 'grad_norm': 0.3039960563182831, 'learning_rate': 1.8153344807001474e-05, 'epoch': 0.4, 'timestamp': 1762966070.8745584, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7858, 'grad_norm': 0.19805437326431274, 'learning_rate': 1.7972707021208252e-05, 'epoch': 0.4, 'timestamp': 1762966072.5166285, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7669, 'grad_norm': 0.21239127218723297, 'learning_rate': 1.779386670084102e-05, 'epoch': 0.4, 'timestamp': 1762966073.9092767, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.78, 'grad_norm': 0.31646668910980225, 'learning_rate': 1.7616805959930083e-05, 'epoch': 0.4, 'timestamp': 1762966075.2973878, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7708, 'grad_norm': 0.25224679708480835, 'learning_rate': 1.7441507090483e-05, 'epoch': 0.4, 'timestamp': 1762966076.761799, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7645, 'grad_norm': 0.253289133310318, 'learning_rate': 1.7267952560713585e-05, 'epoch': 0.4, 'timestamp': 1762966078.1259284, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7657, 'grad_norm': 0.28165680170059204, 'learning_rate': 1.7097834796768136e-05, 'epoch': 0.4, 'timestamp': 1762966079.4411132, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7718, 'grad_norm': 0.232308492064476, 'learning_rate': 1.6927700033594618e-05, 'epoch': 0.4, 'timestamp': 1762966080.6053429, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7654, 'grad_norm': 0.199370875954628, 'learning_rate': 1.675925822382626e-05, 'epoch': 0.4, 'timestamp': 1762966081.7660084, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7672, 'grad_norm': 0.21630901098251343, 'learning_rate': 1.6592492521457127e-05, 'epoch': 0.41, 'timestamp': 1762966082.7707257, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:48:06.643496: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:48:06.654321: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966086.667580 1749974 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966086.671669 1749974 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966086.682342 1749974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966086.682358 1749974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966086.682359 1749974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966086.682361 1749974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:48:06.685850: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:48:08 - TensorFlow version 2.19.1 available.
 14%|        | 41000/303576 [26:00<44:19, 98.75it/s]2025-11-12 16:48:17.221093: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:48:17.231975: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966097.244853 1750132 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966097.248562 1750132 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966097.259093 1750132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966097.259109 1750132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966097.259110 1750132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966097.259112 1750132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:48:17.262206: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:48:19 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 14%|        | 41000/303576 [26:11<44:19, 98.75it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [A 14%|        | 41001/303576 [26:11<47:03:43,  1.55it/s] 14%|        | 41006/303576 [26:11<39:24:29,  1.85it/s] 14%|        | 41015/303576 [26:11<27:50:36,  2.62it/s] 14%|        | 41023/303576 [26:12<20:28:10,  3.56it/s] 14%|        | 41031/303576 [26:12<15:00:58,  4.86it/s] 14%|        | 41038/303576 [26:12<11:26:01,  6.38it/s] 14%|        | 41045/303576 [26:12<8:41:10,  8.40it/s]  14%|        | 41052/303576 [26:12<6:36:16, 11.04it/s] 14%|        | 41058/303576 [26:12<5:13:44, 13.95it/s] 14%|        | 41065/303576 [26:12<4:01:27, 18.12it/s] 14%|        | 41072/303576 [26:12<3:11:11, 22.88it/s] 14%|        | 41079/303576 [26:13<2:36:35, 27.94it/s] 14%|        | 41085/303576 [26:13<2:14:37, 32.50it/s] 14%|        | 41091/303576 [26:13<1:59:04, 36.74it/s] 14%|        | 41097/303576 [26:13<1:49:20, 40.01it/s]                                                         14%|        | 41100/303576 [26:13<1:49:19, 40.01it/s] 14%|        | 41103/303576 [26:13<1:42:15, 42.78it/s] 14%|        | 41110/303576 [26:13<1:32:00, 47.54it/s] 14%|        | 41117/303576 [26:13<1:23:20, 52.49it/s] 14%|        | 41124/303576 [26:13<1:19:40, 54.90it/s] 14%|        | 41131/303576 [26:13<1:15:40, 57.80it/s] 14%|        | 41138/303576 [26:14<1:13:25, 59.58it/s] 14%|        | 41145/303576 [26:14<1:10:46, 61.80it/s] 14%|        | 41152/303576 [26:14<1:10:05, 62.39it/s] 14%|        | 41159/303576 [26:14<1:12:10, 60.59it/s] 14%|        | 41166/303576 [26:14<1:12:45, 60.12it/s] 14%|        | 41174/303576 [26:14<1:06:48, 65.46it/s] 14%|        | 41183/303576 [26:14<1:01:14, 71.40it/s] 14%|        | 41192/303576 [26:14<58:12, 75.12it/s]   14%|        | 41200/303576 [26:14<57:41, 75.79it/s]                                                       14%|        | 41200/303576 [26:14<57:41, 75.79it/s] 14%|        | 41209/303576 [26:15<55:19, 79.04it/s] 14%|        | 41217/303576 [26:15<55:12, 79.19it/s] 14%|        | 41226/303576 [26:15<54:55, 79.61it/s] 14%|        | 41235/303576 [26:15<54:47, 79.79it/s] 14%|        | 41244/303576 [26:15<54:19, 80.49it/s] 14%|        | 41253/303576 [26:15<54:13, 80.64it/s] 14%|        | 41262/303576 [26:15<54:08, 80.75it/s] 14%|        | 41271/303576 [26:15<54:13, 80.63it/s] 14%|        | 41280/303576 [26:15<54:08, 80.75it/s] 14%|        | 41289/303576 [26:16<53:45, 81.31it/s] 14%|        | 41298/303576 [26:16<53:40, 81.44it/s]                                                       14%|        | 41300/303576 [26:16<53:40, 81.44it/s] 14%|        | 41307/303576 [26:16<54:03, 80.86it/s] 14%|        | 41316/303576 [26:16<53:45, 81.30it/s] 14%|        | 41325/303576 [26:16<54:01, 80.92it/s] 14%|        | 41334/303576 [26:16<53:32, 81.63it/s] 14%|        | 41343/303576 [26:16<53:54, 81.07it/s] 14%|        | 41352/303576 [26:16<53:38, 81.47it/s] 14%|        | 41361/303576 [26:16<54:05, 80.79it/s] 14%|        | 41370/303576 [26:17<53:51, 81.13it/s] 14%|        | 41379/303576 [26:17<54:06, 80.76it/s] 14%|        | 41388/303576 [26:17<53:46, 81.26it/s] 14%|        | 41397/303576 [26:17<54:01, 80.88it/s]                                                       14%|        | 41400/303576 [26:17<54:01, 80.88it/s] 14%|        | 41406/303576 [26:17<54:05, 80.79it/s] 14%|        | 41415/303576 [26:17<54:21, 80.38it/s] 14%|        | 41424/303576 [26:17<53:45, 81.27it/s] 14%|        | 41433/303576 [26:17<53:56, 81.00it/s] 14%|        | 41442/303576 [26:17<53:38, 81.43it/s] 14%|        | 41451/303576 [26:18<53:27, 81.71it/s] 14%|        | 41460/303576 [26:18<52:09, 83.76it/s] 14%|        | 41471/303576 [26:18<49:06, 88.96it/s] 14%|        | 41482/303576 [26:18<46:23, 94.16it/s] 14%|        | 41492/303576 [26:18<48:04, 90.85it/s]                                                       14%|        | 41500/303576 [26:18<48:04, 90.85it/s] 14%|        | 41502/303576 [26:18<50:00, 87.33it/s] 14%|        | 41511/303576 [26:18<51:13, 85.27it/s] 14%|        | 41520/303576 [26:18<52:20, 83.43it/s] 14%|        | 41529/303576 [26:18<53:04, 82.29it/s] 14%|        | 41538/303576 [26:19<53:30, 81.61it/s] 14%|        | 41547/303576 [26:19<53:54, 81.01it/s] 14%|        | 41556/303576 [26:19<54:21, 80.34it/s] 14%|        | 41565/303576 [26:19<53:32, 81.57it/s] 14%|        | 41574/303576 [26:19<53:14, 82.02it/s] 14%|        | 41583/303576 [26:19<53:57, 80.93it/s] 14%|        | 41592/303576 [26:19<54:06, 80.71it/s]                                                       14%|        | 41600/303576 [26:19<54:06, 80.71it/s] 14%|        | 41601/303576 [26:19<54:30, 80.09it/s] 14%|        | 41610/303576 [26:19<54:37, 79.94it/s] 14%|        | 41618/303576 [26:20<54:56, 79.46it/s] 14%|        | 41626/303576 [26:20<55:11, 79.10it/s] 14%|        | 41635/303576 [26:20<54:10, 80.58it/s] 14%|        | 41646/303576 [26:20<50:19, 86.75it/s] 14%|        | 41657/303576 [26:20<47:47, 91.34it/s] 14%|        | 41667/303576 [26:20<48:19, 90.32it/s] 14%|        | 41677/303576 [26:20<50:10, 86.99it/s] 14%|        | 41686/303576 [26:20<51:13, 85.21it/s] 14%|        | 41695/303576 [26:20<52:09, 83.68it/s]                                                       14%|        | 41700/303576 [26:20<52:09, 83.68it/s] 14%|        | 41704/303576 [26:21<52:52, 82.54it/s] 14%|        | 41713/303576 [26:21<53:24, 81.71it/s] 14%|        | 41722/303576 [26:21<53:40, 81.32it/s] 14%|        | 41731/303576 [26:21<53:59, 80.84it/s] 14%|        | 41740/303576 [26:21<54:14, 80.46it/s] 14%|        | 41749/303576 [26:21<54:18, 80.36it/s] 14%|        | 41758/303576 [26:21<54:20, 80.31it/s] 14%|        | 41768/303576 [26:21<51:25, 84.86it/s] 14%|        | 41779/303576 [26:21<48:11, 90.54it/s] 14%|        | 41789/303576 [26:22<47:28, 91.90it/s] 14%|        | 41799/303576 [26:22<49:20, 88.43it/s]                                                       14%|        | 41800/303576 [26:22<49:20, 88.43it/s] 14%|        | 41808/303576 [26:22<50:39, 86.12it/s] 14%|        | 41817/303576 [26:22<51:09, 85.28it/s] 14%|        | 41826/303576 [26:22<51:42, 84.37it/s] 14%|        | 41835/303576 [26:22<52:15, 83.49it/s] 14%|        | 41844/303576 [26:22<52:33, 82.99it/s] 14%|        | 41853/303576 [26:22<52:46, 82.66it/s] 14%|        | 41862/303576 [26:22<52:54, 82.45it/s] 14%|        | 41871/303576 [26:23<53:03, 82.20it/s] 14%|        | 41880/303576 [26:23<53:07, 82.10it/s] 14%|        | 41889/303576 [26:23<53:16, 81.87it/s] 14%|        | 41898/303576 [26:23<53:15, 81.89it/s]                                                       14%|        | 41900/303576 [26:23<53:15, 81.89it/s] 14%|        | 41907/303576 [26:23<53:15, 81.88it/s] 14%|        | 41916/303576 [26:23<53:20, 81.75it/s] 14%|        | 41925/303576 [26:23<53:17, 81.83it/s] 14%|        | 41934/303576 [26:23<53:27, 81.58it/s] 14%|        | 41943/303576 [26:23<53:29, 81.51it/s] 14%|        | 41952/303576 [26:24<53:15, 81.88it/s] 14%|        | 41961/303576 [26:24<53:46, 81.09it/s] 14%|        | 41970/303576 [26:24<52:56, 82.36it/s] 14%|        | 41979/303576 [26:24<53:10, 82.00it/s] 14%|        | 41988/303576 [26:24<53:02, 82.21it/s] 14%|        | 41997/303576 [26:24<53:13, 81.92it/s]                                                       14%|        | 42000/303576 [26:24<53:13, 81.92it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7372868061065674, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.3847, 'eval_samples_per_second': 10.096, 'eval_steps_per_second': 0.089, 'epoch': 0.41, 'timestamp': 1762966105.1559331, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7849, 'grad_norm': 0.2866421341896057, 'learning_rate': 1.6427386248110167e-05, 'epoch': 0.41, 'timestamp': 1762966106.9127269, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7676, 'grad_norm': 0.2385036200284958, 'learning_rate': 1.6263922891369215e-05, 'epoch': 0.41, 'timestamp': 1762966108.3904922, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7761, 'grad_norm': 0.22745385766029358, 'learning_rate': 1.610208610312754e-05, 'epoch': 0.41, 'timestamp': 1762966109.6172068, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7714, 'grad_norm': 0.23828212916851044, 'learning_rate': 1.5941859697952945e-05, 'epoch': 0.41, 'timestamp': 1762966110.8526537, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7678, 'grad_norm': 0.24497823417186737, 'learning_rate': 1.578322765146894e-05, 'epoch': 0.41, 'timestamp': 1762966112.0098197, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.22007839381694794, 'learning_rate': 1.5626174098752202e-05, 'epoch': 0.41, 'timestamp': 1762966113.2560122, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7748, 'grad_norm': 0.2363731414079666, 'learning_rate': 1.5470683332745863e-05, 'epoch': 0.41, 'timestamp': 1762966114.4355738, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7622, 'grad_norm': 0.2222239375114441, 'learning_rate': 1.5316739802688674e-05, 'epoch': 0.41, 'timestamp': 1762966115.6116374, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7681, 'grad_norm': 0.24888326227664948, 'learning_rate': 1.516432811255973e-05, 'epoch': 0.41, 'timestamp': 1762966116.8329544, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7718, 'grad_norm': 0.28613197803497314, 'learning_rate': 1.5013433019538737e-05, 'epoch': 0.42, 'timestamp': 1762966118.054833, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:48:41.406997: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:48:41.417816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966121.431023 1750831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966121.435045 1750831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966121.445549 1750831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966121.445565 1750831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966121.445567 1750831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966121.445568 1750831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:48:41.448979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:48:43 - TensorFlow version 2.19.1 available.
2025-11-12 16:48:50.952641: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:48:50.963332: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966130.976095 1750989 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966130.979916 1750989 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966130.990530 1750989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966130.990547 1750989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966130.990549 1750989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966130.990550 1750989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:48:50.993792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:48:52 - TensorFlow version 2.19.1 available.
 14%|        | 42000/303576 [26:40<53:13, 81.92it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 14%|        | 42000/303576 [26:45<53:13, 81.92it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-42000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-42000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-42000/model.safetensors
 14%|        | 42001/303576 [26:45<61:44:29,  1.18it/s] 14%|        | 42007/303576 [26:45<46:18:37,  1.57it/s] 14%|        | 42015/303576 [26:45<31:36:39,  2.30it/s] 14%|        | 42022/303576 [26:45<22:49:39,  3.18it/s] 14%|        | 42029/303576 [26:46<16:33:00,  4.39it/s] 14%|        | 42035/303576 [26:46<12:32:56,  5.79it/s] 14%|        | 42041/303576 [26:46<9:29:46,  7.65it/s]  14%|        | 42047/303576 [26:46<7:12:52, 10.07it/s] 14%|        | 42053/303576 [26:46<5:30:25, 13.19it/s] 14%|        | 42060/303576 [26:46<4:06:05, 17.71it/s] 14%|        | 42067/303576 [26:46<3:10:57, 22.82it/s] 14%|        | 42074/303576 [26:46<2:33:23, 28.41it/s] 14%|        | 42082/303576 [26:46<2:02:13, 35.66it/s] 14%|        | 42090/303576 [26:47<1:40:30, 43.36it/s] 14%|        | 42098/303576 [26:47<1:26:36, 50.32it/s]                                                         14%|        | 42100/303576 [26:47<1:26:36, 50.32it/s] 14%|        | 42106/303576 [26:47<1:17:29, 56.23it/s] 14%|        | 42114/303576 [26:47<1:11:11, 61.22it/s] 14%|        | 42122/303576 [26:47<1:06:47, 65.24it/s] 14%|        | 42130/303576 [26:47<1:03:35, 68.51it/s] 14%|        | 42138/303576 [26:47<1:01:29, 70.86it/s] 14%|        | 42146/303576 [26:47<1:00:24, 72.13it/s] 14%|        | 42154/303576 [26:47<59:18, 73.47it/s]   14%|        | 42162/303576 [26:48<58:37, 74.31it/s] 14%|        | 42170/303576 [26:48<58:11, 74.87it/s] 14%|        | 42178/303576 [26:48<57:55, 75.21it/s] 14%|        | 42186/303576 [26:48<57:43, 75.47it/s] 14%|        | 42194/303576 [26:48<57:05, 76.31it/s]                                                       14%|        | 42200/303576 [26:48<57:05, 76.31it/s] 14%|        | 42203/303576 [26:48<55:54, 77.91it/s] 14%|        | 42212/303576 [26:48<55:13, 78.88it/s] 14%|        | 42220/303576 [26:48<55:08, 78.99it/s] 14%|        | 42229/303576 [26:48<54:57, 79.25it/s] 14%|        | 42237/303576 [26:48<54:50, 79.42it/s] 14%|        | 42245/303576 [26:49<54:44, 79.58it/s] 14%|        | 42253/303576 [26:49<54:48, 79.48it/s] 14%|        | 42261/303576 [26:49<54:50, 79.42it/s] 14%|        | 42269/303576 [26:49<54:48, 79.47it/s] 14%|        | 42277/303576 [26:49<54:50, 79.41it/s] 14%|        | 42285/303576 [26:49<54:48, 79.45it/s] 14%|        | 42294/303576 [26:49<54:08, 80.42it/s]                                                       14%|        | 42300/303576 [26:49<54:08, 80.42it/s] 14%|        | 42304/303576 [26:49<52:04, 83.62it/s] 14%|        | 42313/303576 [26:49<51:19, 84.84it/s] 14%|        | 42322/303576 [26:50<50:46, 85.75it/s] 14%|        | 42331/303576 [26:50<52:45, 82.52it/s] 14%|        | 42340/303576 [26:50<53:45, 80.98it/s] 14%|        | 42349/303576 [26:50<53:00, 82.13it/s] 14%|        | 42358/303576 [26:50<52:05, 83.58it/s] 14%|        | 42367/303576 [26:50<54:03, 80.54it/s] 14%|        | 42376/303576 [26:50<55:52, 77.92it/s] 14%|        | 42384/303576 [26:50<57:24, 75.84it/s] 14%|        | 42393/303576 [26:50<55:07, 78.96it/s]                                                       14%|        | 42400/303576 [26:50<55:07, 78.96it/s] 14%|        | 42403/303576 [26:51<51:29, 84.53it/s] 14%|        | 42414/303576 [26:51<48:14, 90.22it/s] 14%|        | 42425/303576 [26:51<46:16, 94.04it/s] 14%|        | 42435/303576 [26:51<47:13, 92.15it/s] 14%|        | 42445/303576 [26:51<49:36, 87.74it/s] 14%|        | 42454/303576 [26:51<52:46, 82.45it/s] 14%|        | 42463/303576 [26:51<55:39, 78.20it/s] 14%|        | 42471/303576 [26:51<57:16, 75.97it/s] 14%|        | 42479/303576 [26:51<58:43, 74.11it/s] 14%|        | 42487/303576 [26:52<57:55, 75.11it/s] 14%|        | 42495/303576 [26:52<57:07, 76.18it/s]                                                       14%|        | 42500/303576 [26:52<57:06, 76.18it/s] 14%|        | 42503/303576 [26:52<56:49, 76.58it/s] 14%|        | 42511/303576 [26:52<56:45, 76.66it/s] 14%|        | 42519/303576 [26:52<56:33, 76.94it/s] 14%|        | 42527/303576 [26:52<56:17, 77.29it/s] 14%|        | 42535/303576 [26:52<1:01:35, 70.63it/s] 14%|        | 42543/303576 [26:52<1:05:24, 66.51it/s] 14%|        | 42550/303576 [26:52<1:09:30, 62.59it/s] 14%|        | 42557/303576 [26:53<1:13:10, 59.46it/s] 14%|        | 42564/303576 [26:53<1:14:42, 58.23it/s] 14%|        | 42570/303576 [26:53<1:16:07, 57.14it/s] 14%|        | 42576/303576 [26:53<1:16:59, 56.50it/s] 14%|        | 42582/303576 [26:53<1:17:08, 56.39it/s] 14%|        | 42589/303576 [26:53<1:13:22, 59.28it/s] 14%|        | 42596/303576 [26:53<1:11:03, 61.21it/s]                                                         14%|        | 42600/303576 [26:53<1:11:03, 61.21it/s] 14%|        | 42603/303576 [26:53<1:10:23, 61.79it/s] 14%|        | 42610/303576 [26:53<1:08:26, 63.55it/s] 14%|        | 42617/303576 [26:54<1:08:13, 63.75it/s] 14%|        | 42624/303576 [26:54<1:07:52, 64.07it/s] 14%|        | 42631/303576 [26:54<1:06:34, 65.32it/s] 14%|        | 42638/303576 [26:54<1:05:51, 66.03it/s] 14%|        | 42645/303576 [26:54<1:05:34, 66.31it/s] 14%|        | 42652/303576 [26:54<1:04:59, 66.92it/s] 14%|        | 42659/303576 [26:54<1:04:53, 67.01it/s] 14%|        | 42666/303576 [26:54<1:04:46, 67.12it/s] 14%|        | 42673/303576 [26:54<1:04:46, 67.13it/s] 14%|        | 42680/303576 [26:55<1:04:37, 67.28it/s] 14%|        | 42687/303576 [26:55<1:04:35, 67.31it/s] 14%|        | 42694/303576 [26:55<1:04:31, 67.39it/s]                                                         14%|        | 42700/303576 [26:55<1:04:31, 67.39it/s] 14%|        | 42701/303576 [26:55<1:04:39, 67.25it/s] 14%|        | 42708/303576 [26:55<1:04:27, 67.46it/s] 14%|        | 42715/303576 [26:55<1:04:00, 67.92it/s] 14%|        | 42722/303576 [26:55<1:03:58, 67.96it/s] 14%|        | 42729/303576 [26:55<1:03:42, 68.24it/s] 14%|        | 42736/303576 [26:55<1:03:46, 68.17it/s] 14%|        | 42743/303576 [26:55<1:05:53, 65.97it/s] 14%|        | 42750/303576 [26:56<1:07:35, 64.32it/s] 14%|        | 42757/303576 [26:56<1:08:33, 63.40it/s] 14%|        | 42764/303576 [26:56<1:09:03, 62.94it/s] 14%|        | 42771/303576 [26:56<1:09:41, 62.37it/s] 14%|        | 42778/303576 [26:56<1:09:55, 62.16it/s] 14%|        | 42785/303576 [26:56<1:10:02, 62.06it/s] 14%|        | 42792/303576 [26:56<1:10:27, 61.69it/s] 14%|        | 42799/303576 [26:56<1:10:32, 61.61it/s]                                                         14%|        | 42800/303576 [26:56<1:10:32, 61.61it/s] 14%|        | 42806/303576 [26:57<1:10:23, 61.74it/s] 14%|        | 42813/303576 [26:57<1:10:26, 61.70it/s] 14%|        | 42820/303576 [26:57<1:10:44, 61.43it/s] 14%|        | 42827/303576 [26:57<1:11:03, 61.16it/s] 14%|        | 42834/303576 [26:57<1:11:22, 60.88it/s] 14%|        | 42841/303576 [26:57<1:10:55, 61.27it/s] 14%|        | 42848/303576 [26:57<1:10:56, 61.26it/s] 14%|        | 42855/303576 [26:57<1:10:53, 61.29it/s] 14%|        | 42862/303576 [26:57<1:10:55, 61.26it/s] 14%|        | 42869/303576 [26:58<1:10:54, 61.27it/s] 14%|        | 42876/303576 [26:58<1:10:48, 61.36it/s] 14%|        | 42883/303576 [26:58<1:10:37, 61.52it/s] 14%|        | 42890/303576 [26:58<1:10:32, 61.59it/s] 14%|        | 42897/303576 [26:58<1:10:48, 61.35it/s]                                                         14%|        | 42900/303576 [26:58<1:10:48, 61.35it/s] 14%|        | 42904/303576 [26:58<1:10:53, 61.28it/s] 14%|        | 42911/303576 [26:58<1:10:59, 61.20it/s] 14%|        | 42918/303576 [26:58<1:10:41, 61.45it/s] 14%|        | 42925/303576 [26:58<1:10:38, 61.50it/s] 14%|        | 42932/303576 [26:59<1:10:54, 61.27it/s] 14%|        | 42939/303576 [26:59<1:10:44, 61.40it/s] 14%|        | 42946/303576 [26:59<1:10:33, 61.57it/s] 14%|        | 42953/303576 [26:59<1:10:42, 61.43it/s] 14%|        | 42960/303576 [26:59<1:12:06, 60.23it/s] 14%|        | 42967/303576 [26:59<1:13:37, 58.99it/s] 14%|        | 42973/303576 [26:59<1:13:43, 58.92it/s] 14%|        | 42979/303576 [26:59<1:14:13, 58.51it/s] 14%|        | 42986/303576 [26:59<1:12:07, 60.21it/s] 14%|        | 42993/303576 [27:00<1:11:49, 60.47it/s] 14%|        | 43000/303576 [27:00<1:11:21, 60.86it/s]                                                         14%|        | 43000/303576 [27:00<1:11:21, 60.86it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7370602488517761, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.8975, 'eval_samples_per_second': 10.815, 'eval_steps_per_second': 0.096, 'epoch': 0.42, 'timestamp': 1762966138.9527512, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7615, 'grad_norm': 0.3078464865684509, 'learning_rate': 1.4864039432481535e-05, 'epoch': 0.42, 'timestamp': 1762966140.6663368, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7787, 'grad_norm': 0.23535014688968658, 'learning_rate': 1.4716132410410814e-05, 'epoch': 0.42, 'timestamp': 1762966141.968869, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7664, 'grad_norm': 0.2872864305973053, 'learning_rate': 1.4569697161021892e-05, 'epoch': 0.42, 'timestamp': 1762966143.207654, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7699, 'grad_norm': 0.3059691786766052, 'learning_rate': 1.4424719039203276e-05, 'epoch': 0.42, 'timestamp': 1762966144.4348655, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7792, 'grad_norm': 0.2853841781616211, 'learning_rate': 1.4281183545572048e-05, 'epoch': 0.42, 'timestamp': 1762966145.6703887, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7597, 'grad_norm': 0.26918458938598633, 'learning_rate': 1.4139076325023705e-05, 'epoch': 0.42, 'timestamp': 1762966147.2835588, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7775, 'grad_norm': 0.18737982213497162, 'learning_rate': 1.399838316529656e-05, 'epoch': 0.42, 'timestamp': 1762966148.776469, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.775, 'grad_norm': 0.265668660402298, 'learning_rate': 1.38590899955503e-05, 'epoch': 0.42, 'timestamp': 1762966150.3461652, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.23692083358764648, 'learning_rate': 1.3721182884958794e-05, 'epoch': 0.42, 'timestamp': 1762966151.977239, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7656, 'grad_norm': 0.2627354562282562, 'learning_rate': 1.358464804131682e-05, 'epoch': 0.42, 'timestamp': 1762966153.6300254, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:49:17.596908: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:49:17.607858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966157.621016 1751430 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966157.624800 1751430 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966157.635305 1751430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966157.635325 1751430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966157.635327 1751430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966157.635328 1751430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:49:17.638405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:49:19 - TensorFlow version 2.19.1 available.
 14%|        | 43000/303576 [27:10<1:11:21, 60.86it/s]2025-11-12 16:49:28.111768: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:49:28.122555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966168.135521 1751588 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966168.139298 1751588 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966168.150026 1751588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966168.150045 1751588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966168.150046 1751588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966168.150048 1751588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:49:28.153318: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:49:30 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                        
                                             [A 14%|        | 43000/303576 [27:22<1:11:21, 60.86it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [A 14%|        | 43001/303576 [27:22<98:06:11,  1.36s/it] 14%|        | 43006/303576 [27:22<69:30:43,  1.04it/s] 14%|        | 43012/303576 [27:23<46:41:40,  1.55it/s] 14%|        | 43018/303576 [27:23<32:06:55,  2.25it/s] 14%|        | 43023/303576 [27:23<23:40:26,  3.06it/s] 14%|        | 43028/303576 [27:23<17:24:15,  4.16it/s] 14%|        | 43034/303576 [27:23<12:08:11,  5.96it/s] 14%|        | 43040/303576 [27:23<8:42:39,  8.31it/s]  14%|        | 43046/303576 [27:23<6:24:27, 11.29it/s] 14%|        | 43052/303576 [27:23<4:51:20, 14.90it/s] 14%|        | 43058/303576 [27:24<3:47:45, 19.06it/s] 14%|        | 43064/303576 [27:24<3:03:30, 23.66it/s] 14%|        | 43070/303576 [27:24<2:31:42, 28.62it/s] 14%|        | 43076/303576 [27:24<2:10:27, 33.28it/s] 14%|        | 43082/303576 [27:24<1:53:12, 38.35it/s] 14%|        | 43089/303576 [27:24<1:39:13, 43.75it/s] 14%|        | 43095/303576 [27:24<1:31:29, 47.45it/s]                                                         14%|        | 43100/303576 [27:24<1:31:29, 47.45it/s] 14%|        | 43101/303576 [27:24<1:30:57, 47.73it/s] 14%|        | 43107/303576 [27:25<1:31:06, 47.65it/s] 14%|        | 43113/303576 [27:25<1:31:27, 47.47it/s] 14%|        | 43119/303576 [27:25<1:28:59, 48.78it/s] 14%|        | 43126/303576 [27:25<1:22:58, 52.31it/s] 14%|        | 43132/303576 [27:25<1:21:12, 53.45it/s] 14%|        | 43138/303576 [27:25<1:20:11, 54.13it/s] 14%|        | 43144/303576 [27:25<1:18:37, 55.21it/s] 14%|        | 43150/303576 [27:25<1:17:12, 56.22it/s] 14%|        | 43156/303576 [27:25<1:16:13, 56.94it/s] 14%|        | 43162/303576 [27:25<1:15:38, 57.38it/s] 14%|        | 43168/303576 [27:26<1:15:18, 57.64it/s] 14%|        | 43174/303576 [27:26<1:14:59, 57.87it/s] 14%|        | 43180/303576 [27:26<1:14:57, 57.90it/s] 14%|        | 43186/303576 [27:26<1:14:51, 57.98it/s] 14%|        | 43192/303576 [27:26<1:14:38, 58.14it/s] 14%|        | 43198/303576 [27:26<1:14:33, 58.20it/s]                                                         14%|        | 43200/303576 [27:26<1:14:33, 58.20it/s] 14%|        | 43204/303576 [27:26<1:14:36, 58.17it/s] 14%|        | 43210/303576 [27:26<1:14:46, 58.04it/s] 14%|        | 43216/303576 [27:26<1:14:28, 58.27it/s] 14%|        | 43222/303576 [27:27<1:14:38, 58.14it/s] 14%|        | 43228/303576 [27:27<1:14:30, 58.23it/s] 14%|        | 43234/303576 [27:27<1:14:26, 58.29it/s] 14%|        | 43240/303576 [27:27<1:14:17, 58.41it/s] 14%|        | 43247/303576 [27:27<1:13:00, 59.43it/s] 14%|        | 43254/303576 [27:27<1:10:59, 61.11it/s] 14%|        | 43261/303576 [27:27<1:09:32, 62.38it/s] 14%|        | 43268/303576 [27:27<1:14:38, 58.13it/s] 14%|        | 43274/303576 [27:27<1:16:46, 56.51it/s] 14%|        | 43280/303576 [27:28<1:19:40, 54.45it/s] 14%|        | 43286/303576 [27:28<1:21:27, 53.25it/s] 14%|        | 43292/303576 [27:28<1:20:50, 53.66it/s] 14%|        | 43298/303576 [27:28<1:20:37, 53.81it/s]                                                         14%|        | 43300/303576 [27:28<1:20:37, 53.81it/s] 14%|        | 43304/303576 [27:28<1:19:59, 54.23it/s] 14%|        | 43310/303576 [27:28<1:20:11, 54.09it/s] 14%|        | 43316/303576 [27:28<1:19:25, 54.61it/s] 14%|        | 43323/303576 [27:28<1:16:45, 56.51it/s] 14%|        | 43330/303576 [27:28<1:14:29, 58.23it/s] 14%|        | 43337/303576 [27:29<1:12:39, 59.70it/s] 14%|        | 43343/303576 [27:29<1:12:50, 59.54it/s] 14%|        | 43351/303576 [27:29<1:06:26, 65.27it/s] 14%|        | 43360/303576 [27:29<1:01:54, 70.06it/s] 14%|        | 43368/303576 [27:29<59:54, 72.39it/s]   14%|        | 43377/303576 [27:29<57:30, 75.42it/s] 14%|        | 43386/303576 [27:29<55:31, 78.09it/s] 14%|        | 43395/303576 [27:29<54:00, 80.28it/s]                                                       14%|        | 43400/303576 [27:29<54:00, 80.28it/s] 14%|        | 43404/303576 [27:29<53:12, 81.50it/s] 14%|        | 43413/303576 [27:29<53:08, 81.59it/s] 14%|        | 43422/303576 [27:30<53:39, 80.80it/s] 14%|        | 43432/303576 [27:30<51:31, 84.14it/s] 14%|        | 43442/303576 [27:30<49:10, 88.17it/s] 14%|        | 43452/303576 [27:30<47:52, 90.55it/s] 14%|        | 43463/303576 [27:30<45:49, 94.61it/s] 14%|        | 43474/303576 [27:30<44:15, 97.94it/s] 14%|        | 43484/303576 [27:30<44:11, 98.08it/s] 14%|        | 43495/303576 [27:30<42:57, 100.92it/s]                                                        14%|        | 43500/303576 [27:30<42:56, 100.92it/s] 14%|        | 43506/303576 [27:30<42:53, 101.05it/s] 14%|        | 43517/303576 [27:31<42:10, 102.76it/s] 14%|        | 43528/303576 [27:31<42:05, 102.95it/s] 14%|        | 43539/303576 [27:31<43:27, 99.74it/s]  14%|        | 43550/303576 [27:31<43:13, 100.26it/s] 14%|        | 43561/303576 [27:31<42:57, 100.87it/s] 14%|        | 43572/303576 [27:31<43:00, 100.74it/s] 14%|        | 43583/303576 [27:31<42:21, 102.31it/s] 14%|        | 43594/303576 [27:31<42:30, 101.94it/s]                                                        14%|        | 43600/303576 [27:31<42:30, 101.94it/s] 14%|        | 43605/303576 [27:31<44:50, 96.64it/s]  14%|        | 43615/303576 [27:32<47:22, 91.45it/s] 14%|        | 43625/303576 [27:32<49:52, 86.86it/s] 14%|        | 43634/303576 [27:32<51:27, 84.20it/s] 14%|        | 43643/303576 [27:32<52:43, 82.17it/s] 14%|        | 43652/303576 [27:32<53:38, 80.76it/s] 14%|        | 43661/303576 [27:32<54:16, 79.82it/s] 14%|        | 43669/303576 [27:32<54:16, 79.81it/s] 14%|        | 43677/303576 [27:32<54:40, 79.22it/s] 14%|        | 43685/303576 [27:32<55:06, 78.60it/s] 14%|        | 43693/303576 [27:33<55:20, 78.26it/s]                                                       14%|        | 43700/303576 [27:33<55:20, 78.26it/s] 14%|        | 43702/303576 [27:33<54:51, 78.95it/s] 14%|        | 43710/303576 [27:33<55:07, 78.56it/s] 14%|        | 43718/303576 [27:33<55:18, 78.32it/s] 14%|        | 43726/303576 [27:33<55:09, 78.51it/s] 14%|        | 43734/303576 [27:33<55:08, 78.53it/s] 14%|        | 43743/303576 [27:33<54:35, 79.34it/s] 14%|        | 43751/303576 [27:33<54:31, 79.43it/s] 14%|        | 43759/303576 [27:33<54:33, 79.36it/s] 14%|        | 43767/303576 [27:34<54:34, 79.33it/s] 14%|        | 43775/303576 [27:34<54:38, 79.23it/s] 14%|        | 43783/303576 [27:34<54:51, 78.94it/s] 14%|        | 43791/303576 [27:34<54:41, 79.16it/s] 14%|        | 43799/303576 [27:34<54:44, 79.09it/s]                                                       14%|        | 43800/303576 [27:34<54:44, 79.09it/s] 14%|        | 43807/303576 [27:34<54:45, 79.06it/s] 14%|        | 43815/303576 [27:34<54:44, 79.10it/s] 14%|        | 43823/303576 [27:34<54:41, 79.16it/s] 14%|        | 43831/303576 [27:34<54:56, 78.80it/s] 14%|        | 43839/303576 [27:34<54:59, 78.72it/s] 14%|        | 43847/303576 [27:35<55:00, 78.69it/s] 14%|        | 43855/303576 [27:35<57:03, 75.87it/s] 14%|        | 43863/303576 [27:35<58:26, 74.06it/s] 14%|        | 43871/303576 [27:35<59:32, 72.70it/s] 14%|        | 43879/303576 [27:35<1:00:30, 71.53it/s] 14%|        | 43887/303576 [27:35<1:00:56, 71.02it/s] 14%|        | 43895/303576 [27:35<1:02:28, 69.27it/s]                                                         14%|        | 43900/303576 [27:35<1:02:28, 69.27it/s] 14%|        | 43902/303576 [27:35<1:03:20, 68.32it/s] 14%|        | 43909/303576 [27:35<1:03:37, 68.03it/s] 14%|        | 43917/303576 [27:36<1:02:33, 69.18it/s] 14%|        | 43924/303576 [27:36<1:03:38, 68.01it/s] 14%|        | 43931/303576 [27:36<1:03:49, 67.81it/s] 14%|        | 43940/303576 [27:36<59:49, 72.34it/s]   14%|        | 43948/303576 [27:36<58:57, 73.38it/s] 14%|        | 43956/303576 [27:36<58:06, 74.46it/s] 14%|        | 43967/303576 [27:36<52:01, 83.16it/s] 14%|        | 43977/303576 [27:36<49:37, 87.18it/s] 14%|        | 43986/303576 [27:36<50:51, 85.07it/s] 14%|        | 43995/303576 [27:36<51:18, 84.33it/s]                                                       14%|        | 44000/303576 [27:37<51:18, 84.33it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7371364235877991, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.6548, 'eval_samples_per_second': 9.976, 'eval_steps_per_second': 0.088, 'epoch': 0.42, 'timestamp': 1762966176.285487, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7732, 'grad_norm': 0.2182547152042389, 'learning_rate': 1.3449471809660747e-05, 'epoch': 0.43, 'timestamp': 1762966178.303597, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7665, 'grad_norm': 0.2756149172782898, 'learning_rate': 1.3316972368139677e-05, 'epoch': 0.43, 'timestamp': 1762966180.088636, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8026, 'grad_norm': 0.30056139826774597, 'learning_rate': 1.3184459686447962e-05, 'epoch': 0.43, 'timestamp': 1762966181.852266, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7522, 'grad_norm': 0.21638908982276917, 'learning_rate': 1.3053265593570855e-05, 'epoch': 0.43, 'timestamp': 1762966183.277436, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7688, 'grad_norm': 0.21999520063400269, 'learning_rate': 1.2923376968677666e-05, 'epoch': 0.43, 'timestamp': 1762966184.3278701, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7772, 'grad_norm': 0.27262404561042786, 'learning_rate': 1.279478082149863e-05, 'epoch': 0.43, 'timestamp': 1762966185.3181934, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7618, 'grad_norm': 0.2628185451030731, 'learning_rate': 1.2667464291025767e-05, 'epoch': 0.43, 'timestamp': 1762966186.5938818, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7719, 'grad_norm': 0.23290182650089264, 'learning_rate': 1.2541414644226629e-05, 'epoch': 0.43, 'timestamp': 1762966187.8599582, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7784, 'grad_norm': 0.2788533866405487, 'learning_rate': 1.2416619274770857e-05, 'epoch': 0.43, 'timestamp': 1762966189.2282586, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7703, 'grad_norm': 0.20753300189971924, 'learning_rate': 1.2293065701769433e-05, 'epoch': 0.43, 'timestamp': 1762966190.493218, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:49:53.863510: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:49:53.874179: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966193.887043 1752024 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966193.890905 1752024 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966193.901583 1752024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966193.901599 1752024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966193.901601 1752024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966193.901602 1752024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:49:53.904815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:49:55 - TensorFlow version 2.19.1 available.
2025-11-12 16:50:03.460397: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:50:03.471101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966203.483970 1752182 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966203.487846 1752182 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966203.498404 1752182 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966203.498425 1752182 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966203.498427 1752182 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966203.498429 1752182 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:50:03.501697: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 14%|        | 44000/303576 [27:50<51:18, 84.33it/s]2025-11-12T16:50:05 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 14%|        | 44000/303576 [27:58<51:18, 84.33it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-44000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-44000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-44000/model.safetensors
 14%|        | 44001/303576 [27:58<57:02:17,  1.26it/s] 14%|        | 44008/303576 [27:58<42:00:34,  1.72it/s] 14%|        | 44016/303576 [27:58<29:30:55,  2.44it/s] 15%|        | 44024/303576 [27:58<20:52:11,  3.45it/s] 15%|        | 44032/303576 [27:58<14:52:13,  4.85it/s] 15%|        | 44040/303576 [27:58<10:41:45,  6.74it/s] 15%|        | 44048/303576 [27:58<7:46:10,  9.28it/s]  15%|        | 44058/303576 [27:59<5:19:15, 13.55it/s] 15%|        | 44066/303576 [27:59<4:04:26, 17.69it/s] 15%|        | 44075/303576 [27:59<3:04:03, 23.50it/s] 15%|        | 44084/303576 [27:59<2:22:05, 30.44it/s] 15%|        | 44094/303576 [27:59<1:50:52, 39.00it/s]                                                         15%|        | 44100/303576 [27:59<1:50:52, 39.00it/s] 15%|        | 44103/303576 [27:59<1:34:29, 45.76it/s] 15%|        | 44112/303576 [27:59<1:24:30, 51.17it/s] 15%|        | 44120/303576 [27:59<1:17:52, 55.52it/s] 15%|        | 44128/303576 [27:59<1:12:58, 59.26it/s] 15%|        | 44136/303576 [28:00<1:08:36, 63.03it/s] 15%|        | 44145/303576 [28:00<1:02:52, 68.77it/s] 15%|        | 44154/303576 [28:00<58:39, 73.70it/s]   15%|        | 44163/303576 [28:00<56:42, 76.25it/s] 15%|        | 44172/303576 [28:00<55:15, 78.23it/s] 15%|        | 44181/303576 [28:00<54:56, 78.68it/s] 15%|        | 44191/303576 [28:00<51:32, 83.88it/s] 15%|        | 44200/303576 [28:00<52:00, 83.13it/s]                                                       15%|        | 44200/303576 [28:00<52:00, 83.13it/s] 15%|        | 44209/303576 [28:00<52:23, 82.52it/s] 15%|        | 44218/303576 [28:01<52:11, 82.82it/s] 15%|        | 44227/303576 [28:01<52:36, 82.17it/s] 15%|        | 44236/303576 [28:01<52:22, 82.53it/s] 15%|        | 44245/303576 [28:01<52:16, 82.67it/s] 15%|        | 44255/303576 [28:01<50:04, 86.31it/s] 15%|        | 44264/303576 [28:01<51:16, 84.30it/s] 15%|        | 44273/303576 [28:01<52:33, 82.23it/s] 15%|        | 44282/303576 [28:01<53:35, 80.64it/s] 15%|        | 44291/303576 [28:01<54:33, 79.21it/s] 15%|        | 44299/303576 [28:02<55:09, 78.33it/s]                                                       15%|        | 44300/303576 [28:02<55:09, 78.33it/s] 15%|        | 44307/303576 [28:02<55:32, 77.80it/s] 15%|        | 44315/303576 [28:02<55:47, 77.45it/s] 15%|        | 44323/303576 [28:02<55:53, 77.31it/s] 15%|        | 44332/303576 [28:02<54:30, 79.27it/s] 15%|        | 44343/303576 [28:02<49:23, 87.47it/s] 15%|        | 44354/303576 [28:02<46:28, 92.95it/s] 15%|        | 44365/303576 [28:02<44:23, 97.33it/s] 15%|        | 44375/303576 [28:02<46:07, 93.67it/s] 15%|        | 44385/303576 [28:03<50:27, 85.60it/s] 15%|        | 44394/303576 [28:03<53:38, 80.53it/s]                                                       15%|        | 44400/303576 [28:03<53:38, 80.53it/s] 15%|        | 44403/303576 [28:03<55:24, 77.96it/s] 15%|        | 44411/303576 [28:03<56:43, 76.15it/s] 15%|        | 44419/303576 [28:03<57:49, 74.70it/s] 15%|        | 44427/303576 [28:03<58:45, 73.50it/s] 15%|        | 44435/303576 [28:03<59:25, 72.69it/s] 15%|        | 44443/303576 [28:03<1:00:01, 71.96it/s] 15%|        | 44451/303576 [28:03<58:15, 74.12it/s]   15%|        | 44460/303576 [28:04<56:57, 75.82it/s] 15%|        | 44470/303576 [28:04<53:48, 80.24it/s] 15%|        | 44479/303576 [28:04<52:55, 81.60it/s] 15%|        | 44488/303576 [28:04<53:07, 81.29it/s] 15%|        | 44497/303576 [28:04<53:22, 80.91it/s]                                                       15%|        | 44500/303576 [28:04<53:22, 80.91it/s] 15%|        | 44506/303576 [28:04<54:16, 79.56it/s] 15%|        | 44514/303576 [28:04<54:41, 78.95it/s] 15%|        | 44522/303576 [28:04<54:50, 78.74it/s] 15%|        | 44530/303576 [28:04<57:43, 74.79it/s] 15%|        | 44538/303576 [28:05<1:02:20, 69.25it/s] 15%|        | 44546/303576 [28:05<1:06:06, 65.30it/s] 15%|        | 44553/303576 [28:05<1:09:19, 62.28it/s] 15%|        | 44560/303576 [28:05<1:13:24, 58.80it/s] 15%|        | 44566/303576 [28:05<1:15:18, 57.33it/s] 15%|        | 44572/303576 [28:05<1:16:42, 56.27it/s] 15%|        | 44578/303576 [28:05<1:17:43, 55.54it/s] 15%|        | 44584/303576 [28:05<1:17:40, 55.57it/s] 15%|        | 44590/303576 [28:06<1:17:15, 55.87it/s] 15%|        | 44596/303576 [28:06<1:16:38, 56.32it/s]                                                         15%|        | 44600/303576 [28:06<1:16:38, 56.32it/s] 15%|        | 44602/303576 [28:06<1:16:03, 56.75it/s] 15%|        | 44608/303576 [28:06<1:15:49, 56.92it/s] 15%|        | 44614/303576 [28:06<1:15:21, 57.27it/s] 15%|        | 44620/303576 [28:06<1:14:53, 57.62it/s] 15%|        | 44626/303576 [28:06<1:14:37, 57.84it/s] 15%|        | 44632/303576 [28:06<1:14:37, 57.83it/s] 15%|        | 44638/303576 [28:06<1:14:39, 57.81it/s] 15%|        | 44644/303576 [28:06<1:15:02, 57.51it/s] 15%|        | 44650/303576 [28:07<1:15:19, 57.29it/s] 15%|        | 44656/303576 [28:07<1:15:28, 57.17it/s] 15%|        | 44662/303576 [28:07<1:15:03, 57.49it/s] 15%|        | 44668/303576 [28:07<1:16:51, 56.15it/s] 15%|        | 44674/303576 [28:07<1:18:56, 54.67it/s] 15%|        | 44680/303576 [28:07<1:20:12, 53.80it/s] 15%|        | 44686/303576 [28:07<1:22:32, 52.28it/s] 15%|        | 44692/303576 [28:07<1:23:33, 51.64it/s] 15%|        | 44698/303576 [28:07<1:24:15, 51.21it/s]                                                         15%|        | 44700/303576 [28:08<1:24:15, 51.21it/s] 15%|        | 44704/303576 [28:08<1:25:25, 50.51it/s] 15%|        | 44710/303576 [28:08<1:24:41, 50.94it/s] 15%|        | 44716/303576 [28:08<1:22:43, 52.15it/s] 15%|        | 44722/303576 [28:08<1:20:33, 53.56it/s] 15%|        | 44728/303576 [28:08<1:19:18, 54.39it/s] 15%|        | 44734/303576 [28:08<1:17:57, 55.34it/s] 15%|        | 44740/303576 [28:08<1:16:42, 56.24it/s] 15%|        | 44746/303576 [28:08<1:16:01, 56.74it/s] 15%|        | 44752/303576 [28:08<1:16:18, 56.53it/s] 15%|        | 44758/303576 [28:09<1:15:32, 57.11it/s] 15%|        | 44764/303576 [28:09<1:14:57, 57.54it/s] 15%|        | 44770/303576 [28:09<1:14:56, 57.56it/s] 15%|        | 44776/303576 [28:09<1:15:26, 57.17it/s] 15%|        | 44782/303576 [28:09<1:16:23, 56.47it/s] 15%|        | 44788/303576 [28:09<1:15:44, 56.95it/s] 15%|        | 44794/303576 [28:09<1:15:23, 57.21it/s] 15%|        | 44800/303576 [28:09<1:14:49, 57.64it/s]                                                         15%|        | 44800/303576 [28:09<1:14:49, 57.64it/s] 15%|        | 44806/303576 [28:09<1:15:14, 57.32it/s] 15%|        | 44812/303576 [28:09<1:14:57, 57.53it/s] 15%|        | 44818/303576 [28:10<1:14:38, 57.77it/s] 15%|        | 44824/303576 [28:10<1:14:36, 57.81it/s] 15%|        | 44830/303576 [28:10<1:14:43, 57.72it/s] 15%|        | 44836/303576 [28:10<1:13:57, 58.31it/s] 15%|        | 44842/303576 [28:10<1:14:48, 57.65it/s] 15%|        | 44848/303576 [28:10<1:14:46, 57.67it/s] 15%|        | 44854/303576 [28:10<1:14:46, 57.66it/s] 15%|        | 44860/303576 [28:10<1:16:19, 56.50it/s] 15%|        | 44866/303576 [28:10<1:18:08, 55.18it/s] 15%|        | 44872/303576 [28:11<1:18:41, 54.80it/s] 15%|        | 44878/303576 [28:11<1:18:26, 54.97it/s] 15%|        | 44884/303576 [28:11<1:17:16, 55.79it/s] 15%|        | 44890/303576 [28:11<1:17:30, 55.62it/s] 15%|        | 44896/303576 [28:11<1:17:49, 55.39it/s]                                                         15%|        | 44900/303576 [28:11<1:17:49, 55.39it/s] 15%|        | 44902/303576 [28:11<1:18:25, 54.97it/s] 15%|        | 44908/303576 [28:11<1:17:32, 55.59it/s] 15%|        | 44914/303576 [28:11<1:18:13, 55.11it/s] 15%|        | 44920/303576 [28:11<1:18:16, 55.07it/s] 15%|        | 44926/303576 [28:12<1:17:31, 55.60it/s] 15%|        | 44932/303576 [28:12<1:16:02, 56.69it/s] 15%|        | 44938/303576 [28:12<1:18:46, 54.72it/s] 15%|        | 44944/303576 [28:12<1:22:46, 52.08it/s] 15%|        | 44950/303576 [28:12<1:25:17, 50.54it/s] 15%|        | 44956/303576 [28:12<1:22:36, 52.18it/s] 15%|        | 44963/303576 [28:12<1:17:53, 55.34it/s] 15%|        | 44969/303576 [28:12<1:17:04, 55.92it/s] 15%|        | 44975/303576 [28:12<1:16:34, 56.28it/s] 15%|        | 44981/303576 [28:13<1:16:44, 56.16it/s] 15%|        | 44987/303576 [28:13<1:16:48, 56.12it/s] 15%|        | 44993/303576 [28:13<1:17:13, 55.81it/s] 15%|        | 44999/303576 [28:13<1:17:32, 55.58it/s]                                                         15%|        | 45000/303576 [28:13<1:17:32, 55.58it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7361429333686829, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.1648, 'eval_samples_per_second': 10.678, 'eval_steps_per_second': 0.094, 'epoch': 0.43, 'timestamp': 1762966211.658421, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7881, 'grad_norm': 0.29368868470191956, 'learning_rate': 1.2170741568526411e-05, 'epoch': 0.44, 'timestamp': 1762966212.9934673, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7632, 'grad_norm': 0.20549094676971436, 'learning_rate': 1.2049634641303166e-05, 'epoch': 0.44, 'timestamp': 1762966214.2429922, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7732, 'grad_norm': 0.1987902671098709, 'learning_rate': 1.192973280809485e-05, 'epoch': 0.44, 'timestamp': 1762966215.476374, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7743, 'grad_norm': 0.28850892186164856, 'learning_rate': 1.1811024077419077e-05, 'epoch': 0.44, 'timestamp': 1762966216.66215, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7844, 'grad_norm': 0.2699519395828247, 'learning_rate': 1.1693496577116629e-05, 'epoch': 0.44, 'timestamp': 1762966217.9592128, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7938, 'grad_norm': 0.2802930176258087, 'learning_rate': 1.1577138553164136e-05, 'epoch': 0.44, 'timestamp': 1762966219.626119, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7615, 'grad_norm': 0.20533165335655212, 'learning_rate': 1.1461938368498535e-05, 'epoch': 0.44, 'timestamp': 1762966221.4498303, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.767, 'grad_norm': 0.3260524272918701, 'learning_rate': 1.1347884501853238e-05, 'epoch': 0.44, 'timestamp': 1762966223.2174416, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.2544824779033661, 'learning_rate': 1.1234965546605871e-05, 'epoch': 0.44, 'timestamp': 1762966224.9934134, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7675, 'grad_norm': 0.2264523059129715, 'learning_rate': 1.1123170209637483e-05, 'epoch': 0.44, 'timestamp': 1762966226.8125982, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:50:30.673398: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:50:30.684194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966230.697314 1752622 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966230.701365 1752622 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966230.711895 1752622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966230.711911 1752622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966230.711913 1752622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966230.711915 1752622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:50:30.715296: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:50:33 - TensorFlow version 2.19.1 available.
2025-11-12 16:50:41.318802: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:50:41.329533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966241.342378 1752780 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966241.346074 1752780 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966241.356523 1752780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966241.356540 1752780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966241.356542 1752780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966241.356543 1752780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:50:41.359626: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:50:43 - TensorFlow version 2.19.1 available.
 15%|        | 45000/303576 [28:30<1:17:32, 55.58it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A 15%|        | 45000/303576 [28:35<1:17:32, 55.58it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 15%|        | 45001/303576 [28:35<102:15:29,  1.42s/it] 15%|        | 45005/303576 [28:36<75:58:51,  1.06s/it]  15%|        | 45010/303576 [28:36<52:13:24,  1.38it/s] 15%|        | 45015/303576 [28:36<36:22:29,  1.97it/s] 15%|        | 45020/303576 [28:36<25:35:35,  2.81it/s] 15%|        | 45025/303576 [28:36<18:14:20,  3.94it/s] 15%|        | 45030/303576 [28:36<13:08:24,  5.47it/s] 15%|        | 45035/303576 [28:36<9:38:10,  7.45it/s]  15%|        | 45040/303576 [28:36<7:10:28, 10.01it/s] 15%|        | 45045/303576 [28:36<5:29:20, 13.08it/s] 15%|        | 45050/303576 [28:37<4:16:59, 16.77it/s] 15%|        | 45055/303576 [28:37<3:28:24, 20.67it/s] 15%|        | 45061/303576 [28:37<2:45:53, 25.97it/s] 15%|        | 45067/303576 [28:37<2:17:24, 31.35it/s] 15%|        | 45073/303576 [28:37<1:59:00, 36.20it/s] 15%|        | 45079/303576 [28:37<1:49:08, 39.48it/s] 15%|        | 45085/303576 [28:37<1:44:12, 41.34it/s] 15%|        | 45090/303576 [28:37<1:41:19, 42.52it/s] 15%|        | 45095/303576 [28:37<1:41:07, 42.60it/s] 15%|        | 45100/303576 [28:38<1:39:46, 43.18it/s]                                                         15%|        | 45100/303576 [28:38<1:39:46, 43.18it/s] 15%|        | 45105/303576 [28:38<1:40:51, 42.72it/s] 15%|        | 45110/303576 [28:38<1:41:08, 42.59it/s] 15%|        | 45115/303576 [28:38<1:39:47, 43.16it/s] 15%|        | 45120/303576 [28:38<1:36:10, 44.79it/s] 15%|        | 45125/303576 [28:38<1:35:38, 45.04it/s] 15%|        | 45130/303576 [28:38<1:33:15, 46.19it/s] 15%|        | 45137/303576 [28:38<1:24:47, 50.80it/s] 15%|        | 45143/303576 [28:38<1:22:35, 52.16it/s] 15%|        | 45149/303576 [28:39<1:19:41, 54.05it/s] 15%|        | 45155/303576 [28:39<1:17:57, 55.24it/s] 15%|        | 45161/303576 [28:39<1:17:13, 55.78it/s] 15%|        | 45168/303576 [28:39<1:15:21, 57.16it/s] 15%|        | 45175/303576 [28:39<1:12:39, 59.27it/s] 15%|        | 45182/303576 [28:39<1:11:17, 60.41it/s] 15%|        | 45189/303576 [28:39<1:10:12, 61.33it/s] 15%|        | 45196/303576 [28:39<1:08:51, 62.54it/s]                                                         15%|        | 45200/303576 [28:39<1:08:51, 62.54it/s] 15%|        | 45203/303576 [28:39<1:08:22, 62.98it/s] 15%|        | 45210/303576 [28:40<1:07:44, 63.57it/s] 15%|        | 45217/303576 [28:40<1:07:12, 64.06it/s] 15%|        | 45224/303576 [28:40<1:07:27, 63.83it/s] 15%|        | 45231/303576 [28:40<1:10:41, 60.91it/s] 15%|        | 45238/303576 [28:40<1:12:39, 59.26it/s] 15%|        | 45245/303576 [28:40<1:11:05, 60.57it/s] 15%|        | 45252/303576 [28:40<1:11:26, 60.27it/s] 15%|        | 45259/303576 [28:40<1:12:04, 59.73it/s] 15%|        | 45265/303576 [28:40<1:13:41, 58.42it/s] 15%|        | 45272/303576 [28:41<1:13:02, 58.94it/s] 15%|        | 45278/303576 [28:41<1:14:02, 58.15it/s] 15%|        | 45284/303576 [28:41<1:15:49, 56.78it/s] 15%|        | 45290/303576 [28:41<1:20:49, 53.26it/s] 15%|        | 45296/303576 [28:41<1:23:43, 51.41it/s]                                                         15%|        | 45300/303576 [28:41<1:23:43, 51.41it/s] 15%|        | 45302/303576 [28:41<1:25:56, 50.08it/s] 15%|        | 45308/303576 [28:41<1:24:09, 51.15it/s] 15%|        | 45314/303576 [28:41<1:22:35, 52.12it/s] 15%|        | 45320/303576 [28:42<1:20:51, 53.23it/s] 15%|        | 45326/303576 [28:42<1:19:46, 53.96it/s] 15%|        | 45332/303576 [28:42<1:18:04, 55.13it/s] 15%|        | 45338/303576 [28:42<1:20:13, 53.65it/s] 15%|        | 45344/303576 [28:42<1:18:01, 55.16it/s] 15%|        | 45351/303576 [28:42<1:15:30, 57.00it/s] 15%|        | 45358/303576 [28:42<1:13:58, 58.18it/s] 15%|        | 45365/303576 [28:42<1:11:56, 59.82it/s] 15%|        | 45372/303576 [28:42<1:09:39, 61.78it/s] 15%|        | 45379/303576 [28:43<1:08:30, 62.81it/s] 15%|        | 45386/303576 [28:43<1:07:12, 64.03it/s] 15%|        | 45393/303576 [28:43<1:06:18, 64.89it/s] 15%|        | 45400/303576 [28:43<1:05:43, 65.47it/s]                                                         15%|        | 45400/303576 [28:43<1:05:43, 65.47it/s] 15%|        | 45407/303576 [28:43<1:05:26, 65.75it/s] 15%|        | 45414/303576 [28:43<1:05:19, 65.87it/s] 15%|        | 45421/303576 [28:43<1:05:04, 66.12it/s] 15%|        | 45428/303576 [28:43<1:05:00, 66.19it/s] 15%|        | 45435/303576 [28:43<1:06:09, 65.04it/s] 15%|        | 45442/303576 [28:43<1:06:32, 64.66it/s] 15%|        | 45449/303576 [28:44<1:05:38, 65.55it/s] 15%|        | 45456/303576 [28:44<1:05:40, 65.51it/s] 15%|        | 45463/303576 [28:44<1:05:31, 65.64it/s] 15%|        | 45470/303576 [28:44<1:05:32, 65.64it/s] 15%|        | 45477/303576 [28:44<1:09:51, 61.58it/s] 15%|        | 45484/303576 [28:44<1:13:50, 58.26it/s] 15%|        | 45490/303576 [28:44<1:13:27, 58.56it/s] 15%|        | 45496/303576 [28:44<1:13:39, 58.40it/s]                                                         15%|        | 45500/303576 [28:44<1:13:39, 58.40it/s] 15%|        | 45502/303576 [28:44<1:13:50, 58.25it/s] 15%|        | 45508/303576 [28:45<1:14:19, 57.87it/s] 15%|        | 45514/303576 [28:45<1:14:13, 57.94it/s] 15%|        | 45520/303576 [28:45<1:14:10, 57.99it/s] 15%|        | 45526/303576 [28:45<1:14:11, 57.97it/s] 15%|        | 45532/303576 [28:45<1:17:03, 55.81it/s] 15%|        | 45538/303576 [28:45<1:16:20, 56.34it/s] 15%|        | 45544/303576 [28:45<1:15:46, 56.76it/s] 15%|        | 45551/303576 [28:45<1:13:37, 58.41it/s] 15%|        | 45558/303576 [28:45<1:11:15, 60.34it/s] 15%|        | 45565/303576 [28:46<1:09:41, 61.70it/s] 15%|        | 45572/303576 [28:46<1:08:48, 62.49it/s] 15%|        | 45579/303576 [28:46<1:08:07, 63.12it/s] 15%|        | 45586/303576 [28:46<1:07:40, 63.53it/s] 15%|        | 45593/303576 [28:46<1:07:20, 63.84it/s] 15%|        | 45600/303576 [28:46<1:07:13, 63.96it/s]                                                         15%|        | 45600/303576 [28:46<1:07:13, 63.96it/s] 15%|        | 45607/303576 [28:46<1:09:01, 62.29it/s] 15%|        | 45614/303576 [28:46<1:11:08, 60.43it/s] 15%|        | 45621/303576 [28:46<1:13:13, 58.72it/s] 15%|        | 45627/303576 [28:47<1:14:09, 57.97it/s] 15%|        | 45633/303576 [28:47<1:14:53, 57.41it/s] 15%|        | 45639/303576 [28:47<1:14:28, 57.72it/s] 15%|        | 45646/303576 [28:47<1:11:30, 60.12it/s] 15%|        | 45653/303576 [28:47<1:10:21, 61.09it/s] 15%|        | 45660/303576 [28:47<1:08:50, 62.44it/s] 15%|        | 45667/303576 [28:47<1:07:30, 63.67it/s] 15%|        | 45674/303576 [28:47<1:06:53, 64.26it/s] 15%|        | 45681/303576 [28:47<1:06:19, 64.81it/s] 15%|        | 45688/303576 [28:48<1:06:02, 65.08it/s] 15%|        | 45695/303576 [28:48<1:05:47, 65.33it/s]                                                         15%|        | 45700/303576 [28:48<1:05:47, 65.33it/s] 15%|        | 45702/303576 [28:48<1:05:46, 65.34it/s] 15%|        | 45709/303576 [28:48<1:05:33, 65.56it/s] 15%|        | 45716/303576 [28:48<1:05:28, 65.64it/s] 15%|        | 45723/303576 [28:48<1:05:17, 65.81it/s] 15%|        | 45730/303576 [28:48<1:05:00, 66.10it/s] 15%|        | 45737/303576 [28:48<1:04:49, 66.28it/s] 15%|        | 45744/303576 [28:48<1:04:44, 66.37it/s] 15%|        | 45751/303576 [28:48<1:04:55, 66.18it/s] 15%|        | 45758/303576 [28:49<1:04:54, 66.21it/s] 15%|        | 45765/303576 [28:49<1:03:53, 67.26it/s] 15%|        | 45774/303576 [28:49<59:34, 72.12it/s]   15%|        | 45782/303576 [28:49<58:49, 73.05it/s] 15%|        | 45790/303576 [28:49<58:15, 73.75it/s] 15%|        | 45798/303576 [28:49<57:30, 74.70it/s]                                                       15%|        | 45800/303576 [28:49<57:30, 74.70it/s] 15%|        | 45807/303576 [28:49<54:35, 78.70it/s] 15%|        | 45817/303576 [28:49<52:07, 82.43it/s] 15%|        | 45826/303576 [28:49<50:46, 84.60it/s] 15%|        | 45836/303576 [28:50<49:44, 86.36it/s] 15%|        | 45846/303576 [28:50<49:00, 87.65it/s] 15%|        | 45855/303576 [28:50<48:46, 88.06it/s] 15%|        | 45865/303576 [28:50<48:20, 88.84it/s] 15%|        | 45874/303576 [28:50<48:12, 89.11it/s] 15%|        | 45884/303576 [28:50<48:02, 89.40it/s] 15%|        | 45894/303576 [28:50<47:55, 89.62it/s]                                                       15%|        | 45900/303576 [28:50<47:55, 89.62it/s] 15%|        | 45904/303576 [28:50<47:18, 90.79it/s] 15%|        | 45914/303576 [28:50<46:15, 92.82it/s] 15%|        | 45925/303576 [28:50<44:54, 95.61it/s] 15%|        | 45936/303576 [28:51<43:57, 97.69it/s] 15%|        | 45946/303576 [28:51<46:52, 91.61it/s] 15%|        | 45956/303576 [28:51<51:08, 83.94it/s] 15%|        | 45965/303576 [28:51<54:13, 79.19it/s] 15%|        | 45974/303576 [28:51<55:57, 76.72it/s] 15%|        | 45982/303576 [28:51<57:19, 74.89it/s] 15%|        | 45990/303576 [28:51<58:28, 73.41it/s] 15%|        | 45998/303576 [28:51<59:21, 72.32it/s]                                                       15%|        | 46000/303576 [28:52<59:21, 72.32it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7365241050720215, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.6001, 'eval_samples_per_second': 10.0, 'eval_steps_per_second': 0.088, 'epoch': 0.44, 'timestamp': 1762966249.4133942, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.774, 'grad_norm': 0.29810240864753723, 'learning_rate': 1.1012487310203153e-05, 'epoch': 0.45, 'timestamp': 1762966251.5447667, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7663, 'grad_norm': 0.26256611943244934, 'learning_rate': 1.090290577881376e-05, 'epoch': 0.45, 'timestamp': 1762966253.358693, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7735, 'grad_norm': 0.23489975929260254, 'learning_rate': 1.079549420554946e-05, 'epoch': 0.45, 'timestamp': 1762966255.1151903, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7699, 'grad_norm': 0.259766161441803, 'learning_rate': 1.0688071899050783e-05, 'epoch': 0.45, 'timestamp': 1762966256.7831829, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7579, 'grad_norm': 0.23773539066314697, 'learning_rate': 1.0581718515541062e-05, 'epoch': 0.45, 'timestamp': 1762966258.3893113, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7733, 'grad_norm': 0.2895617187023163, 'learning_rate': 1.0476423418529685e-05, 'epoch': 0.45, 'timestamp': 1762966260.0354953, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7823, 'grad_norm': 0.22585925459861755, 'learning_rate': 1.0372176077366117e-05, 'epoch': 0.45, 'timestamp': 1762966261.6522472, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7571, 'grad_norm': 0.264843225479126, 'learning_rate': 1.0268966066186793e-05, 'epoch': 0.45, 'timestamp': 1762966263.0749767, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7674, 'grad_norm': 0.2556808292865753, 'learning_rate': 1.0166783062872373e-05, 'epoch': 0.45, 'timestamp': 1762966264.1863892, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7811, 'grad_norm': 0.23081240057945251, 'learning_rate': 1.0065616848015432e-05, 'epoch': 0.45, 'timestamp': 1762966265.4424825, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:51:08.831406: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:51:08.842075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966268.854998 1753221 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966268.858883 1753221 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966268.869269 1753221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966268.869287 1753221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966268.869289 1753221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966268.869291 1753221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:51:08.872538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:51:10 - TensorFlow version 2.19.1 available.
2025-11-12 16:51:18.621477: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:51:18.632205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966278.645079 1753379 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966278.648925 1753379 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966278.659267 1753379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966278.659282 1753379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966278.659284 1753379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966278.659286 1753379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:51:18.662482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:51:20 - TensorFlow version 2.19.1 available.
 15%|        | 46000/303576 [29:10<59:21, 72.32it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 15%|        | 46000/303576 [29:13<59:21, 72.32it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-46000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-46000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-46000/model.safetensors
 15%|        | 46001/303576 [29:13<67:34:57,  1.06it/s] 15%|        | 46008/303576 [29:13<47:24:57,  1.51it/s] 15%|        | 46016/303576 [29:13<32:01:25,  2.23it/s] 15%|        | 46024/303576 [29:13<22:01:24,  3.25it/s] 15%|        | 46032/303576 [29:13<15:22:51,  4.65it/s] 15%|        | 46040/303576 [29:13<10:53:57,  6.56it/s] 15%|        | 46048/303576 [29:13<7:50:13,  9.13it/s]  15%|        | 46056/303576 [29:14<5:44:08, 12.47it/s] 15%|        | 46064/303576 [29:14<4:16:28, 16.73it/s] 15%|        | 46072/303576 [29:14<3:15:31, 21.95it/s] 15%|        | 46080/303576 [29:14<2:33:35, 27.94it/s] 15%|        | 46088/303576 [29:14<2:04:31, 34.46it/s] 15%|        | 46096/303576 [29:14<1:44:09, 41.20it/s]                                                         15%|        | 46100/303576 [29:14<1:44:09, 41.20it/s] 15%|        | 46104/303576 [29:14<1:29:48, 47.78it/s] 15%|        | 46112/303576 [29:14<1:19:59, 53.64it/s] 15%|        | 46120/303576 [29:14<1:13:04, 58.72it/s] 15%|        | 46128/303576 [29:15<1:08:22, 62.76it/s] 15%|        | 46136/303576 [29:15<1:05:01, 65.98it/s] 15%|        | 46144/303576 [29:15<1:02:41, 68.43it/s] 15%|        | 46152/303576 [29:15<1:01:04, 70.25it/s] 15%|        | 46160/303576 [29:15<59:52, 71.65it/s]   15%|        | 46168/303576 [29:15<59:01, 72.68it/s] 15%|        | 46176/303576 [29:15<58:29, 73.34it/s] 15%|        | 46184/303576 [29:15<58:04, 73.86it/s] 15%|        | 46192/303576 [29:15<57:49, 74.18it/s] 15%|        | 46200/303576 [29:16<57:40, 74.38it/s]                                                       15%|        | 46200/303576 [29:16<57:40, 74.38it/s] 15%|        | 46208/303576 [29:16<56:59, 75.26it/s] 15%|        | 46216/303576 [29:16<56:46, 75.55it/s] 15%|        | 46224/303576 [29:16<56:14, 76.27it/s] 15%|        | 46232/303576 [29:16<55:53, 76.75it/s] 15%|        | 46240/303576 [29:16<55:36, 77.12it/s] 15%|        | 46249/303576 [29:16<53:32, 80.10it/s] 15%|        | 46259/303576 [29:16<51:29, 83.29it/s] 15%|        | 46268/303576 [29:16<50:22, 85.14it/s] 15%|        | 46277/303576 [29:16<49:34, 86.51it/s] 15%|        | 46286/303576 [29:17<49:01, 87.46it/s] 15%|        | 46295/303576 [29:17<48:56, 87.61it/s]                                                       15%|        | 46300/303576 [29:17<48:56, 87.61it/s] 15%|        | 46304/303576 [29:17<48:36, 88.21it/s] 15%|        | 46313/303576 [29:17<48:29, 88.41it/s] 15%|        | 46322/303576 [29:17<48:19, 88.72it/s] 15%|        | 46331/303576 [29:17<48:08, 89.04it/s] 15%|        | 46340/303576 [29:17<48:01, 89.26it/s] 15%|        | 46349/303576 [29:17<47:58, 89.35it/s] 15%|        | 46358/303576 [29:17<47:54, 89.49it/s] 15%|        | 46367/303576 [29:17<47:56, 89.41it/s] 15%|        | 46376/303576 [29:18<47:52, 89.53it/s] 15%|        | 46385/303576 [29:18<47:54, 89.47it/s] 15%|        | 46394/303576 [29:18<47:51, 89.56it/s]                                                       15%|        | 46400/303576 [29:18<47:51, 89.56it/s] 15%|        | 46403/303576 [29:18<47:54, 89.47it/s] 15%|        | 46412/303576 [29:18<47:54, 89.48it/s] 15%|        | 46421/303576 [29:18<47:52, 89.54it/s] 15%|        | 46430/303576 [29:18<47:54, 89.46it/s] 15%|        | 46439/303576 [29:18<47:52, 89.50it/s] 15%|        | 46449/303576 [29:18<47:46, 89.70it/s] 15%|        | 46458/303576 [29:18<47:45, 89.73it/s] 15%|        | 46467/303576 [29:19<47:45, 89.73it/s] 15%|        | 46476/303576 [29:19<47:46, 89.68it/s] 15%|        | 46485/303576 [29:19<47:47, 89.67it/s] 15%|        | 46494/303576 [29:19<47:47, 89.66it/s]                                                       15%|        | 46500/303576 [29:19<47:47, 89.66it/s] 15%|        | 46503/303576 [29:19<47:55, 89.40it/s] 15%|        | 46512/303576 [29:19<47:53, 89.45it/s] 15%|        | 46521/303576 [29:19<47:55, 89.40it/s] 15%|        | 46530/303576 [29:19<47:55, 89.40it/s] 15%|        | 46539/303576 [29:19<47:51, 89.50it/s] 15%|        | 46548/303576 [29:19<47:52, 89.47it/s] 15%|        | 46557/303576 [29:20<47:51, 89.50it/s] 15%|        | 46566/303576 [29:20<47:49, 89.56it/s] 15%|        | 46575/303576 [29:20<47:59, 89.26it/s] 15%|        | 46584/303576 [29:20<47:53, 89.45it/s] 15%|        | 46593/303576 [29:20<48:04, 89.10it/s]                                                       15%|        | 46600/303576 [29:20<48:04, 89.10it/s] 15%|        | 46602/303576 [29:20<48:04, 89.08it/s] 15%|        | 46611/303576 [29:20<48:03, 89.10it/s] 15%|        | 46620/303576 [29:20<47:58, 89.27it/s] 15%|        | 46629/303576 [29:20<47:55, 89.36it/s] 15%|        | 46638/303576 [29:20<47:50, 89.51it/s] 15%|        | 46647/303576 [29:21<48:38, 88.03it/s] 15%|        | 46656/303576 [29:21<49:15, 86.92it/s] 15%|        | 46665/303576 [29:21<50:14, 85.22it/s] 15%|        | 46674/303576 [29:21<50:39, 84.52it/s] 15%|        | 46684/303576 [29:21<49:13, 86.97it/s] 15%|        | 46695/303576 [29:21<47:00, 91.09it/s]                                                       15%|        | 46700/303576 [29:21<47:00, 91.09it/s] 15%|        | 46705/303576 [29:21<45:51, 93.37it/s] 15%|        | 46716/303576 [29:21<44:48, 95.54it/s] 15%|        | 46727/303576 [29:21<44:12, 96.83it/s] 15%|        | 46737/303576 [29:22<43:57, 97.36it/s] 15%|        | 46748/303576 [29:22<43:30, 98.40it/s] 15%|        | 46758/303576 [29:22<43:24, 98.62it/s] 15%|        | 46768/303576 [29:22<43:20, 98.76it/s] 15%|        | 46778/303576 [29:22<43:16, 98.89it/s] 15%|        | 46788/303576 [29:22<43:15, 98.93it/s] 15%|        | 46798/303576 [29:22<43:09, 99.15it/s]                                                       15%|        | 46800/303576 [29:22<43:09, 99.15it/s] 15%|        | 46808/303576 [29:22<43:04, 99.35it/s] 15%|        | 46818/303576 [29:22<43:04, 99.35it/s] 15%|        | 46828/303576 [29:22<43:03, 99.40it/s] 15%|        | 46839/303576 [29:23<42:59, 99.54it/s] 15%|        | 46850/303576 [29:23<42:52, 99.81it/s] 15%|        | 46860/303576 [29:23<43:15, 98.90it/s] 15%|        | 46871/303576 [29:23<43:08, 99.19it/s] 15%|        | 46882/303576 [29:23<43:28, 98.39it/s] 15%|        | 46892/303576 [29:23<48:17, 88.57it/s]                                                       15%|        | 46900/303576 [29:23<48:17, 88.57it/s] 15%|        | 46902/303576 [29:23<51:41, 82.76it/s] 15%|        | 46911/303576 [29:23<53:46, 79.56it/s] 15%|        | 46920/303576 [29:24<56:16, 76.02it/s] 15%|        | 46928/303576 [29:24<58:09, 73.56it/s] 15%|        | 46936/303576 [29:24<59:40, 71.67it/s] 15%|        | 46944/303576 [29:24<1:00:50, 70.29it/s] 15%|        | 46952/303576 [29:24<1:01:43, 69.30it/s] 15%|        | 46959/303576 [29:24<1:01:53, 69.10it/s] 15%|        | 46966/303576 [29:24<1:02:39, 68.26it/s] 15%|        | 46973/303576 [29:24<1:02:25, 68.51it/s] 15%|        | 46980/303576 [29:24<1:03:11, 67.68it/s] 15%|        | 46987/303576 [29:25<1:02:44, 68.16it/s] 15%|        | 46994/303576 [29:25<1:03:29, 67.36it/s]                                                         15%|        | 47000/303576 [29:25<1:03:28, 67.36it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7368807792663574, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.3129, 'eval_samples_per_second': 10.604, 'eval_steps_per_second': 0.094, 'epoch': 0.45, 'timestamp': 1762966286.7559128, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7642, 'grad_norm': 0.3218596279621124, 'learning_rate': 9.965457303898407e-06, 'epoch': 0.46, 'timestamp': 1762966288.121193, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7647, 'grad_norm': 0.2639220654964447, 'learning_rate': 9.866294413481714e-06, 'epoch': 0.46, 'timestamp': 1762966289.4539156, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7859, 'grad_norm': 0.2543346881866455, 'learning_rate': 9.768118259401936e-06, 'epoch': 0.46, 'timestamp': 1762966290.6429756, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7722, 'grad_norm': 0.21833233535289764, 'learning_rate': 9.670919022980003e-06, 'epoch': 0.46, 'timestamp': 1762966291.759801, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7805, 'grad_norm': 0.2373379021883011, 'learning_rate': 9.574686983239172e-06, 'epoch': 0.46, 'timestamp': 1762966292.8760588, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.23374362289905548, 'learning_rate': 9.479412515932826e-06, 'epoch': 0.46, 'timestamp': 1762966293.995879, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7806, 'grad_norm': 0.2390562742948532, 'learning_rate': 9.385086092582008e-06, 'epoch': 0.46, 'timestamp': 1762966295.1170855, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.775, 'grad_norm': 0.31033968925476074, 'learning_rate': 9.291698279522405e-06, 'epoch': 0.46, 'timestamp': 1762966296.124938, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7954, 'grad_norm': 0.22178345918655396, 'learning_rate': 9.199239736960914e-06, 'epoch': 0.46, 'timestamp': 1762966297.2059417, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7707, 'grad_norm': 0.1953449845314026, 'learning_rate': 9.107701218041536e-06, 'epoch': 0.46, 'timestamp': 1762966298.6807802, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:51:42.502089: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:51:42.512986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966302.526337 1753682 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966302.530430 1753682 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966302.541170 1753682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966302.541189 1753682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966302.541191 1753682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966302.541192 1753682 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:51:42.544547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:51:44 - TensorFlow version 2.19.1 available.
2025-11-12 16:51:53.123757: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:51:53.134396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966313.147235 1753973 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966313.151320 1753973 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966313.161642 1753973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966313.161661 1753973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966313.161663 1753973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966313.161664 1753973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:51:53.164953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 15%|        | 47000/303576 [29:40<1:03:28, 67.36it/s]2025-11-12T16:51:55 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                        
                                             [A 15%|        | 47000/303576 [29:47<1:03:28, 67.36it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [A 15%|        | 47001/303576 [29:47<68:39:10,  1.04it/s] 15%|        | 47006/303576 [29:47<53:05:36,  1.34it/s] 15%|        | 47013/303576 [29:47<36:45:33,  1.94it/s] 15%|        | 47019/303576 [29:48<26:54:57,  2.65it/s] 15%|        | 47025/303576 [29:48<19:40:11,  3.62it/s] 15%|        | 47031/303576 [29:48<14:25:03,  4.94it/s] 15%|        | 47037/303576 [29:48<10:38:49,  6.69it/s] 15%|        | 47042/303576 [29:48<8:18:11,  8.58it/s]  15%|        | 47047/303576 [29:48<6:27:48, 11.02it/s] 15%|        | 47052/303576 [29:48<5:06:10, 13.96it/s] 16%|        | 47057/303576 [29:48<4:04:02, 17.52it/s] 16%|        | 47064/303576 [29:49<2:59:57, 23.76it/s] 16%|        | 47071/303576 [29:49<2:19:45, 30.59it/s] 16%|        | 47080/303576 [29:49<1:46:32, 40.13it/s] 16%|        | 47090/303576 [29:49<1:23:36, 51.13it/s] 16%|        | 47099/303576 [29:49<1:12:33, 58.91it/s]                                                         16%|        | 47100/303576 [29:49<1:12:33, 58.91it/s] 16%|        | 47108/303576 [29:49<1:06:24, 64.37it/s] 16%|        | 47117/303576 [29:49<1:01:27, 69.55it/s] 16%|        | 47126/303576 [29:49<58:07, 73.53it/s]   16%|        | 47135/303576 [29:49<56:47, 75.26it/s] 16%|        | 47144/303576 [29:50<55:06, 77.54it/s] 16%|        | 47153/303576 [29:50<54:00, 79.13it/s] 16%|        | 47162/303576 [29:50<54:31, 78.37it/s] 16%|        | 47171/303576 [29:50<54:53, 77.85it/s] 16%|        | 47179/303576 [29:50<55:04, 77.60it/s] 16%|        | 47187/303576 [29:50<55:14, 77.35it/s] 16%|        | 47195/303576 [29:50<58:54, 72.53it/s]                                                       16%|        | 47200/303576 [29:50<58:54, 72.53it/s] 16%|        | 47203/303576 [29:50<1:04:10, 66.58it/s] 16%|        | 47210/303576 [29:50<1:07:25, 63.38it/s] 16%|        | 47217/303576 [29:51<1:09:57, 61.07it/s] 16%|        | 47224/303576 [29:51<1:12:07, 59.24it/s] 16%|        | 47230/303576 [29:51<1:13:03, 58.48it/s] 16%|        | 47237/303576 [29:51<1:11:32, 59.71it/s] 16%|        | 47243/303576 [29:51<1:11:37, 59.65it/s] 16%|        | 47250/303576 [29:51<1:10:41, 60.44it/s] 16%|        | 47257/303576 [29:51<1:13:47, 57.90it/s] 16%|        | 47263/303576 [29:51<1:18:32, 54.39it/s] 16%|        | 47269/303576 [29:52<1:22:04, 52.05it/s] 16%|        | 47275/303576 [29:52<1:24:29, 50.55it/s] 16%|        | 47281/303576 [29:52<1:26:27, 49.41it/s] 16%|        | 47286/303576 [29:52<1:27:03, 49.06it/s] 16%|        | 47291/303576 [29:52<1:29:10, 47.90it/s] 16%|        | 47296/303576 [29:52<1:29:00, 47.98it/s]                                                         16%|        | 47300/303576 [29:52<1:29:00, 47.98it/s] 16%|        | 47301/303576 [29:52<1:30:31, 47.18it/s] 16%|        | 47306/303576 [29:52<1:29:55, 47.50it/s] 16%|        | 47311/303576 [29:52<1:31:10, 46.85it/s] 16%|        | 47316/303576 [29:53<1:30:00, 47.45it/s] 16%|        | 47321/303576 [29:53<1:31:37, 46.62it/s] 16%|        | 47326/303576 [29:53<1:30:14, 47.33it/s] 16%|        | 47331/303576 [29:53<1:31:13, 46.81it/s] 16%|        | 47336/303576 [29:53<1:30:09, 47.37it/s] 16%|        | 47341/303576 [29:53<1:31:13, 46.82it/s] 16%|        | 47346/303576 [29:53<1:30:05, 47.40it/s] 16%|        | 47351/303576 [29:53<1:31:10, 46.84it/s] 16%|        | 47356/303576 [29:53<1:29:54, 47.50it/s] 16%|        | 47361/303576 [29:53<1:30:59, 46.93it/s] 16%|        | 47366/303576 [29:54<1:29:52, 47.51it/s] 16%|        | 47371/303576 [29:54<1:30:55, 46.96it/s] 16%|        | 47376/303576 [29:54<1:29:37, 47.64it/s] 16%|        | 47381/303576 [29:54<1:30:55, 46.96it/s] 16%|        | 47386/303576 [29:54<1:29:56, 47.47it/s] 16%|        | 47391/303576 [29:54<1:31:12, 46.81it/s] 16%|        | 47396/303576 [29:54<1:30:06, 47.38it/s]                                                         16%|        | 47400/303576 [29:54<1:30:06, 47.38it/s] 16%|        | 47401/303576 [29:54<1:31:14, 46.79it/s] 16%|        | 47406/303576 [29:54<1:29:56, 47.47it/s] 16%|        | 47411/303576 [29:55<1:30:49, 47.01it/s] 16%|        | 47416/303576 [29:55<1:29:27, 47.72it/s] 16%|        | 47421/303576 [29:55<1:30:41, 47.07it/s] 16%|        | 47426/303576 [29:55<1:29:23, 47.76it/s] 16%|        | 47431/303576 [29:55<1:30:26, 47.20it/s] 16%|        | 47436/303576 [29:55<1:29:13, 47.85it/s] 16%|        | 47441/303576 [29:55<1:30:23, 47.23it/s] 16%|        | 47446/303576 [29:55<1:29:14, 47.83it/s] 16%|        | 47451/303576 [29:55<1:30:26, 47.20it/s] 16%|        | 47456/303576 [29:55<1:29:16, 47.82it/s] 16%|        | 47461/303576 [29:56<1:30:41, 47.07it/s] 16%|        | 47466/303576 [29:56<1:29:28, 47.71it/s] 16%|        | 47471/303576 [29:56<1:30:39, 47.09it/s] 16%|        | 47476/303576 [29:56<1:29:27, 47.72it/s] 16%|        | 47481/303576 [29:56<1:30:33, 47.13it/s] 16%|        | 47486/303576 [29:56<1:29:24, 47.74it/s] 16%|        | 47491/303576 [29:56<1:30:37, 47.10it/s] 16%|        | 47496/303576 [29:56<1:29:33, 47.66it/s]                                                         16%|        | 47500/303576 [29:56<1:29:33, 47.66it/s] 16%|        | 47501/303576 [29:56<1:30:52, 46.96it/s] 16%|        | 47506/303576 [29:57<1:29:33, 47.65it/s] 16%|        | 47511/303576 [29:57<1:30:27, 47.18it/s] 16%|        | 47516/303576 [29:57<1:29:09, 47.87it/s] 16%|        | 47522/303576 [29:57<1:25:29, 49.92it/s] 16%|        | 47528/303576 [29:57<1:22:36, 51.66it/s] 16%|        | 47534/303576 [29:57<1:20:47, 52.82it/s] 16%|        | 47540/303576 [29:57<1:19:51, 53.43it/s] 16%|        | 47546/303576 [29:57<1:17:29, 55.07it/s] 16%|        | 47553/303576 [29:57<1:14:31, 57.26it/s] 16%|        | 47559/303576 [29:58<1:18:03, 54.67it/s] 16%|        | 47565/303576 [29:58<1:19:44, 53.51it/s] 16%|        | 47571/303576 [29:58<1:21:04, 52.63it/s] 16%|        | 47577/303576 [29:58<1:18:39, 54.24it/s] 16%|        | 47585/303576 [29:58<1:09:30, 61.38it/s] 16%|        | 47594/303576 [29:58<1:02:28, 68.29it/s]                                                         16%|        | 47600/303576 [29:58<1:02:28, 68.29it/s] 16%|        | 47604/303576 [29:58<56:12, 75.90it/s]   16%|        | 47613/303576 [29:58<54:22, 78.45it/s] 16%|        | 47624/303576 [29:58<49:43, 85.78it/s] 16%|        | 47635/303576 [29:59<47:34, 89.66it/s] 16%|        | 47645/303576 [29:59<46:06, 92.51it/s] 16%|        | 47655/303576 [29:59<45:28, 93.80it/s] 16%|        | 47665/303576 [29:59<46:53, 90.97it/s] 16%|        | 47675/303576 [29:59<48:20, 88.24it/s] 16%|        | 47684/303576 [29:59<49:30, 86.13it/s] 16%|        | 47693/303576 [29:59<49:56, 85.39it/s]                                                       16%|        | 47700/303576 [29:59<49:56, 85.39it/s] 16%|        | 47702/303576 [29:59<50:40, 84.15it/s] 16%|        | 47711/303576 [29:59<50:47, 83.95it/s] 16%|        | 47720/303576 [30:00<51:16, 83.17it/s] 16%|        | 47729/303576 [30:00<50:58, 83.64it/s] 16%|        | 47738/303576 [30:00<51:07, 83.41it/s] 16%|        | 47747/303576 [30:00<51:09, 83.35it/s] 16%|        | 47756/303576 [30:00<51:42, 82.47it/s] 16%|        | 47765/303576 [30:00<51:36, 82.62it/s] 16%|        | 47774/303576 [30:00<51:55, 82.11it/s] 16%|        | 47783/303576 [30:00<51:58, 82.03it/s] 16%|        | 47792/303576 [30:00<51:59, 81.98it/s]                                                       16%|        | 47800/303576 [30:00<51:59, 81.98it/s] 16%|        | 47801/303576 [30:00<51:43, 82.41it/s] 16%|        | 47810/303576 [30:01<51:58, 82.00it/s] 16%|        | 47819/303576 [30:01<51:42, 82.45it/s] 16%|        | 47828/303576 [30:01<51:50, 82.22it/s] 16%|        | 47837/303576 [30:01<52:16, 81.53it/s] 16%|        | 47846/303576 [30:01<50:57, 83.63it/s] 16%|        | 47855/303576 [30:01<51:01, 83.53it/s] 16%|        | 47864/303576 [30:01<51:24, 82.91it/s] 16%|        | 47873/303576 [30:01<51:24, 82.89it/s] 16%|        | 47882/303576 [30:01<51:40, 82.47it/s] 16%|        | 47891/303576 [30:02<51:27, 82.81it/s] 16%|        | 47900/303576 [30:02<51:46, 82.31it/s]                                                       16%|        | 47900/303576 [30:02<51:46, 82.31it/s] 16%|        | 47909/303576 [30:02<51:35, 82.60it/s] 16%|        | 47918/303576 [30:02<51:47, 82.27it/s] 16%|        | 47927/303576 [30:02<52:39, 80.90it/s] 16%|        | 47936/303576 [30:02<53:27, 79.69it/s] 16%|        | 47944/303576 [30:02<53:56, 78.98it/s] 16%|        | 47952/303576 [30:02<54:13, 78.57it/s] 16%|        | 47960/303576 [30:02<54:20, 78.40it/s] 16%|        | 47968/303576 [30:03<54:20, 78.39it/s] 16%|        | 47976/303576 [30:03<54:23, 78.32it/s] 16%|        | 47984/303576 [30:03<56:59, 74.75it/s] 16%|        | 47992/303576 [30:03<1:01:07, 69.70it/s] 16%|        | 48000/303576 [30:03<1:04:33, 65.98it/s]                                                         16%|        | 48000/303576 [30:03<1:04:33, 65.98it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7367480993270874, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4913, 'eval_samples_per_second': 10.048, 'eval_steps_per_second': 0.089, 'epoch': 0.46, 'timestamp': 1762966321.1725452, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7645, 'grad_norm': 0.2559843957424164, 'learning_rate': 9.017073567920624e-06, 'epoch': 0.47, 'timestamp': 1762966322.9247444, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7791, 'grad_norm': 0.2021162211894989, 'learning_rate': 8.927347722851262e-06, 'epoch': 0.47, 'timestamp': 1762966324.2270381, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7808, 'grad_norm': 0.30629366636276245, 'learning_rate': 8.838514709276815e-06, 'epoch': 0.47, 'timestamp': 1762966326.1376255, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7619, 'grad_norm': 0.2964951694011688, 'learning_rate': 8.75056564293347e-06, 'epoch': 0.47, 'timestamp': 1762966328.2606137, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7808, 'grad_norm': 0.31768593192100525, 'learning_rate': 8.663491727961727e-06, 'epoch': 0.47, 'timestamp': 1762966330.3688445, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7725, 'grad_norm': 0.2724516689777374, 'learning_rate': 8.577284256026684e-06, 'epoch': 0.47, 'timestamp': 1762966332.0830646, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.783, 'grad_norm': 0.22546571493148804, 'learning_rate': 8.49193460544713e-06, 'epoch': 0.47, 'timestamp': 1762966333.2008598, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7673, 'grad_norm': 0.21835017204284668, 'learning_rate': 8.407434240333317e-06, 'epoch': 0.47, 'timestamp': 1762966334.4147258, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7727, 'grad_norm': 0.32306477427482605, 'learning_rate': 8.323774709733205e-06, 'epoch': 0.47, 'timestamp': 1762966335.6247702, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7703, 'grad_norm': 0.23331177234649658, 'learning_rate': 8.240947646787318e-06, 'epoch': 0.47, 'timestamp': 1762966336.977934, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:52:20.372627: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:52:20.383206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966340.395941 1754408 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966340.399761 1754408 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966340.410101 1754408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966340.410118 1754408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966340.410119 1754408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966340.410121 1754408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:52:20.413335: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:52:22 - TensorFlow version 2.19.1 available.
2025-11-12 16:52:30.089412: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:52:30.100342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966350.113369 1754572 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966350.117375 1754572 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966350.127993 1754572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966350.128010 1754572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966350.128012 1754572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966350.128013 1754572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:52:30.131399: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:52:32 - TensorFlow version 2.19.1 available.
 16%|        | 48000/303576 [30:20<1:04:33, 65.98it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A 16%|        | 48000/303576 [30:24<1:04:33, 65.98it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-48000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-48000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-48000/model.safetensors
 16%|        | 48001/303576 [30:24<77:12:57,  1.09s/it] 16%|        | 48010/303576 [30:24<47:10:25,  1.50it/s] 16%|        | 48018/303576 [30:25<31:47:11,  2.23it/s] 16%|        | 48026/303576 [30:25<21:51:39,  3.25it/s] 16%|        | 48034/303576 [30:25<15:17:01,  4.64it/s] 16%|        | 48042/303576 [30:25<10:50:53,  6.54it/s] 16%|        | 48050/303576 [30:25<7:49:22,  9.07it/s]  16%|        | 48058/303576 [30:25<5:44:38, 12.36it/s] 16%|        | 48066/303576 [30:25<4:18:30, 16.47it/s] 16%|        | 48074/303576 [30:25<3:18:37, 21.44it/s] 16%|        | 48082/303576 [30:25<2:36:58, 27.13it/s] 16%|        | 48090/303576 [30:26<2:07:54, 33.29it/s] 16%|        | 48098/303576 [30:26<1:47:37, 39.56it/s]                                                         16%|        | 48100/303576 [30:26<1:47:37, 39.56it/s] 16%|        | 48107/303576 [30:26<1:29:01, 47.83it/s] 16%|        | 48118/303576 [30:26<1:11:54, 59.20it/s] 16%|        | 48128/303576 [30:26<1:02:40, 67.93it/s] 16%|        | 48138/303576 [30:26<58:03, 73.34it/s]   16%|        | 48147/303576 [30:26<56:12, 75.73it/s] 16%|        | 48156/303576 [30:26<54:23, 78.26it/s] 16%|        | 48165/303576 [30:26<53:29, 79.58it/s] 16%|        | 48174/303576 [30:27<53:25, 79.68it/s] 16%|        | 48183/303576 [30:27<52:38, 80.85it/s] 16%|        | 48192/303576 [30:27<52:37, 80.88it/s]                                                       16%|        | 48200/303576 [30:27<52:37, 80.88it/s] 16%|        | 48201/303576 [30:27<52:16, 81.41it/s] 16%|        | 48210/303576 [30:27<52:24, 81.20it/s] 16%|        | 48219/303576 [30:27<52:14, 81.46it/s] 16%|        | 48228/303576 [30:27<52:31, 81.03it/s] 16%|        | 48237/303576 [30:27<52:10, 81.56it/s] 16%|        | 48246/303576 [30:27<52:24, 81.19it/s] 16%|        | 48255/303576 [30:28<51:59, 81.86it/s] 16%|        | 48264/303576 [30:28<50:59, 83.45it/s] 16%|        | 48273/303576 [30:28<50:41, 83.95it/s] 16%|        | 48283/303576 [30:28<48:09, 88.35it/s] 16%|        | 48294/303576 [30:28<45:48, 92.88it/s]                                                       16%|        | 48300/303576 [30:28<45:48, 92.88it/s] 16%|        | 48305/303576 [30:28<44:56, 94.68it/s] 16%|        | 48315/303576 [30:28<46:25, 91.64it/s] 16%|        | 48325/303576 [30:28<47:53, 88.84it/s] 16%|        | 48334/303576 [30:28<48:51, 87.07it/s] 16%|        | 48343/303576 [30:28<50:20, 84.50it/s] 16%|        | 48352/303576 [30:29<53:42, 79.20it/s] 16%|        | 48360/303576 [30:29<59:17, 71.73it/s] 16%|        | 48368/303576 [30:29<1:05:09, 65.28it/s] 16%|        | 48375/303576 [30:29<1:12:06, 58.99it/s] 16%|        | 48382/303576 [30:29<1:15:56, 56.01it/s] 16%|        | 48388/303576 [30:29<1:19:13, 53.69it/s] 16%|        | 48394/303576 [30:29<1:21:58, 51.88it/s] 16%|        | 48400/303576 [30:30<1:24:36, 50.27it/s]                                                         16%|        | 48400/303576 [30:30<1:24:36, 50.27it/s] 16%|        | 48406/303576 [30:30<1:26:25, 49.21it/s] 16%|        | 48411/303576 [30:30<1:29:27, 47.54it/s] 16%|        | 48416/303576 [30:30<1:30:39, 46.91it/s] 16%|        | 48421/303576 [30:30<1:31:22, 46.54it/s] 16%|        | 48426/303576 [30:30<1:30:12, 47.15it/s] 16%|        | 48434/303576 [30:30<1:17:23, 54.94it/s] 16%|        | 48445/303576 [30:30<1:02:00, 68.58it/s] 16%|        | 48456/303576 [30:30<53:13, 79.89it/s]   16%|        | 48467/303576 [30:31<48:12, 88.19it/s] 16%|        | 48478/303576 [30:31<45:38, 93.14it/s] 16%|        | 48488/303576 [30:31<48:54, 86.92it/s] 16%|        | 48497/303576 [30:31<51:47, 82.07it/s]                                                       16%|        | 48500/303576 [30:31<51:47, 82.07it/s] 16%|        | 48506/303576 [30:31<54:30, 78.00it/s] 16%|        | 48514/303576 [30:31<54:34, 77.90it/s] 16%|        | 48524/303576 [30:31<51:17, 82.87it/s] 16%|        | 48535/303576 [30:31<48:06, 88.34it/s] 16%|        | 48546/303576 [30:31<45:54, 92.58it/s] 16%|        | 48557/303576 [30:32<44:19, 95.88it/s] 16%|        | 48568/303576 [30:32<43:13, 98.34it/s] 16%|        | 48578/303576 [30:32<46:45, 90.90it/s] 16%|        | 48588/303576 [30:32<50:27, 84.24it/s] 16%|        | 48597/303576 [30:32<52:37, 80.75it/s]                                                       16%|        | 48600/303576 [30:32<52:37, 80.75it/s] 16%|        | 48606/303576 [30:32<54:45, 77.61it/s] 16%|        | 48614/303576 [30:32<55:51, 76.08it/s] 16%|        | 48622/303576 [30:32<56:13, 75.58it/s] 16%|        | 48630/303576 [30:33<56:48, 74.80it/s] 16%|        | 48638/303576 [30:33<57:24, 74.02it/s] 16%|        | 48646/303576 [30:33<58:01, 73.22it/s] 16%|        | 48654/303576 [30:33<58:31, 72.60it/s] 16%|        | 48662/303576 [30:33<59:34, 71.31it/s] 16%|        | 48670/303576 [30:33<59:57, 70.85it/s] 16%|        | 48678/303576 [30:33<1:00:49, 69.84it/s] 16%|        | 48685/303576 [30:33<1:00:55, 69.72it/s] 16%|        | 48693/303576 [30:33<1:00:06, 70.68it/s]                                                         16%|        | 48700/303576 [30:34<1:00:06, 70.68it/s] 16%|        | 48701/303576 [30:34<59:50, 71.00it/s]   16%|        | 48709/303576 [30:34<58:27, 72.66it/s] 16%|        | 48718/303576 [30:34<56:26, 75.26it/s] 16%|        | 48727/303576 [30:34<54:48, 77.51it/s] 16%|        | 48735/303576 [30:34<55:25, 76.63it/s] 16%|        | 48743/303576 [30:34<56:34, 75.07it/s] 16%|        | 48751/303576 [30:34<57:11, 74.27it/s] 16%|        | 48759/303576 [30:34<57:51, 73.39it/s] 16%|        | 48767/303576 [30:34<58:27, 72.65it/s] 16%|        | 48775/303576 [30:35<58:36, 72.45it/s] 16%|        | 48783/303576 [30:35<58:47, 72.23it/s] 16%|        | 48791/303576 [30:35<58:52, 72.12it/s] 16%|        | 48799/303576 [30:35<58:53, 72.11it/s]                                                       16%|        | 48800/303576 [30:35<58:53, 72.11it/s] 16%|        | 48807/303576 [30:35<59:32, 71.32it/s] 16%|        | 48815/303576 [30:35<1:00:25, 70.26it/s] 16%|        | 48823/303576 [30:35<1:00:26, 70.26it/s] 16%|        | 48831/303576 [30:35<1:00:18, 70.40it/s] 16%|        | 48839/303576 [30:35<1:00:09, 70.57it/s] 16%|        | 48847/303576 [30:36<1:00:05, 70.65it/s] 16%|        | 48855/303576 [30:36<59:54, 70.86it/s]   16%|        | 48863/303576 [30:36<59:52, 70.91it/s] 16%|        | 48871/303576 [30:36<1:00:21, 70.34it/s] 16%|        | 48879/303576 [30:36<1:01:17, 69.25it/s] 16%|        | 48886/303576 [30:36<1:01:14, 69.32it/s] 16%|        | 48893/303576 [30:36<1:02:10, 68.26it/s] 16%|        | 48900/303576 [30:36<1:01:52, 68.59it/s]                                                         16%|        | 48900/303576 [30:36<1:01:52, 68.59it/s] 16%|        | 48907/303576 [30:36<1:02:40, 67.73it/s] 16%|        | 48915/303576 [30:37<1:02:28, 67.94it/s] 16%|        | 48922/303576 [30:37<1:02:05, 68.36it/s] 16%|        | 48929/303576 [30:37<1:02:52, 67.50it/s] 16%|        | 48936/303576 [30:37<1:02:25, 67.98it/s] 16%|        | 48943/303576 [30:37<1:03:09, 67.20it/s] 16%|        | 48950/303576 [30:37<1:02:36, 67.79it/s] 16%|        | 48957/303576 [30:37<1:03:04, 67.28it/s] 16%|        | 48965/303576 [30:37<1:01:28, 69.03it/s] 16%|        | 48973/303576 [30:37<59:51, 70.89it/s]   16%|        | 48981/303576 [30:38<58:36, 72.40it/s] 16%|        | 48989/303576 [30:38<57:58, 73.19it/s] 16%|        | 48997/303576 [30:38<57:25, 73.88it/s]                                                       16%|        | 49000/303576 [30:38<57:25, 73.88it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7364446520805359, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.1864, 'eval_samples_per_second': 10.667, 'eval_steps_per_second': 0.094, 'epoch': 0.47, 'timestamp': 1762966358.1649282, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.77, 'grad_norm': 0.23803630471229553, 'learning_rate': 8.158944767892004e-06, 'epoch': 0.48, 'timestamp': 1762966359.6262808, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7696, 'grad_norm': 0.3013251721858978, 'learning_rate': 8.077757871870911e-06, 'epoch': 0.48, 'timestamp': 1762966360.7788293, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7611, 'grad_norm': 0.2518309950828552, 'learning_rate': 7.997378839154823e-06, 'epoch': 0.48, 'timestamp': 1762966361.9277403, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7568, 'grad_norm': 0.23352280259132385, 'learning_rate': 7.918591490118613e-06, 'epoch': 0.48, 'timestamp': 1762966363.5395226, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7614, 'grad_norm': 0.2679974436759949, 'learning_rate': 7.839796268159045e-06, 'epoch': 0.48, 'timestamp': 1762966364.932341, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7804, 'grad_norm': 0.2529003918170929, 'learning_rate': 7.761785110765951e-06, 'epoch': 0.48, 'timestamp': 1762966366.09024, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.24705396592617035, 'learning_rate': 7.684550215978364e-06, 'epoch': 0.48, 'timestamp': 1762966367.4973903, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7747, 'grad_norm': 0.28313472867012024, 'learning_rate': 7.608083859470022e-06, 'epoch': 0.48, 'timestamp': 1762966368.8450682, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.772, 'grad_norm': 0.2024489790201187, 'learning_rate': 7.532378393776796e-06, 'epoch': 0.48, 'timestamp': 1762966370.2869775, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8043, 'grad_norm': 0.2830182611942291, 'learning_rate': 7.457426247531898e-06, 'epoch': 0.48, 'timestamp': 1762966371.7068715, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:52:55.523102: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:52:55.533760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966375.546487 1754876 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966375.550301 1754876 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966375.560652 1754876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966375.560669 1754876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966375.560672 1754876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966375.560674 1754876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:52:55.563884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:52:57 - TensorFlow version 2.19.1 available.
 16%|        | 49000/303576 [30:50<57:25, 73.88it/s]2025-11-12 16:53:05.962867: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:53:05.973412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966385.986105 1755034 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966385.989917 1755034 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966386.000122 1755034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966386.000139 1755034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966386.000141 1755034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966386.000142 1755034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:53:06.003320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:53:07 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 16%|        | 49000/303576 [31:00<57:25, 73.88it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 16%|        | 49001/303576 [31:00<72:15:56,  1.02s/it] 16%|        | 49006/303576 [31:00<55:06:29,  1.28it/s] 16%|        | 49013/303576 [31:01<37:37:14,  1.88it/s] 16%|        | 49019/303576 [31:01<27:15:09,  2.59it/s] 16%|        | 49025/303576 [31:01<19:44:16,  3.58it/s] 16%|        | 49031/303576 [31:01<14:21:07,  4.93it/s] 16%|        | 49037/303576 [31:01<10:30:19,  6.73it/s] 16%|        | 49043/303576 [31:01<7:46:41,  9.09it/s]  16%|        | 49049/303576 [31:01<5:51:04, 12.08it/s] 16%|        | 49055/303576 [31:01<4:29:57, 15.71it/s] 16%|        | 49061/303576 [31:01<3:32:20, 19.98it/s] 16%|        | 49067/303576 [31:02<2:51:09, 24.78it/s] 16%|        | 49073/303576 [31:02<2:22:34, 29.75it/s] 16%|        | 49079/303576 [31:02<2:02:25, 34.65it/s] 16%|        | 49085/303576 [31:02<1:48:19, 39.16it/s] 16%|        | 49091/303576 [31:02<1:38:38, 43.00it/s] 16%|        | 49097/303576 [31:02<1:30:53, 46.66it/s]                                                         16%|        | 49100/303576 [31:02<1:30:53, 46.66it/s] 16%|        | 49103/303576 [31:02<1:25:17, 49.73it/s] 16%|        | 49109/303576 [31:02<1:22:03, 51.69it/s] 16%|        | 49115/303576 [31:02<1:19:49, 53.13it/s] 16%|        | 49121/303576 [31:02<1:18:18, 54.16it/s] 16%|        | 49127/303576 [31:03<1:17:22, 54.80it/s] 16%|        | 49133/303576 [31:03<1:16:03, 55.76it/s] 16%|        | 49139/303576 [31:03<1:15:48, 55.94it/s] 16%|        | 49145/303576 [31:03<1:15:31, 56.15it/s] 16%|        | 49151/303576 [31:03<1:14:06, 57.22it/s] 16%|        | 49157/303576 [31:03<1:14:12, 57.14it/s] 16%|        | 49163/303576 [31:03<1:14:47, 56.70it/s] 16%|        | 49169/303576 [31:03<1:14:32, 56.89it/s] 16%|        | 49175/303576 [31:03<1:14:18, 57.05it/s] 16%|        | 49181/303576 [31:04<1:13:46, 57.46it/s] 16%|        | 49187/303576 [31:04<1:13:59, 57.30it/s] 16%|        | 49193/303576 [31:04<1:13:40, 57.54it/s] 16%|        | 49199/303576 [31:04<1:12:55, 58.14it/s]                                                         16%|        | 49200/303576 [31:04<1:12:55, 58.14it/s] 16%|        | 49205/303576 [31:04<1:13:27, 57.71it/s] 16%|        | 49211/303576 [31:04<1:13:37, 57.58it/s] 16%|        | 49217/303576 [31:04<1:14:03, 57.24it/s] 16%|        | 49223/303576 [31:04<1:13:57, 57.32it/s] 16%|        | 49229/303576 [31:04<1:13:48, 57.44it/s] 16%|        | 49235/303576 [31:04<1:14:00, 57.27it/s] 16%|        | 49241/303576 [31:05<1:13:57, 57.31it/s] 16%|        | 49247/303576 [31:05<1:14:43, 56.72it/s] 16%|        | 49253/303576 [31:05<1:14:55, 56.57it/s] 16%|        | 49259/303576 [31:05<1:13:56, 57.32it/s] 16%|        | 49265/303576 [31:05<1:13:47, 57.44it/s] 16%|        | 49271/303576 [31:05<1:13:12, 57.89it/s] 16%|        | 49277/303576 [31:05<1:13:16, 57.83it/s] 16%|        | 49283/303576 [31:05<1:12:48, 58.21it/s] 16%|        | 49289/303576 [31:05<1:13:00, 58.05it/s] 16%|        | 49296/303576 [31:06<1:12:21, 58.57it/s]                                                         16%|        | 49300/303576 [31:06<1:12:21, 58.57it/s] 16%|        | 49302/303576 [31:06<1:12:12, 58.69it/s] 16%|        | 49308/303576 [31:06<1:12:08, 58.75it/s] 16%|        | 49314/303576 [31:06<1:12:46, 58.24it/s] 16%|        | 49320/303576 [31:06<1:13:03, 58.00it/s] 16%|        | 49326/303576 [31:06<1:12:41, 58.30it/s] 16%|        | 49332/303576 [31:06<1:12:22, 58.54it/s] 16%|        | 49338/303576 [31:06<1:12:10, 58.71it/s] 16%|        | 49344/303576 [31:06<1:13:13, 57.87it/s] 16%|        | 49350/303576 [31:06<1:12:46, 58.22it/s] 16%|        | 49356/303576 [31:07<1:13:22, 57.74it/s] 16%|        | 49362/303576 [31:07<1:13:21, 57.76it/s] 16%|        | 49368/303576 [31:07<1:12:50, 58.16it/s] 16%|        | 49374/303576 [31:07<1:13:14, 57.84it/s] 16%|        | 49380/303576 [31:07<1:12:44, 58.24it/s] 16%|        | 49390/303576 [31:07<1:01:43, 68.63it/s] 16%|        | 49399/303576 [31:07<56:38, 74.79it/s]                                                         16%|        | 49400/303576 [31:07<56:38, 74.79it/s] 16%|        | 49408/303576 [31:07<55:20, 76.54it/s] 16%|        | 49417/303576 [31:07<54:25, 77.83it/s] 16%|        | 49426/303576 [31:08<53:44, 78.81it/s] 16%|        | 49435/303576 [31:08<53:19, 79.44it/s] 16%|        | 49444/303576 [31:08<53:00, 79.89it/s] 16%|        | 49453/303576 [31:08<52:43, 80.34it/s] 16%|        | 49462/303576 [31:08<52:58, 79.95it/s] 16%|        | 49470/303576 [31:08<53:41, 78.89it/s] 16%|        | 49478/303576 [31:08<56:50, 74.50it/s] 16%|        | 49486/303576 [31:08<1:01:49, 68.50it/s] 16%|        | 49493/303576 [31:08<1:05:39, 64.49it/s] 16%|        | 49500/303576 [31:09<1:08:23, 61.92it/s]                                                         16%|        | 49500/303576 [31:09<1:08:23, 61.92it/s] 16%|        | 49507/303576 [31:09<1:10:45, 59.85it/s] 16%|        | 49514/303576 [31:09<1:12:54, 58.08it/s] 16%|        | 49520/303576 [31:09<1:14:03, 57.17it/s] 16%|        | 49526/303576 [31:09<1:14:24, 56.91it/s] 16%|        | 49532/303576 [31:09<1:14:34, 56.77it/s] 16%|        | 49538/303576 [31:09<1:14:47, 56.61it/s] 16%|        | 49544/303576 [31:09<1:14:53, 56.53it/s] 16%|        | 49550/303576 [31:09<1:15:01, 56.43it/s] 16%|        | 49556/303576 [31:10<1:15:07, 56.35it/s] 16%|        | 49562/303576 [31:10<1:15:12, 56.29it/s] 16%|        | 49568/303576 [31:10<1:15:16, 56.24it/s] 16%|        | 49574/303576 [31:10<1:15:22, 56.17it/s] 16%|        | 49580/303576 [31:10<1:15:47, 55.85it/s] 16%|        | 49586/303576 [31:10<1:15:29, 56.08it/s] 16%|        | 49592/303576 [31:10<1:15:34, 56.01it/s] 16%|        | 49598/303576 [31:10<1:15:11, 56.30it/s]                                                         16%|        | 49600/303576 [31:10<1:15:11, 56.30it/s] 16%|        | 49604/303576 [31:10<1:14:42, 56.65it/s] 16%|        | 49610/303576 [31:11<1:14:33, 56.77it/s] 16%|        | 49616/303576 [31:11<1:14:02, 57.17it/s] 16%|        | 49622/303576 [31:11<1:13:11, 57.83it/s] 16%|        | 49628/303576 [31:11<1:13:29, 57.59it/s] 16%|        | 49634/303576 [31:11<1:13:12, 57.81it/s] 16%|        | 49640/303576 [31:11<1:12:46, 58.15it/s] 16%|        | 49646/303576 [31:11<1:12:35, 58.30it/s] 16%|        | 49652/303576 [31:11<1:12:13, 58.60it/s] 16%|        | 49659/303576 [31:11<1:10:10, 60.30it/s] 16%|        | 49666/303576 [31:11<1:11:27, 59.22it/s] 16%|        | 49672/303576 [31:12<1:12:55, 58.03it/s] 16%|        | 49678/303576 [31:12<1:13:45, 57.37it/s] 16%|        | 49685/303576 [31:12<1:12:25, 58.42it/s] 16%|        | 49691/303576 [31:12<1:11:57, 58.81it/s] 16%|        | 49697/303576 [31:12<1:12:20, 58.49it/s]                                                         16%|        | 49700/303576 [31:12<1:12:20, 58.49it/s] 16%|        | 49703/303576 [31:12<1:12:43, 58.18it/s] 16%|        | 49710/303576 [31:12<1:09:28, 60.90it/s] 16%|        | 49717/303576 [31:12<1:07:38, 62.56it/s] 16%|        | 49724/303576 [31:12<1:06:02, 64.07it/s] 16%|        | 49731/303576 [31:13<1:05:34, 64.52it/s] 16%|        | 49738/303576 [31:13<1:05:32, 64.55it/s] 16%|        | 49745/303576 [31:13<1:07:20, 62.83it/s] 16%|        | 49752/303576 [31:13<1:07:22, 62.79it/s] 16%|        | 49759/303576 [31:13<1:06:56, 63.19it/s] 16%|        | 49766/303576 [31:13<1:06:56, 63.20it/s] 16%|        | 49773/303576 [31:13<1:06:41, 63.43it/s] 16%|        | 49780/303576 [31:13<1:06:40, 63.44it/s] 16%|        | 49787/303576 [31:13<1:06:16, 63.82it/s] 16%|        | 49794/303576 [31:14<1:06:40, 63.44it/s]                                                         16%|        | 49800/303576 [31:14<1:06:39, 63.44it/s] 16%|        | 49801/303576 [31:14<1:06:55, 63.21it/s] 16%|        | 49808/303576 [31:14<1:07:05, 63.04it/s] 16%|        | 49815/303576 [31:14<1:06:47, 63.32it/s] 16%|        | 49822/303576 [31:14<1:07:11, 62.95it/s] 16%|        | 49829/303576 [31:14<1:06:48, 63.30it/s] 16%|        | 49836/303576 [31:14<1:07:02, 63.09it/s] 16%|        | 49843/303576 [31:14<1:07:07, 63.01it/s] 16%|        | 49850/303576 [31:14<1:07:19, 62.81it/s] 16%|        | 49857/303576 [31:15<1:06:57, 63.15it/s] 16%|        | 49864/303576 [31:15<1:07:11, 62.93it/s] 16%|        | 49871/303576 [31:15<1:06:54, 63.19it/s] 16%|        | 49878/303576 [31:15<1:09:33, 60.79it/s] 16%|        | 49885/303576 [31:15<1:08:27, 61.76it/s] 16%|        | 49892/303576 [31:15<1:07:18, 62.82it/s] 16%|        | 49899/303576 [31:15<1:06:58, 63.13it/s]                                                         16%|        | 49900/303576 [31:15<1:06:58, 63.13it/s] 16%|        | 49906/303576 [31:15<1:06:26, 63.64it/s] 16%|        | 49913/303576 [31:15<1:06:12, 63.85it/s] 16%|        | 49920/303576 [31:16<1:05:46, 64.28it/s] 16%|        | 49928/303576 [31:16<1:03:20, 66.74it/s] 16%|        | 49939/303576 [31:16<54:20, 77.80it/s]   16%|        | 49950/303576 [31:16<49:11, 85.93it/s] 16%|        | 49961/303576 [31:16<45:59, 91.90it/s] 16%|        | 49971/303576 [31:16<46:41, 90.54it/s] 16%|        | 49981/303576 [31:16<46:51, 90.21it/s] 16%|        | 49991/303576 [31:16<47:09, 89.61it/s]                                                       16%|        | 50000/303576 [31:16<47:09, 89.61it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.737003743648529, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4777, 'eval_samples_per_second': 10.054, 'eval_steps_per_second': 0.089, 'epoch': 0.48, 'timestamp': 1762966394.1850815, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7586, 'grad_norm': 0.28445160388946533, 'learning_rate': 7.383219924708635e-06, 'epoch': 0.49, 'timestamp': 1762966396.0534694, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.768, 'grad_norm': 0.2523771822452545, 'learning_rate': 7.310483052175963e-06, 'epoch': 0.49, 'timestamp': 1762966397.7946894, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8112, 'grad_norm': 0.260437935590744, 'learning_rate': 7.237738911321294e-06, 'epoch': 0.49, 'timestamp': 1762966399.5304117, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7777, 'grad_norm': 0.24519377946853638, 'learning_rate': 7.165718622774455e-06, 'epoch': 0.49, 'timestamp': 1762966401.1283255, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7758, 'grad_norm': 0.23212528228759766, 'learning_rate': 7.094414983726296e-06, 'epoch': 0.49, 'timestamp': 1762966402.5160446, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.772, 'grad_norm': 0.22829090058803558, 'learning_rate': 7.023820863040378e-06, 'epoch': 0.49, 'timestamp': 1762966404.3051953, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7756, 'grad_norm': 0.2867640256881714, 'learning_rate': 6.953929200539788e-06, 'epoch': 0.49, 'timestamp': 1762966406.0177634, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7794, 'grad_norm': 0.38349801301956177, 'learning_rate': 6.884733006301038e-06, 'epoch': 0.49, 'timestamp': 1762966407.5821133, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7666, 'grad_norm': 0.2143019288778305, 'learning_rate': 6.816225359955004e-06, 'epoch': 0.49, 'timestamp': 1762966409.1739647, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7768, 'grad_norm': 0.20983074605464935, 'learning_rate': 6.74839940999481e-06, 'epoch': 0.49, 'timestamp': 1762966410.3325725, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:53:33.714074: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:53:33.724853: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966413.737900 1755474 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966413.741837 1755474 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966413.752287 1755474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966413.752303 1755474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966413.752304 1755474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966413.752306 1755474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:53:33.755506: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:53:35 - TensorFlow version 2.19.1 available.
2025-11-12 16:53:43.478992: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:53:43.489627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966423.502376 1755632 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966423.506219 1755632 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966423.516561 1755632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966423.516575 1755632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966423.516577 1755632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966423.516578 1755632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:53:43.519803: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 16%|        | 50000/303576 [31:30<47:09, 89.61it/s]2025-11-12T16:53:45 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 16%|        | 50000/303576 [31:38<47:09, 89.61it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-50000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-50000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-50000/model.safetensors
 16%|        | 50001/303576 [31:38<46:27:55,  1.52it/s] 16%|        | 50008/303576 [31:38<35:56:23,  1.96it/s] 16%|        | 50017/303576 [31:38<25:30:20,  2.76it/s] 16%|        | 50025/303576 [31:38<18:45:53,  3.75it/s] 16%|        | 50033/303576 [31:38<13:45:16,  5.12it/s] 16%|        | 50041/303576 [31:38<10:05:39,  6.98it/s] 16%|        | 50049/303576 [31:39<7:26:41,  9.46it/s]  16%|        | 50057/303576 [31:39<5:32:57, 12.69it/s] 16%|        | 50065/303576 [31:39<4:12:05, 16.76it/s] 16%|        | 50073/303576 [31:39<3:14:48, 21.69it/s] 16%|        | 50081/303576 [31:39<2:34:24, 27.36it/s] 16%|        | 50089/303576 [31:39<2:06:04, 33.51it/s] 17%|        | 50097/303576 [31:39<1:45:57, 39.87it/s]                                                         17%|        | 50100/303576 [31:39<1:45:57, 39.87it/s] 17%|        | 50105/303576 [31:39<1:31:58, 45.93it/s] 17%|        | 50113/303576 [31:39<1:22:11, 51.40it/s] 17%|        | 50121/303576 [31:40<1:15:08, 56.21it/s] 17%|        | 50129/303576 [31:40<1:10:17, 60.09it/s] 17%|        | 50137/303576 [31:40<1:06:57, 63.08it/s] 17%|        | 50145/303576 [31:40<1:04:47, 65.19it/s] 17%|        | 50155/303576 [31:40<57:07, 73.94it/s]   17%|        | 50166/303576 [31:40<51:14, 82.44it/s] 17%|        | 50177/303576 [31:40<47:36, 88.71it/s] 17%|        | 50189/303576 [31:40<44:16, 95.38it/s] 17%|        | 50200/303576 [31:40<43:04, 98.05it/s]                                                       17%|        | 50200/303576 [31:40<43:04, 98.05it/s] 17%|        | 50211/303576 [31:41<42:49, 98.61it/s] 17%|        | 50221/303576 [31:41<42:41, 98.91it/s] 17%|        | 50232/303576 [31:41<42:30, 99.33it/s] 17%|        | 50243/303576 [31:41<41:30, 101.72it/s] 17%|        | 50254/303576 [31:41<43:10, 97.80it/s]  17%|        | 50264/303576 [31:41<45:37, 92.54it/s] 17%|        | 50275/303576 [31:41<44:13, 95.45it/s] 17%|        | 50286/303576 [31:41<42:52, 98.45it/s] 17%|        | 50297/303576 [31:41<42:05, 100.29it/s]                                                        17%|        | 50300/303576 [31:41<42:05, 100.29it/s] 17%|        | 50308/303576 [31:42<41:09, 102.55it/s] 17%|        | 50319/303576 [31:42<42:18, 99.78it/s]  17%|        | 50330/303576 [31:42<45:32, 92.68it/s] 17%|        | 50341/303576 [31:42<44:26, 94.97it/s] 17%|        | 50352/303576 [31:42<43:47, 96.37it/s] 17%|        | 50362/303576 [31:42<45:43, 92.29it/s] 17%|        | 50372/303576 [31:42<47:05, 89.60it/s] 17%|        | 50382/303576 [31:42<46:53, 89.99it/s] 17%|        | 50393/303576 [31:42<45:19, 93.11it/s]                                                       17%|        | 50400/303576 [31:43<45:19, 93.11it/s] 17%|        | 50404/303576 [31:43<44:21, 95.12it/s] 17%|        | 50414/303576 [31:43<45:47, 92.13it/s] 17%|        | 50424/303576 [31:43<47:54, 88.07it/s] 17%|        | 50433/303576 [31:43<49:46, 84.75it/s] 17%|        | 50442/303576 [31:43<51:01, 82.67it/s] 17%|        | 50451/303576 [31:43<51:12, 82.38it/s] 17%|        | 50460/303576 [31:43<51:25, 82.05it/s] 17%|        | 50469/303576 [31:43<51:30, 81.90it/s] 17%|        | 50478/303576 [31:43<51:15, 82.31it/s] 17%|        | 50487/303576 [31:44<51:24, 82.06it/s] 17%|        | 50496/303576 [31:44<51:07, 82.50it/s]                                                       17%|        | 50500/303576 [31:44<51:07, 82.50it/s] 17%|        | 50505/303576 [31:44<51:02, 82.64it/s] 17%|        | 50514/303576 [31:44<50:10, 84.05it/s] 17%|        | 50523/303576 [31:44<49:36, 85.02it/s] 17%|        | 50532/303576 [31:44<49:14, 85.63it/s] 17%|        | 50541/303576 [31:44<48:41, 86.61it/s] 17%|        | 50550/303576 [31:44<48:59, 86.08it/s] 17%|        | 50559/303576 [31:44<49:40, 84.88it/s] 17%|        | 50568/303576 [31:45<49:57, 84.42it/s] 17%|        | 50577/303576 [31:45<50:29, 83.51it/s] 17%|        | 50586/303576 [31:45<49:44, 84.76it/s] 17%|        | 50595/303576 [31:46<4:36:31, 15.25it/s]                                                         17%|        | 50600/303576 [31:47<4:36:31, 15.25it/s] 17%|        | 50602/303576 [31:47<3:45:35, 18.69it/s] 17%|        | 50609/303576 [31:47<3:06:34, 22.60it/s] 17%|        | 50615/303576 [31:47<2:40:08, 26.33it/s] 17%|        | 50621/303576 [31:47<2:18:39, 30.40it/s] 17%|        | 50627/303576 [31:47<2:02:11, 34.50it/s] 17%|        | 50633/303576 [31:47<1:49:33, 38.48it/s] 17%|        | 50639/303576 [31:47<1:40:19, 42.02it/s] 17%|        | 50645/303576 [31:47<1:34:02, 44.82it/s] 17%|        | 50651/303576 [31:48<1:29:07, 47.30it/s] 17%|        | 50657/303576 [31:48<1:24:40, 49.79it/s] 17%|        | 50663/303576 [31:49<7:20:00,  9.58it/s] 17%|        | 50669/303576 [31:50<5:31:33, 12.71it/s] 17%|        | 50675/303576 [31:50<4:15:48, 16.48it/s] 17%|        | 50681/303576 [31:50<3:22:36, 20.80it/s] 17%|        | 50687/303576 [31:50<2:45:08, 25.52it/s] 17%|        | 50693/303576 [31:50<2:18:25, 30.45it/s] 17%|        | 50699/303576 [31:50<2:00:18, 35.03it/s]                                                         17%|        | 50700/303576 [31:50<2:00:18, 35.03it/s] 17%|        | 50705/303576 [31:50<1:47:06, 39.35it/s] 17%|        | 50711/303576 [31:50<1:37:09, 43.38it/s] 17%|        | 50717/303576 [31:50<1:29:51, 46.90it/s] 17%|        | 50723/303576 [31:51<1:24:15, 50.02it/s] 17%|        | 50729/303576 [31:51<1:21:18, 51.82it/s] 17%|        | 50735/303576 [31:51<1:18:32, 53.65it/s] 17%|        | 50741/303576 [31:51<1:16:40, 54.96it/s] 17%|        | 50747/303576 [31:51<1:15:51, 55.54it/s] 17%|        | 50753/303576 [31:51<1:15:06, 56.11it/s] 17%|        | 50759/303576 [31:51<1:14:14, 56.75it/s] 17%|        | 50765/303576 [31:51<1:13:49, 57.07it/s] 17%|        | 50771/303576 [31:51<1:13:31, 57.30it/s] 17%|        | 50777/303576 [31:51<1:13:04, 57.66it/s] 17%|        | 50783/303576 [31:52<1:12:55, 57.77it/s] 17%|        | 50789/303576 [31:52<1:12:37, 58.01it/s] 17%|        | 50795/303576 [31:52<1:11:58, 58.53it/s]                                                         17%|        | 50800/303576 [31:52<1:11:58, 58.53it/s] 17%|        | 50801/303576 [31:52<1:12:03, 58.46it/s] 17%|        | 50809/303576 [31:52<1:06:28, 63.37it/s] 17%|        | 50818/303576 [31:52<59:49, 70.42it/s]   17%|        | 50828/303576 [31:52<54:13, 77.68it/s] 17%|        | 50838/303576 [31:52<50:53, 82.77it/s] 17%|        | 50849/303576 [31:52<47:17, 89.08it/s] 17%|        | 50860/303576 [31:53<45:29, 92.60it/s] 17%|        | 50871/303576 [31:53<44:05, 95.53it/s] 17%|        | 50881/303576 [31:53<44:18, 95.06it/s] 17%|        | 50891/303576 [31:53<46:02, 91.47it/s]                                                       17%|        | 50900/303576 [31:53<46:02, 91.47it/s] 17%|        | 50901/303576 [31:53<47:55, 87.86it/s] 17%|        | 50910/303576 [31:53<49:35, 84.90it/s] 17%|        | 50919/303576 [31:53<50:04, 84.10it/s] 17%|        | 50928/303576 [31:53<52:15, 80.58it/s] 17%|        | 50937/303576 [31:53<54:58, 76.58it/s] 17%|        | 50945/303576 [31:54<56:14, 74.87it/s] 17%|        | 50953/303576 [31:54<57:48, 72.83it/s] 17%|        | 50962/303576 [31:54<55:45, 75.52it/s] 17%|        | 50971/303576 [31:54<53:46, 78.30it/s] 17%|        | 50981/303576 [31:54<50:23, 83.56it/s] 17%|        | 50990/303576 [31:54<50:04, 84.08it/s] 17%|        | 50999/303576 [31:54<51:51, 81.18it/s]                                                       17%|        | 51000/303576 [31:54<51:51, 81.18it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7369574904441833, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.4324, 'eval_samples_per_second': 10.545, 'eval_steps_per_second': 0.093, 'epoch': 0.49, 'timestamp': 1762966431.7655141, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8217, 'grad_norm': 0.2655838429927826, 'learning_rate': 6.681248373090607e-06, 'epoch': 0.5, 'timestamp': 1762966433.2394893, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7763, 'grad_norm': 0.2281551957130432, 'learning_rate': 6.614765533411157e-06, 'epoch': 0.5, 'timestamp': 1762966434.3969011, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.21137972176074982, 'learning_rate': 6.548944241952193e-06, 'epoch': 0.5, 'timestamp': 1762966435.4085817, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7592, 'grad_norm': 0.2344188541173935, 'learning_rate': 6.483777915871436e-06, 'epoch': 0.5, 'timestamp': 1762966436.486413, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7652, 'grad_norm': 0.29379788041114807, 'learning_rate': 6.419260037830233e-06, 'epoch': 0.5, 'timestamp': 1762966437.706333, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7667, 'grad_norm': 0.23902787268161774, 'learning_rate': 6.355384155341775e-06, 'epoch': 0.5, 'timestamp': 1762966440.5170443, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7666, 'grad_norm': 0.2149685025215149, 'learning_rate': 6.292143880125754e-06, 'epoch': 0.5, 'timestamp': 1762966444.0634189, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7678, 'grad_norm': 0.23344334959983826, 'learning_rate': 6.229532887469468e-06, 'epoch': 0.5, 'timestamp': 1762966445.7915435, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7591, 'grad_norm': 0.21994835138320923, 'learning_rate': 6.1675449155953e-06, 'epoch': 0.5, 'timestamp': 1762966446.893958, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7753, 'grad_norm': 0.2359391450881958, 'learning_rate': 6.106173765034459e-06, 'epoch': 0.5, 'timestamp': 1762966448.1744745, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:54:12.014151: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:54:12.025116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966452.038495 1756072 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966452.042614 1756072 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966452.053289 1756072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966452.053305 1756072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966452.053307 1756072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966452.053308 1756072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:54:12.056763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:54:14 - TensorFlow version 2.19.1 available.
2025-11-12 16:54:22.533315: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:54:22.544005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966462.556867 1756230 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966462.560712 1756230 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966462.571114 1756230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966462.571130 1756230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966462.571132 1756230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966462.571134 1756230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:54:22.574392: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 17%|        | 51000/303576 [32:10<51:51, 81.18it/s]2025-11-12T16:54:24 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 17%|        | 51000/303576 [32:17<51:51, 81.18it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 17%|        | 51001/303576 [32:17<69:02:35,  1.02it/s] 17%|        | 51006/303576 [32:17<53:09:56,  1.32it/s] 17%|        | 51014/303576 [32:17<35:00:43,  2.00it/s] 17%|        | 51021/303576 [32:17<24:44:28,  2.84it/s] 17%|        | 51028/303576 [32:17<17:37:50,  3.98it/s] 17%|        | 51035/303576 [32:17<12:41:01,  5.53it/s] 17%|        | 51041/303576 [32:18<9:36:18,  7.30it/s]  17%|        | 51047/303576 [32:18<7:16:59,  9.63it/s] 17%|        | 51053/303576 [32:18<5:34:00, 12.60it/s] 17%|        | 51059/303576 [32:18<4:19:19, 16.23it/s] 17%|        | 51066/303576 [32:18<3:14:54, 21.59it/s] 17%|        | 51074/303576 [32:18<2:28:00, 28.43it/s] 17%|        | 51082/303576 [32:18<1:58:50, 35.41it/s] 17%|        | 51090/303576 [32:18<1:39:51, 42.14it/s] 17%|        | 51098/303576 [32:18<1:27:12, 48.25it/s]                                                         17%|        | 51100/303576 [32:18<1:27:12, 48.25it/s] 17%|        | 51106/303576 [32:19<1:18:32, 53.57it/s] 17%|        | 51114/303576 [32:19<1:12:52, 57.74it/s] 17%|        | 51122/303576 [32:19<1:08:52, 61.10it/s] 17%|        | 51130/303576 [32:19<1:06:06, 63.64it/s] 17%|        | 51138/303576 [32:19<1:03:26, 66.31it/s] 17%|        | 51146/303576 [32:19<1:02:14, 67.59it/s] 17%|        | 51154/303576 [32:19<1:01:30, 68.40it/s] 17%|        | 51162/303576 [32:19<1:01:19, 68.61it/s] 17%|        | 51170/303576 [32:19<1:00:51, 69.13it/s] 17%|        | 51178/303576 [32:20<1:00:28, 69.56it/s] 17%|        | 51186/303576 [32:20<1:00:21, 69.70it/s] 17%|        | 51194/303576 [32:20<1:00:42, 69.28it/s]                                                         17%|        | 51200/303576 [32:20<1:00:42, 69.28it/s] 17%|        | 51201/303576 [32:20<1:01:22, 68.52it/s] 17%|        | 51209/303576 [32:20<1:00:59, 68.97it/s] 17%|        | 51217/303576 [32:20<1:00:28, 69.56it/s] 17%|        | 51225/303576 [32:20<1:00:02, 70.05it/s] 17%|        | 51233/303576 [32:20<59:36, 70.56it/s]   17%|        | 51241/303576 [32:20<59:25, 70.78it/s] 17%|        | 51249/303576 [32:21<1:00:23, 69.64it/s] 17%|        | 51257/303576 [32:21<1:00:26, 69.58it/s] 17%|        | 51265/303576 [32:21<59:41, 70.45it/s]   17%|        | 51274/303576 [32:21<57:01, 73.73it/s] 17%|        | 51282/303576 [32:21<55:57, 75.14it/s] 17%|        | 51290/303576 [32:21<55:18, 76.02it/s] 17%|        | 51298/303576 [32:21<54:33, 77.07it/s]                                                       17%|        | 51300/303576 [32:21<54:33, 77.07it/s] 17%|        | 51306/303576 [32:21<54:31, 77.11it/s] 17%|        | 51314/303576 [32:21<54:26, 77.23it/s] 17%|        | 51322/303576 [32:22<54:05, 77.73it/s] 17%|        | 51330/303576 [32:22<53:58, 77.88it/s] 17%|        | 51338/303576 [32:22<53:57, 77.92it/s] 17%|        | 51346/303576 [32:22<54:57, 76.50it/s] 17%|        | 51354/303576 [32:22<55:51, 75.25it/s] 17%|        | 51362/303576 [32:22<56:43, 74.11it/s] 17%|        | 51370/303576 [32:22<57:12, 73.47it/s] 17%|        | 51378/303576 [32:22<58:04, 72.37it/s] 17%|        | 51386/303576 [32:22<59:12, 70.99it/s] 17%|        | 51394/303576 [32:23<1:00:04, 69.97it/s]                                                         17%|        | 51400/303576 [32:23<1:00:04, 69.97it/s] 17%|        | 51402/303576 [32:23<1:00:43, 69.21it/s] 17%|        | 51409/303576 [32:23<1:01:23, 68.46it/s] 17%|        | 51416/303576 [32:23<1:01:28, 68.37it/s] 17%|        | 51423/303576 [32:23<1:01:55, 67.86it/s] 17%|        | 51430/303576 [32:23<1:01:55, 67.86it/s] 17%|        | 51437/303576 [32:23<1:02:07, 67.64it/s] 17%|        | 51444/303576 [32:23<1:01:59, 67.79it/s] 17%|        | 51451/303576 [32:23<1:02:14, 67.52it/s] 17%|        | 51458/303576 [32:23<1:01:51, 67.92it/s] 17%|        | 51466/303576 [32:24<1:00:32, 69.40it/s] 17%|        | 51475/303576 [32:24<57:22, 73.24it/s]   17%|        | 51483/303576 [32:24<56:22, 74.54it/s] 17%|        | 51491/303576 [32:24<55:51, 75.21it/s] 17%|        | 51499/303576 [32:24<55:01, 76.34it/s]                                                       17%|        | 51500/303576 [32:24<55:01, 76.34it/s] 17%|        | 51507/303576 [32:24<54:37, 76.92it/s] 17%|        | 51515/303576 [32:24<54:16, 77.39it/s] 17%|        | 51523/303576 [32:24<56:53, 73.85it/s] 17%|        | 51531/303576 [32:24<1:01:52, 67.89it/s] 17%|        | 51538/303576 [32:25<1:04:54, 64.72it/s] 17%|        | 51545/303576 [32:25<1:07:34, 62.16it/s] 17%|        | 51552/303576 [32:25<1:11:15, 58.94it/s] 17%|        | 51558/303576 [32:25<1:15:24, 55.70it/s] 17%|        | 51564/303576 [32:25<1:14:06, 56.68it/s] 17%|        | 51570/303576 [32:25<1:13:35, 57.07it/s] 17%|        | 51576/303576 [32:25<1:13:01, 57.51it/s] 17%|        | 51582/303576 [32:25<1:13:00, 57.52it/s] 17%|        | 51588/303576 [32:25<1:12:43, 57.75it/s] 17%|        | 51594/303576 [32:26<1:12:46, 57.71it/s] 17%|        | 51600/303576 [32:26<1:12:44, 57.73it/s]                                                         17%|        | 51600/303576 [32:26<1:12:44, 57.73it/s] 17%|        | 51606/303576 [32:26<1:12:58, 57.55it/s] 17%|        | 51612/303576 [32:26<1:14:41, 56.22it/s] 17%|        | 51618/303576 [32:26<1:15:02, 55.96it/s] 17%|        | 51624/303576 [32:26<1:15:09, 55.87it/s] 17%|        | 51630/303576 [32:26<1:14:41, 56.22it/s] 17%|        | 51636/303576 [32:26<1:13:38, 57.02it/s] 17%|        | 51642/303576 [32:26<1:12:34, 57.85it/s] 17%|        | 51648/303576 [32:27<1:11:48, 58.47it/s] 17%|        | 51655/303576 [32:27<1:11:08, 59.02it/s] 17%|        | 51662/303576 [32:27<1:10:37, 59.45it/s] 17%|        | 51669/303576 [32:27<1:10:19, 59.69it/s] 17%|        | 51676/303576 [32:27<1:09:52, 60.09it/s] 17%|        | 51683/303576 [32:27<1:09:40, 60.26it/s] 17%|        | 51690/303576 [32:27<1:09:28, 60.43it/s] 17%|        | 51697/303576 [32:27<1:09:26, 60.46it/s]                                                         17%|        | 51700/303576 [32:27<1:09:26, 60.46it/s] 17%|        | 51704/303576 [32:27<1:09:20, 60.54it/s] 17%|        | 51711/303576 [32:28<1:09:45, 60.18it/s] 17%|        | 51718/303576 [32:28<1:09:58, 59.99it/s] 17%|        | 51725/303576 [32:28<1:09:48, 60.13it/s] 17%|        | 51732/303576 [32:28<1:09:28, 60.42it/s] 17%|        | 51739/303576 [32:28<1:09:31, 60.38it/s] 17%|        | 51746/303576 [32:28<1:09:16, 60.59it/s] 17%|        | 51753/303576 [32:28<1:09:18, 60.55it/s] 17%|        | 51760/303576 [32:28<1:09:48, 60.13it/s] 17%|        | 51767/303576 [32:28<1:08:22, 61.38it/s] 17%|        | 51774/303576 [32:29<1:09:04, 60.75it/s] 17%|        | 51781/303576 [32:29<1:09:22, 60.49it/s] 17%|        | 51788/303576 [32:29<1:09:25, 60.45it/s] 17%|        | 51795/303576 [32:29<1:09:30, 60.38it/s]                                                         17%|        | 51800/303576 [32:29<1:09:30, 60.38it/s] 17%|        | 51802/303576 [32:29<1:09:44, 60.17it/s] 17%|        | 51809/303576 [32:29<1:09:39, 60.24it/s] 17%|        | 51816/303576 [32:29<1:09:29, 60.38it/s] 17%|        | 51823/303576 [32:29<1:09:31, 60.35it/s] 17%|        | 51830/303576 [32:30<1:11:56, 58.32it/s] 17%|        | 51836/303576 [32:30<1:13:30, 57.08it/s] 17%|        | 51842/303576 [32:30<1:14:48, 56.08it/s] 17%|        | 51848/303576 [32:30<1:15:41, 55.43it/s] 17%|        | 51854/303576 [32:30<1:16:05, 55.14it/s] 17%|        | 51860/303576 [32:30<1:16:11, 55.06it/s] 17%|        | 51866/303576 [32:30<1:16:33, 54.79it/s] 17%|        | 51872/303576 [32:30<1:16:54, 54.55it/s] 17%|        | 51878/303576 [32:30<1:17:05, 54.41it/s] 17%|        | 51884/303576 [32:31<1:17:16, 54.29it/s] 17%|        | 51890/303576 [32:31<1:17:12, 54.33it/s] 17%|        | 51896/303576 [32:31<1:17:02, 54.45it/s]                                                         17%|        | 51900/303576 [32:31<1:17:02, 54.45it/s] 17%|        | 51902/303576 [32:31<1:16:07, 55.10it/s] 17%|        | 51908/303576 [32:31<1:15:35, 55.48it/s] 17%|        | 51914/303576 [32:31<1:14:36, 56.21it/s] 17%|        | 51920/303576 [32:31<1:13:28, 57.08it/s] 17%|        | 51926/303576 [32:31<1:18:04, 53.72it/s] 17%|        | 51932/303576 [32:31<1:20:25, 52.15it/s] 17%|        | 51938/303576 [32:32<1:17:21, 54.21it/s] 17%|        | 51944/303576 [32:32<1:15:07, 55.82it/s] 17%|        | 51950/303576 [32:32<1:14:22, 56.38it/s] 17%|        | 51956/303576 [32:32<1:15:44, 55.37it/s] 17%|        | 51962/303576 [32:32<1:19:43, 52.60it/s] 17%|        | 51968/303576 [32:32<1:22:33, 50.79it/s] 17%|        | 51974/303576 [32:32<1:24:22, 49.69it/s] 17%|        | 51980/303576 [32:32<1:24:31, 49.61it/s] 17%|        | 51988/303576 [32:32<1:15:33, 55.49it/s] 17%|        | 51995/303576 [32:33<1:11:10, 58.91it/s]                                                         17%|        | 52000/303576 [32:33<1:11:10, 58.91it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7371118068695068, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.5273, 'eval_samples_per_second': 10.032, 'eval_steps_per_second': 0.089, 'epoch': 0.5, 'timestamp': 1762966470.702165, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.3859970271587372, 'learning_rate': 6.045413298006974e-06, 'epoch': 0.5, 'timestamp': 1762966472.37761, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.754, 'grad_norm': 0.2764841616153717, 'learning_rate': 5.98525743780783e-06, 'epoch': 0.51, 'timestamp': 1762966473.8020234, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.789, 'grad_norm': 0.2316683977842331, 'learning_rate': 5.925700168199255e-06, 'epoch': 0.51, 'timestamp': 1762966475.1664917, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7678, 'grad_norm': 0.3116433918476105, 'learning_rate': 5.8667355328090255e-06, 'epoch': 0.51, 'timestamp': 1762966476.5349197, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7758, 'grad_norm': 0.2216784656047821, 'learning_rate': 5.8083576345347476e-06, 'epoch': 0.51, 'timestamp': 1762966477.9368336, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7649, 'grad_norm': 0.2697701156139374, 'learning_rate': 5.7505606349541095e-06, 'epoch': 0.51, 'timestamp': 1762966479.612661, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.2752407491207123, 'learning_rate': 5.69333875374095e-06, 'epoch': 0.51, 'timestamp': 1762966481.3121448, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7684, 'grad_norm': 0.26262202858924866, 'learning_rate': 5.63668626808719e-06, 'epoch': 0.51, 'timestamp': 1762966482.967456, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7672, 'grad_norm': 0.21417410671710968, 'learning_rate': 5.580597512130461e-06, 'epoch': 0.51, 'timestamp': 1762966484.7661693, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7633, 'grad_norm': 0.22954556345939636, 'learning_rate': 5.5250668763874815e-06, 'epoch': 0.51, 'timestamp': 1762966486.575063, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:54:49.955923: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:54:49.966966: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966489.980412 1756670 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966489.984542 1756670 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966489.995271 1756670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966489.995289 1756670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966489.995291 1756670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966489.995292 1756670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:54:49.998849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:54:51 - TensorFlow version 2.19.1 available.
2025-11-12 16:54:59.684632: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:54:59.695418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966499.708504 1756829 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966499.712503 1756829 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966499.723099 1756829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966499.723115 1756829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966499.723117 1756829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966499.723118 1756829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:54:59.726625: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:55:01 - TensorFlow version 2.19.1 available.
 17%|        | 52000/303576 [32:50<1:11:10, 58.91it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                        
                                             [A 17%|        | 52000/303576 [32:54<1:11:10, 58.91it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-52000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-52000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-52000/model.safetensors
 17%|        | 52001/303576 [32:54<68:50:15,  1.02it/s] 17%|        | 52011/303576 [32:54<41:48:25,  1.67it/s] 17%|        | 52019/303576 [32:54<29:02:02,  2.41it/s] 17%|        | 52028/303576 [32:54<19:36:47,  3.56it/s] 17%|        | 52037/303576 [32:54<13:33:25,  5.15it/s] 17%|        | 52046/303576 [32:54<9:32:38,  7.32it/s]  17%|        | 52055/303576 [32:54<6:51:03, 10.20it/s] 17%|        | 52064/303576 [32:54<4:59:51, 13.98it/s] 17%|        | 52073/303576 [32:55<3:44:04, 18.71it/s] 17%|        | 52082/303576 [32:55<2:51:28, 24.45it/s] 17%|        | 52091/303576 [32:55<2:14:55, 31.07it/s] 17%|        | 52100/303576 [32:55<1:50:20, 37.98it/s]                                                         17%|        | 52100/303576 [32:55<1:50:20, 37.98it/s] 17%|        | 52109/303576 [32:55<1:32:12, 45.45it/s] 17%|        | 52118/303576 [32:55<1:19:42, 52.58it/s] 17%|        | 52127/303576 [32:55<1:11:02, 58.99it/s] 17%|        | 52136/303576 [32:55<1:05:04, 64.40it/s] 17%|        | 52145/303576 [32:55<1:01:11, 68.49it/s] 17%|        | 52154/303576 [32:56<59:12, 70.77it/s]   17%|        | 52163/303576 [32:56<56:57, 73.56it/s] 17%|        | 52172/303576 [32:56<56:43, 73.87it/s] 17%|        | 52180/303576 [32:56<55:43, 75.20it/s] 17%|        | 52188/303576 [32:56<55:05, 76.05it/s] 17%|        | 52196/303576 [32:56<54:43, 76.56it/s]                                                       17%|        | 52200/303576 [32:56<54:43, 76.56it/s] 17%|        | 52204/303576 [32:56<54:30, 76.85it/s] 17%|        | 52212/303576 [32:56<54:09, 77.35it/s] 17%|        | 52220/303576 [32:56<54:04, 77.47it/s] 17%|        | 52228/303576 [32:56<53:57, 77.64it/s] 17%|        | 52236/303576 [32:57<54:01, 77.55it/s] 17%|        | 52244/303576 [32:57<54:02, 77.52it/s] 17%|        | 52252/303576 [32:57<53:50, 77.80it/s] 17%|        | 52260/303576 [32:57<53:43, 77.97it/s] 17%|        | 52268/303576 [32:57<53:43, 77.96it/s] 17%|        | 52276/303576 [32:57<53:38, 78.08it/s] 17%|        | 52284/303576 [32:57<53:37, 78.11it/s] 17%|        | 52292/303576 [32:57<53:34, 78.18it/s] 17%|        | 52300/303576 [32:57<53:36, 78.13it/s]                                                       17%|        | 52300/303576 [32:57<53:36, 78.13it/s] 17%|        | 52308/303576 [32:57<53:37, 78.09it/s] 17%|        | 52316/303576 [32:58<53:32, 78.22it/s] 17%|        | 52324/303576 [32:58<53:27, 78.34it/s] 17%|        | 52332/303576 [32:58<53:28, 78.31it/s] 17%|        | 52340/303576 [32:58<53:28, 78.31it/s] 17%|        | 52348/303576 [32:58<53:27, 78.33it/s] 17%|        | 52356/303576 [32:58<53:31, 78.23it/s] 17%|        | 52364/303576 [32:58<53:30, 78.24it/s] 17%|        | 52372/303576 [32:58<53:26, 78.34it/s] 17%|        | 52380/303576 [32:58<53:27, 78.31it/s] 17%|        | 52388/303576 [32:59<53:27, 78.31it/s] 17%|        | 52396/303576 [32:59<53:58, 77.55it/s]                                                       17%|        | 52400/303576 [32:59<53:58, 77.55it/s] 17%|        | 52404/303576 [32:59<53:57, 77.57it/s] 17%|        | 52412/303576 [32:59<54:08, 77.32it/s] 17%|        | 52420/303576 [32:59<54:06, 77.37it/s] 17%|        | 52428/303576 [32:59<54:00, 77.49it/s] 17%|        | 52438/303576 [32:59<50:07, 83.49it/s] 17%|        | 52448/303576 [32:59<47:26, 88.21it/s] 17%|        | 52458/303576 [32:59<45:46, 91.42it/s] 17%|        | 52468/303576 [32:59<44:49, 93.36it/s] 17%|        | 52478/303576 [33:00<44:10, 94.72it/s] 17%|        | 52488/303576 [33:00<46:16, 90.42it/s] 17%|        | 52498/303576 [33:00<47:51, 87.44it/s]                                                       17%|        | 52500/303576 [33:00<47:51, 87.44it/s] 17%|        | 52507/303576 [33:00<48:39, 85.99it/s] 17%|        | 52516/303576 [33:00<49:38, 84.29it/s] 17%|        | 52526/303576 [33:00<47:42, 87.71it/s] 17%|        | 52535/303576 [33:00<49:16, 84.91it/s] 17%|        | 52544/303576 [33:00<50:27, 82.92it/s] 17%|        | 52553/303576 [33:00<50:36, 82.66it/s] 17%|        | 52562/303576 [33:01<51:16, 81.58it/s] 17%|        | 52571/303576 [33:01<51:19, 81.50it/s] 17%|        | 52580/303576 [33:01<51:16, 81.58it/s] 17%|        | 52589/303576 [33:01<50:44, 82.43it/s] 17%|        | 52598/303576 [33:01<50:43, 82.46it/s]                                                       17%|        | 52600/303576 [33:01<50:43, 82.46it/s] 17%|        | 52607/303576 [33:01<51:41, 80.91it/s] 17%|        | 52616/303576 [33:01<51:51, 80.65it/s] 17%|        | 52625/303576 [33:01<52:09, 80.18it/s] 17%|        | 52634/303576 [33:01<51:40, 80.94it/s] 17%|        | 52643/303576 [33:02<50:47, 82.34it/s] 17%|        | 52652/303576 [33:02<50:53, 82.18it/s] 17%|        | 52661/303576 [33:02<50:38, 82.58it/s] 17%|        | 52670/303576 [33:02<50:40, 82.51it/s] 17%|        | 52679/303576 [33:02<50:21, 83.05it/s] 17%|        | 52688/303576 [33:02<50:42, 82.47it/s] 17%|        | 52697/303576 [33:02<50:29, 82.80it/s]                                                       17%|        | 52700/303576 [33:02<50:29, 82.80it/s] 17%|        | 52706/303576 [33:02<50:43, 82.42it/s] 17%|        | 52715/303576 [33:02<50:24, 82.95it/s] 17%|        | 52724/303576 [33:03<50:31, 82.74it/s] 17%|        | 52735/303576 [33:03<47:22, 88.25it/s] 17%|        | 52744/303576 [33:03<47:37, 87.78it/s] 17%|        | 52753/303576 [33:03<47:41, 87.66it/s] 17%|        | 52762/303576 [33:03<48:19, 86.51it/s] 17%|        | 52771/303576 [33:03<48:58, 85.34it/s] 17%|        | 52780/303576 [33:03<49:58, 83.63it/s] 17%|        | 52789/303576 [33:03<50:12, 83.24it/s] 17%|        | 52798/303576 [33:03<50:34, 82.64it/s]                                                       17%|        | 52800/303576 [33:03<50:34, 82.64it/s] 17%|        | 52807/303576 [33:04<50:34, 82.63it/s] 17%|        | 52816/303576 [33:04<50:14, 83.18it/s] 17%|        | 52825/303576 [33:04<50:09, 83.32it/s] 17%|        | 52834/303576 [33:04<49:41, 84.11it/s] 17%|        | 52843/303576 [33:04<49:49, 83.88it/s] 17%|        | 52852/303576 [33:04<49:25, 84.55it/s] 17%|        | 52861/303576 [33:04<49:36, 84.24it/s] 17%|        | 52870/303576 [33:04<49:24, 84.56it/s] 17%|        | 52879/303576 [33:04<49:36, 84.23it/s] 17%|        | 52888/303576 [33:04<50:11, 83.24it/s] 17%|        | 52897/303576 [33:05<50:20, 83.00it/s]                                                       17%|        | 52900/303576 [33:05<50:20, 83.00it/s] 17%|        | 52906/303576 [33:05<51:06, 81.74it/s] 17%|        | 52915/303576 [33:05<51:06, 81.73it/s] 17%|        | 52924/303576 [33:05<51:31, 81.07it/s] 17%|        | 52933/303576 [33:05<51:28, 81.15it/s] 17%|        | 52942/303576 [33:05<51:49, 80.61it/s] 17%|        | 52951/303576 [33:05<51:36, 80.93it/s] 17%|        | 52960/303576 [33:05<51:34, 80.98it/s] 17%|        | 52969/303576 [33:05<51:14, 81.50it/s] 17%|        | 52978/303576 [33:06<51:01, 81.86it/s] 17%|        | 52987/303576 [33:06<51:42, 80.78it/s] 17%|        | 52996/303576 [33:06<51:32, 81.04it/s]                                                       17%|        | 53000/303576 [33:06<51:31, 81.04it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7371013164520264, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 20.9611, 'eval_samples_per_second': 10.782, 'eval_steps_per_second': 0.095, 'epoch': 0.51, 'timestamp': 1762966507.5366127, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7555, 'grad_norm': 0.2302672564983368, 'learning_rate': 5.470088807193028e-06, 'epoch': 0.51, 'timestamp': 1762966508.800373, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7719, 'grad_norm': 0.45054498314857483, 'learning_rate': 5.415657806144532e-06, 'epoch': 0.52, 'timestamp': 1762966510.0548449, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7686, 'grad_norm': 0.22463995218276978, 'learning_rate': 5.3617684295521645e-06, 'epoch': 0.52, 'timestamp': 1762966511.3362057, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7594, 'grad_norm': 0.23671795427799225, 'learning_rate': 5.308415287894397e-06, 'epoch': 0.52, 'timestamp': 1762966512.6168416, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7701, 'grad_norm': 0.23617048561573029, 'learning_rate': 5.255593045279017e-06, 'epoch': 0.52, 'timestamp': 1762966513.7565963, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7747, 'grad_norm': 0.22144822776317596, 'learning_rate': 5.20329641890946e-06, 'epoch': 0.52, 'timestamp': 1762966514.9707935, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7729, 'grad_norm': 0.2458021640777588, 'learning_rate': 5.151520178556495e-06, 'epoch': 0.52, 'timestamp': 1762966516.1917589, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.2539549767971039, 'learning_rate': 5.100259146035119e-06, 'epoch': 0.52, 'timestamp': 1762966517.3695824, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.768, 'grad_norm': 0.22976773977279663, 'learning_rate': 5.049508194686689e-06, 'epoch': 0.52, 'timestamp': 1762966518.5664065, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.758, 'grad_norm': 0.354160338640213, 'learning_rate': 4.9992622488662225e-06, 'epoch': 0.52, 'timestamp': 1762966519.8002748, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:55:23.583609: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:55:23.594311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966523.607408 1757264 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966523.611464 1757264 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966523.621961 1757264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966523.621975 1757264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966523.621977 1757264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966523.621979 1757264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:55:23.625381: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:55:25 - TensorFlow version 2.19.1 available.
 17%|        | 53000/303576 [33:20<51:31, 81.04it/s]2025-11-12 16:55:34.018767: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:55:34.029432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966534.042382 1757422 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966534.046229 1757422 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966534.056610 1757422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966534.056630 1757422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966534.056632 1757422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966534.056633 1757422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:55:34.059835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:55:35 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 17%|        | 53000/303576 [33:28<51:31, 81.04it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 17%|        | 53001/303576 [33:28<61:00:44,  1.14it/s] 17%|        | 53006/303576 [33:28<48:14:34,  1.44it/s] 17%|        | 53013/303576 [33:29<34:15:16,  2.03it/s] 17%|        | 53019/303576 [33:29<25:30:02,  2.73it/s] 17%|        | 53025/303576 [33:29<18:54:21,  3.68it/s] 17%|        | 53030/303576 [33:29<14:38:31,  4.75it/s] 17%|        | 53035/303576 [33:29<11:17:28,  6.16it/s] 17%|        | 53040/303576 [33:29<8:41:39,  8.00it/s]  17%|        | 53045/303576 [33:29<6:46:40, 10.27it/s] 17%|        | 53050/303576 [33:30<5:20:34, 13.03it/s] 17%|        | 53055/303576 [33:30<4:19:52, 16.07it/s] 17%|        | 53059/303576 [33:30<3:42:01, 18.81it/s] 17%|        | 53063/303576 [33:30<3:11:46, 21.77it/s] 17%|        | 53067/303576 [33:30<2:49:03, 24.70it/s] 17%|        | 53071/303576 [33:30<2:31:58, 27.47it/s] 17%|        | 53075/303576 [33:30<2:19:09, 30.00it/s] 17%|        | 53079/303576 [33:30<2:09:50, 32.15it/s] 17%|        | 53083/303576 [33:30<2:03:48, 33.72it/s] 17%|        | 53088/303576 [33:31<1:54:29, 36.46it/s] 17%|        | 53093/303576 [33:31<1:47:51, 38.70it/s] 17%|        | 53099/303576 [33:31<1:38:17, 42.47it/s]                                                         17%|        | 53100/303576 [33:31<1:38:17, 42.47it/s] 17%|        | 53106/303576 [33:31<1:24:15, 49.55it/s] 17%|        | 53115/303576 [33:31<1:09:25, 60.12it/s] 17%|        | 53124/303576 [33:31<1:01:34, 67.80it/s] 18%|        | 53133/303576 [33:31<57:22, 72.74it/s]   18%|        | 53142/303576 [33:31<54:31, 76.55it/s] 18%|        | 53151/303576 [33:31<52:31, 79.45it/s] 18%|        | 53160/303576 [33:32<51:10, 81.54it/s] 18%|        | 53169/303576 [33:32<50:13, 83.10it/s] 18%|        | 53178/303576 [33:32<50:43, 82.28it/s] 18%|        | 53187/303576 [33:32<50:33, 82.54it/s] 18%|        | 53196/303576 [33:32<49:47, 83.81it/s]                                                       18%|        | 53200/303576 [33:32<49:47, 83.81it/s] 18%|        | 53206/303576 [33:32<47:44, 87.41it/s] 18%|        | 53215/303576 [33:32<49:30, 84.27it/s] 18%|        | 53224/303576 [33:32<50:44, 82.23it/s] 18%|        | 53233/303576 [33:32<51:42, 80.69it/s] 18%|        | 53242/303576 [33:33<52:05, 80.09it/s] 18%|        | 53251/303576 [33:33<52:35, 79.33it/s] 18%|        | 53259/303576 [33:33<52:37, 79.28it/s] 18%|        | 53267/303576 [33:33<53:45, 77.60it/s] 18%|        | 53275/303576 [33:33<54:50, 76.07it/s] 18%|        | 53283/303576 [33:33<56:10, 74.26it/s] 18%|        | 53291/303576 [33:33<57:04, 73.08it/s] 18%|        | 53299/303576 [33:33<57:39, 72.34it/s]                                                       18%|        | 53300/303576 [33:33<57:39, 72.34it/s] 18%|        | 53307/303576 [33:33<58:16, 71.58it/s] 18%|        | 53315/303576 [33:34<59:02, 70.65it/s] 18%|        | 53323/303576 [33:34<59:21, 70.26it/s] 18%|        | 53331/303576 [33:34<1:00:12, 69.28it/s] 18%|        | 53338/303576 [33:34<1:00:45, 68.65it/s] 18%|        | 53346/303576 [33:34<1:00:24, 69.05it/s] 18%|        | 53354/303576 [33:34<59:58, 69.53it/s]   18%|        | 53362/303576 [33:34<1:00:07, 69.37it/s] 18%|        | 53369/303576 [33:34<1:00:07, 69.36it/s] 18%|        | 53377/303576 [33:34<59:30, 70.07it/s]   18%|        | 53385/303576 [33:35<59:16, 70.36it/s] 18%|        | 53393/303576 [33:35<59:08, 70.50it/s]                                                       18%|        | 53400/303576 [33:35<59:08, 70.50it/s] 18%|        | 53401/303576 [33:35<57:55, 71.98it/s] 18%|        | 53411/303576 [33:35<52:26, 79.51it/s] 18%|        | 53421/303576 [33:35<49:09, 84.80it/s] 18%|        | 53431/303576 [33:35<46:52, 88.93it/s] 18%|        | 53441/303576 [33:35<45:23, 91.86it/s] 18%|        | 53452/303576 [33:35<43:51, 95.04it/s] 18%|        | 53462/303576 [33:35<43:28, 95.89it/s] 18%|        | 53473/303576 [33:35<42:54, 97.13it/s] 18%|        | 53483/303576 [33:36<42:46, 97.44it/s] 18%|        | 53493/303576 [33:36<42:32, 97.99it/s]                                                       18%|        | 53500/303576 [33:36<42:32, 97.99it/s] 18%|        | 53503/303576 [33:36<42:26, 98.19it/s] 18%|        | 53513/303576 [33:36<42:15, 98.61it/s] 18%|        | 53523/303576 [33:36<42:14, 98.66it/s] 18%|        | 53533/303576 [33:36<42:04, 99.06it/s] 18%|        | 53543/303576 [33:36<42:00, 99.22it/s] 18%|        | 53553/303576 [33:36<42:14, 98.63it/s] 18%|        | 53563/303576 [33:36<45:37, 91.34it/s] 18%|        | 53573/303576 [33:37<48:13, 86.40it/s] 18%|        | 53582/303576 [33:37<49:59, 83.34it/s] 18%|        | 53591/303576 [33:37<51:27, 80.97it/s] 18%|        | 53600/303576 [33:37<52:02, 80.06it/s]                                                       18%|        | 53600/303576 [33:37<52:02, 80.06it/s] 18%|        | 53609/303576 [33:37<53:13, 78.28it/s] 18%|        | 53617/303576 [33:37<53:25, 77.98it/s] 18%|        | 53625/303576 [33:37<53:30, 77.85it/s] 18%|        | 53634/303576 [33:37<52:28, 79.38it/s] 18%|        | 53643/303576 [33:37<51:51, 80.32it/s] 18%|        | 53653/303576 [33:38<50:02, 83.25it/s] 18%|        | 53663/303576 [33:38<48:50, 85.28it/s] 18%|        | 53672/303576 [33:38<48:46, 85.38it/s] 18%|        | 53681/303576 [33:38<50:04, 83.17it/s] 18%|        | 53690/303576 [33:38<49:51, 83.54it/s] 18%|        | 53700/303576 [33:38<48:36, 85.68it/s]                                                       18%|        | 53700/303576 [33:38<48:36, 85.68it/s] 18%|        | 53709/303576 [33:38<48:49, 85.29it/s] 18%|        | 53718/303576 [33:38<48:59, 85.01it/s] 18%|        | 53727/303576 [33:38<49:14, 84.56it/s] 18%|        | 53736/303576 [33:39<49:16, 84.50it/s] 18%|        | 53745/303576 [33:39<49:34, 84.00it/s] 18%|        | 53754/303576 [33:39<49:41, 83.80it/s] 18%|        | 53763/303576 [33:39<49:35, 83.95it/s] 18%|        | 53772/303576 [33:39<49:41, 83.77it/s] 18%|        | 53781/303576 [33:39<49:44, 83.69it/s] 18%|        | 53790/303576 [33:39<49:44, 83.70it/s] 18%|        | 53799/303576 [33:39<49:40, 83.79it/s]                                                       18%|        | 53800/303576 [33:39<49:40, 83.79it/s] 18%|        | 53808/303576 [33:39<49:37, 83.88it/s] 18%|        | 53817/303576 [33:40<49:34, 83.98it/s] 18%|        | 53826/303576 [33:40<49:28, 84.12it/s] 18%|        | 53835/303576 [33:40<49:56, 83.36it/s] 18%|        | 53844/303576 [33:40<49:34, 83.95it/s] 18%|        | 53853/303576 [33:40<49:26, 84.18it/s] 18%|        | 53862/303576 [33:40<49:37, 83.88it/s] 18%|        | 53871/303576 [33:40<49:28, 84.11it/s] 18%|        | 53880/303576 [33:40<49:25, 84.20it/s] 18%|        | 53889/303576 [33:40<49:50, 83.50it/s] 18%|        | 53898/303576 [33:40<49:47, 83.57it/s]                                                       18%|        | 53900/303576 [33:40<49:47, 83.57it/s] 18%|        | 53907/303576 [33:41<49:43, 83.69it/s] 18%|        | 53916/303576 [33:41<49:45, 83.64it/s] 18%|        | 53925/303576 [33:41<49:46, 83.58it/s] 18%|        | 53934/303576 [33:41<49:36, 83.88it/s] 18%|        | 53943/303576 [33:41<49:46, 83.59it/s] 18%|        | 53952/303576 [33:41<49:44, 83.63it/s] 18%|        | 53961/303576 [33:41<49:49, 83.49it/s] 18%|        | 53970/303576 [33:41<49:47, 83.56it/s] 18%|        | 53979/303576 [33:41<49:59, 83.22it/s] 18%|        | 53988/303576 [33:42<49:50, 83.46it/s] 18%|        | 53997/303576 [33:42<49:54, 83.34it/s]                                                       18%|        | 54000/303576 [33:42<49:54, 83.34it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7370879650115967, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.4622, 'eval_samples_per_second': 10.061, 'eval_steps_per_second': 0.089, 'epoch': 0.52, 'timestamp': 1762966542.2629519, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7752, 'grad_norm': 0.2817620038986206, 'learning_rate': 4.9495162834347436e-06, 'epoch': 0.52, 'timestamp': 1762966544.7610023, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7739, 'grad_norm': 0.25312310457229614, 'learning_rate': 4.900755398796625e-06, 'epoch': 0.53, 'timestamp': 1762966545.9403431, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7768, 'grad_norm': 0.36010104417800903, 'learning_rate': 4.851989641666769e-06, 'epoch': 0.53, 'timestamp': 1762966547.2613256, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7856, 'grad_norm': 0.22955366969108582, 'learning_rate': 4.803709136069569e-06, 'epoch': 0.53, 'timestamp': 1762966548.6923108, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7742, 'grad_norm': 0.26952099800109863, 'learning_rate': 4.755909053431376e-06, 'epoch': 0.53, 'timestamp': 1762966549.7008681, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7677, 'grad_norm': 0.28835776448249817, 'learning_rate': 4.708584613226041e-06, 'epoch': 0.53, 'timestamp': 1762966550.848432, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7678, 'grad_norm': 0.2347172647714615, 'learning_rate': 4.661731082496815e-06, 'epoch': 0.53, 'timestamp': 1762966552.0530937, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7662, 'grad_norm': 0.29699769616127014, 'learning_rate': 4.615343775382984e-06, 'epoch': 0.53, 'timestamp': 1762966553.2460654, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7837, 'grad_norm': 0.27294978499412537, 'learning_rate': 4.5694180526512604e-06, 'epoch': 0.53, 'timestamp': 1762966554.4392438, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7573, 'grad_norm': 0.2895621955394745, 'learning_rate': 4.523949321231797e-06, 'epoch': 0.53, 'timestamp': 1762966555.6370432, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:55:59.005171: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:55:59.015921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966559.029059 1757859 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966559.033120 1757859 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966559.043726 1757859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966559.043742 1757859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966559.043744 1757859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966559.043746 1757859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:55:59.047149: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:56:00 - TensorFlow version 2.19.1 available.
2025-11-12 16:56:08.571957: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:56:08.582640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966568.595589 1758017 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966568.599458 1758017 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966568.609886 1758017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966568.609903 1758017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966568.609905 1758017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966568.609907 1758017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:56:08.613132: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:56:10 - TensorFlow version 2.19.1 available.
 18%|        | 54000/303576 [34:00<49:54, 83.34it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 18%|        | 54000/303576 [34:03<49:54, 83.34it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-54000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-54000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-54000/model.safetensors
 18%|        | 54001/303576 [34:03<59:22:26,  1.17it/s] 18%|        | 54011/303576 [34:03<38:02:21,  1.82it/s] 18%|        | 54021/303576 [34:03<25:17:18,  2.74it/s] 18%|        | 54030/303576 [34:03<17:51:04,  3.88it/s] 18%|        | 54040/303576 [34:03<12:16:25,  5.65it/s] 18%|        | 54049/303576 [34:03<8:53:05,  7.80it/s]  18%|        | 54058/303576 [34:03<6:30:06, 10.66it/s] 18%|        | 54067/303576 [34:04<4:49:04, 14.39it/s] 18%|        | 54076/303576 [34:04<3:37:38, 19.11it/s] 18%|        | 54085/303576 [34:04<2:46:26, 24.98it/s] 18%|        | 54096/303576 [34:04<2:03:21, 33.71it/s]                                                         18%|        | 54100/303576 [34:04<2:03:20, 33.71it/s] 18%|        | 54107/303576 [34:04<1:36:01, 43.30it/s] 18%|        | 54118/303576 [34:04<1:18:01, 53.29it/s] 18%|        | 54129/303576 [34:04<1:06:25, 62.58it/s] 18%|        | 54140/303576 [34:04<58:25, 71.16it/s]   18%|        | 54150/303576 [34:04<57:08, 72.75it/s] 18%|        | 54160/303576 [34:05<54:56, 75.65it/s] 18%|        | 54170/303576 [34:05<53:10, 78.17it/s] 18%|        | 54179/303576 [34:05<52:03, 79.85it/s] 18%|        | 54188/303576 [34:05<51:17, 81.05it/s] 18%|        | 54197/303576 [34:05<49:56, 83.21it/s]                                                       18%|        | 54200/303576 [34:05<49:56, 83.21it/s] 18%|        | 54206/303576 [34:05<49:12, 84.47it/s] 18%|        | 54215/303576 [34:05<48:29, 85.72it/s] 18%|        | 54224/303576 [34:05<48:04, 86.44it/s] 18%|        | 54233/303576 [34:05<48:17, 86.06it/s] 18%|        | 54242/303576 [34:06<49:09, 84.54it/s] 18%|        | 54251/303576 [34:06<49:10, 84.51it/s] 18%|        | 54260/303576 [34:06<48:56, 84.90it/s] 18%|        | 54269/303576 [34:06<48:20, 85.95it/s] 18%|        | 54278/303576 [34:06<47:57, 86.62it/s] 18%|        | 54288/303576 [34:06<46:41, 88.98it/s] 18%|        | 54299/303576 [34:06<44:28, 93.42it/s]                                                       18%|        | 54300/303576 [34:06<44:28, 93.42it/s] 18%|        | 54311/303576 [34:06<42:06, 98.64it/s] 18%|        | 54322/303576 [34:06<41:23, 100.36it/s] 18%|        | 54333/303576 [34:06<41:03, 101.17it/s] 18%|        | 54344/303576 [34:07<40:26, 102.73it/s] 18%|        | 54355/303576 [34:07<41:04, 101.11it/s] 18%|        | 54366/303576 [34:07<43:31, 95.41it/s]  18%|        | 54376/303576 [34:07<45:43, 90.82it/s] 18%|        | 54386/303576 [34:07<47:10, 88.05it/s] 18%|        | 54395/303576 [34:07<48:28, 85.66it/s]                                                       18%|        | 54400/303576 [34:07<48:28, 85.66it/s] 18%|        | 54404/303576 [34:07<49:16, 84.29it/s] 18%|        | 54413/303576 [34:07<49:55, 83.19it/s] 18%|        | 54422/303576 [34:08<50:04, 82.91it/s] 18%|        | 54431/303576 [34:08<49:44, 83.47it/s] 18%|        | 54440/303576 [34:08<49:20, 84.15it/s] 18%|        | 54449/303576 [34:08<49:52, 83.24it/s] 18%|        | 54458/303576 [34:08<50:31, 82.17it/s] 18%|        | 54467/303576 [34:08<51:11, 81.12it/s] 18%|        | 54476/303576 [34:08<51:14, 81.02it/s] 18%|        | 54485/303576 [34:08<51:31, 80.56it/s] 18%|        | 54494/303576 [34:08<51:42, 80.29it/s]                                                       18%|        | 54500/303576 [34:08<51:42, 80.29it/s] 18%|        | 54503/303576 [34:09<50:12, 82.67it/s] 18%|        | 54512/303576 [34:09<51:04, 81.27it/s] 18%|        | 54521/303576 [34:09<50:21, 82.41it/s] 18%|        | 54530/303576 [34:09<51:06, 81.21it/s] 18%|        | 54539/303576 [34:09<51:53, 80.00it/s] 18%|        | 54548/303576 [34:09<56:59, 72.82it/s] 18%|        | 54556/303576 [34:09<59:59, 69.19it/s] 18%|        | 54564/303576 [34:09<1:02:05, 66.83it/s] 18%|        | 54571/303576 [34:09<1:03:39, 65.20it/s] 18%|        | 54578/303576 [34:10<1:04:48, 64.03it/s] 18%|        | 54585/303576 [34:10<1:05:49, 63.04it/s] 18%|        | 54592/303576 [34:10<1:06:15, 62.63it/s] 18%|        | 54599/303576 [34:10<1:08:52, 60.25it/s]                                                         18%|        | 54600/303576 [34:10<1:08:52, 60.25it/s] 18%|        | 54606/303576 [34:10<1:14:55, 55.38it/s] 18%|        | 54612/303576 [34:10<1:18:07, 53.12it/s] 18%|        | 54618/303576 [34:10<1:20:24, 51.61it/s] 18%|        | 54624/303576 [34:10<1:22:08, 50.51it/s] 18%|        | 54630/303576 [34:11<1:23:24, 49.75it/s] 18%|        | 54635/303576 [34:11<1:23:34, 49.64it/s] 18%|        | 54640/303576 [34:11<1:25:12, 48.69it/s] 18%|        | 54645/303576 [34:11<1:24:50, 48.90it/s] 18%|        | 54651/303576 [34:11<1:23:26, 49.73it/s] 18%|        | 54657/303576 [34:11<1:20:56, 51.26it/s] 18%|        | 54663/303576 [34:11<1:19:19, 52.30it/s] 18%|        | 54669/303576 [34:11<1:18:31, 52.83it/s] 18%|        | 54675/303576 [34:11<1:17:46, 53.34it/s] 18%|        | 54681/303576 [34:12<1:19:03, 52.47it/s] 18%|        | 54687/303576 [34:12<1:17:33, 53.48it/s] 18%|        | 54695/303576 [34:12<1:10:08, 59.14it/s]                                                         18%|        | 54700/303576 [34:12<1:10:07, 59.14it/s] 18%|        | 54703/303576 [34:12<1:05:59, 62.85it/s] 18%|        | 54711/303576 [34:12<1:03:24, 65.42it/s] 18%|        | 54718/303576 [34:12<1:02:13, 66.65it/s] 18%|        | 54726/303576 [34:12<1:01:21, 67.59it/s] 18%|        | 54734/303576 [34:12<1:01:03, 67.93it/s] 18%|        | 54742/303576 [34:12<1:00:45, 68.27it/s] 18%|        | 54750/303576 [34:13<1:00:39, 68.37it/s] 18%|        | 54758/303576 [34:13<59:20, 69.89it/s]   18%|        | 54766/303576 [34:13<57:29, 72.12it/s] 18%|        | 54774/303576 [34:13<56:11, 73.79it/s] 18%|        | 54782/303576 [34:13<1:00:04, 69.01it/s] 18%|        | 54789/303576 [34:13<1:02:49, 66.01it/s] 18%|        | 54796/303576 [34:13<1:06:07, 62.70it/s]                                                         18%|        | 54800/303576 [34:13<1:06:07, 62.70it/s] 18%|        | 54803/303576 [34:13<1:09:02, 60.05it/s] 18%|        | 54810/303576 [34:14<1:11:31, 57.97it/s] 18%|        | 54816/303576 [34:14<1:13:01, 56.77it/s] 18%|        | 54822/303576 [34:14<1:14:00, 56.01it/s] 18%|        | 54828/303576 [34:14<1:14:19, 55.78it/s] 18%|        | 54834/303576 [34:14<1:14:01, 56.00it/s] 18%|        | 54840/303576 [34:14<1:13:23, 56.48it/s] 18%|        | 54846/303576 [34:14<1:12:44, 56.99it/s] 18%|        | 54852/303576 [34:14<1:11:40, 57.84it/s] 18%|        | 54858/303576 [34:14<1:13:49, 56.15it/s] 18%|        | 54864/303576 [34:15<1:17:45, 53.31it/s] 18%|        | 54870/303576 [34:15<1:20:36, 51.42it/s] 18%|        | 54876/303576 [34:15<1:22:37, 50.16it/s] 18%|        | 54882/303576 [34:15<1:24:13, 49.21it/s] 18%|        | 54889/303576 [34:15<1:18:06, 53.07it/s] 18%|        | 54896/303576 [34:15<1:14:00, 56.00it/s]                                                         18%|        | 54900/303576 [34:15<1:14:00, 56.00it/s] 18%|        | 54903/303576 [34:15<1:11:20, 58.10it/s] 18%|        | 54910/303576 [34:15<1:09:22, 59.74it/s] 18%|        | 54917/303576 [34:15<1:07:51, 61.07it/s] 18%|        | 54924/303576 [34:16<1:06:57, 61.89it/s] 18%|        | 54931/303576 [34:16<1:06:14, 62.55it/s] 18%|        | 54938/303576 [34:16<1:05:55, 62.86it/s] 18%|        | 54945/303576 [34:16<1:05:32, 63.22it/s] 18%|        | 54952/303576 [34:16<1:05:09, 63.59it/s] 18%|        | 54959/303576 [34:16<1:04:59, 63.76it/s] 18%|        | 54966/303576 [34:16<1:04:41, 64.04it/s] 18%|        | 54973/303576 [34:16<1:04:38, 64.10it/s] 18%|        | 54980/303576 [34:16<1:03:16, 65.49it/s] 18%|        | 54989/303576 [34:17<57:38, 71.88it/s]   18%|        | 54998/303576 [34:17<53:52, 76.89it/s]                                                       18%|        | 55000/303576 [34:17<53:52, 76.89it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7367677688598633, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.0669, 'eval_samples_per_second': 10.728, 'eval_steps_per_second': 0.095, 'epoch': 0.53, 'timestamp': 1762966576.7043421, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7712, 'grad_norm': 0.2690976560115814, 'learning_rate': 4.47893303375882e-06, 'epoch': 0.53, 'timestamp': 1762966577.8834896, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7562, 'grad_norm': 0.22847765684127808, 'learning_rate': 4.4343646881158615e-06, 'epoch': 0.54, 'timestamp': 1762966578.9874065, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7729, 'grad_norm': 0.2587990462779999, 'learning_rate': 4.3902398269854815e-06, 'epoch': 0.54, 'timestamp': 1762966580.1121845, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7749, 'grad_norm': 0.2766648828983307, 'learning_rate': 4.3465540374034935e-06, 'epoch': 0.54, 'timestamp': 1762966581.1898315, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.759, 'grad_norm': 0.23061881959438324, 'learning_rate': 4.303302950317645e-06, 'epoch': 0.54, 'timestamp': 1762966582.410932, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7614, 'grad_norm': 0.21855418384075165, 'learning_rate': 4.260482240150616e-06, 'epoch': 0.54, 'timestamp': 1762966583.921876, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7901, 'grad_norm': 0.28512853384017944, 'learning_rate': 4.218087624367453e-06, 'epoch': 0.54, 'timestamp': 1762966585.823172, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7695, 'grad_norm': 0.2849145233631134, 'learning_rate': 4.1761148630472585e-06, 'epoch': 0.54, 'timestamp': 1762966587.305363, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7627, 'grad_norm': 0.2916025221347809, 'learning_rate': 4.13455975845915e-06, 'epoch': 0.54, 'timestamp': 1762966589.1416638, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.758, 'grad_norm': 0.22675830125808716, 'learning_rate': 4.093418154642441e-06, 'epoch': 0.54, 'timestamp': 1762966590.6086123, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:56:34.409865: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:56:34.420639: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966594.433737 1758325 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966594.437653 1758325 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966594.448194 1758325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966594.448216 1758325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966594.448218 1758325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966594.448219 1758325 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:56:34.451519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:56:36 - TensorFlow version 2.19.1 available.
 18%|        | 55000/303576 [34:30<53:52, 76.89it/s]2025-11-12 16:56:44.958571: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:56:44.969427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966604.982546 1758615 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966604.986366 1758615 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966604.997145 1758615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966604.997161 1758615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966604.997162 1758615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966604.997164 1758615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:56:45.000337: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:56:46 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 18%|        | 55000/303576 [34:39<53:52, 76.89it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [A 18%|        | 55001/303576 [34:39<72:17:27,  1.05s/it] 18%|        | 55005/303576 [34:39<57:35:15,  1.20it/s] 18%|        | 55012/303576 [34:39<38:27:43,  1.80it/s] 18%|        | 55018/303576 [34:40<27:36:49,  2.50it/s] 18%|        | 55024/303576 [34:40<19:53:51,  3.47it/s] 18%|        | 55030/303576 [34:40<14:21:36,  4.81it/s] 18%|        | 55036/303576 [34:40<10:27:53,  6.60it/s] 18%|        | 55042/303576 [34:40<7:43:57,  8.93it/s]  18%|        | 55048/303576 [34:40<5:49:14, 11.86it/s] 18%|        | 55054/303576 [34:40<4:28:14, 15.44it/s] 18%|        | 55060/303576 [34:40<3:31:29, 19.58it/s] 18%|        | 55066/303576 [34:40<2:51:37, 24.13it/s] 18%|        | 55072/303576 [34:41<2:23:50, 28.79it/s] 18%|        | 55078/303576 [34:41<2:03:36, 33.51it/s] 18%|        | 55084/303576 [34:41<1:48:49, 38.06it/s] 18%|        | 55090/303576 [34:41<1:38:11, 42.17it/s] 18%|        | 55096/303576 [34:41<1:30:50, 45.58it/s]                                                         18%|        | 55100/303576 [34:41<1:30:50, 45.58it/s] 18%|        | 55102/303576 [34:41<1:25:40, 48.34it/s] 18%|        | 55108/303576 [34:41<1:21:23, 50.88it/s] 18%|        | 55114/303576 [34:41<1:18:39, 52.65it/s] 18%|        | 55120/303576 [34:41<1:17:11, 53.64it/s] 18%|        | 55126/303576 [34:42<1:16:06, 54.41it/s] 18%|        | 55132/303576 [34:42<1:15:18, 54.99it/s] 18%|        | 55138/303576 [34:42<1:15:07, 55.12it/s] 18%|        | 55144/303576 [34:42<1:14:34, 55.52it/s] 18%|        | 55150/303576 [34:42<1:14:18, 55.72it/s] 18%|        | 55156/303576 [34:42<1:14:03, 55.91it/s] 18%|        | 55162/303576 [34:42<1:13:50, 56.07it/s] 18%|        | 55168/303576 [34:42<1:13:40, 56.19it/s] 18%|        | 55174/303576 [34:42<1:13:34, 56.27it/s] 18%|        | 55180/303576 [34:43<1:13:33, 56.28it/s] 18%|        | 55186/303576 [34:43<1:13:32, 56.29it/s] 18%|        | 55192/303576 [34:43<1:13:39, 56.21it/s] 18%|        | 55198/303576 [34:43<1:13:37, 56.23it/s]                                                         18%|        | 55200/303576 [34:43<1:13:37, 56.23it/s] 18%|        | 55204/303576 [34:43<1:13:34, 56.26it/s] 18%|        | 55210/303576 [34:43<1:13:28, 56.34it/s] 18%|        | 55216/303576 [34:43<1:13:24, 56.39it/s] 18%|        | 55222/303576 [34:43<1:13:24, 56.39it/s] 18%|        | 55228/303576 [34:43<1:13:34, 56.26it/s] 18%|        | 55234/303576 [34:43<1:12:32, 57.06it/s] 18%|        | 55243/303576 [34:44<1:02:36, 66.10it/s] 18%|        | 55252/303576 [34:44<58:02, 71.30it/s]   18%|        | 55261/303576 [34:44<55:39, 74.35it/s] 18%|        | 55270/303576 [34:44<53:44, 77.01it/s] 18%|        | 55279/303576 [34:44<51:48, 79.89it/s] 18%|        | 55288/303576 [34:44<50:56, 81.22it/s] 18%|        | 55297/303576 [34:44<51:56, 79.67it/s]                                                       18%|        | 55300/303576 [34:44<51:56, 79.67it/s] 18%|        | 55305/303576 [34:44<53:46, 76.96it/s] 18%|        | 55313/303576 [34:44<55:00, 75.22it/s] 18%|        | 55321/303576 [34:45<55:56, 73.95it/s] 18%|        | 55329/303576 [34:45<56:17, 73.51it/s] 18%|        | 55337/303576 [34:45<55:26, 74.61it/s] 18%|        | 55345/303576 [34:45<55:16, 74.85it/s] 18%|        | 55354/303576 [34:45<54:25, 76.01it/s] 18%|        | 55362/303576 [34:45<56:20, 73.41it/s] 18%|        | 55371/303576 [34:45<54:23, 76.06it/s] 18%|        | 55380/303576 [34:45<53:31, 77.29it/s] 18%|        | 55389/303576 [34:45<52:24, 78.92it/s] 18%|        | 55398/303576 [34:46<51:56, 79.63it/s]                                                       18%|        | 55400/303576 [34:46<51:56, 79.63it/s] 18%|        | 55407/303576 [34:46<51:23, 80.47it/s] 18%|        | 55416/303576 [34:46<51:21, 80.52it/s] 18%|        | 55425/303576 [34:46<50:53, 81.27it/s] 18%|        | 55434/303576 [34:46<50:54, 81.23it/s] 18%|        | 55443/303576 [34:46<50:49, 81.36it/s] 18%|        | 55452/303576 [34:46<50:57, 81.15it/s] 18%|        | 55461/303576 [34:46<50:36, 81.71it/s] 18%|        | 55470/303576 [34:46<50:49, 81.35it/s] 18%|        | 55479/303576 [34:47<50:33, 81.79it/s] 18%|        | 55488/303576 [34:47<50:46, 81.43it/s] 18%|        | 55497/303576 [34:47<50:26, 81.96it/s]                                                       18%|        | 55500/303576 [34:47<50:26, 81.96it/s] 18%|        | 55506/303576 [34:47<50:38, 81.63it/s] 18%|        | 55515/303576 [34:47<51:13, 80.70it/s] 18%|        | 55524/303576 [34:47<53:22, 77.45it/s] 18%|        | 55532/303576 [34:47<54:58, 75.20it/s] 18%|        | 55540/303576 [34:47<56:29, 73.19it/s] 18%|        | 55548/303576 [34:47<57:23, 72.02it/s] 18%|        | 55556/303576 [34:48<57:59, 71.29it/s] 18%|        | 55564/303576 [34:48<58:36, 70.53it/s] 18%|        | 55572/303576 [34:48<58:18, 70.88it/s] 18%|        | 55580/303576 [34:48<56:53, 72.65it/s] 18%|        | 55589/303576 [34:48<55:09, 74.93it/s] 18%|        | 55597/303576 [34:48<54:52, 75.32it/s]                                                       18%|        | 55600/303576 [34:48<54:52, 75.32it/s] 18%|        | 55605/303576 [34:48<58:13, 70.97it/s] 18%|        | 55613/303576 [34:48<1:01:57, 66.70it/s] 18%|        | 55620/303576 [34:49<1:05:40, 62.92it/s] 18%|        | 55627/303576 [34:49<1:08:25, 60.39it/s] 18%|        | 55634/303576 [34:49<1:09:53, 59.13it/s] 18%|        | 55640/303576 [34:49<1:11:22, 57.89it/s] 18%|        | 55646/303576 [34:49<1:12:53, 56.69it/s] 18%|        | 55652/303576 [34:49<1:13:51, 55.95it/s] 18%|        | 55658/303576 [34:49<1:14:41, 55.32it/s] 18%|        | 55664/303576 [34:49<1:15:28, 54.74it/s] 18%|        | 55670/303576 [34:49<1:15:49, 54.49it/s] 18%|        | 55676/303576 [34:50<1:16:05, 54.30it/s] 18%|        | 55682/303576 [34:50<1:16:22, 54.10it/s] 18%|        | 55688/303576 [34:50<1:19:09, 52.19it/s] 18%|        | 55694/303576 [34:50<1:21:52, 50.46it/s] 18%|        | 55700/303576 [34:50<1:22:42, 49.95it/s]                                                         18%|        | 55700/303576 [34:50<1:22:42, 49.95it/s] 18%|        | 55708/303576 [34:50<1:13:58, 55.85it/s] 18%|        | 55716/303576 [34:50<1:07:08, 61.53it/s] 18%|        | 55725/303576 [34:50<1:00:03, 68.79it/s] 18%|        | 55734/303576 [34:50<55:41, 74.16it/s]   18%|        | 55743/303576 [34:51<52:48, 78.23it/s] 18%|        | 55752/303576 [34:51<50:54, 81.14it/s] 18%|        | 55761/303576 [34:51<49:36, 83.25it/s] 18%|        | 55770/303576 [34:51<48:39, 84.87it/s] 18%|        | 55779/303576 [34:51<48:09, 85.75it/s] 18%|        | 55788/303576 [34:51<47:41, 86.61it/s] 18%|        | 55797/303576 [34:51<47:23, 87.13it/s]                                                       18%|        | 55800/303576 [34:51<47:23, 87.13it/s] 18%|        | 55806/303576 [34:51<47:17, 87.32it/s] 18%|        | 55815/303576 [34:51<47:10, 87.53it/s] 18%|        | 55824/303576 [34:52<47:07, 87.62it/s] 18%|        | 55833/303576 [34:52<46:50, 88.16it/s] 18%|        | 55843/303576 [34:52<46:02, 89.66it/s] 18%|        | 55852/303576 [34:52<46:08, 89.48it/s] 18%|        | 55861/303576 [34:52<46:54, 88.00it/s] 18%|        | 55870/303576 [34:52<47:21, 87.16it/s] 18%|        | 55879/303576 [34:52<47:48, 86.35it/s] 18%|        | 55888/303576 [34:52<47:50, 86.28it/s] 18%|        | 55897/303576 [34:52<48:01, 85.94it/s]                                                       18%|        | 55900/303576 [34:52<48:01, 85.94it/s] 18%|        | 55906/303576 [34:52<48:04, 85.86it/s] 18%|        | 55915/303576 [34:53<48:09, 85.70it/s] 18%|        | 55924/303576 [34:53<48:04, 85.87it/s] 18%|        | 55933/303576 [34:53<48:18, 85.45it/s] 18%|        | 55942/303576 [34:53<48:10, 85.66it/s] 18%|        | 55951/303576 [34:53<48:20, 85.36it/s] 18%|        | 55960/303576 [34:53<48:13, 85.58it/s] 18%|        | 55969/303576 [34:53<48:19, 85.40it/s] 18%|        | 55978/303576 [34:53<48:12, 85.60it/s] 18%|        | 55987/303576 [34:53<48:22, 85.31it/s] 18%|        | 55996/303576 [34:54<48:18, 85.43it/s]                                                       18%|        | 56000/303576 [34:54<48:18, 85.43it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7368427515029907, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.436, 'eval_samples_per_second': 10.073, 'eval_steps_per_second': 0.089, 'epoch': 0.54, 'timestamp': 1762966613.045068, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7792, 'grad_norm': 0.24906113743782043, 'learning_rate': 4.052685936991003e-06, 'epoch': 0.54, 'timestamp': 1762966615.0573385, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7727, 'grad_norm': 0.23582997918128967, 'learning_rate': 4.012359031841767e-06, 'epoch': 0.55, 'timestamp': 1762966616.8298354, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7731, 'grad_norm': 0.24140004813671112, 'learning_rate': 3.972830689136209e-06, 'epoch': 0.55, 'timestamp': 1762966618.2276669, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7808, 'grad_norm': 0.31659984588623047, 'learning_rate': 3.9332983965120964e-06, 'epoch': 0.55, 'timestamp': 1762966619.5425243, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7631, 'grad_norm': 0.25332069396972656, 'learning_rate': 3.894159476342635e-06, 'epoch': 0.55, 'timestamp': 1762966620.7667255, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8182, 'grad_norm': 0.25868940353393555, 'learning_rate': 3.855410014311766e-06, 'epoch': 0.55, 'timestamp': 1762966622.134102, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7633, 'grad_norm': 0.2997289001941681, 'learning_rate': 3.817046135053456e-06, 'epoch': 0.55, 'timestamp': 1762966624.0053353, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7673, 'grad_norm': 0.29015812277793884, 'learning_rate': 3.779064001764131e-06, 'epoch': 0.55, 'timestamp': 1762966625.1758938, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.772, 'grad_norm': 0.2492290437221527, 'learning_rate': 3.741459815818946e-06, 'epoch': 0.55, 'timestamp': 1762966626.3210986, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7591, 'grad_norm': 0.4635140895843506, 'learning_rate': 3.7042298163918897e-06, 'epoch': 0.55, 'timestamp': 1762966627.4943607, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:57:10.846673: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:57:10.857657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966630.870992 1758924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966630.874835 1758924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966630.885743 1758924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966630.885760 1758924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966630.885762 1758924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966630.885764 1758924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:57:10.889149: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:57:12 - TensorFlow version 2.19.1 available.
2025-11-12 16:57:20.592258: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:57:20.603078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966640.615963 1759078 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966640.619713 1759078 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966640.630305 1759078 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966640.630325 1759078 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966640.630327 1759078 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966640.630328 1759078 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:57:20.633497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:57:22 - TensorFlow version 2.19.1 available.
 18%|        | 56000/303576 [35:10<48:18, 85.43it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 18%|        | 56000/303576 [35:15<48:18, 85.43it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-56000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-56000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-56000/model.safetensors
 18%|        | 56001/303576 [35:15<57:19:28,  1.20it/s] 18%|        | 56007/303576 [35:15<43:25:31,  1.58it/s] 18%|        | 56015/303576 [35:15<29:55:56,  2.30it/s] 18%|        | 56022/303576 [35:15<21:45:28,  3.16it/s] 18%|        | 56029/303576 [35:15<15:49:58,  4.34it/s] 18%|        | 56035/303576 [35:16<12:01:52,  5.72it/s] 18%|        | 56041/303576 [35:16<9:07:24,  7.54it/s]  18%|        | 56047/303576 [35:16<6:55:44,  9.92it/s] 18%|        | 56053/303576 [35:16<5:16:57, 13.02it/s] 18%|        | 56059/303576 [35:16<4:05:19, 16.82it/s] 18%|        | 56066/303576 [35:16<3:06:05, 22.17it/s] 18%|        | 56073/303576 [35:16<2:27:32, 27.96it/s] 18%|        | 56080/303576 [35:16<2:01:39, 33.91it/s] 18%|        | 56087/303576 [35:16<1:43:57, 39.68it/s] 18%|        | 56094/303576 [35:17<1:32:02, 44.82it/s]                                                         18%|        | 56100/303576 [35:17<1:32:01, 44.82it/s] 18%|        | 56101/303576 [35:17<1:24:16, 48.94it/s] 18%|        | 56108/303576 [35:17<1:18:16, 52.70it/s] 18%|        | 56115/303576 [35:17<1:14:14, 55.55it/s] 18%|        | 56124/303576 [35:17<1:04:09, 64.29it/s] 18%|        | 56134/303576 [35:17<57:24, 71.83it/s]   18%|        | 56143/303576 [35:17<54:38, 75.47it/s] 18%|        | 56152/303576 [35:17<53:15, 77.44it/s] 18%|        | 56161/303576 [35:17<51:58, 79.34it/s] 19%|        | 56170/303576 [35:18<51:24, 80.20it/s] 19%|        | 56179/303576 [35:18<50:46, 81.22it/s] 19%|        | 56188/303576 [35:18<50:36, 81.48it/s] 19%|        | 56197/303576 [35:18<50:15, 82.04it/s]                                                       19%|        | 56200/303576 [35:18<50:15, 82.04it/s] 19%|        | 56206/303576 [35:18<50:14, 82.07it/s] 19%|        | 56215/303576 [35:18<49:57, 82.52it/s] 19%|        | 56224/303576 [35:18<52:08, 79.06it/s] 19%|        | 56232/303576 [35:18<55:09, 74.73it/s] 19%|        | 56240/303576 [35:18<57:31, 71.66it/s] 19%|        | 56248/303576 [35:19<59:07, 69.72it/s] 19%|        | 56256/303576 [35:19<1:00:15, 68.40it/s] 19%|        | 56263/303576 [35:19<1:01:17, 67.25it/s] 19%|        | 56270/303576 [35:19<1:01:42, 66.80it/s] 19%|        | 56277/303576 [35:19<1:02:11, 66.28it/s] 19%|        | 56284/303576 [35:19<1:01:42, 66.79it/s] 19%|        | 56292/303576 [35:19<1:00:37, 67.99it/s] 19%|        | 56300/303576 [35:19<57:46, 71.33it/s]                                                         19%|        | 56300/303576 [35:19<57:46, 71.33it/s] 19%|        | 56308/303576 [35:19<55:52, 73.75it/s] 19%|        | 56317/303576 [35:20<54:07, 76.14it/s] 19%|        | 56326/303576 [35:20<52:02, 79.19it/s] 19%|        | 56335/303576 [35:20<51:03, 80.71it/s] 19%|        | 56344/303576 [35:20<51:02, 80.73it/s] 19%|        | 56353/303576 [35:20<51:47, 79.56it/s] 19%|        | 56361/303576 [35:20<53:14, 77.39it/s] 19%|        | 56369/303576 [35:20<54:22, 75.78it/s] 19%|        | 56377/303576 [35:20<55:12, 74.63it/s] 19%|        | 56385/303576 [35:20<55:45, 73.89it/s] 19%|        | 56393/303576 [35:21<56:21, 73.11it/s]                                                       19%|        | 56400/303576 [35:21<56:21, 73.11it/s] 19%|        | 56401/303576 [35:21<56:54, 72.39it/s] 19%|        | 56409/303576 [35:21<57:12, 72.02it/s] 19%|        | 56417/303576 [35:21<57:07, 72.11it/s] 19%|        | 56425/303576 [35:21<57:06, 72.13it/s] 19%|        | 56433/303576 [35:21<57:21, 71.81it/s] 19%|        | 56441/303576 [35:21<57:13, 71.98it/s] 19%|        | 56449/303576 [35:21<57:12, 72.00it/s] 19%|        | 56457/303576 [35:21<57:11, 72.01it/s] 19%|        | 56465/303576 [35:22<57:30, 71.62it/s] 19%|        | 56473/303576 [35:22<57:22, 71.78it/s] 19%|        | 56481/303576 [35:22<55:51, 73.74it/s] 19%|        | 56490/303576 [35:22<54:30, 75.55it/s] 19%|        | 56498/303576 [35:22<53:46, 76.57it/s]                                                       19%|        | 56500/303576 [35:22<53:46, 76.57it/s] 19%|        | 56506/303576 [35:22<53:12, 77.39it/s] 19%|        | 56515/303576 [35:22<52:28, 78.47it/s] 19%|        | 56524/303576 [35:22<52:06, 79.01it/s] 19%|        | 56533/303576 [35:22<51:50, 79.42it/s] 19%|        | 56542/303576 [35:23<51:36, 79.78it/s] 19%|        | 56551/303576 [35:23<50:57, 80.80it/s] 19%|        | 56560/303576 [35:23<50:56, 80.82it/s] 19%|        | 56569/303576 [35:23<50:33, 81.42it/s] 19%|        | 56578/303576 [35:23<50:33, 81.42it/s] 19%|        | 56587/303576 [35:23<50:09, 82.06it/s] 19%|        | 56596/303576 [35:23<50:20, 81.76it/s]                                                       19%|        | 56600/303576 [35:23<50:20, 81.76it/s] 19%|        | 56605/303576 [35:23<49:14, 83.59it/s] 19%|        | 56614/303576 [35:23<48:37, 84.64it/s] 19%|        | 56623/303576 [35:24<48:17, 85.24it/s] 19%|        | 56632/303576 [35:24<48:44, 84.45it/s] 19%|        | 56641/303576 [35:24<48:42, 84.50it/s] 19%|        | 56650/303576 [35:24<49:33, 83.03it/s] 19%|        | 56659/303576 [35:24<49:57, 82.38it/s] 19%|        | 56668/303576 [35:24<49:10, 83.68it/s] 19%|        | 56678/303576 [35:24<47:52, 85.94it/s] 19%|        | 56687/303576 [35:24<47:49, 86.05it/s] 19%|        | 56696/303576 [35:24<47:52, 85.95it/s]                                                       19%|        | 56700/303576 [35:24<47:52, 85.95it/s] 19%|        | 56705/303576 [35:24<48:09, 85.42it/s] 19%|        | 56714/303576 [35:25<48:10, 85.40it/s] 19%|        | 56723/303576 [35:25<49:09, 83.69it/s] 19%|        | 56732/303576 [35:25<49:17, 83.47it/s] 19%|        | 56741/303576 [35:25<49:36, 82.92it/s] 19%|        | 56750/303576 [35:25<49:25, 83.24it/s] 19%|        | 56759/303576 [35:25<49:08, 83.71it/s] 19%|        | 56768/303576 [35:25<48:49, 84.26it/s] 19%|        | 56777/303576 [35:25<48:48, 84.29it/s] 19%|        | 56786/303576 [35:25<48:44, 84.38it/s] 19%|        | 56795/303576 [35:26<48:40, 84.51it/s]                                                       19%|        | 56800/303576 [35:26<48:40, 84.51it/s] 19%|        | 56804/303576 [35:26<48:56, 84.03it/s] 19%|        | 56813/303576 [35:26<49:26, 83.18it/s] 19%|        | 56822/303576 [35:26<49:26, 83.18it/s] 19%|        | 56831/303576 [35:26<49:46, 82.63it/s] 19%|        | 56840/303576 [35:26<49:36, 82.90it/s] 19%|        | 56849/303576 [35:26<49:49, 82.54it/s] 19%|        | 56858/303576 [35:26<49:20, 83.34it/s] 19%|        | 56867/303576 [35:26<49:13, 83.53it/s] 19%|        | 56876/303576 [35:27<48:48, 84.25it/s] 19%|        | 56885/303576 [35:27<48:46, 84.30it/s] 19%|        | 56894/303576 [35:27<50:17, 81.75it/s]                                                       19%|        | 56900/303576 [35:27<50:17, 81.75it/s] 19%|        | 56903/303576 [35:27<51:22, 80.03it/s] 19%|        | 56912/303576 [35:27<55:51, 73.59it/s] 19%|        | 56920/303576 [35:27<1:00:54, 67.49it/s] 19%|        | 56927/303576 [35:27<1:04:07, 64.10it/s] 19%|        | 56934/303576 [35:27<1:06:32, 61.77it/s] 19%|        | 56941/303576 [35:28<1:08:56, 59.63it/s] 19%|        | 56948/303576 [35:28<1:10:15, 58.50it/s] 19%|        | 56954/303576 [35:28<1:11:18, 57.64it/s] 19%|        | 56960/303576 [35:28<1:12:05, 57.01it/s] 19%|        | 56966/303576 [35:28<1:13:00, 56.29it/s] 19%|        | 56972/303576 [35:28<1:13:35, 55.85it/s] 19%|        | 56978/303576 [35:28<1:13:55, 55.60it/s] 19%|        | 56984/303576 [35:28<1:14:45, 54.98it/s] 19%|        | 56990/303576 [35:28<1:15:24, 54.50it/s] 19%|        | 56996/303576 [35:29<1:18:58, 52.03it/s]                                                         19%|        | 57000/303576 [35:29<1:18:58, 52.03it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366140484809875, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.3096, 'eval_samples_per_second': 10.606, 'eval_steps_per_second': 0.094, 'epoch': 0.55, 'timestamp': 1762966648.8044457, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7759, 'grad_norm': 0.26437705755233765, 'learning_rate': 3.6673702800796516e-06, 'epoch': 0.55, 'timestamp': 1762966650.613743, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7812, 'grad_norm': 0.20539338886737823, 'learning_rate': 3.6308775205292516e-06, 'epoch': 0.56, 'timestamp': 1762966651.854997, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7737, 'grad_norm': 0.2136855125427246, 'learning_rate': 3.5947478880693522e-06, 'epoch': 0.56, 'timestamp': 1762966653.2899241, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7732, 'grad_norm': 0.24985763430595398, 'learning_rate': 3.5589777693452683e-06, 'epoch': 0.56, 'timestamp': 1762966654.596308, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.78, 'grad_norm': 0.22873887419700623, 'learning_rate': 3.523563586957578e-06, 'epoch': 0.56, 'timestamp': 1762966655.9523823, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7805, 'grad_norm': 0.3066595494747162, 'learning_rate': 3.4885017991043485e-06, 'epoch': 0.56, 'timestamp': 1762966657.1784668, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7676, 'grad_norm': 0.27659913897514343, 'learning_rate': 3.4537888992269226e-06, 'epoch': 0.56, 'timestamp': 1762966658.3514097, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7721, 'grad_norm': 0.25949835777282715, 'learning_rate': 3.4194214156592158e-06, 'epoch': 0.56, 'timestamp': 1762966659.5446582, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7691, 'grad_norm': 0.26482462882995605, 'learning_rate': 3.3853959112805224e-06, 'epoch': 0.56, 'timestamp': 1762966660.7616973, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7728, 'grad_norm': 0.21003474295139313, 'learning_rate': 3.3517089831717572e-06, 'epoch': 0.56, 'timestamp': 1762966662.5750573, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:57:46.405989: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:57:46.416925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966666.429997 1759518 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966666.433973 1759518 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966666.444486 1759518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966666.444502 1759518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966666.444504 1759518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966666.444505 1759518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:57:46.447836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:57:48 - TensorFlow version 2.19.1 available.
 19%|        | 57000/303576 [35:40<1:18:58, 52.03it/s]2025-11-12 16:57:57.111650: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:57:57.122283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966677.135349 1759683 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966677.139346 1759683 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966677.149932 1759683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966677.149949 1759683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966677.149951 1759683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966677.149952 1759683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:57:57.153339: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:57:59 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A 19%|        | 57000/303576 [35:51<1:18:58, 52.03it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 19%|        | 57001/303576 [35:51<82:10:05,  1.20s/it] 19%|        | 57006/303576 [35:51<60:17:47,  1.14it/s] 19%|        | 57011/303576 [35:52<43:53:52,  1.56it/s] 19%|        | 57016/303576 [35:52<31:49:39,  2.15it/s] 19%|        | 57021/303576 [35:52<23:05:47,  2.97it/s] 19%|        | 57026/303576 [35:52<16:44:56,  4.09it/s] 19%|        | 57032/303576 [35:52<11:34:50,  5.91it/s] 19%|        | 57038/303576 [35:52<8:13:28,  8.33it/s]  19%|        | 57044/303576 [35:52<5:59:32, 11.43it/s] 19%|        | 57050/303576 [35:52<4:29:24, 15.25it/s] 19%|        | 57056/303576 [35:52<3:27:59, 19.75it/s] 19%|        | 57062/303576 [35:52<2:45:46, 24.78it/s] 19%|        | 57068/303576 [35:53<2:16:40, 30.06it/s] 19%|        | 57074/303576 [35:53<1:56:26, 35.28it/s] 19%|        | 57080/303576 [35:53<1:42:15, 40.18it/s] 19%|        | 57086/303576 [35:53<1:32:30, 44.41it/s] 19%|        | 57092/303576 [35:53<1:25:25, 48.09it/s] 19%|        | 57098/303576 [35:53<1:22:17, 49.92it/s]                                                         19%|        | 57100/303576 [35:53<1:22:17, 49.92it/s] 19%|        | 57105/303576 [35:53<1:18:08, 52.57it/s] 19%|        | 57112/303576 [35:53<1:14:41, 54.99it/s] 19%|        | 57118/303576 [35:53<1:13:08, 56.16it/s] 19%|        | 57125/303576 [35:54<1:11:08, 57.74it/s] 19%|        | 57131/303576 [35:54<1:11:19, 57.58it/s] 19%|        | 57137/303576 [35:54<1:13:23, 55.96it/s] 19%|        | 57143/303576 [35:54<1:12:34, 56.60it/s] 19%|        | 57149/303576 [35:54<1:12:48, 56.41it/s] 19%|        | 57156/303576 [35:54<1:09:06, 59.43it/s] 19%|        | 57164/303576 [35:54<1:02:58, 65.22it/s] 19%|        | 57174/303576 [35:54<54:34, 75.24it/s]   19%|        | 57183/303576 [35:54<53:32, 76.71it/s] 19%|        | 57191/303576 [35:55<53:58, 76.09it/s] 19%|        | 57199/303576 [35:55<54:04, 75.93it/s]                                                       19%|        | 57200/303576 [35:55<54:04, 75.93it/s] 19%|        | 57207/303576 [35:55<54:23, 75.49it/s] 19%|        | 57215/303576 [35:55<54:53, 74.80it/s] 19%|        | 57223/303576 [35:55<54:04, 75.92it/s] 19%|        | 57232/303576 [35:55<52:47, 77.77it/s] 19%|        | 57241/303576 [35:55<51:53, 79.13it/s] 19%|        | 57250/303576 [35:55<51:27, 79.79it/s] 19%|        | 57259/303576 [35:55<51:11, 80.19it/s] 19%|        | 57268/303576 [35:55<51:02, 80.44it/s] 19%|        | 57277/303576 [35:56<50:51, 80.72it/s] 19%|        | 57286/303576 [35:56<50:49, 80.77it/s] 19%|        | 57295/303576 [35:56<50:45, 80.88it/s]                                                       19%|        | 57300/303576 [35:56<50:45, 80.88it/s] 19%|        | 57304/303576 [35:56<50:40, 81.00it/s] 19%|        | 57313/303576 [35:56<50:38, 81.04it/s] 19%|        | 57322/303576 [35:56<50:32, 81.19it/s] 19%|        | 57331/303576 [35:56<50:32, 81.21it/s] 19%|        | 57342/303576 [35:56<47:07, 87.08it/s] 19%|        | 57353/303576 [35:56<44:58, 91.25it/s] 19%|        | 57364/303576 [35:57<43:25, 94.50it/s] 19%|        | 57375/303576 [35:57<42:23, 96.79it/s] 19%|        | 57386/303576 [35:57<41:43, 98.34it/s] 19%|        | 57397/303576 [35:57<41:28, 98.94it/s]                                                       19%|        | 57400/303576 [35:57<41:28, 98.94it/s] 19%|        | 57408/303576 [35:57<41:00, 100.06it/s] 19%|        | 57419/303576 [35:57<40:41, 100.81it/s] 19%|        | 57430/303576 [35:57<40:25, 101.47it/s] 19%|        | 57441/303576 [35:57<40:09, 102.15it/s] 19%|        | 57452/303576 [35:57<40:09, 102.16it/s] 19%|        | 57463/303576 [35:58<40:03, 102.38it/s] 19%|        | 57474/303576 [35:58<39:57, 102.66it/s] 19%|        | 57485/303576 [35:58<40:14, 101.90it/s] 19%|        | 57496/303576 [35:58<40:47, 100.53it/s]                                                        19%|        | 57500/303576 [35:58<40:47, 100.53it/s] 19%|        | 57507/303576 [35:58<41:12, 99.52it/s]  19%|        | 57517/303576 [35:58<41:25, 99.01it/s] 19%|        | 57527/303576 [35:58<41:37, 98.53it/s] 19%|        | 57537/303576 [35:58<41:34, 98.64it/s] 19%|        | 57547/303576 [35:58<44:16, 92.62it/s] 19%|        | 57557/303576 [35:59<46:02, 89.05it/s] 19%|        | 57566/303576 [35:59<47:04, 87.11it/s] 19%|        | 57575/303576 [35:59<48:03, 85.32it/s] 19%|        | 57584/303576 [35:59<48:28, 84.57it/s] 19%|        | 57594/303576 [35:59<46:52, 87.46it/s]                                                       19%|        | 57600/303576 [35:59<46:52, 87.46it/s] 19%|        | 57604/303576 [35:59<45:11, 90.72it/s] 19%|        | 57614/303576 [35:59<44:04, 93.01it/s] 19%|        | 57624/303576 [35:59<43:14, 94.80it/s] 19%|        | 57634/303576 [35:59<42:38, 96.12it/s] 19%|        | 57644/303576 [35:59<42:18, 96.87it/s] 19%|        | 57654/303576 [36:00<41:56, 97.74it/s] 19%|        | 57664/303576 [36:00<41:47, 98.06it/s] 19%|        | 57674/303576 [36:00<41:40, 98.35it/s] 19%|        | 57684/303576 [36:00<41:41, 98.30it/s] 19%|        | 57694/303576 [36:00<41:35, 98.54it/s]                                                       19%|        | 57700/303576 [36:00<41:35, 98.54it/s] 19%|        | 57704/303576 [36:00<41:30, 98.74it/s] 19%|        | 57714/303576 [36:00<41:25, 98.92it/s] 19%|        | 57725/303576 [36:00<41:13, 99.37it/s] 19%|        | 57735/303576 [36:00<41:12, 99.41it/s] 19%|        | 57745/303576 [36:01<41:11, 99.46it/s] 19%|        | 57756/303576 [36:01<41:07, 99.64it/s] 19%|        | 57766/303576 [36:01<41:04, 99.72it/s] 19%|        | 57776/303576 [36:01<41:30, 98.68it/s] 19%|        | 57787/303576 [36:01<41:19, 99.13it/s] 19%|        | 57798/303576 [36:01<41:04, 99.71it/s]                                                       19%|        | 57800/303576 [36:01<41:04, 99.71it/s] 19%|        | 57808/303576 [36:01<41:07, 99.62it/s] 19%|        | 57818/303576 [36:01<41:12, 99.38it/s] 19%|        | 57829/303576 [36:01<41:08, 99.55it/s] 19%|        | 57840/303576 [36:01<41:02, 99.80it/s] 19%|        | 57851/303576 [36:02<40:55, 100.09it/s] 19%|        | 57862/303576 [36:02<40:56, 100.04it/s] 19%|        | 57873/303576 [36:02<40:56, 100.00it/s] 19%|        | 57884/303576 [36:02<40:55, 100.05it/s] 19%|        | 57895/303576 [36:02<40:54, 100.10it/s]                                                        19%|        | 57900/303576 [36:02<40:54, 100.10it/s] 19%|        | 57906/303576 [36:02<40:43, 100.55it/s] 19%|        | 57917/303576 [36:02<40:33, 100.94it/s] 19%|        | 57928/303576 [36:02<40:26, 101.22it/s] 19%|        | 57939/303576 [36:02<40:21, 101.46it/s] 19%|        | 57950/303576 [36:03<40:33, 100.94it/s] 19%|        | 57961/303576 [36:03<40:35, 100.85it/s] 19%|        | 57972/303576 [36:03<40:31, 100.99it/s] 19%|        | 57983/303576 [36:03<40:35, 100.84it/s] 19%|        | 57994/303576 [36:03<41:28, 98.70it/s]                                                        19%|        | 58000/303576 [36:03<41:28, 98.70it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7364311814308167, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.6399, 'eval_samples_per_second': 9.982, 'eval_steps_per_second': 0.088, 'epoch': 0.56, 'timestamp': 1762966685.2156644, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7654, 'grad_norm': 0.27266725897789, 'learning_rate': 3.31835726227513e-06, 'epoch': 0.56, 'timestamp': 1762966687.0805626, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7813, 'grad_norm': 0.19453363120555878, 'learning_rate': 3.2853374130572033e-06, 'epoch': 0.57, 'timestamp': 1762966688.5711339, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7875, 'grad_norm': 0.2257203757762909, 'learning_rate': 3.2526461331753087e-06, 'epoch': 0.57, 'timestamp': 1762966689.8219554, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.765, 'grad_norm': 0.27115970849990845, 'learning_rate': 3.220280153147263e-06, 'epoch': 0.57, 'timestamp': 1762966690.8835475, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7721, 'grad_norm': 0.23306316137313843, 'learning_rate': 3.188236236024395e-06, 'epoch': 0.57, 'timestamp': 1762966691.8657463, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7652, 'grad_norm': 0.265271931886673, 'learning_rate': 3.156511177067821e-06, 'epoch': 0.57, 'timestamp': 1762966692.9856522, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7669, 'grad_norm': 0.24120484292507172, 'learning_rate': 3.1251018034279213e-06, 'epoch': 0.57, 'timestamp': 1762966693.9960806, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7916, 'grad_norm': 0.23158115148544312, 'learning_rate': 3.094004973827026e-06, 'epoch': 0.57, 'timestamp': 1762966695.0001142, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7673, 'grad_norm': 0.2724124491214752, 'learning_rate': 3.0632175782452607e-06, 'epoch': 0.57, 'timestamp': 1762966696.0003815, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7665, 'grad_norm': 0.24479031562805176, 'learning_rate': 3.0327365376095085e-06, 'epoch': 0.57, 'timestamp': 1762966697.0097787, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:58:20.402654: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:58:20.413669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966700.427081 1760119 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966700.431214 1760119 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966700.441947 1760119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966700.441963 1760119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966700.441965 1760119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966700.441967 1760119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:58:20.445405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:58:22 - TensorFlow version 2.19.1 available.
2025-11-12 16:58:30.017955: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:58:30.028833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966710.041990 1760278 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966710.045938 1760278 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966710.056574 1760278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966710.056591 1760278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966710.056592 1760278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966710.056594 1760278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:58:30.059889: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:58:31 - TensorFlow version 2.19.1 available.
 19%|        | 58000/303576 [36:20<41:28, 98.70it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 19%|        | 58000/303576 [36:24<41:28, 98.70it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-58000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-58000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-58000/model.safetensors
 19%|        | 58001/303576 [36:24<44:54:48,  1.52it/s] 19%|        | 58008/303576 [36:24<34:37:32,  1.97it/s] 19%|        | 58018/303576 [36:24<23:38:49,  2.88it/s] 19%|        | 58029/303576 [36:25<15:53:10,  4.29it/s] 19%|        | 58039/303576 [36:25<11:17:40,  6.04it/s] 19%|        | 58049/303576 [36:25<8:07:22,  8.40it/s]  19%|        | 58058/303576 [36:25<6:04:32, 11.23it/s] 19%|        | 58067/303576 [36:25<4:34:58, 14.88it/s] 19%|        | 58076/303576 [36:25<3:30:30, 19.44it/s] 19%|        | 58085/303576 [36:25<2:44:15, 24.91it/s] 19%|        | 58094/303576 [36:25<2:10:29, 31.35it/s]                                                         19%|        | 58100/303576 [36:25<2:10:29, 31.35it/s] 19%|        | 58103/303576 [36:25<1:45:21, 38.83it/s] 19%|        | 58113/303576 [36:26<1:26:09, 47.48it/s] 19%|        | 58122/303576 [36:26<1:14:43, 54.74it/s] 19%|        | 58131/303576 [36:26<1:06:14, 61.75it/s] 19%|        | 58140/303576 [36:26<1:00:09, 67.99it/s] 19%|        | 58149/303576 [36:26<55:57, 73.09it/s]   19%|        | 58158/303576 [36:26<52:55, 77.28it/s] 19%|        | 58167/303576 [36:26<50:42, 80.66it/s] 19%|        | 58176/303576 [36:26<49:18, 82.93it/s] 19%|        | 58185/303576 [36:26<48:23, 84.51it/s] 19%|        | 58194/303576 [36:26<47:35, 85.94it/s]                                                       19%|        | 58200/303576 [36:27<47:35, 85.94it/s] 19%|        | 58203/303576 [36:27<47:00, 86.99it/s] 19%|        | 58212/303576 [36:27<46:46, 87.41it/s] 19%|        | 58221/303576 [36:27<46:29, 87.97it/s] 19%|        | 58230/303576 [36:27<46:23, 88.14it/s] 19%|        | 58239/303576 [36:27<46:22, 88.19it/s] 19%|        | 58248/303576 [36:27<46:09, 88.58it/s] 19%|        | 58257/303576 [36:27<46:01, 88.83it/s] 19%|        | 58266/303576 [36:27<46:03, 88.77it/s] 19%|        | 58275/303576 [36:27<45:53, 89.10it/s] 19%|        | 58284/303576 [36:27<45:50, 89.18it/s] 19%|        | 58293/303576 [36:28<45:52, 89.11it/s]                                                       19%|        | 58300/303576 [36:28<45:52, 89.11it/s] 19%|        | 58302/303576 [36:28<46:19, 88.25it/s] 19%|        | 58311/303576 [36:28<46:22, 88.13it/s] 19%|        | 58320/303576 [36:28<46:30, 87.90it/s] 19%|        | 58329/303576 [36:28<46:46, 87.40it/s] 19%|        | 58338/303576 [36:28<49:00, 83.40it/s] 19%|        | 58347/303576 [36:28<55:23, 73.79it/s] 19%|        | 58355/303576 [36:28<59:29, 68.69it/s] 19%|        | 58363/303576 [36:29<1:02:56, 64.94it/s] 19%|        | 58370/303576 [36:29<1:05:35, 62.30it/s] 19%|        | 58377/303576 [36:29<1:07:22, 60.66it/s] 19%|        | 58384/303576 [36:29<1:08:51, 59.34it/s] 19%|        | 58390/303576 [36:29<1:09:49, 58.52it/s] 19%|        | 58396/303576 [36:29<1:10:11, 58.21it/s]                                                         19%|        | 58400/303576 [36:29<1:10:11, 58.21it/s] 19%|        | 58402/303576 [36:29<1:10:31, 57.94it/s] 19%|        | 58408/303576 [36:29<1:10:35, 57.88it/s] 19%|        | 58414/303576 [36:29<1:11:04, 57.49it/s] 19%|        | 58420/303576 [36:30<1:13:02, 55.94it/s] 19%|        | 58426/303576 [36:30<1:11:55, 56.80it/s] 19%|        | 58432/303576 [36:30<1:11:29, 57.15it/s] 19%|        | 58438/303576 [36:30<1:10:34, 57.90it/s] 19%|        | 58444/303576 [36:30<1:09:56, 58.41it/s] 19%|        | 58450/303576 [36:30<1:09:53, 58.46it/s] 19%|        | 58456/303576 [36:30<1:09:41, 58.61it/s] 19%|        | 58462/303576 [36:30<1:09:46, 58.55it/s] 19%|        | 58468/303576 [36:30<1:09:24, 58.85it/s] 19%|        | 58474/303576 [36:30<1:10:09, 58.23it/s] 19%|        | 58480/303576 [36:31<1:13:25, 55.64it/s] 19%|        | 58486/303576 [36:31<1:18:06, 52.30it/s] 19%|        | 58493/303576 [36:31<1:14:19, 54.96it/s] 19%|        | 58499/303576 [36:31<1:15:25, 54.15it/s]                                                         19%|        | 58500/303576 [36:31<1:15:25, 54.15it/s] 19%|        | 58505/303576 [36:31<1:16:32, 53.37it/s] 19%|        | 58511/303576 [36:31<1:17:25, 52.76it/s] 19%|        | 58517/303576 [36:31<1:18:25, 52.08it/s] 19%|        | 58523/303576 [36:31<1:19:07, 51.61it/s] 19%|        | 58529/303576 [36:32<1:19:40, 51.26it/s] 19%|        | 58535/303576 [36:32<1:19:58, 51.06it/s] 19%|        | 58541/303576 [36:32<1:20:08, 50.96it/s] 19%|        | 58547/303576 [36:32<1:19:09, 51.59it/s] 19%|        | 58553/303576 [36:32<1:17:50, 52.46it/s] 19%|        | 58559/303576 [36:32<1:16:03, 53.68it/s] 19%|        | 58565/303576 [36:32<1:14:45, 54.62it/s] 19%|        | 58571/303576 [36:32<1:13:49, 55.31it/s] 19%|        | 58577/303576 [36:32<1:12:55, 55.99it/s] 19%|        | 58583/303576 [36:33<1:12:14, 56.52it/s] 19%|        | 58589/303576 [36:33<1:11:14, 57.31it/s] 19%|        | 58596/303576 [36:33<1:09:43, 58.56it/s]                                                         19%|        | 58600/303576 [36:33<1:09:43, 58.56it/s] 19%|        | 58602/303576 [36:33<1:09:35, 58.68it/s] 19%|        | 58608/303576 [36:33<1:09:33, 58.69it/s] 19%|        | 58614/303576 [36:33<1:09:39, 58.61it/s] 19%|        | 58620/303576 [36:33<1:10:11, 58.17it/s] 19%|        | 58626/303576 [36:33<1:10:16, 58.10it/s] 19%|        | 58632/303576 [36:33<1:12:11, 56.55it/s] 19%|        | 58638/303576 [36:34<1:15:27, 54.09it/s] 19%|        | 58644/303576 [36:34<1:14:39, 54.67it/s] 19%|        | 58650/303576 [36:34<1:15:11, 54.29it/s] 19%|        | 58656/303576 [36:34<1:14:56, 54.47it/s] 19%|        | 58662/303576 [36:34<1:15:05, 54.36it/s] 19%|        | 58668/303576 [36:34<1:15:01, 54.41it/s] 19%|        | 58674/303576 [36:34<1:14:17, 54.94it/s] 19%|        | 58680/303576 [36:34<1:14:16, 54.96it/s] 19%|        | 58686/303576 [36:34<1:13:10, 55.78it/s] 19%|        | 58692/303576 [36:34<1:14:10, 55.03it/s] 19%|        | 58698/303576 [36:35<1:12:55, 55.97it/s]                                                         19%|        | 58700/303576 [36:35<1:12:55, 55.97it/s] 19%|        | 58704/303576 [36:35<1:12:36, 56.21it/s] 19%|        | 58710/303576 [36:35<1:12:19, 56.43it/s] 19%|        | 58716/303576 [36:35<1:12:24, 56.36it/s] 19%|        | 58722/303576 [36:35<1:12:49, 56.04it/s] 19%|        | 58728/303576 [36:35<1:16:58, 53.02it/s] 19%|        | 58734/303576 [36:35<1:22:57, 49.19it/s] 19%|        | 58740/303576 [36:35<1:18:29, 51.99it/s] 19%|        | 58747/303576 [36:35<1:13:07, 55.80it/s] 19%|        | 58754/303576 [36:36<1:09:35, 58.63it/s] 19%|        | 58761/303576 [36:36<1:06:22, 61.47it/s] 19%|        | 58768/303576 [36:36<1:04:16, 63.48it/s] 19%|        | 58775/303576 [36:36<1:02:52, 64.90it/s] 19%|        | 58782/303576 [36:36<1:01:48, 66.00it/s] 19%|        | 58789/303576 [36:36<1:01:06, 66.77it/s] 19%|        | 58796/303576 [36:36<1:00:44, 67.16it/s]                                                         19%|        | 58800/303576 [36:36<1:00:44, 67.16it/s] 19%|        | 58803/303576 [36:36<1:00:31, 67.40it/s] 19%|        | 58810/303576 [36:36<1:00:15, 67.69it/s] 19%|        | 58817/303576 [36:37<1:00:00, 67.98it/s] 19%|        | 58824/303576 [36:37<59:42, 68.31it/s]   19%|        | 58831/303576 [36:37<59:44, 68.27it/s] 19%|        | 58838/303576 [36:37<59:44, 68.28it/s] 19%|        | 58845/303576 [36:37<59:39, 68.37it/s] 19%|        | 58852/303576 [36:37<59:36, 68.42it/s] 19%|        | 58859/303576 [36:37<59:38, 68.38it/s] 19%|        | 58866/303576 [36:37<59:42, 68.31it/s] 19%|        | 58873/303576 [36:37<59:45, 68.26it/s] 19%|        | 58880/303576 [36:37<59:36, 68.42it/s] 19%|        | 58887/303576 [36:38<59:40, 68.33it/s] 19%|        | 58894/303576 [36:38<59:45, 68.25it/s]                                                       19%|        | 58900/303576 [36:38<59:44, 68.25it/s] 19%|        | 58901/303576 [36:38<59:47, 68.20it/s] 19%|        | 58908/303576 [36:38<59:39, 68.35it/s] 19%|        | 58915/303576 [36:38<59:37, 68.39it/s] 19%|        | 58922/303576 [36:38<59:39, 68.34it/s] 19%|        | 58929/303576 [36:38<59:40, 68.33it/s] 19%|        | 58936/303576 [36:38<59:39, 68.35it/s] 19%|        | 58943/303576 [36:38<59:36, 68.40it/s] 19%|        | 58950/303576 [36:38<59:34, 68.44it/s] 19%|        | 58957/303576 [36:39<59:30, 68.50it/s] 19%|        | 58964/303576 [36:39<59:30, 68.51it/s] 19%|        | 58971/303576 [36:39<59:33, 68.46it/s] 19%|        | 58978/303576 [36:39<59:41, 68.30it/s] 19%|        | 58985/303576 [36:39<59:47, 68.19it/s] 19%|        | 58992/303576 [36:39<1:00:35, 67.27it/s] 19%|        | 58999/303576 [36:39<1:02:22, 65.36it/s]                                                         19%|        | 59000/303576 [36:39<1:02:22, 65.36it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7367629408836365, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.1171, 'eval_samples_per_second': 10.702, 'eval_steps_per_second': 0.095, 'epoch': 0.57, 'timestamp': 1762966718.1274476, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7785, 'grad_norm': 0.31512969732284546, 'learning_rate': 3.0025588034854545e-06, 'epoch': 0.57, 'timestamp': 1762966719.361909, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7825, 'grad_norm': 0.23806129395961761, 'learning_rate': 2.972681357772731e-06, 'epoch': 0.58, 'timestamp': 1762966720.4840503, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7835, 'grad_norm': 0.24175724387168884, 'learning_rate': 2.9431012124030627e-06, 'epoch': 0.58, 'timestamp': 1762966721.6092734, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7769, 'grad_norm': 0.2754489481449127, 'learning_rate': 2.9138154090414265e-06, 'epoch': 0.58, 'timestamp': 1762966723.1487277, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7757, 'grad_norm': 0.23830021917819977, 'learning_rate': 2.8851095297431688e-06, 'epoch': 0.58, 'timestamp': 1762966724.9234388, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7628, 'grad_norm': 0.25178641080856323, 'learning_rate': 2.8564007819744014e-06, 'epoch': 0.58, 'timestamp': 1762966726.7631214, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7634, 'grad_norm': 0.2381916493177414, 'learning_rate': 2.8279777052312753e-06, 'epoch': 0.58, 'timestamp': 1762966728.5661147, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7738, 'grad_norm': 0.22524511814117432, 'learning_rate': 2.7998374568981685e-06, 'epoch': 0.58, 'timestamp': 1762966730.2127345, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7725, 'grad_norm': 0.2711387872695923, 'learning_rate': 2.771977222645366e-06, 'epoch': 0.58, 'timestamp': 1762966731.675225, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7776, 'grad_norm': 0.25233596563339233, 'learning_rate': 2.7443942161475884e-06, 'epoch': 0.58, 'timestamp': 1762966733.1588562, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:58:56.980532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:58:56.991275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966737.004301 1760586 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966737.008233 1760586 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966737.018790 1760586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966737.018808 1760586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966737.018810 1760586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966737.018811 1760586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:58:57.022087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:58:59 - TensorFlow version 2.19.1 available.
 19%|        | 59000/303576 [36:50<1:02:22, 65.36it/s]2025-11-12 16:59:07.725083: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:59:07.735750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966747.748552 1760876 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966747.752438 1760876 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966747.762879 1760876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966747.762893 1760876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966747.762895 1760876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966747.762896 1760876 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:59:07.766141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:59:09 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                        
                                             [A 19%|        | 59000/303576 [37:02<1:02:22, 65.36it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 19%|        | 59001/303576 [37:02<85:41:56,  1.26s/it] 19%|        | 59005/303576 [37:02<65:45:15,  1.03it/s] 19%|        | 59011/303576 [37:02<44:09:13,  1.54it/s] 19%|        | 59017/303576 [37:02<30:20:24,  2.24it/s] 19%|        | 59022/303576 [37:03<22:19:47,  3.04it/s] 19%|        | 59027/303576 [37:03<16:27:26,  4.13it/s] 19%|        | 59032/303576 [37:03<12:10:56,  5.58it/s] 19%|        | 59038/303576 [37:03<8:33:30,  7.94it/s]  19%|        | 59044/303576 [37:03<6:11:59, 10.96it/s] 19%|        | 59050/303576 [37:03<4:37:04, 14.71it/s] 19%|        | 59056/303576 [37:03<3:34:01, 19.04it/s] 19%|        | 59062/303576 [37:03<2:50:58, 23.83it/s] 19%|        | 59068/303576 [37:04<2:21:30, 28.80it/s] 19%|        | 59074/303576 [37:04<2:00:39, 33.78it/s] 19%|        | 59080/303576 [37:04<1:45:59, 38.45it/s] 19%|        | 59086/303576 [37:04<1:35:35, 42.62it/s] 19%|        | 59092/303576 [37:04<1:28:14, 46.17it/s] 19%|        | 59098/303576 [37:04<1:23:48, 48.62it/s]                                                         19%|        | 59100/303576 [37:04<1:23:48, 48.62it/s] 19%|        | 59104/303576 [37:04<1:21:15, 50.14it/s] 19%|        | 59110/303576 [37:04<1:19:14, 51.42it/s] 19%|        | 59116/303576 [37:04<1:16:34, 53.21it/s] 19%|        | 59123/303576 [37:04<1:13:36, 55.34it/s] 19%|        | 59129/303576 [37:05<1:13:28, 55.45it/s] 19%|        | 59135/303576 [37:05<1:12:59, 55.81it/s] 19%|        | 59144/303576 [37:05<1:03:25, 64.23it/s] 19%|        | 59153/303576 [37:05<58:05, 70.12it/s]   19%|        | 59162/303576 [37:05<54:37, 74.58it/s] 19%|        | 59171/303576 [37:05<53:28, 76.17it/s] 19%|        | 59180/303576 [37:05<52:07, 78.14it/s] 19%|        | 59189/303576 [37:05<51:23, 79.26it/s] 20%|        | 59198/303576 [37:05<51:14, 79.49it/s]                                                       20%|        | 59200/303576 [37:05<51:14, 79.49it/s] 20%|        | 59207/303576 [37:06<50:37, 80.46it/s] 20%|        | 59216/303576 [37:06<50:15, 81.02it/s] 20%|        | 59225/303576 [37:06<50:08, 81.21it/s] 20%|        | 59234/303576 [37:06<50:11, 81.12it/s] 20%|        | 59243/303576 [37:06<50:01, 81.41it/s] 20%|        | 59252/303576 [37:06<49:41, 81.94it/s] 20%|        | 59261/303576 [37:06<49:47, 81.78it/s] 20%|        | 59270/303576 [37:06<49:45, 81.83it/s] 20%|        | 59279/303576 [37:06<49:38, 82.02it/s] 20%|        | 59288/303576 [37:07<50:00, 81.43it/s] 20%|        | 59297/303576 [37:07<49:40, 81.95it/s]                                                       20%|        | 59300/303576 [37:07<49:40, 81.95it/s] 20%|        | 59306/303576 [37:07<49:38, 82.02it/s] 20%|        | 59315/303576 [37:07<49:43, 81.88it/s] 20%|        | 59324/303576 [37:07<49:46, 81.77it/s] 20%|        | 59333/303576 [37:07<49:52, 81.62it/s] 20%|        | 59342/303576 [37:07<49:36, 82.06it/s] 20%|        | 59351/303576 [37:07<49:26, 82.33it/s] 20%|        | 59360/303576 [37:07<49:24, 82.37it/s] 20%|        | 59369/303576 [37:08<49:38, 81.99it/s] 20%|        | 59378/303576 [37:08<49:16, 82.60it/s] 20%|        | 59387/303576 [37:08<50:16, 80.94it/s] 20%|        | 59396/303576 [37:08<50:13, 81.03it/s]                                                       20%|        | 59400/303576 [37:08<50:13, 81.03it/s] 20%|        | 59405/303576 [37:08<50:01, 81.36it/s] 20%|        | 59414/303576 [37:08<50:04, 81.26it/s] 20%|        | 59423/303576 [37:08<49:52, 81.59it/s] 20%|        | 59432/303576 [37:08<49:59, 81.39it/s] 20%|        | 59441/303576 [37:08<49:49, 81.66it/s] 20%|        | 59450/303576 [37:09<49:52, 81.58it/s] 20%|        | 59459/303576 [37:09<49:36, 82.03it/s] 20%|        | 59468/303576 [37:09<49:43, 81.81it/s] 20%|        | 59477/303576 [37:09<49:26, 82.29it/s] 20%|        | 59486/303576 [37:09<49:03, 82.91it/s] 20%|        | 59495/303576 [37:09<49:49, 81.65it/s]                                                       20%|        | 59500/303576 [37:09<49:49, 81.65it/s] 20%|        | 59504/303576 [37:09<49:08, 82.77it/s] 20%|        | 59513/303576 [37:09<48:42, 83.51it/s] 20%|        | 59522/303576 [37:09<48:20, 84.13it/s] 20%|        | 59531/303576 [37:10<48:12, 84.37it/s] 20%|        | 59540/303576 [37:10<47:55, 84.88it/s] 20%|        | 59549/303576 [37:10<47:54, 84.88it/s] 20%|        | 59558/303576 [37:10<47:43, 85.22it/s] 20%|        | 59567/303576 [37:10<47:47, 85.08it/s] 20%|        | 59576/303576 [37:10<48:57, 83.05it/s] 20%|        | 59585/303576 [37:10<51:04, 79.61it/s] 20%|        | 59593/303576 [37:10<52:49, 76.97it/s]                                                       20%|        | 59600/303576 [37:10<52:49, 76.97it/s] 20%|        | 59601/303576 [37:10<53:57, 75.35it/s] 20%|        | 59609/303576 [37:10<54:44, 74.28it/s] 20%|        | 59618/303576 [37:11<52:57, 76.79it/s] 20%|        | 59627/303576 [37:11<51:31, 78.92it/s] 20%|        | 59636/303576 [37:11<50:12, 80.98it/s] 20%|        | 59645/303576 [37:11<49:34, 82.00it/s] 20%|        | 59654/303576 [37:11<48:57, 83.04it/s] 20%|        | 59663/303576 [37:11<48:54, 83.11it/s] 20%|        | 59672/303576 [37:11<48:28, 83.87it/s] 20%|        | 59681/303576 [37:11<48:22, 84.04it/s] 20%|        | 59690/303576 [37:11<48:16, 84.19it/s] 20%|        | 59699/303576 [37:12<48:58, 83.01it/s]                                                       20%|        | 59700/303576 [37:12<48:58, 83.01it/s] 20%|        | 59708/303576 [37:12<49:37, 81.89it/s] 20%|        | 59717/303576 [37:12<49:49, 81.57it/s] 20%|        | 59726/303576 [37:12<50:06, 81.11it/s] 20%|        | 59735/303576 [37:12<49:41, 81.79it/s] 20%|        | 59744/303576 [37:12<49:39, 81.84it/s] 20%|        | 59753/303576 [37:12<49:20, 82.36it/s] 20%|        | 59762/303576 [37:12<49:30, 82.09it/s] 20%|        | 59771/303576 [37:12<49:04, 82.80it/s] 20%|        | 59780/303576 [37:13<49:13, 82.56it/s] 20%|        | 59789/303576 [37:13<49:18, 82.40it/s] 20%|        | 59798/303576 [37:13<49:23, 82.25it/s]                                                       20%|        | 59800/303576 [37:13<49:23, 82.25it/s] 20%|        | 59807/303576 [37:13<49:10, 82.61it/s] 20%|        | 59816/303576 [37:13<49:17, 82.43it/s] 20%|        | 59825/303576 [37:13<49:02, 82.85it/s] 20%|        | 59834/303576 [37:13<49:11, 82.60it/s] 20%|        | 59843/303576 [37:13<48:57, 82.98it/s] 20%|        | 59852/303576 [37:13<49:22, 82.26it/s] 20%|        | 59861/303576 [37:14<49:20, 82.33it/s] 20%|        | 59870/303576 [37:14<49:36, 81.87it/s] 20%|        | 59879/303576 [37:14<49:27, 82.12it/s] 20%|        | 59888/303576 [37:14<49:38, 81.82it/s] 20%|        | 59897/303576 [37:14<48:26, 83.84it/s]                                                       20%|        | 59900/303576 [37:14<48:26, 83.84it/s] 20%|        | 59906/303576 [37:14<48:40, 83.43it/s] 20%|        | 59915/303576 [37:14<50:21, 80.63it/s] 20%|        | 59924/303576 [37:14<55:28, 73.19it/s] 20%|        | 59932/303576 [37:15<1:01:44, 65.76it/s] 20%|        | 59939/303576 [37:15<1:04:55, 62.54it/s] 20%|        | 59946/303576 [37:15<1:09:51, 58.13it/s] 20%|        | 59953/303576 [37:15<1:09:05, 58.77it/s] 20%|        | 59959/303576 [37:15<1:09:13, 58.66it/s] 20%|        | 59965/303576 [37:15<1:09:13, 58.65it/s] 20%|        | 59971/303576 [37:15<1:09:12, 58.66it/s] 20%|        | 59977/303576 [37:15<1:09:12, 58.66it/s] 20%|        | 59983/303576 [37:15<1:09:15, 58.62it/s] 20%|        | 59989/303576 [37:16<1:09:42, 58.24it/s] 20%|        | 59995/303576 [37:16<1:09:22, 58.52it/s]                                                         20%|        | 60000/303576 [37:16<1:09:21, 58.52it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7369422316551208, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.8385, 'eval_samples_per_second': 9.896, 'eval_steps_per_second': 0.088, 'epoch': 0.58, 'timestamp': 1762966755.9979749, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7754, 'grad_norm': 0.29684409499168396, 'learning_rate': 2.717085678805347e-06, 'epoch': 0.58, 'timestamp': 1762966758.0138795, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7729, 'grad_norm': 0.24907200038433075, 'learning_rate': 2.690048879469029e-06, 'epoch': 0.59, 'timestamp': 1762966759.4176013, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7619, 'grad_norm': 0.21950337290763855, 'learning_rate': 2.6632811141657773e-06, 'epoch': 0.59, 'timestamp': 1762966760.6361048, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7552, 'grad_norm': 0.22140181064605713, 'learning_rate': 2.6367797058290465e-06, 'epoch': 0.59, 'timestamp': 1762966761.8623235, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7648, 'grad_norm': 0.21012035012245178, 'learning_rate': 2.6105420040308758e-06, 'epoch': 0.59, 'timestamp': 1762966763.0801947, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7683, 'grad_norm': 0.21475231647491455, 'learning_rate': 2.5845653847168186e-06, 'epoch': 0.59, 'timestamp': 1762966764.3158324, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7777, 'grad_norm': 0.20747852325439453, 'learning_rate': 2.5588472499434987e-06, 'epoch': 0.59, 'timestamp': 1762966765.523127, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7699, 'grad_norm': 0.2118743658065796, 'learning_rate': 2.5333850276187954e-06, 'epoch': 0.59, 'timestamp': 1762966766.7427232, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7631, 'grad_norm': 0.23884665966033936, 'learning_rate': 2.508176171244612e-06, 'epoch': 0.59, 'timestamp': 1762966767.9460936, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7734, 'grad_norm': 0.26592281460762024, 'learning_rate': 2.483218159662186e-06, 'epoch': 0.59, 'timestamp': 1762966769.6444976, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 16:59:33.029426: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:59:33.040183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966773.053001 1761185 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966773.056744 1761185 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966773.067695 1761185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966773.067716 1761185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966773.067717 1761185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966773.067719 1761185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:59:33.071076: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T16:59:35 - TensorFlow version 2.19.1 available.
2025-11-12 16:59:42.699597: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 16:59:42.710257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966782.723009 1761343 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966782.726843 1761343 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966782.737207 1761343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966782.737222 1761343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966782.737223 1761343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966782.737225 1761343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 16:59:42.740457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 20%|        | 60000/303576 [37:30<1:09:21, 58.52it/s]2025-11-12T16:59:44 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                        
                                             [A 20%|        | 60000/303576 [37:37<1:09:21, 58.52it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-60000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-60000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-60000/model.safetensors
 20%|        | 60001/303576 [37:37<72:38:10,  1.07s/it] 20%|        | 60007/303576 [37:37<51:25:24,  1.32it/s] 20%|        | 60013/303576 [37:37<36:27:36,  1.86it/s] 20%|        | 60019/303576 [37:37<25:55:26,  2.61it/s] 20%|        | 60025/303576 [37:38<18:31:36,  3.65it/s] 20%|        | 60033/303576 [37:38<12:08:22,  5.57it/s] 20%|        | 60042/303576 [37:38<7:57:39,  8.50it/s]  20%|        | 60051/303576 [37:38<5:29:06, 12.33it/s] 20%|        | 60059/303576 [37:38<4:06:15, 16.48it/s] 20%|        | 60067/303576 [37:38<3:08:51, 21.49it/s] 20%|        | 60075/303576 [37:38<2:29:03, 27.23it/s] 20%|        | 60083/303576 [37:38<2:01:21, 33.44it/s] 20%|        | 60091/303576 [37:38<1:42:52, 39.45it/s] 20%|        | 60099/303576 [37:39<1:29:01, 45.58it/s]                                                         20%|        | 60100/303576 [37:39<1:29:01, 45.58it/s] 20%|        | 60107/303576 [37:39<1:20:02, 50.69it/s] 20%|        | 60115/303576 [37:39<1:13:21, 55.31it/s] 20%|        | 60123/303576 [37:39<1:08:08, 59.54it/s] 20%|        | 60132/303576 [37:39<1:02:31, 64.89it/s] 20%|        | 60141/303576 [37:39<58:21, 69.53it/s]   20%|        | 60149/303576 [37:39<56:57, 71.22it/s] 20%|        | 60157/303576 [37:39<56:35, 71.68it/s] 20%|        | 60165/303576 [37:39<56:39, 71.60it/s] 20%|        | 60173/303576 [37:40<56:37, 71.63it/s] 20%|        | 60181/303576 [37:40<56:36, 71.65it/s] 20%|        | 60189/303576 [37:40<56:39, 71.60it/s] 20%|        | 60197/303576 [37:40<56:45, 71.46it/s]                                                       20%|        | 60200/303576 [37:40<56:45, 71.46it/s] 20%|        | 60205/303576 [37:40<57:44, 70.24it/s] 20%|        | 60213/303576 [37:40<58:29, 69.35it/s] 20%|        | 60220/303576 [37:40<58:47, 68.98it/s] 20%|        | 60228/303576 [37:40<57:09, 70.95it/s] 20%|        | 60237/303576 [37:40<54:36, 74.26it/s] 20%|        | 60246/303576 [37:41<53:23, 75.96it/s] 20%|        | 60255/303576 [37:41<52:06, 77.84it/s] 20%|        | 60264/303576 [37:41<51:37, 78.55it/s] 20%|        | 60273/303576 [37:41<51:04, 79.40it/s] 20%|        | 60282/303576 [37:41<50:29, 80.30it/s] 20%|        | 60291/303576 [37:41<52:52, 76.69it/s] 20%|        | 60299/303576 [37:41<54:15, 74.73it/s]                                                       20%|        | 60300/303576 [37:41<54:15, 74.73it/s] 20%|        | 60307/303576 [37:41<55:21, 73.23it/s] 20%|        | 60315/303576 [37:41<56:10, 72.16it/s] 20%|        | 60323/303576 [37:42<56:44, 71.45it/s] 20%|        | 60331/303576 [37:42<57:16, 70.78it/s] 20%|        | 60339/303576 [37:42<57:53, 70.03it/s] 20%|        | 60347/303576 [37:42<58:07, 69.74it/s] 20%|        | 60355/303576 [37:42<58:10, 69.69it/s] 20%|        | 60363/303576 [37:42<58:07, 69.75it/s] 20%|        | 60371/303576 [37:42<57:58, 69.91it/s] 20%|        | 60379/303576 [37:42<57:46, 70.16it/s] 20%|        | 60387/303576 [37:43<57:50, 70.08it/s] 20%|        | 60395/303576 [37:43<57:43, 70.21it/s]                                                       20%|        | 60400/303576 [37:43<57:43, 70.21it/s] 20%|        | 60403/303576 [37:43<57:56, 69.95it/s] 20%|        | 60411/303576 [37:43<57:49, 70.09it/s] 20%|        | 60419/303576 [37:43<57:40, 70.27it/s] 20%|        | 60427/303576 [37:43<56:39, 71.52it/s] 20%|        | 60436/303576 [37:43<53:43, 75.42it/s] 20%|        | 60445/303576 [37:43<51:34, 78.56it/s] 20%|        | 60455/303576 [37:43<49:06, 82.51it/s] 20%|        | 60464/303576 [37:44<49:54, 81.20it/s] 20%|        | 60473/303576 [37:44<49:38, 81.62it/s] 20%|        | 60482/303576 [37:44<49:48, 81.35it/s] 20%|        | 60491/303576 [37:44<49:06, 82.51it/s] 20%|        | 60500/303576 [37:44<49:28, 81.90it/s]                                                       20%|        | 60500/303576 [37:44<49:28, 81.90it/s] 20%|        | 60509/303576 [37:44<49:47, 81.37it/s] 20%|        | 60518/303576 [37:44<50:27, 80.29it/s] 20%|        | 60527/303576 [37:44<51:06, 79.25it/s] 20%|        | 60535/303576 [37:44<57:23, 70.57it/s] 20%|        | 60543/303576 [37:45<1:01:34, 65.78it/s] 20%|        | 60550/303576 [37:45<1:04:25, 62.86it/s] 20%|        | 60557/303576 [37:45<1:06:45, 60.68it/s] 20%|        | 60564/303576 [37:45<1:07:56, 59.61it/s] 20%|        | 60571/303576 [37:45<1:08:21, 59.25it/s] 20%|        | 60577/303576 [37:45<1:08:53, 58.79it/s] 20%|        | 60583/303576 [37:45<1:08:45, 58.90it/s] 20%|        | 60589/303576 [37:45<1:08:34, 59.06it/s] 20%|        | 60595/303576 [37:46<1:08:33, 59.07it/s]                                                         20%|        | 60600/303576 [37:46<1:08:33, 59.07it/s] 20%|        | 60602/303576 [37:46<1:08:13, 59.36it/s] 20%|        | 60608/303576 [37:46<1:09:11, 58.53it/s] 20%|        | 60614/303576 [37:46<1:09:54, 57.92it/s] 20%|        | 60620/303576 [37:46<1:10:24, 57.51it/s] 20%|        | 60626/303576 [37:46<1:10:17, 57.60it/s] 20%|        | 60632/303576 [37:46<1:10:40, 57.29it/s] 20%|        | 60638/303576 [37:46<1:10:49, 57.17it/s] 20%|        | 60644/303576 [37:46<1:11:30, 56.62it/s] 20%|        | 60650/303576 [37:46<1:12:00, 56.23it/s] 20%|        | 60656/303576 [37:47<1:12:13, 56.06it/s] 20%|        | 60662/303576 [37:47<1:12:14, 56.05it/s] 20%|        | 60668/303576 [37:47<1:12:20, 55.96it/s] 20%|        | 60674/303576 [37:47<1:12:37, 55.75it/s] 20%|        | 60680/303576 [37:47<1:12:17, 56.00it/s] 20%|        | 60686/303576 [37:47<1:12:21, 55.95it/s] 20%|        | 60692/303576 [37:47<1:12:35, 55.77it/s] 20%|        | 60698/303576 [37:47<1:12:38, 55.73it/s]                                                         20%|        | 60700/303576 [37:47<1:12:38, 55.73it/s] 20%|        | 60704/303576 [37:47<1:12:42, 55.67it/s] 20%|        | 60710/303576 [37:48<1:13:03, 55.40it/s] 20%|        | 60716/303576 [37:48<1:12:57, 55.47it/s] 20%|        | 60722/303576 [37:48<1:12:54, 55.52it/s] 20%|        | 60728/303576 [37:48<1:12:59, 55.45it/s] 20%|        | 60734/303576 [37:48<1:13:00, 55.44it/s] 20%|        | 60740/303576 [37:48<1:12:54, 55.51it/s] 20%|        | 60746/303576 [37:48<1:13:00, 55.44it/s] 20%|        | 60752/303576 [37:48<1:12:50, 55.56it/s] 20%|        | 60758/303576 [37:48<1:12:58, 55.45it/s] 20%|        | 60764/303576 [37:49<1:12:51, 55.54it/s] 20%|        | 60770/303576 [37:49<1:12:49, 55.57it/s] 20%|        | 60776/303576 [37:49<1:12:57, 55.47it/s] 20%|        | 60782/303576 [37:49<1:12:53, 55.52it/s] 20%|        | 60788/303576 [37:49<1:13:36, 54.97it/s] 20%|        | 60794/303576 [37:49<1:14:32, 54.28it/s] 20%|        | 60800/303576 [37:49<1:14:53, 54.03it/s]                                                         20%|        | 60800/303576 [37:49<1:14:53, 54.03it/s] 20%|        | 60806/303576 [37:49<1:15:13, 53.79it/s] 20%|        | 60812/303576 [37:49<1:15:05, 53.88it/s] 20%|        | 60818/303576 [37:50<1:13:52, 54.77it/s] 20%|        | 60824/303576 [37:50<1:14:05, 54.60it/s] 20%|        | 60830/303576 [37:50<1:14:53, 54.02it/s] 20%|        | 60836/303576 [37:50<1:13:39, 54.92it/s] 20%|        | 60842/303576 [37:50<1:13:28, 55.06it/s] 20%|        | 60848/303576 [37:50<1:13:52, 54.76it/s] 20%|        | 60854/303576 [37:50<1:13:34, 54.98it/s] 20%|        | 60860/303576 [37:50<1:14:41, 54.16it/s] 20%|        | 60866/303576 [37:50<1:15:45, 53.40it/s] 20%|        | 60872/303576 [37:51<1:19:01, 51.19it/s] 20%|        | 60878/303576 [37:51<1:21:14, 49.79it/s] 20%|        | 60884/303576 [37:51<1:23:12, 48.61it/s] 20%|        | 60889/303576 [37:51<1:24:54, 47.64it/s] 20%|        | 60896/303576 [37:51<1:16:36, 52.79it/s]                                                         20%|        | 60900/303576 [37:51<1:16:36, 52.79it/s] 20%|        | 60903/303576 [37:51<1:11:18, 56.72it/s] 20%|        | 60910/303576 [37:51<1:07:52, 59.58it/s] 20%|        | 60917/303576 [37:51<1:05:39, 61.60it/s] 20%|        | 60924/303576 [37:51<1:04:13, 62.97it/s] 20%|        | 60931/303576 [37:52<1:02:39, 64.54it/s] 20%|        | 60938/303576 [37:52<1:01:57, 65.27it/s] 20%|        | 60946/303576 [37:52<59:51, 67.56it/s]   20%|        | 60955/303576 [37:52<55:56, 72.28it/s] 20%|        | 60964/303576 [37:52<54:04, 74.77it/s] 20%|        | 60973/303576 [37:52<52:21, 77.23it/s] 20%|        | 60982/303576 [37:52<51:32, 78.44it/s] 20%|        | 60991/303576 [37:52<50:35, 79.91it/s] 20%|        | 61000/303576 [37:52<50:10, 80.59it/s]                                                       20%|        | 61000/303576 [37:52<50:10, 80.59it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7365261912345886, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.3877, 'eval_samples_per_second': 10.567, 'eval_steps_per_second': 0.094, 'epoch': 0.59, 'timestamp': 1762966791.033204, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7836, 'grad_norm': 0.22264157235622406, 'learning_rate': 2.458508496799953e-06, 'epoch': 0.59, 'timestamp': 1762966792.5324028, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7857, 'grad_norm': 0.20896422863006592, 'learning_rate': 2.4340447114239133e-06, 'epoch': 0.59, 'timestamp': 1762966793.902476, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.762, 'grad_norm': 0.2756170928478241, 'learning_rate': 2.409824356890475e-06, 'epoch': 0.6, 'timestamp': 1762966795.2244523, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7698, 'grad_norm': 0.23543666303157806, 'learning_rate': 2.3858450109017747e-06, 'epoch': 0.6, 'timestamp': 1762966796.6594453, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7629, 'grad_norm': 0.2348935306072235, 'learning_rate': 2.3621042752634105e-06, 'epoch': 0.6, 'timestamp': 1762966797.910185, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7693, 'grad_norm': 0.20478512346744537, 'learning_rate': 2.3385997756446006e-06, 'epoch': 0.6, 'timestamp': 1762966799.5266628, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7659, 'grad_norm': 0.3056029677391052, 'learning_rate': 2.315329161340729e-06, 'epoch': 0.6, 'timestamp': 1762966801.3098376, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7677, 'grad_norm': 0.21663956344127655, 'learning_rate': 2.2922901050382372e-06, 'epoch': 0.6, 'timestamp': 1762966803.1261995, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7702, 'grad_norm': 0.23741304874420166, 'learning_rate': 2.269480302581882e-06, 'epoch': 0.6, 'timestamp': 1762966805.0049248, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.785, 'grad_norm': 0.2210291177034378, 'learning_rate': 2.247122184962781e-06, 'epoch': 0.6, 'timestamp': 1762966806.3402374, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:00:10.137235: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:00:10.148199: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966810.161645 1761782 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966810.165714 1761782 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966810.176362 1761782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966810.176377 1761782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966810.176380 1761782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966810.176382 1761782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:00:10.179800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:00:12 - TensorFlow version 2.19.1 available.
2025-11-12 17:00:20.640653: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:00:20.651488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966820.664633 1761940 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966820.668628 1761940 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966820.679215 1761940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966820.679229 1761940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966820.679231 1761940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966820.679232 1761940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:00:20.682464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:00:22 - TensorFlow version 2.19.1 available.
 20%|        | 61000/303576 [38:10<50:10, 80.59it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 20%|        | 61000/303576 [38:15<50:10, 80.59it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 20%|        | 61001/303576 [38:15<70:51:02,  1.05s/it] 20%|        | 61006/303576 [38:15<53:34:22,  1.26it/s] 20%|        | 61013/303576 [38:15<36:07:07,  1.87it/s] 20%|        | 61020/303576 [38:15<24:49:43,  2.71it/s] 20%|        | 61027/303576 [38:15<17:18:34,  3.89it/s] 20%|        | 61034/303576 [38:15<12:14:23,  5.50it/s] 20%|        | 61042/303576 [38:15<8:25:36,  7.99it/s]  20%|        | 61049/303576 [38:16<6:13:02, 10.84it/s] 20%|        | 61057/303576 [38:16<4:28:25, 15.06it/s] 20%|        | 61066/303576 [38:16<3:13:26, 20.89it/s] 20%|        | 61075/303576 [38:16<2:26:14, 27.64it/s] 20%|        | 61083/303576 [38:16<1:58:02, 34.24it/s] 20%|        | 61092/303576 [38:16<1:35:57, 42.12it/s]                                                         20%|        | 61100/303576 [38:16<1:35:57, 42.12it/s] 20%|        | 61101/303576 [38:16<1:21:31, 49.57it/s] 20%|        | 61110/303576 [38:16<1:11:25, 56.58it/s] 20%|        | 61119/303576 [38:16<1:04:09, 62.98it/s] 20%|        | 61128/303576 [38:16<59:25, 67.99it/s]   20%|        | 61137/303576 [38:17<57:19, 70.49it/s] 20%|        | 61146/303576 [38:17<54:22, 74.30it/s] 20%|        | 61155/303576 [38:17<52:21, 77.17it/s] 20%|        | 61164/303576 [38:17<51:22, 78.65it/s] 20%|        | 61173/303576 [38:17<50:36, 79.83it/s] 20%|        | 61183/303576 [38:17<47:26, 85.15it/s] 20%|        | 61193/303576 [38:17<45:16, 89.22it/s]                                                       20%|        | 61200/303576 [38:17<45:16, 89.22it/s] 20%|        | 61204/303576 [38:17<43:36, 92.64it/s] 20%|        | 61215/303576 [38:17<42:34, 94.86it/s] 20%|        | 61225/303576 [38:18<43:24, 93.05it/s] 20%|        | 61235/303576 [38:18<44:59, 89.76it/s] 20%|        | 61245/303576 [38:18<46:24, 87.03it/s] 20%|        | 61254/303576 [38:18<47:30, 85.00it/s] 20%|        | 61263/303576 [38:18<47:44, 84.58it/s] 20%|        | 61272/303576 [38:18<48:14, 83.72it/s] 20%|        | 61281/303576 [38:18<48:20, 83.53it/s] 20%|        | 61290/303576 [38:18<48:44, 82.86it/s] 20%|        | 61299/303576 [38:18<48:41, 82.93it/s]                                                       20%|        | 61300/303576 [38:18<48:41, 82.93it/s] 20%|        | 61308/303576 [38:19<49:00, 82.39it/s] 20%|        | 61317/303576 [38:19<48:57, 82.48it/s] 20%|        | 61326/303576 [38:19<49:10, 82.10it/s] 20%|        | 61335/303576 [38:19<48:39, 82.98it/s] 20%|        | 61344/303576 [38:19<48:36, 83.06it/s] 20%|        | 61353/303576 [38:19<49:22, 81.75it/s] 20%|        | 61362/303576 [38:19<50:19, 80.21it/s] 20%|        | 61371/303576 [38:19<50:31, 79.90it/s] 20%|        | 61382/303576 [38:19<47:08, 85.64it/s] 20%|        | 61393/303576 [38:20<44:40, 90.34it/s]                                                       20%|        | 61400/303576 [38:20<44:40, 90.34it/s] 20%|        | 61404/303576 [38:20<43:12, 93.43it/s] 20%|        | 61414/303576 [38:20<42:32, 94.87it/s] 20%|        | 61425/303576 [38:20<41:39, 96.89it/s] 20%|        | 61435/303576 [38:20<41:18, 97.71it/s] 20%|        | 61445/303576 [38:20<41:15, 97.80it/s] 20%|        | 61456/303576 [38:20<40:54, 98.65it/s] 20%|        | 61467/303576 [38:20<40:35, 99.40it/s] 20%|        | 61478/303576 [38:20<40:15, 100.24it/s] 20%|        | 61489/303576 [38:21<40:06, 100.60it/s] 20%|        | 61500/303576 [38:21<40:08, 100.50it/s]                                                        20%|        | 61500/303576 [38:21<40:08, 100.50it/s] 20%|        | 61511/303576 [38:21<40:22, 99.93it/s]  20%|        | 61521/303576 [38:21<43:41, 92.34it/s] 20%|        | 61531/303576 [38:21<45:40, 88.31it/s] 20%|        | 61540/303576 [38:21<46:41, 86.40it/s] 20%|        | 61549/303576 [38:21<48:18, 83.50it/s] 20%|        | 61558/303576 [38:21<50:29, 79.88it/s] 20%|        | 61567/303576 [38:21<52:25, 76.95it/s] 20%|        | 61575/303576 [38:22<54:39, 73.80it/s] 20%|        | 61583/303576 [38:22<55:47, 72.29it/s] 20%|        | 61591/303576 [38:22<56:58, 70.78it/s] 20%|        | 61599/303576 [38:22<57:31, 70.11it/s]                                                       20%|        | 61600/303576 [38:22<57:31, 70.11it/s] 20%|        | 61607/303576 [38:22<57:52, 69.68it/s] 20%|        | 61615/303576 [38:22<57:46, 69.79it/s] 20%|        | 61623/303576 [38:22<57:50, 69.71it/s] 20%|        | 61630/303576 [38:22<57:57, 69.58it/s] 20%|        | 61637/303576 [38:23<58:44, 68.65it/s] 20%|        | 61644/303576 [38:23<58:30, 68.93it/s] 20%|        | 61651/303576 [38:23<59:54, 67.30it/s] 20%|        | 61658/303576 [38:23<59:25, 67.86it/s] 20%|        | 61665/303576 [38:23<59:33, 67.70it/s] 20%|        | 61673/303576 [38:23<58:29, 68.94it/s] 20%|        | 61680/303576 [38:23<58:22, 69.07it/s] 20%|        | 61688/303576 [38:23<57:56, 69.58it/s] 20%|        | 61696/303576 [38:23<57:42, 69.85it/s]                                                       20%|        | 61700/303576 [38:23<57:42, 69.85it/s] 20%|        | 61704/303576 [38:23<57:33, 70.03it/s] 20%|        | 61712/303576 [38:24<57:24, 70.22it/s] 20%|        | 61720/303576 [38:24<57:07, 70.56it/s] 20%|        | 61728/303576 [38:24<57:02, 70.67it/s] 20%|        | 61736/303576 [38:24<56:54, 70.83it/s] 20%|        | 61744/303576 [38:24<57:20, 70.28it/s] 20%|        | 61752/303576 [38:24<57:19, 70.32it/s] 20%|        | 61760/303576 [38:24<57:25, 70.18it/s] 20%|        | 61768/303576 [38:24<57:32, 70.04it/s] 20%|        | 61776/303576 [38:25<57:15, 70.38it/s] 20%|        | 61784/303576 [38:25<57:15, 70.39it/s] 20%|        | 61792/303576 [38:25<57:03, 70.62it/s] 20%|        | 61800/303576 [38:25<57:18, 70.32it/s]                                                       20%|        | 61800/303576 [38:25<57:18, 70.32it/s] 20%|        | 61808/303576 [38:25<57:03, 70.62it/s] 20%|        | 61816/303576 [38:25<56:47, 70.95it/s] 20%|        | 61824/303576 [38:25<57:00, 70.68it/s] 20%|        | 61832/303576 [38:25<57:06, 70.55it/s] 20%|        | 61840/303576 [38:25<56:47, 70.94it/s] 20%|        | 61848/303576 [38:26<55:25, 72.69it/s] 20%|        | 61857/303576 [38:26<53:46, 74.92it/s] 20%|        | 61866/303576 [38:26<52:16, 77.05it/s] 20%|        | 61875/303576 [38:26<51:44, 77.84it/s] 20%|        | 61884/303576 [38:26<50:59, 79.01it/s] 20%|        | 61893/303576 [38:26<50:35, 79.63it/s]                                                       20%|        | 61900/303576 [38:26<50:35, 79.63it/s] 20%|        | 61902/303576 [38:26<49:44, 80.98it/s] 20%|        | 61911/303576 [38:26<50:53, 79.15it/s] 20%|        | 61919/303576 [38:26<52:29, 76.73it/s] 20%|        | 61927/303576 [38:27<53:53, 74.73it/s] 20%|        | 61935/303576 [38:27<54:38, 73.70it/s] 20%|        | 61943/303576 [38:27<55:08, 73.02it/s] 20%|        | 61952/303576 [38:27<52:55, 76.08it/s] 20%|        | 61961/303576 [38:27<51:53, 77.59it/s] 20%|        | 61970/303576 [38:27<50:47, 79.28it/s] 20%|        | 61979/303576 [38:27<50:24, 79.89it/s] 20%|        | 61988/303576 [38:27<50:04, 80.41it/s] 20%|        | 61997/303576 [38:27<49:21, 81.57it/s]                                                       20%|        | 62000/303576 [38:27<49:21, 81.57it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7365739941596985, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.3442, 'eval_samples_per_second': 10.114, 'eval_steps_per_second': 0.09, 'epoch': 0.6, 'timestamp': 1762966828.684808, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7669, 'grad_norm': 0.2187802940607071, 'learning_rate': 2.224761833181113e-06, 'epoch': 0.6, 'timestamp': 1762966830.0922394, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7602, 'grad_norm': 0.2438848614692688, 'learning_rate': 2.2026239816867645e-06, 'epoch': 0.6, 'timestamp': 1762966831.247987, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7751, 'grad_norm': 0.2161140739917755, 'learning_rate': 2.1807064164547374e-06, 'epoch': 0.61, 'timestamp': 1762966832.425317, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7783, 'grad_norm': 0.2158522754907608, 'learning_rate': 2.1590069454910446e-06, 'epoch': 0.61, 'timestamp': 1762966833.58996, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7902, 'grad_norm': 0.2507769763469696, 'learning_rate': 2.137737172330721e-06, 'epoch': 0.61, 'timestamp': 1762966834.585852, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7858, 'grad_norm': 0.2527085840702057, 'learning_rate': 2.116465273761995e-06, 'epoch': 0.61, 'timestamp': 1762966835.9186487, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7856, 'grad_norm': 0.2487049251794815, 'learning_rate': 2.0954050446513183e-06, 'epoch': 0.61, 'timestamp': 1762966837.3686678, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7679, 'grad_norm': 0.2801162302494049, 'learning_rate': 2.074554378747604e-06, 'epoch': 0.61, 'timestamp': 1762966838.7882752, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8014, 'grad_norm': 0.22853271663188934, 'learning_rate': 2.0539111907583555e-06, 'epoch': 0.61, 'timestamp': 1762966840.093558, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7728, 'grad_norm': 0.21045805513858795, 'learning_rate': 2.0334734161411176e-06, 'epoch': 0.61, 'timestamp': 1762966841.3783412, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:00:44.742110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:00:44.752925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966844.766231 1762380 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966844.770265 1762380 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966844.780999 1762380 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966844.781016 1762380 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966844.781018 1762380 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966844.781020 1762380 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:00:44.784447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:00:46 - TensorFlow version 2.19.1 available.
 20%|        | 62000/303576 [38:40<49:21, 81.57it/s]2025-11-12 17:00:54.461220: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:00:54.471921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966854.484935 1762538 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966854.488870 1762538 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966854.499517 1762538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966854.499536 1762538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966854.499538 1762538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966854.499539 1762538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:00:54.502853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:00:56 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 20%|        | 62000/303576 [38:48<49:21, 81.57it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-62000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-62000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-62000/model.safetensors
 20%|        | 62001/303576 [38:49<57:57:36,  1.16it/s] 20%|        | 62007/303576 [38:49<43:23:19,  1.55it/s] 20%|        | 62015/303576 [38:49<29:31:56,  2.27it/s] 20%|        | 62022/303576 [38:49<21:16:53,  3.15it/s] 20%|        | 62029/303576 [38:49<15:22:14,  4.37it/s] 20%|        | 62036/303576 [38:49<11:10:14,  6.01it/s] 20%|        | 62043/303576 [38:49<8:11:46,  8.19it/s]  20%|        | 62050/303576 [38:49<6:06:11, 10.99it/s] 20%|        | 62056/303576 [38:50<4:46:57, 14.03it/s] 20%|        | 62062/303576 [38:50<3:46:49, 17.75it/s] 20%|        | 62068/303576 [38:50<3:02:19, 22.08it/s] 20%|        | 62074/303576 [38:50<2:29:39, 26.90it/s] 20%|        | 62080/303576 [38:50<2:06:25, 31.83it/s] 20%|        | 62086/303576 [38:50<1:49:39, 36.70it/s] 20%|        | 62092/303576 [38:50<1:37:36, 41.23it/s] 20%|        | 62098/303576 [38:50<1:29:47, 44.82it/s]                                                         20%|        | 62100/303576 [38:50<1:29:47, 44.82it/s] 20%|        | 62104/303576 [38:50<1:25:45, 46.93it/s] 20%|        | 62110/303576 [38:50<1:24:25, 47.67it/s] 20%|        | 62116/303576 [38:51<1:22:29, 48.79it/s] 20%|        | 62122/303576 [38:51<1:21:06, 49.61it/s] 20%|        | 62128/303576 [38:51<1:21:16, 49.51it/s] 20%|        | 62134/303576 [38:51<1:20:44, 49.84it/s] 20%|        | 62140/303576 [38:51<1:19:56, 50.33it/s] 20%|        | 62146/303576 [38:51<1:19:19, 50.72it/s] 20%|        | 62152/303576 [38:51<1:18:36, 51.19it/s] 20%|        | 62158/303576 [38:51<1:18:22, 51.34it/s] 20%|        | 62164/303576 [38:52<1:15:36, 53.21it/s] 20%|        | 62170/303576 [38:52<1:13:56, 54.41it/s] 20%|        | 62176/303576 [38:52<1:13:13, 54.95it/s] 20%|        | 62182/303576 [38:52<1:11:43, 56.09it/s] 20%|        | 62189/303576 [38:52<1:09:57, 57.51it/s] 20%|        | 62195/303576 [38:52<1:09:11, 58.14it/s]                                                         20%|        | 62200/303576 [38:52<1:09:11, 58.14it/s] 20%|        | 62201/303576 [38:52<1:10:13, 57.29it/s] 20%|        | 62207/303576 [38:52<1:10:07, 57.37it/s] 20%|        | 62213/303576 [38:52<1:09:58, 57.49it/s] 20%|        | 62219/303576 [38:52<1:09:52, 57.57it/s] 20%|        | 62225/303576 [38:53<1:09:54, 57.54it/s] 20%|        | 62231/303576 [38:53<1:09:51, 57.59it/s] 21%|        | 62237/303576 [38:53<1:10:02, 57.43it/s] 21%|        | 62243/303576 [38:53<1:09:59, 57.46it/s] 21%|        | 62249/303576 [38:53<1:10:00, 57.45it/s] 21%|        | 62255/303576 [38:53<1:09:58, 57.48it/s] 21%|        | 62261/303576 [38:53<1:09:53, 57.55it/s] 21%|        | 62267/303576 [38:53<1:10:01, 57.43it/s] 21%|        | 62273/303576 [38:53<1:10:04, 57.39it/s] 21%|        | 62279/303576 [38:54<1:10:05, 57.37it/s] 21%|        | 62285/303576 [38:54<1:10:09, 57.32it/s] 21%|        | 62291/303576 [38:54<1:10:08, 57.33it/s] 21%|        | 62297/303576 [38:54<1:10:12, 57.27it/s]                                                         21%|        | 62300/303576 [38:54<1:10:12, 57.27it/s] 21%|        | 62303/303576 [38:54<1:10:07, 57.34it/s] 21%|        | 62309/303576 [38:54<1:10:02, 57.41it/s] 21%|        | 62315/303576 [38:54<1:10:17, 57.21it/s] 21%|        | 62321/303576 [38:54<1:11:25, 56.30it/s] 21%|        | 62327/303576 [38:54<1:12:09, 55.72it/s] 21%|        | 62333/303576 [38:54<1:12:32, 55.42it/s] 21%|        | 62339/303576 [38:55<1:12:18, 55.61it/s] 21%|        | 62345/303576 [38:55<1:12:07, 55.74it/s] 21%|        | 62351/303576 [38:55<1:12:18, 55.60it/s] 21%|        | 62357/303576 [38:55<1:11:10, 56.49it/s] 21%|        | 62364/303576 [38:55<1:09:34, 57.78it/s] 21%|        | 62371/303576 [38:55<1:08:26, 58.74it/s] 21%|        | 62378/303576 [38:55<1:08:00, 59.11it/s] 21%|        | 62384/303576 [38:55<1:09:36, 57.75it/s] 21%|        | 62390/303576 [38:55<1:10:22, 57.12it/s] 21%|        | 62396/303576 [38:56<1:11:08, 56.50it/s]                                                         21%|        | 62400/303576 [38:56<1:11:08, 56.50it/s] 21%|        | 62402/303576 [38:56<1:11:26, 56.26it/s] 21%|        | 62409/303576 [38:56<1:09:16, 58.02it/s] 21%|        | 62415/303576 [38:56<1:10:08, 57.30it/s] 21%|        | 62421/303576 [38:56<1:10:04, 57.35it/s] 21%|        | 62427/303576 [38:56<1:09:43, 57.64it/s] 21%|        | 62433/303576 [38:56<1:09:52, 57.52it/s] 21%|        | 62439/303576 [38:56<1:10:22, 57.10it/s] 21%|        | 62445/303576 [38:56<1:10:44, 56.82it/s] 21%|        | 62451/303576 [38:57<1:11:30, 56.20it/s] 21%|        | 62457/303576 [38:57<1:11:36, 56.12it/s] 21%|        | 62463/303576 [38:57<1:11:34, 56.15it/s] 21%|        | 62469/303576 [38:57<1:11:02, 56.56it/s] 21%|        | 62475/303576 [38:57<1:11:12, 56.43it/s] 21%|        | 62481/303576 [38:57<1:11:07, 56.50it/s] 21%|        | 62487/303576 [38:57<1:11:50, 55.92it/s] 21%|        | 62493/303576 [38:57<1:11:54, 55.88it/s] 21%|        | 62499/303576 [38:57<1:12:46, 55.21it/s]                                                         21%|        | 62500/303576 [38:57<1:12:46, 55.21it/s] 21%|        | 62505/303576 [38:58<1:12:34, 55.37it/s] 21%|        | 62511/303576 [38:58<1:12:46, 55.20it/s] 21%|        | 62517/303576 [38:58<1:11:57, 55.83it/s] 21%|        | 62523/303576 [38:58<1:13:59, 54.29it/s] 21%|        | 62529/303576 [38:58<1:13:34, 54.61it/s] 21%|        | 62535/303576 [38:58<1:13:07, 54.94it/s] 21%|        | 62541/303576 [38:58<1:12:19, 55.54it/s] 21%|        | 62547/303576 [38:58<1:13:19, 54.79it/s] 21%|        | 62553/303576 [38:58<1:13:32, 54.62it/s] 21%|        | 62559/303576 [38:58<1:13:01, 55.01it/s] 21%|        | 62565/303576 [38:59<1:14:50, 53.67it/s] 21%|        | 62571/303576 [38:59<1:12:42, 55.24it/s] 21%|        | 62577/303576 [38:59<1:12:01, 55.77it/s] 21%|        | 62583/303576 [38:59<1:12:00, 55.78it/s] 21%|        | 62589/303576 [38:59<1:10:48, 56.72it/s] 21%|        | 62595/303576 [38:59<1:10:08, 57.26it/s]                                                         21%|        | 62600/303576 [38:59<1:10:08, 57.26it/s] 21%|        | 62601/303576 [38:59<1:09:42, 57.62it/s] 21%|        | 62607/303576 [38:59<1:11:05, 56.49it/s] 21%|        | 62614/303576 [38:59<1:07:11, 59.77it/s] 21%|        | 62621/303576 [39:00<1:04:59, 61.79it/s] 21%|        | 62628/303576 [39:00<1:03:47, 62.95it/s] 21%|        | 62635/303576 [39:00<1:02:49, 63.92it/s] 21%|        | 62643/303576 [39:00<1:00:28, 66.39it/s] 21%|        | 62651/303576 [39:00<57:20, 70.02it/s]   21%|        | 62659/303576 [39:00<55:45, 72.02it/s] 21%|        | 62667/303576 [39:00<54:38, 73.49it/s] 21%|        | 62675/303576 [39:00<53:44, 74.71it/s] 21%|        | 62683/303576 [39:00<52:55, 75.86it/s] 21%|        | 62692/303576 [39:01<52:05, 77.06it/s] 21%|        | 62700/303576 [39:01<52:04, 77.09it/s]                                                       21%|        | 62700/303576 [39:01<52:04, 77.09it/s] 21%|        | 62709/303576 [39:01<50:58, 78.75it/s] 21%|        | 62718/303576 [39:01<48:59, 81.95it/s] 21%|        | 62727/303576 [39:01<49:22, 81.31it/s] 21%|        | 62736/303576 [39:01<49:09, 81.65it/s] 21%|        | 62745/303576 [39:01<50:48, 78.99it/s] 21%|        | 62753/303576 [39:01<52:32, 76.40it/s] 21%|        | 62761/303576 [39:01<53:14, 75.38it/s] 21%|        | 62772/303576 [39:01<47:34, 84.36it/s] 21%|        | 62783/303576 [39:02<44:20, 90.52it/s] 21%|        | 62794/303576 [39:02<42:19, 94.81it/s]                                                       21%|        | 62800/303576 [39:02<42:19, 94.81it/s] 21%|        | 62805/303576 [39:02<41:29, 96.72it/s] 21%|        | 62816/303576 [39:02<40:49, 98.29it/s] 21%|        | 62826/303576 [39:02<43:08, 93.02it/s] 21%|        | 62836/303576 [39:02<45:30, 88.16it/s] 21%|        | 62845/303576 [39:02<46:57, 85.45it/s] 21%|        | 62854/303576 [39:02<48:37, 82.50it/s] 21%|        | 62863/303576 [39:02<47:36, 84.28it/s] 21%|        | 62874/303576 [39:03<44:47, 89.58it/s] 21%|        | 62885/303576 [39:03<42:14, 94.96it/s] 21%|        | 62896/303576 [39:03<41:08, 97.50it/s]                                                       21%|        | 62900/303576 [39:03<41:08, 97.50it/s] 21%|        | 62907/303576 [39:03<40:09, 99.88it/s] 21%|        | 62918/303576 [39:03<39:38, 101.19it/s] 21%|        | 62929/303576 [39:03<39:29, 101.58it/s] 21%|        | 62940/303576 [39:03<39:07, 102.53it/s] 21%|        | 62951/303576 [39:03<38:59, 102.85it/s] 21%|        | 62962/303576 [39:03<38:32, 104.05it/s] 21%|        | 62973/303576 [39:04<38:05, 105.27it/s] 21%|        | 62984/303576 [39:04<42:32, 94.27it/s]  21%|        | 62995/303576 [39:04<41:41, 96.18it/s]                                                       21%|        | 63000/303576 [39:04<41:41, 96.18it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7368550300598145, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.047, 'eval_samples_per_second': 10.738, 'eval_steps_per_second': 0.095, 'epoch': 0.61, 'timestamp': 1762966862.4258702, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8006, 'grad_norm': 0.24577957391738892, 'learning_rate': 2.0132390108969985e-06, 'epoch': 0.61, 'timestamp': 1762966864.2337103, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7661, 'grad_norm': 0.25032830238342285, 'learning_rate': 1.9932059513662434e-06, 'epoch': 0.61, 'timestamp': 1762966866.0898938, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7768, 'grad_norm': 0.21316805481910706, 'learning_rate': 1.9733722340258564e-06, 'epoch': 0.62, 'timestamp': 1762966867.8304713, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7715, 'grad_norm': 0.2595458924770355, 'learning_rate': 1.953735875289214e-06, 'epoch': 0.62, 'timestamp': 1762966869.5986392, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7756, 'grad_norm': 0.2216828167438507, 'learning_rate': 1.9342949113076963e-06, 'epoch': 0.62, 'timestamp': 1762966871.3640847, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7568, 'grad_norm': 0.21380239725112915, 'learning_rate': 1.9150473977742705e-06, 'epoch': 0.62, 'timestamp': 1762966873.158234, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7698, 'grad_norm': 0.2513762414455414, 'learning_rate': 1.8959914097290495e-06, 'epoch': 0.62, 'timestamp': 1762966874.5509925, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7625, 'grad_norm': 0.2606746256351471, 'learning_rate': 1.877125041366768e-06, 'epoch': 0.62, 'timestamp': 1762966875.6998112, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7639, 'grad_norm': 0.2658306360244751, 'learning_rate': 1.8584464058461818e-06, 'epoch': 0.62, 'timestamp': 1762966876.791615, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7993, 'grad_norm': 0.2179749608039856, 'learning_rate': 1.8399536351013704e-06, 'epoch': 0.62, 'timestamp': 1762966877.7915812, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:01:21.624735: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:01:21.635831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966881.649421 1762975 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966881.653548 1762975 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966881.664282 1762975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966881.664298 1762975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966881.664300 1762975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966881.664302 1762975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:01:21.667789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:01:23 - TensorFlow version 2.19.1 available.
2025-11-12 17:01:32.362663: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:01:32.373468: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966892.386397 1763133 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966892.390401 1763133 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966892.401034 1763133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966892.401051 1763133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966892.401053 1763133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966892.401055 1763133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:01:32.404482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
 21%|        | 63000/303576 [39:20<41:41, 96.18it/s]2025-11-12T17:01:34 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.12it/s][A                                                      
                                             [A 21%|        | 63000/303576 [39:26<41:41, 96.18it/s]
100%|| 2/2 [00:01<00:00,  1.12it/s][A
                                             [A 21%|        | 63001/303576 [39:27<48:34:17,  1.38it/s] 21%|        | 63005/303576 [39:27<41:24:02,  1.61it/s] 21%|        | 63014/303576 [39:27<28:19:37,  2.36it/s] 21%|        | 63021/303576 [39:27<21:11:21,  3.15it/s] 21%|        | 63027/303576 [39:27<16:20:26,  4.09it/s] 21%|        | 63033/303576 [39:27<12:24:19,  5.39it/s] 21%|        | 63040/303576 [39:27<8:56:12,  7.48it/s]  21%|        | 63047/303576 [39:27<6:32:52, 10.20it/s] 21%|        | 63054/303576 [39:28<4:53:16, 13.67it/s] 21%|        | 63061/303576 [39:28<3:43:35, 17.93it/s] 21%|        | 63068/303576 [39:28<2:55:19, 22.86it/s] 21%|        | 63075/303576 [39:28<2:21:22, 28.35it/s] 21%|        | 63083/303576 [39:28<1:53:17, 35.38it/s] 21%|        | 63090/303576 [39:28<1:37:17, 41.20it/s] 21%|        | 63098/303576 [39:28<1:24:26, 47.46it/s]                                                         21%|        | 63100/303576 [39:28<1:24:26, 47.46it/s] 21%|        | 63106/303576 [39:28<1:15:48, 52.87it/s] 21%|        | 63114/303576 [39:28<1:09:58, 57.27it/s] 21%|        | 63122/303576 [39:29<1:06:02, 60.68it/s] 21%|        | 63130/303576 [39:29<1:03:29, 63.11it/s] 21%|        | 63138/303576 [39:29<1:01:58, 64.66it/s] 21%|        | 63146/303576 [39:29<1:00:40, 66.05it/s] 21%|        | 63154/303576 [39:29<59:51, 66.94it/s]   21%|        | 63162/303576 [39:29<59:04, 67.83it/s] 21%|        | 63170/303576 [39:29<58:30, 68.47it/s] 21%|        | 63178/303576 [39:29<58:19, 68.69it/s] 21%|        | 63186/303576 [39:30<58:05, 68.98it/s] 21%|        | 63194/303576 [39:30<58:12, 68.82it/s]                                                       21%|        | 63200/303576 [39:30<58:12, 68.82it/s] 21%|        | 63202/303576 [39:30<58:07, 68.93it/s] 21%|        | 63210/303576 [39:30<58:00, 69.06it/s] 21%|        | 63218/303576 [39:30<57:59, 69.08it/s] 21%|        | 63226/303576 [39:30<57:55, 69.15it/s] 21%|        | 63233/303576 [39:30<57:49, 69.27it/s] 21%|        | 63240/303576 [39:30<58:05, 68.96it/s] 21%|        | 63248/303576 [39:30<57:47, 69.30it/s] 21%|        | 63256/303576 [39:31<57:29, 69.67it/s] 21%|        | 63266/303576 [39:31<52:32, 76.23it/s] 21%|        | 63277/303576 [39:31<48:13, 83.05it/s] 21%|        | 63286/303576 [39:31<48:00, 83.42it/s] 21%|        | 63295/303576 [39:31<47:51, 83.67it/s]                                                       21%|        | 63300/303576 [39:31<47:51, 83.67it/s] 21%|        | 63304/303576 [39:31<47:48, 83.77it/s] 21%|        | 63313/303576 [39:31<47:47, 83.78it/s] 21%|        | 63323/303576 [39:31<45:41, 87.63it/s] 21%|        | 63332/303576 [39:31<48:06, 83.22it/s] 21%|        | 63341/303576 [39:32<51:21, 77.96it/s] 21%|        | 63349/303576 [39:32<53:49, 74.39it/s] 21%|        | 63357/303576 [39:32<55:48, 71.74it/s] 21%|        | 63365/303576 [39:32<57:19, 69.84it/s] 21%|        | 63373/303576 [39:32<58:18, 68.67it/s] 21%|        | 63380/303576 [39:32<59:03, 67.79it/s] 21%|        | 63387/303576 [39:32<59:14, 67.57it/s] 21%|        | 63394/303576 [39:32<59:49, 66.91it/s]                                                       21%|        | 63400/303576 [39:32<59:49, 66.91it/s] 21%|        | 63401/303576 [39:32<59:51, 66.87it/s] 21%|        | 63408/303576 [39:33<1:00:19, 66.35it/s] 21%|        | 63415/303576 [39:33<1:00:19, 66.36it/s] 21%|        | 63422/303576 [39:33<59:30, 67.26it/s]   21%|        | 63430/303576 [39:33<58:37, 68.27it/s] 21%|        | 63438/303576 [39:33<57:37, 69.46it/s] 21%|        | 63446/303576 [39:33<56:56, 70.28it/s] 21%|        | 63454/303576 [39:33<56:24, 70.94it/s] 21%|        | 63462/303576 [39:33<56:19, 71.04it/s] 21%|        | 63470/303576 [39:33<56:33, 70.76it/s] 21%|        | 63478/303576 [39:34<56:42, 70.57it/s] 21%|        | 63486/303576 [39:34<56:49, 70.41it/s] 21%|        | 63494/303576 [39:34<56:10, 71.24it/s]                                                       21%|        | 63500/303576 [39:34<56:09, 71.24it/s] 21%|        | 63502/303576 [39:34<55:06, 72.62it/s] 21%|        | 63511/303576 [39:34<53:19, 75.03it/s] 21%|        | 63520/303576 [39:34<51:34, 77.58it/s] 21%|        | 63529/303576 [39:34<50:57, 78.51it/s] 21%|        | 63537/303576 [39:34<50:44, 78.85it/s] 21%|        | 63545/303576 [39:34<50:31, 79.17it/s] 21%|        | 63554/303576 [39:35<50:22, 79.40it/s] 21%|        | 63562/303576 [39:35<50:18, 79.52it/s] 21%|        | 63571/303576 [39:35<50:07, 79.80it/s] 21%|        | 63580/303576 [39:35<49:09, 81.37it/s] 21%|        | 63589/303576 [39:35<49:36, 80.63it/s] 21%|        | 63598/303576 [39:35<51:23, 77.84it/s]                                                       21%|        | 63600/303576 [39:35<51:23, 77.84it/s] 21%|        | 63606/303576 [39:35<52:47, 75.76it/s] 21%|        | 63614/303576 [39:35<53:32, 74.69it/s] 21%|        | 63622/303576 [39:35<54:10, 73.81it/s] 21%|        | 63630/303576 [39:36<54:46, 73.00it/s] 21%|        | 63638/303576 [39:36<55:14, 72.40it/s] 21%|        | 63646/303576 [39:36<55:11, 72.45it/s] 21%|        | 63656/303576 [39:36<51:12, 78.09it/s] 21%|        | 63665/303576 [39:36<50:36, 79.00it/s] 21%|        | 63674/303576 [39:36<49:42, 80.44it/s] 21%|        | 63685/303576 [39:36<46:07, 86.68it/s] 21%|        | 63696/303576 [39:36<43:14, 92.44it/s]                                                       21%|        | 63700/303576 [39:36<43:14, 92.44it/s] 21%|        | 63706/303576 [39:36<42:20, 94.42it/s] 21%|        | 63717/303576 [39:36<40:57, 97.61it/s] 21%|        | 63728/303576 [39:37<40:26, 98.83it/s] 21%|        | 63738/303576 [39:37<41:08, 97.16it/s] 21%|        | 63748/303576 [39:37<43:00, 92.92it/s] 21%|        | 63758/303576 [39:37<44:23, 90.03it/s] 21%|        | 63768/303576 [39:37<45:18, 88.21it/s] 21%|        | 63777/303576 [39:37<45:54, 87.05it/s] 21%|        | 63786/303576 [39:37<46:37, 85.72it/s] 21%|        | 63795/303576 [39:37<46:59, 85.04it/s]                                                       21%|        | 63800/303576 [39:37<46:59, 85.04it/s] 21%|        | 63806/303576 [39:37<43:52, 91.09it/s] 21%|        | 63817/303576 [39:38<41:29, 96.31it/s] 21%|        | 63827/303576 [39:38<44:09, 90.48it/s] 21%|        | 63838/303576 [39:38<42:39, 93.66it/s] 21%|        | 63848/303576 [39:38<41:56, 95.27it/s] 21%|        | 63858/303576 [39:38<41:29, 96.30it/s] 21%|        | 63868/303576 [39:38<41:03, 97.32it/s] 21%|        | 63878/303576 [39:38<40:47, 97.95it/s] 21%|        | 63888/303576 [39:38<40:38, 98.28it/s] 21%|        | 63899/303576 [39:38<40:20, 99.02it/s]                                                       21%|        | 63900/303576 [39:38<40:20, 99.02it/s] 21%|        | 63909/303576 [39:39<40:30, 98.62it/s] 21%|        | 63919/303576 [39:39<40:32, 98.51it/s] 21%|        | 63929/303576 [39:39<40:39, 98.24it/s] 21%|        | 63939/303576 [39:39<40:38, 98.28it/s] 21%|        | 63949/303576 [39:39<40:29, 98.62it/s] 21%|        | 63960/303576 [39:39<40:05, 99.61it/s] 21%|        | 63970/303576 [39:39<40:09, 99.42it/s] 21%|        | 63981/303576 [39:39<39:59, 99.85it/s] 21%|        | 63992/303576 [39:39<40:02, 99.74it/s]                                                       21%|        | 64000/303576 [39:39<40:02, 99.74it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7368043661117554, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.641, 'eval_samples_per_second': 9.982, 'eval_steps_per_second': 0.088, 'epoch': 0.62, 'timestamp': 1762966900.4330373, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7519, 'grad_norm': 0.2915794253349304, 'learning_rate': 1.8216448796548976e-06, 'epoch': 0.62, 'timestamp': 1762966902.231008, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7785, 'grad_norm': 0.24769476056098938, 'learning_rate': 1.803518308432856e-06, 'epoch': 0.62, 'timestamp': 1762966903.6702192, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7664, 'grad_norm': 0.24192316830158234, 'learning_rate': 1.7855721085817305e-06, 'epoch': 0.63, 'timestamp': 1762966904.9681308, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.771, 'grad_norm': 0.23295462131500244, 'learning_rate': 1.7678044852871013e-06, 'epoch': 0.63, 'timestamp': 1762966906.3766034, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7731, 'grad_norm': 0.2054363638162613, 'learning_rate': 1.7502136615941357e-06, 'epoch': 0.63, 'timestamp': 1762966907.794716, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7715, 'grad_norm': 0.320886492729187, 'learning_rate': 1.7327978782298793e-06, 'epoch': 0.63, 'timestamp': 1762966909.0480564, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7736, 'grad_norm': 0.2583497166633606, 'learning_rate': 1.7155553934273046e-06, 'epoch': 0.63, 'timestamp': 1762966910.2700922, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7644, 'grad_norm': 0.2850091755390167, 'learning_rate': 1.698484482751119e-06, 'epoch': 0.63, 'timestamp': 1762966911.3805492, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7628, 'grad_norm': 0.24183662235736847, 'learning_rate': 1.6815834389253013e-06, 'epoch': 0.63, 'timestamp': 1762966912.3939319, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7823, 'grad_norm': 0.2377060353755951, 'learning_rate': 1.6648505716623576e-06, 'epoch': 0.63, 'timestamp': 1762966913.409396, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:01:56.768652: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:01:56.779442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966916.792539 1763442 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966916.796527 1763442 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966916.807106 1763442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966916.807127 1763442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966916.807129 1763442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966916.807131 1763442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:01:56.810506: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:01:58 - TensorFlow version 2.19.1 available.
 21%|        | 64000/303576 [39:50<40:02, 99.74it/s]2025-11-12 17:02:06.519788: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:02:06.530640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966926.543619 1763729 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966926.547528 1763729 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966926.558128 1763729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966926.558143 1763729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966926.558144 1763729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966926.558146 1763729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:02:06.561410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:02:08 - TensorFlow version 2.19.1 available.

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                      
                                             [A 21%|        | 64000/303576 [40:01<40:02, 99.74it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-64000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-64000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-64000/model.safetensors
 21%|        | 64001/303576 [40:01<42:15:45,  1.57it/s] 21%|        | 64008/303576 [40:01<32:49:54,  2.03it/s] 21%|        | 64018/303576 [40:01<22:43:07,  2.93it/s] 21%|        | 64027/303576 [40:01<16:25:17,  4.05it/s] 21%|        | 64035/303576 [40:01<12:16:12,  5.42it/s] 21%|        | 64043/303576 [40:01<9:08:34,  7.28it/s]  21%|        | 64051/303576 [40:01<6:49:45,  9.74it/s] 21%|        | 64059/303576 [40:01<5:08:50, 12.93it/s] 21%|        | 64066/303576 [40:02<4:02:54, 16.43it/s] 21%|        | 64073/303576 [40:02<3:12:46, 20.71it/s] 21%|        | 64080/303576 [40:02<2:35:13, 25.72it/s] 21%|        | 64087/303576 [40:02<2:07:56, 31.20it/s] 21%|        | 64094/303576 [40:02<1:48:18, 36.85it/s]                                                         21%|        | 64100/303576 [40:02<1:48:18, 36.85it/s] 21%|        | 64101/303576 [40:02<1:34:07, 42.40it/s] 21%|        | 64108/303576 [40:02<1:27:48, 45.45it/s] 21%|        | 64115/303576 [40:02<1:22:52, 48.16it/s] 21%|        | 64122/303576 [40:02<1:18:41, 50.72it/s] 21%|        | 64129/303576 [40:03<1:17:35, 51.43it/s] 21%|        | 64135/303576 [40:03<1:16:29, 52.17it/s] 21%|        | 64142/303576 [40:03<1:12:41, 54.90it/s] 21%|        | 64149/303576 [40:03<1:09:01, 57.81it/s] 21%|        | 64157/303576 [40:03<1:02:49, 63.51it/s] 21%|        | 64166/303576 [40:03<57:40, 69.18it/s]   21%|        | 64175/303576 [40:03<54:37, 73.03it/s] 21%|        | 64184/303576 [40:03<52:54, 75.41it/s] 21%|        | 64193/303576 [40:03<51:32, 77.41it/s]                                                       21%|        | 64200/303576 [40:04<51:32, 77.41it/s] 21%|        | 64202/303576 [40:04<50:49, 78.50it/s] 21%|        | 64211/303576 [40:04<49:49, 80.07it/s] 21%|        | 64220/303576 [40:04<49:24, 80.74it/s] 21%|        | 64229/303576 [40:04<48:40, 81.96it/s] 21%|        | 64238/303576 [40:04<48:33, 82.15it/s] 21%|        | 64247/303576 [40:04<47:48, 83.42it/s] 21%|        | 64256/303576 [40:04<47:48, 83.42it/s] 21%|        | 64265/303576 [40:04<47:19, 84.29it/s] 21%|        | 64274/303576 [40:04<47:21, 84.21it/s] 21%|        | 64283/303576 [40:05<46:58, 84.90it/s] 21%|        | 64292/303576 [40:05<47:08, 84.60it/s]                                                       21%|        | 64300/303576 [40:05<47:08, 84.60it/s] 21%|        | 64301/303576 [40:05<47:01, 84.80it/s] 21%|        | 64310/303576 [40:05<47:08, 84.58it/s] 21%|        | 64319/303576 [40:05<47:01, 84.80it/s] 21%|        | 64328/303576 [40:05<47:14, 84.42it/s] 21%|        | 64337/303576 [40:05<47:01, 84.78it/s] 21%|        | 64346/303576 [40:05<47:09, 84.55it/s] 21%|        | 64355/303576 [40:05<46:57, 84.90it/s] 21%|        | 64364/303576 [40:06<47:08, 84.58it/s] 21%|        | 64373/303576 [40:06<47:02, 84.76it/s] 21%|        | 64382/303576 [40:06<47:13, 84.43it/s] 21%|        | 64391/303576 [40:06<46:59, 84.82it/s] 21%|        | 64400/303576 [40:06<47:07, 84.60it/s]                                                       21%|        | 64400/303576 [40:06<47:07, 84.60it/s] 21%|        | 64409/303576 [40:06<47:19, 84.23it/s] 21%|        | 64418/303576 [40:06<47:47, 83.42it/s] 21%|        | 64427/303576 [40:06<47:45, 83.45it/s] 21%|        | 64436/303576 [40:06<48:39, 81.90it/s] 21%|        | 64445/303576 [40:06<48:13, 82.63it/s] 21%|        | 64454/303576 [40:07<48:09, 82.75it/s] 21%|        | 64463/303576 [40:07<47:49, 83.32it/s] 21%|        | 64472/303576 [40:07<48:06, 82.85it/s] 21%|        | 64481/303576 [40:07<47:54, 83.17it/s] 21%|        | 64490/303576 [40:07<48:04, 82.89it/s] 21%|        | 64499/303576 [40:07<47:55, 83.15it/s]                                                       21%|        | 64500/303576 [40:07<47:55, 83.15it/s] 21%|        | 64508/303576 [40:07<48:15, 82.57it/s] 21%|       | 64517/303576 [40:07<48:03, 82.90it/s] 21%|       | 64526/303576 [40:07<48:29, 82.15it/s] 21%|       | 64535/303576 [40:08<48:08, 82.76it/s] 21%|       | 64544/303576 [40:08<48:38, 81.90it/s] 21%|       | 64553/303576 [40:08<48:16, 82.52it/s] 21%|       | 64562/303576 [40:08<48:28, 82.19it/s] 21%|       | 64571/303576 [40:08<48:12, 82.63it/s] 21%|       | 64580/303576 [40:08<49:06, 81.12it/s] 21%|       | 64589/303576 [40:08<49:14, 80.90it/s] 21%|       | 64598/303576 [40:08<49:29, 80.47it/s]                                                       21%|       | 64600/303576 [40:08<49:29, 80.47it/s] 21%|       | 64607/303576 [40:08<47:59, 83.00it/s] 21%|       | 64617/303576 [40:09<45:47, 86.97it/s] 21%|       | 64627/303576 [40:09<44:06, 90.30it/s] 21%|       | 64638/303576 [40:09<42:51, 92.93it/s] 21%|       | 64648/303576 [40:09<42:01, 94.76it/s] 21%|       | 64659/303576 [40:09<41:11, 96.68it/s] 21%|       | 64670/303576 [40:09<40:51, 97.47it/s] 21%|       | 64681/303576 [40:09<40:21, 98.65it/s] 21%|       | 64692/303576 [40:09<40:02, 99.43it/s]                                                       21%|       | 64700/303576 [40:09<40:02, 99.43it/s] 21%|       | 64702/303576 [40:09<40:20, 98.70it/s] 21%|       | 64712/303576 [40:09<40:15, 98.89it/s] 21%|       | 64722/303576 [40:10<40:07, 99.21it/s] 21%|       | 64732/303576 [40:10<40:10, 99.10it/s] 21%|       | 64743/303576 [40:10<39:28, 100.86it/s] 21%|       | 64754/303576 [40:10<38:31, 103.34it/s] 21%|       | 64765/303576 [40:10<37:54, 104.97it/s] 21%|       | 64776/303576 [40:10<37:24, 106.37it/s] 21%|       | 64787/303576 [40:10<37:46, 105.36it/s] 21%|       | 64798/303576 [40:10<43:31, 91.44it/s]                                                        21%|       | 64800/303576 [40:10<43:31, 91.44it/s] 21%|       | 64808/303576 [40:11<47:17, 84.15it/s] 21%|       | 64817/303576 [40:11<49:33, 80.30it/s] 21%|       | 64826/303576 [40:11<51:22, 77.46it/s] 21%|       | 64834/303576 [40:11<51:08, 77.79it/s] 21%|       | 64843/303576 [40:11<50:17, 79.11it/s] 21%|       | 64852/303576 [40:11<49:54, 79.72it/s] 21%|       | 64861/303576 [40:11<49:17, 80.72it/s] 21%|       | 64870/303576 [40:11<48:56, 81.29it/s] 21%|       | 64879/303576 [40:11<48:32, 81.96it/s] 21%|       | 64888/303576 [40:12<48:48, 81.49it/s] 21%|       | 64897/303576 [40:12<48:28, 82.07it/s]                                                       21%|       | 64900/303576 [40:12<48:28, 82.07it/s] 21%|       | 64906/303576 [40:12<48:34, 81.89it/s] 21%|       | 64915/303576 [40:12<48:22, 82.24it/s] 21%|       | 64924/303576 [40:12<48:28, 82.06it/s] 21%|       | 64933/303576 [40:12<48:08, 82.61it/s] 21%|       | 64942/303576 [40:12<48:18, 82.32it/s] 21%|       | 64951/303576 [40:12<48:10, 82.56it/s] 21%|       | 64960/303576 [40:12<48:17, 82.35it/s] 21%|       | 64969/303576 [40:13<48:03, 82.76it/s] 21%|       | 64978/303576 [40:13<48:15, 82.40it/s] 21%|       | 64987/303576 [40:13<48:02, 82.76it/s] 21%|       | 64996/303576 [40:13<48:13, 82.46it/s]                                                       21%|       | 65000/303576 [40:13<48:13, 82.46it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7369112968444824, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.0605, 'eval_samples_per_second': 10.731, 'eval_steps_per_second': 0.095, 'epoch': 0.63, 'timestamp': 1762966934.4703808, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7678, 'grad_norm': 0.248930424451828, 'learning_rate': 1.6482842074942697e-06, 'epoch': 0.63, 'timestamp': 1762966936.0286324, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7682, 'grad_norm': 0.2682253420352936, 'learning_rate': 1.631882689605134e-06, 'epoch': 0.63, 'timestamp': 1762966937.5032666, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7633, 'grad_norm': 0.23566436767578125, 'learning_rate': 1.61564437766546e-06, 'epoch': 0.64, 'timestamp': 1762966938.6885118, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7587, 'grad_norm': 0.23383989930152893, 'learning_rate': 1.5995676476681215e-06, 'epoch': 0.64, 'timestamp': 1762966939.8696296, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7882, 'grad_norm': 0.2733859419822693, 'learning_rate': 1.5836508917659372e-06, 'epoch': 0.64, 'timestamp': 1762966941.0794814, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7725, 'grad_norm': 0.24379613995552063, 'learning_rate': 1.567892518110868e-06, 'epoch': 0.64, 'timestamp': 1762966942.3078008, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7633, 'grad_norm': 0.22783933579921722, 'learning_rate': 1.5522909506948151e-06, 'epoch': 0.64, 'timestamp': 1762966943.3177075, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7619, 'grad_norm': 0.25290435552597046, 'learning_rate': 1.5368446291920034e-06, 'epoch': 0.64, 'timestamp': 1762966944.3399758, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7885, 'grad_norm': 0.2653326690196991, 'learning_rate': 1.5215520088029294e-06, 'epoch': 0.64, 'timestamp': 1762966945.610971, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7581, 'grad_norm': 0.27375832200050354, 'learning_rate': 1.5064115600998689e-06, 'epoch': 0.64, 'timestamp': 1762966946.8221867, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:02:30.659338: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:02:30.669985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966950.682800 1764036 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966950.686801 1764036 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966950.697260 1764036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966950.697274 1764036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966950.697276 1764036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966950.697277 1764036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:02:30.700640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:02:33 - TensorFlow version 2.19.1 available.
2025-11-12 17:02:41.355411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:02:41.366228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966961.379044 1764195 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966961.382779 1764195 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966961.393294 1764195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966961.393309 1764195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966961.393310 1764195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966961.393312 1764195 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:02:41.396435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:02:43 - TensorFlow version 2.19.1 available.
 21%|       | 65000/303576 [40:30<48:13, 82.46it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.14it/s][A                                                      
                                             [A 21%|       | 65000/303576 [40:36<48:13, 82.46it/s]
100%|| 2/2 [00:01<00:00,  1.14it/s][A
                                             [A 21%|       | 65001/303576 [40:36<58:37:31,  1.13it/s] 21%|       | 65005/303576 [40:36<48:22:06,  1.37it/s] 21%|       | 65012/303576 [40:36<33:54:01,  1.95it/s] 21%|       | 65018/303576 [40:36<25:02:45,  2.65it/s] 21%|       | 65024/303576 [40:36<18:28:16,  3.59it/s] 21%|       | 65029/303576 [40:36<14:15:24,  4.65it/s] 21%|       | 65034/303576 [40:36<10:57:19,  6.05it/s] 21%|       | 65039/303576 [40:37<8:22:25,  7.91it/s]  21%|       | 65046/303576 [40:37<5:48:00, 11.42it/s] 21%|       | 65053/303576 [40:37<4:12:06, 15.77it/s] 21%|       | 65060/303576 [40:37<3:11:21, 20.77it/s] 21%|       | 65068/303576 [40:37<2:22:21, 27.92it/s] 21%|       | 65077/303576 [40:37<1:48:38, 36.59it/s] 21%|       | 65086/303576 [40:37<1:28:26, 44.94it/s] 21%|       | 65095/303576 [40:37<1:15:10, 52.88it/s]                                                         21%|       | 65100/303576 [40:37<1:15:10, 52.88it/s] 21%|       | 65104/303576 [40:37<1:06:50, 59.46it/s] 21%|       | 65113/303576 [40:38<1:00:53, 65.26it/s] 21%|       | 65122/303576 [40:38<57:16, 69.38it/s]   21%|       | 65131/303576 [40:38<54:20, 73.12it/s] 21%|       | 65140/303576 [40:38<52:37, 75.51it/s] 21%|       | 65149/303576 [40:38<50:42, 78.37it/s] 21%|       | 65158/303576 [40:38<50:06, 79.31it/s] 21%|       | 65167/303576 [40:38<49:25, 80.41it/s] 21%|       | 65176/303576 [40:38<49:09, 80.83it/s] 21%|       | 65185/303576 [40:38<48:41, 81.60it/s] 21%|       | 65194/303576 [40:39<48:40, 81.63it/s]                                                       21%|       | 65200/303576 [40:39<48:40, 81.63it/s] 21%|       | 65203/303576 [40:39<48:24, 82.07it/s] 21%|       | 65212/303576 [40:39<48:30, 81.90it/s] 21%|       | 65221/303576 [40:39<48:11, 82.42it/s] 21%|       | 65230/303576 [40:39<48:18, 82.23it/s] 21%|       | 65239/303576 [40:39<48:08, 82.51it/s] 21%|       | 65248/303576 [40:39<48:20, 82.17it/s] 21%|       | 65257/303576 [40:39<48:09, 82.48it/s] 21%|       | 65266/303576 [40:39<48:17, 82.26it/s] 22%|       | 65275/303576 [40:40<48:10, 82.44it/s] 22%|       | 65284/303576 [40:40<48:22, 82.10it/s] 22%|       | 65293/303576 [40:40<48:10, 82.44it/s]                                                       22%|       | 65300/303576 [40:40<48:10, 82.44it/s] 22%|       | 65302/303576 [40:40<48:20, 82.14it/s] 22%|       | 65311/303576 [40:40<48:10, 82.42it/s] 22%|       | 65320/303576 [40:40<48:21, 82.12it/s] 22%|       | 65330/303576 [40:40<46:21, 85.65it/s] 22%|       | 65341/303576 [40:40<44:18, 89.63it/s] 22%|       | 65350/303576 [40:40<46:30, 85.38it/s] 22%|       | 65359/303576 [40:41<48:01, 82.68it/s] 22%|       | 65368/303576 [40:41<49:08, 80.80it/s] 22%|       | 65377/303576 [40:41<49:51, 79.62it/s] 22%|       | 65386/303576 [40:41<48:39, 81.58it/s] 22%|       | 65395/303576 [40:41<48:06, 82.53it/s]                                                       22%|       | 65400/303576 [40:41<48:06, 82.53it/s] 22%|       | 65404/303576 [40:41<48:30, 81.82it/s] 22%|       | 65413/303576 [40:41<48:54, 81.15it/s] 22%|       | 65422/303576 [40:41<53:29, 74.20it/s] 22%|       | 65430/303576 [40:41<57:44, 68.73it/s] 22%|       | 65438/303576 [40:42<1:01:18, 64.74it/s] 22%|       | 65445/303576 [40:42<1:04:42, 61.34it/s] 22%|       | 65452/303576 [40:42<1:07:32, 58.76it/s] 22%|       | 65458/303576 [40:42<1:09:51, 56.80it/s] 22%|       | 65464/303576 [40:42<1:11:18, 55.65it/s] 22%|       | 65470/303576 [40:42<1:12:47, 54.51it/s] 22%|       | 65476/303576 [40:42<1:13:30, 53.98it/s] 22%|       | 65482/303576 [40:42<1:14:09, 53.50it/s] 22%|       | 65488/303576 [40:43<1:14:55, 52.96it/s] 22%|       | 65494/303576 [40:43<1:14:54, 52.97it/s] 22%|       | 65500/303576 [40:43<1:15:09, 52.79it/s]                                                         22%|       | 65500/303576 [40:43<1:15:09, 52.79it/s] 22%|       | 65506/303576 [40:43<1:15:15, 52.72it/s] 22%|       | 65512/303576 [40:43<1:15:21, 52.66it/s] 22%|       | 65518/303576 [40:43<1:15:20, 52.67it/s] 22%|       | 65524/303576 [40:43<1:15:28, 52.56it/s] 22%|       | 65530/303576 [40:43<1:15:21, 52.65it/s] 22%|       | 65536/303576 [40:43<1:15:03, 52.86it/s] 22%|       | 65542/303576 [40:44<1:15:11, 52.77it/s] 22%|       | 65548/303576 [40:44<1:15:17, 52.69it/s] 22%|       | 65554/303576 [40:44<1:15:17, 52.69it/s] 22%|       | 65560/303576 [40:44<1:15:15, 52.71it/s] 22%|       | 65566/303576 [40:44<1:15:16, 52.70it/s] 22%|       | 65572/303576 [40:44<1:15:13, 52.73it/s] 22%|       | 65578/303576 [40:44<1:15:08, 52.79it/s] 22%|       | 65584/303576 [40:44<1:15:17, 52.68it/s] 22%|       | 65590/303576 [40:45<1:15:10, 52.76it/s] 22%|       | 65596/303576 [40:45<1:13:58, 53.62it/s]                                                         22%|       | 65600/303576 [40:45<1:13:58, 53.62it/s] 22%|       | 65602/303576 [40:45<1:13:14, 54.15it/s] 22%|       | 65608/303576 [40:45<1:12:59, 54.34it/s] 22%|       | 65614/303576 [40:45<1:12:43, 54.53it/s] 22%|       | 65620/303576 [40:45<1:12:33, 54.66it/s] 22%|       | 65626/303576 [40:45<1:11:45, 55.27it/s] 22%|       | 65632/303576 [40:45<1:11:37, 55.37it/s] 22%|       | 65638/303576 [40:45<1:11:37, 55.36it/s] 22%|       | 65645/303576 [40:45<1:09:54, 56.72it/s] 22%|       | 65652/303576 [40:46<1:07:53, 58.41it/s] 22%|       | 65659/303576 [40:46<1:06:56, 59.23it/s] 22%|       | 65665/303576 [40:46<1:07:54, 58.39it/s] 22%|       | 65671/303576 [40:46<1:08:30, 57.88it/s] 22%|       | 65677/303576 [40:46<1:08:39, 57.75it/s] 22%|       | 65683/303576 [40:46<1:09:08, 57.34it/s] 22%|       | 65689/303576 [40:46<1:09:00, 57.45it/s] 22%|       | 65695/303576 [40:46<1:08:45, 57.67it/s]                                                         22%|       | 65700/303576 [40:46<1:08:44, 57.67it/s] 22%|       | 65701/303576 [40:46<1:09:57, 56.67it/s] 22%|       | 65707/303576 [40:47<1:11:03, 55.79it/s] 22%|       | 65713/303576 [40:47<1:10:28, 56.25it/s] 22%|       | 65719/303576 [40:47<1:10:55, 55.90it/s] 22%|       | 65725/303576 [40:47<1:10:21, 56.34it/s] 22%|       | 65731/303576 [40:47<1:09:22, 57.14it/s] 22%|       | 65738/303576 [40:47<1:08:06, 58.20it/s] 22%|       | 65744/303576 [40:47<1:07:42, 58.54it/s] 22%|       | 65750/303576 [40:47<1:07:30, 58.72it/s] 22%|       | 65756/303576 [40:47<1:07:14, 58.95it/s] 22%|       | 65763/303576 [40:48<1:06:31, 59.58it/s] 22%|       | 65769/303576 [40:48<1:06:49, 59.32it/s] 22%|       | 65776/303576 [40:48<1:06:32, 59.56it/s] 22%|       | 65782/303576 [40:48<1:06:31, 59.58it/s] 22%|       | 65788/303576 [40:48<1:06:47, 59.33it/s] 22%|       | 65794/303576 [40:48<1:06:39, 59.46it/s] 22%|       | 65800/303576 [40:48<1:07:10, 58.99it/s]                                                         22%|       | 65800/303576 [40:48<1:07:10, 58.99it/s] 22%|       | 65807/303576 [40:48<1:06:26, 59.64it/s] 22%|       | 65814/303576 [40:48<1:03:44, 62.17it/s] 22%|       | 65821/303576 [40:48<1:03:05, 62.80it/s] 22%|       | 65828/303576 [40:49<1:02:14, 63.66it/s] 22%|       | 65835/303576 [40:49<1:04:00, 61.91it/s] 22%|       | 65842/303576 [40:49<1:10:02, 56.57it/s] 22%|       | 65848/303576 [40:49<1:13:35, 53.84it/s] 22%|       | 65854/303576 [40:49<1:16:13, 51.98it/s] 22%|       | 65860/303576 [40:49<1:18:06, 50.72it/s] 22%|       | 65866/303576 [40:49<1:19:38, 49.75it/s] 22%|       | 65872/303576 [40:49<1:20:40, 49.11it/s] 22%|       | 65877/303576 [40:50<1:20:26, 49.25it/s] 22%|       | 65882/303576 [40:50<1:21:36, 48.54it/s] 22%|       | 65889/303576 [40:50<1:16:17, 51.93it/s] 22%|       | 65896/303576 [40:50<1:12:02, 54.99it/s]                                                         22%|       | 65900/303576 [40:50<1:12:02, 54.99it/s] 22%|       | 65903/303576 [40:50<1:09:03, 57.36it/s] 22%|       | 65910/303576 [40:50<1:06:31, 59.55it/s] 22%|       | 65917/303576 [40:50<1:05:28, 60.50it/s] 22%|       | 65924/303576 [40:50<1:04:32, 61.37it/s] 22%|       | 65931/303576 [40:50<1:03:57, 61.93it/s] 22%|       | 65938/303576 [40:51<1:03:32, 62.32it/s] 22%|       | 65945/303576 [40:51<1:03:34, 62.30it/s] 22%|       | 65952/303576 [40:51<1:03:03, 62.80it/s] 22%|       | 65959/303576 [40:51<1:02:12, 63.67it/s] 22%|       | 65966/303576 [40:51<1:01:54, 63.96it/s] 22%|       | 65973/303576 [40:51<1:01:01, 64.89it/s] 22%|       | 65980/303576 [40:51<1:00:29, 65.46it/s] 22%|       | 65987/303576 [40:51<1:00:36, 65.33it/s] 22%|       | 65994/303576 [40:51<1:00:09, 65.82it/s]                                                         22%|       | 66000/303576 [40:52<1:00:09, 65.82it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366111278533936, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.6766, 'eval_samples_per_second': 9.966, 'eval_steps_per_second': 0.088, 'epoch': 0.64, 'timestamp': 1762966969.4992447, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7778, 'grad_norm': 0.2806631326675415, 'learning_rate': 1.491421768873912e-06, 'epoch': 0.64, 'timestamp': 1762966971.3422322, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7688, 'grad_norm': 0.25873175263404846, 'learning_rate': 1.4765811359835328e-06, 'epoch': 0.64, 'timestamp': 1762966972.5532465, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7712, 'grad_norm': 0.28984373807907104, 'learning_rate': 1.4618881772046522e-06, 'epoch': 0.65, 'timestamp': 1762966973.7672842, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7695, 'grad_norm': 0.2984248399734497, 'learning_rate': 1.4473414230822006e-06, 'epoch': 0.65, 'timestamp': 1762966974.968368, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.771, 'grad_norm': 0.21369661390781403, 'learning_rate': 1.4329394187831621e-06, 'epoch': 0.65, 'timestamp': 1762966976.7426155, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7662, 'grad_norm': 0.25050780177116394, 'learning_rate': 1.4186807239510688e-06, 'epoch': 0.65, 'timestamp': 1762966978.6291828, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7687, 'grad_norm': 0.25702938437461853, 'learning_rate': 1.4045639125619528e-06, 'epoch': 0.65, 'timestamp': 1762966980.3813787, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7646, 'grad_norm': 0.23470163345336914, 'learning_rate': 1.3905875727817272e-06, 'epoch': 0.65, 'timestamp': 1762966982.091669, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.758, 'grad_norm': 0.2648007571697235, 'learning_rate': 1.3767503068249887e-06, 'epoch': 0.65, 'timestamp': 1762966983.9224892, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7638, 'grad_norm': 0.2688179612159729, 'learning_rate': 1.363050730815224e-06, 'epoch': 0.65, 'timestamp': 1762966985.4691074, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:03:08.831833: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:03:08.842535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966988.855651 1764635 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966988.859690 1764635 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966988.870215 1764635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966988.870230 1764635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966988.870232 1764635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966988.870233 1764635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:03:08.873656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:03:10 - TensorFlow version 2.19.1 available.
2025-11-12 17:03:18.553632: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:03:18.564587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762966998.577390 1764793 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762966998.581119 1764793 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762966998.591585 1764793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966998.591604 1764793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966998.591606 1764793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762966998.591608 1764793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:03:18.594694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:03:20 - TensorFlow version 2.19.1 available.
 22%|       | 66000/303576 [41:10<1:00:09, 65.82it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.13it/s][A                                                        
                                             [A 22%|       | 66000/303576 [41:13<1:00:09, 65.82it/s]
100%|| 2/2 [00:01<00:00,  1.13it/s][A
                                             [ASaving model checkpoint to /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-66000
Configuration saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-66000/config.json
Model weights saved in /u6/cjrisi/nocturnal/models/ttm/aleppo/2025-11-12_16-21-49/5min_patients/output/checkpoint-66000/model.safetensors
 22%|       | 66001/303576 [41:13<60:36:49,  1.09it/s] 22%|       | 66010/303576 [41:13<39:21:19,  1.68it/s] 22%|       | 66018/303576 [41:13<27:29:24,  2.40it/s] 22%|       | 66025/303576 [41:13<20:08:41,  3.28it/s] 22%|       | 66032/303576 [41:13<14:44:42,  4.48it/s] 22%|       | 66038/303576 [41:13<11:14:18,  5.87it/s] 22%|       | 66044/303576 [41:13<8:30:53,  7.75it/s]  22%|       | 66050/303576 [41:13<6:28:05, 10.20it/s] 22%|       | 66056/303576 [41:14<4:57:12, 13.32it/s] 22%|       | 66062/303576 [41:14<3:51:38, 17.09it/s] 22%|       | 66068/303576 [41:14<3:04:04, 21.51it/s] 22%|       | 66074/303576 [41:14<2:30:10, 26.36it/s] 22%|       | 66080/303576 [41:14<2:06:11, 31.37it/s] 22%|       | 66086/303576 [41:14<1:49:01, 36.31it/s] 22%|       | 66092/303576 [41:14<1:36:58, 40.81it/s] 22%|       | 66098/303576 [41:14<1:28:41, 44.62it/s]                                                         22%|       | 66100/303576 [41:14<1:28:41, 44.62it/s] 22%|       | 66104/303576 [41:14<1:22:26, 48.00it/s] 22%|       | 66111/303576 [41:15<1:17:11, 51.27it/s] 22%|       | 66118/303576 [41:15<1:12:46, 54.38it/s] 22%|       | 66125/303576 [41:15<1:09:36, 56.86it/s] 22%|       | 66132/303576 [41:15<1:06:25, 59.57it/s] 22%|       | 66139/303576 [41:15<1:04:38, 61.22it/s] 22%|       | 66146/303576 [41:15<1:03:31, 62.30it/s] 22%|       | 66153/303576 [41:15<1:03:32, 62.28it/s] 22%|       | 66160/303576 [41:15<1:03:02, 62.77it/s] 22%|       | 66167/303576 [41:15<1:01:31, 64.31it/s] 22%|       | 66174/303576 [41:15<1:00:09, 65.77it/s] 22%|       | 66181/303576 [41:16<59:16, 66.75it/s]   22%|       | 66188/303576 [41:16<58:55, 67.15it/s] 22%|       | 66195/303576 [41:16<58:46, 67.32it/s]                                                       22%|       | 66200/303576 [41:16<58:46, 67.32it/s] 22%|       | 66202/303576 [41:16<58:37, 67.49it/s] 22%|       | 66209/303576 [41:16<1:04:47, 61.05it/s] 22%|       | 66216/303576 [41:16<1:10:57, 55.74it/s] 22%|       | 66222/303576 [41:16<1:14:18, 53.24it/s] 22%|       | 66228/303576 [41:16<1:16:57, 51.40it/s] 22%|       | 66234/303576 [41:17<1:18:52, 50.15it/s] 22%|       | 66240/303576 [41:17<1:20:15, 49.29it/s] 22%|       | 66245/303576 [41:17<1:20:34, 49.09it/s] 22%|       | 66250/303576 [41:17<1:22:15, 48.08it/s] 22%|       | 66256/303576 [41:17<1:22:22, 48.02it/s] 22%|       | 66261/303576 [41:17<1:21:48, 48.35it/s] 22%|       | 66266/303576 [41:17<1:23:25, 47.41it/s] 22%|       | 66271/303576 [41:17<1:22:36, 47.88it/s] 22%|       | 66276/303576 [41:17<1:23:43, 47.24it/s] 22%|       | 66281/303576 [41:18<1:22:59, 47.65it/s] 22%|       | 66286/303576 [41:18<1:23:52, 47.15it/s] 22%|       | 66291/303576 [41:18<1:22:51, 47.73it/s] 22%|       | 66296/303576 [41:18<1:23:48, 47.19it/s]                                                         22%|       | 66300/303576 [41:18<1:23:48, 47.19it/s] 22%|       | 66301/303576 [41:18<1:23:01, 47.63it/s] 22%|       | 66306/303576 [41:18<1:23:54, 47.13it/s] 22%|       | 66311/303576 [41:18<1:22:56, 47.68it/s] 22%|       | 66316/303576 [41:18<1:23:54, 47.13it/s] 22%|       | 66321/303576 [41:18<1:22:56, 47.67it/s] 22%|       | 66326/303576 [41:19<1:23:50, 47.16it/s] 22%|       | 66331/303576 [41:19<1:22:34, 47.89it/s] 22%|       | 66336/303576 [41:19<1:23:11, 47.53it/s] 22%|       | 66342/303576 [41:19<1:22:37, 47.86it/s] 22%|       | 66347/303576 [41:19<1:21:42, 48.39it/s] 22%|       | 66352/303576 [41:19<1:22:48, 47.74it/s] 22%|       | 66357/303576 [41:19<1:21:57, 48.24it/s] 22%|       | 66362/303576 [41:19<1:23:12, 47.51it/s] 22%|       | 66367/303576 [41:19<1:22:08, 48.13it/s] 22%|       | 66372/303576 [41:19<1:23:02, 47.61it/s] 22%|       | 66377/303576 [41:20<1:21:59, 48.21it/s] 22%|       | 66382/303576 [41:20<1:23:00, 47.62it/s] 22%|       | 66387/303576 [41:20<1:22:22, 47.99it/s] 22%|       | 66392/303576 [41:20<1:23:24, 47.40it/s] 22%|       | 66397/303576 [41:20<1:22:21, 48.00it/s]                                                         22%|       | 66400/303576 [41:20<1:22:21, 48.00it/s] 22%|       | 66402/303576 [41:20<1:23:22, 47.41it/s] 22%|       | 66407/303576 [41:20<1:22:06, 48.14it/s] 22%|       | 66412/303576 [41:20<1:22:58, 47.63it/s] 22%|       | 66417/303576 [41:20<1:21:53, 48.26it/s] 22%|       | 66422/303576 [41:21<1:22:48, 47.73it/s] 22%|       | 66427/303576 [41:21<1:21:49, 48.30it/s] 22%|       | 66432/303576 [41:21<1:23:00, 47.61it/s] 22%|       | 66437/303576 [41:21<1:21:56, 48.24it/s] 22%|       | 66442/303576 [41:21<1:23:02, 47.59it/s] 22%|       | 66447/303576 [41:21<1:21:55, 48.24it/s] 22%|       | 66452/303576 [41:21<1:22:49, 47.72it/s] 22%|       | 66457/303576 [41:21<1:21:56, 48.23it/s] 22%|       | 66462/303576 [41:21<1:22:44, 47.76it/s] 22%|       | 66467/303576 [41:21<1:21:38, 48.40it/s] 22%|       | 66472/303576 [41:22<1:22:55, 47.66it/s] 22%|       | 66477/303576 [41:22<1:21:48, 48.30it/s] 22%|       | 66482/303576 [41:22<1:22:52, 47.68it/s] 22%|       | 66487/303576 [41:22<1:22:32, 47.87it/s] 22%|       | 66492/303576 [41:22<1:23:36, 47.27it/s] 22%|       | 66497/303576 [41:22<1:22:27, 47.92it/s]                                                         22%|       | 66500/303576 [41:22<1:22:27, 47.92it/s] 22%|       | 66502/303576 [41:22<1:23:37, 47.25it/s] 22%|       | 66507/303576 [41:22<1:22:35, 47.84it/s] 22%|       | 66512/303576 [41:22<1:23:29, 47.32it/s] 22%|       | 66517/303576 [41:22<1:22:16, 48.02it/s] 22%|       | 66522/303576 [41:23<1:23:19, 47.42it/s] 22%|       | 66528/303576 [41:23<1:23:00, 47.60it/s] 22%|       | 66533/303576 [41:23<1:21:57, 48.20it/s] 22%|       | 66538/303576 [41:23<1:22:56, 47.63it/s] 22%|       | 66543/303576 [41:23<1:21:52, 48.25it/s] 22%|       | 66548/303576 [41:23<1:22:59, 47.60it/s] 22%|       | 66553/303576 [41:23<1:22:22, 47.96it/s] 22%|       | 66558/303576 [41:23<1:23:19, 47.41it/s] 22%|       | 66563/303576 [41:23<1:22:14, 48.03it/s] 22%|       | 66568/303576 [41:24<1:23:05, 47.54it/s] 22%|       | 66573/303576 [41:24<1:22:01, 48.16it/s] 22%|       | 66578/303576 [41:24<1:23:15, 47.44it/s] 22%|       | 66583/303576 [41:24<1:22:03, 48.13it/s] 22%|       | 66588/303576 [41:24<1:23:03, 47.56it/s] 22%|       | 66593/303576 [41:24<1:21:55, 48.21it/s] 22%|       | 66598/303576 [41:24<1:22:55, 47.63it/s]                                                         22%|       | 66600/303576 [41:24<1:22:55, 47.63it/s] 22%|       | 66603/303576 [41:24<1:21:46, 48.30it/s] 22%|       | 66608/303576 [41:24<1:22:41, 47.77it/s] 22%|       | 66614/303576 [41:25<1:22:22, 47.94it/s] 22%|       | 66619/303576 [41:25<1:21:30, 48.45it/s] 22%|       | 66624/303576 [41:25<1:22:30, 47.86it/s] 22%|       | 66630/303576 [41:25<1:22:16, 48.00it/s] 22%|       | 66636/303576 [41:25<1:22:05, 48.10it/s] 22%|       | 66641/303576 [41:25<1:21:23, 48.51it/s] 22%|       | 66646/303576 [41:25<1:22:29, 47.87it/s] 22%|       | 66651/303576 [41:25<1:21:36, 48.39it/s] 22%|       | 66656/303576 [41:25<1:22:36, 47.80it/s] 22%|       | 66661/303576 [41:25<1:21:35, 48.39it/s] 22%|       | 66666/303576 [41:26<1:22:34, 47.82it/s] 22%|       | 66671/303576 [41:26<1:21:31, 48.43it/s] 22%|       | 66676/303576 [41:26<1:22:35, 47.81it/s] 22%|       | 66681/303576 [41:26<1:21:32, 48.42it/s] 22%|       | 66686/303576 [41:26<1:22:42, 47.74it/s] 22%|       | 66691/303576 [41:26<1:22:01, 48.13it/s] 22%|       | 66696/303576 [41:26<1:23:08, 47.48it/s]                                                         22%|       | 66700/303576 [41:26<1:23:08, 47.48it/s] 22%|       | 66701/303576 [41:26<1:21:53, 48.20it/s] 22%|       | 66707/303576 [41:26<1:21:35, 48.38it/s] 22%|       | 66714/303576 [41:27<1:14:17, 53.14it/s] 22%|       | 66721/303576 [41:27<1:10:17, 56.15it/s] 22%|       | 66728/303576 [41:27<1:07:39, 58.34it/s] 22%|       | 66735/303576 [41:27<1:05:35, 60.18it/s] 22%|       | 66742/303576 [41:27<1:03:18, 62.34it/s] 22%|       | 66749/303576 [41:27<1:02:07, 63.53it/s] 22%|       | 66756/303576 [41:27<1:02:00, 63.65it/s] 22%|       | 66763/303576 [41:27<1:01:47, 63.88it/s] 22%|       | 66770/303576 [41:27<1:03:05, 62.55it/s] 22%|       | 66777/303576 [41:28<1:03:14, 62.40it/s] 22%|       | 66784/303576 [41:28<1:02:30, 63.13it/s] 22%|       | 66791/303576 [41:28<1:02:17, 63.36it/s] 22%|       | 66798/303576 [41:28<1:01:37, 64.03it/s]                                                         22%|       | 66800/303576 [41:28<1:01:37, 64.03it/s] 22%|       | 66805/303576 [41:28<1:01:44, 63.91it/s] 22%|       | 66812/303576 [41:28<1:01:35, 64.07it/s] 22%|       | 66819/303576 [41:28<1:00:42, 65.00it/s] 22%|       | 66826/303576 [41:28<1:03:10, 62.45it/s] 22%|       | 66833/303576 [41:28<1:05:01, 60.68it/s] 22%|       | 66840/303576 [41:29<1:06:13, 59.58it/s] 22%|       | 66846/303576 [41:29<1:06:38, 59.21it/s] 22%|       | 66853/303576 [41:29<1:05:15, 60.46it/s] 22%|       | 66860/303576 [41:29<1:05:08, 60.57it/s] 22%|       | 66868/303576 [41:29<1:01:05, 64.58it/s] 22%|       | 66878/303576 [41:29<53:25, 73.84it/s]   22%|       | 66889/303576 [41:29<47:55, 82.33it/s] 22%|       | 66900/303576 [41:29<44:18, 89.02it/s]                                                       22%|       | 66900/303576 [41:29<44:18, 89.02it/s] 22%|       | 66911/303576 [41:29<42:36, 92.58it/s] 22%|       | 66921/303576 [41:30<43:42, 90.24it/s] 22%|       | 66931/303576 [41:30<44:21, 88.92it/s] 22%|       | 66940/303576 [41:30<44:40, 88.27it/s] 22%|       | 66949/303576 [41:30<45:01, 87.58it/s] 22%|       | 66958/303576 [41:30<45:06, 87.43it/s] 22%|       | 66967/303576 [41:30<45:11, 87.25it/s] 22%|       | 66976/303576 [41:30<45:19, 87.01it/s] 22%|       | 66985/303576 [41:30<45:29, 86.68it/s] 22%|       | 66994/303576 [41:30<45:28, 86.72it/s]                                                       22%|       | 67000/303576 [41:30<45:27, 86.72it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366067171096802, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 21.0165, 'eval_samples_per_second': 10.753, 'eval_steps_per_second': 0.095, 'epoch': 0.65, 'timestamp': 1762967006.4862113, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7774, 'grad_norm': 0.24416494369506836, 'learning_rate': 1.3494874746464041e-06, 'epoch': 0.65, 'timestamp': 1762967008.2648754, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7712, 'grad_norm': 0.21231293678283691, 'learning_rate': 1.336192801126074e-06, 'epoch': 0.65, 'timestamp': 1762967009.800193, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7644, 'grad_norm': 0.23431654274463654, 'learning_rate': 1.3228967991190407e-06, 'epoch': 0.66, 'timestamp': 1762967011.8970144, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7673, 'grad_norm': 0.2334848791360855, 'learning_rate': 1.3097331011247396e-06, 'epoch': 0.66, 'timestamp': 1762967013.9909244, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7757, 'grad_norm': 0.2353103756904602, 'learning_rate': 1.2967003906307475e-06, 'epoch': 0.66, 'timestamp': 1762967016.0786717, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7916, 'grad_norm': 0.2578468322753906, 'learning_rate': 1.2837973642248162e-06, 'epoch': 0.66, 'timestamp': 1762967018.170439, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7644, 'grad_norm': 0.21868501603603363, 'learning_rate': 1.2710227314645058e-06, 'epoch': 0.66, 'timestamp': 1762967020.2505972, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7644, 'grad_norm': 0.26865217089653015, 'learning_rate': 1.2583752147481355e-06, 'epoch': 0.66, 'timestamp': 1762967021.8428357, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7696, 'grad_norm': 0.20754191279411316, 'learning_rate': 1.245853549187005e-06, 'epoch': 0.66, 'timestamp': 1762967023.2531645, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7647, 'grad_norm': 0.22643397748470306, 'learning_rate': 1.2334564824788921e-06, 'epoch': 0.66, 'timestamp': 1762967024.3984752, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:03:48.207594: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:03:48.218392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762967028.231525 1765233 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762967028.235286 1765233 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762967028.246019 1765233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967028.246033 1765233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967028.246035 1765233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967028.246036 1765233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:03:48.249421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:03:50 - TensorFlow version 2.19.1 available.
2025-11-12 17:03:58.931347: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:03:58.942040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762967038.954894 1765391 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762967038.958759 1765391 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762967038.969267 1765391 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967038.969282 1765391 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967038.969284 1765391 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967038.969285 1765391 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:03:58.972475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:04:00 - TensorFlow version 2.19.1 available.
 22%|       | 67000/303576 [41:50<45:27, 86.72it/s]
  0%|          | 0/2 [00:00<?, ?it/s][A
100%|| 2/2 [00:01<00:00,  1.15it/s][A                                                      
                                             [A 22%|       | 67000/303576 [41:53<45:27, 86.72it/s]
100%|| 2/2 [00:01<00:00,  1.15it/s][A
                                             [A 22%|       | 67001/303576 [41:53<53:59:24,  1.22it/s] 22%|       | 67006/303576 [41:53<43:21:13,  1.52it/s] 22%|       | 67014/303576 [41:54<30:07:05,  2.18it/s] 22%|       | 67021/303576 [41:54<22:00:31,  2.99it/s] 22%|       | 67027/303576 [41:54<16:39:14,  3.95it/s] 22%|       | 67034/303576 [41:54<11:56:59,  5.50it/s] 22%|       | 67041/303576 [41:54<8:39:20,  7.59it/s]  22%|       | 67048/303576 [41:54<6:20:48, 10.35it/s] 22%|       | 67055/303576 [41:54<4:44:11, 13.87it/s] 22%|       | 67062/303576 [41:54<3:36:24, 18.21it/s] 22%|       | 67069/303576 [41:54<2:48:59, 23.33it/s] 22%|       | 67076/303576 [41:55<2:15:51, 29.01it/s] 22%|       | 67083/303576 [41:55<1:52:36, 35.00it/s] 22%|       | 67090/303576 [41:55<1:36:13, 40.96it/s] 22%|       | 67097/303576 [41:55<1:24:49, 46.46it/s]                                                         22%|       | 67100/303576 [41:55<1:24:49, 46.46it/s] 22%|       | 67104/303576 [41:55<1:17:13, 51.04it/s] 22%|       | 67111/303576 [41:55<1:11:49, 54.87it/s] 22%|       | 67118/303576 [41:55<1:08:49, 57.26it/s] 22%|       | 67125/303576 [41:55<1:06:21, 59.38it/s] 22%|       | 67132/303576 [41:55<1:04:44, 60.86it/s] 22%|       | 67139/303576 [41:56<1:03:35, 61.97it/s] 22%|       | 67146/303576 [41:56<1:02:49, 62.72it/s] 22%|       | 67153/303576 [41:56<1:02:11, 63.36it/s] 22%|       | 67160/303576 [41:56<1:01:45, 63.79it/s] 22%|       | 67167/303576 [41:56<1:01:31, 64.04it/s] 22%|       | 67174/303576 [41:56<1:01:22, 64.20it/s] 22%|       | 67181/303576 [41:56<1:01:08, 64.43it/s] 22%|       | 67188/303576 [41:56<1:00:55, 64.66it/s] 22%|       | 67195/303576 [41:56<1:00:58, 64.60it/s]                                                         22%|       | 67200/303576 [41:56<1:00:58, 64.60it/s] 22%|       | 67202/303576 [41:57<1:01:19, 64.24it/s] 22%|       | 67209/303576 [41:57<1:00:52, 64.71it/s] 22%|       | 67216/303576 [41:57<1:00:35, 65.01it/s] 22%|       | 67223/303576 [41:57<1:00:28, 65.13it/s] 22%|       | 67230/303576 [41:57<1:00:01, 65.62it/s] 22%|       | 67237/303576 [41:57<59:28, 66.22it/s]   22%|       | 67244/303576 [41:57<59:40, 66.01it/s] 22%|       | 67251/303576 [41:57<59:11, 66.55it/s] 22%|       | 67258/303576 [41:57<59:03, 66.69it/s] 22%|       | 67267/303576 [41:57<54:17, 72.53it/s] 22%|       | 67278/303576 [41:58<47:52, 82.25it/s] 22%|       | 67289/303576 [41:58<43:43, 90.05it/s] 22%|       | 67300/303576 [41:58<42:29, 92.67it/s]                                                       22%|       | 67300/303576 [41:58<42:29, 92.67it/s] 22%|       | 67310/303576 [41:58<46:27, 84.77it/s] 22%|       | 67319/303576 [41:58<48:40, 80.89it/s] 22%|       | 67328/303576 [41:58<50:46, 77.55it/s] 22%|       | 67336/303576 [41:58<51:59, 75.74it/s] 22%|       | 67344/303576 [41:58<52:47, 74.59it/s] 22%|       | 67352/303576 [41:59<53:21, 73.78it/s] 22%|       | 67360/303576 [41:59<53:37, 73.42it/s] 22%|       | 67368/303576 [41:59<53:47, 73.19it/s] 22%|       | 67376/303576 [41:59<53:54, 73.03it/s] 22%|       | 67384/303576 [41:59<54:07, 72.73it/s] 22%|       | 67392/303576 [41:59<54:20, 72.44it/s] 22%|       | 67400/303576 [41:59<54:45, 71.89it/s]                                                       22%|       | 67400/303576 [41:59<54:45, 71.89it/s] 22%|       | 67408/303576 [41:59<54:53, 71.70it/s] 22%|       | 67416/303576 [41:59<55:12, 71.29it/s] 22%|       | 67424/303576 [42:00<55:31, 70.87it/s] 22%|       | 67432/303576 [42:00<55:26, 70.98it/s] 22%|       | 67440/303576 [42:00<55:35, 70.79it/s] 22%|       | 67448/303576 [42:00<55:46, 70.56it/s] 22%|       | 67456/303576 [42:00<55:41, 70.66it/s] 22%|       | 67464/303576 [42:00<55:29, 70.92it/s] 22%|       | 67472/303576 [42:00<55:51, 70.45it/s] 22%|       | 67480/303576 [42:00<55:50, 70.46it/s] 22%|       | 67488/303576 [42:00<56:12, 70.00it/s] 22%|       | 67496/303576 [42:01<56:15, 69.93it/s]                                                       22%|       | 67500/303576 [42:01<56:15, 69.93it/s] 22%|       | 67504/303576 [42:01<56:29, 69.65it/s] 22%|       | 67512/303576 [42:01<55:57, 70.31it/s] 22%|       | 67520/303576 [42:01<55:51, 70.43it/s] 22%|       | 67528/303576 [42:01<55:40, 70.66it/s] 22%|       | 67536/303576 [42:01<55:30, 70.88it/s] 22%|       | 67544/303576 [42:01<55:37, 70.72it/s] 22%|       | 67552/303576 [42:01<55:34, 70.78it/s] 22%|       | 67560/303576 [42:01<55:38, 70.69it/s] 22%|       | 67568/303576 [42:02<55:59, 70.26it/s] 22%|       | 67576/303576 [42:02<56:14, 69.94it/s] 22%|       | 67584/303576 [42:02<56:25, 69.71it/s] 22%|       | 67591/303576 [42:02<56:34, 69.53it/s] 22%|       | 67598/303576 [42:02<57:12, 68.75it/s]                                                       22%|       | 67600/303576 [42:02<57:12, 68.75it/s] 22%|       | 67605/303576 [42:02<56:56, 69.07it/s] 22%|       | 67612/303576 [42:02<57:40, 68.18it/s] 22%|       | 67620/303576 [42:02<57:34, 68.30it/s] 22%|       | 67628/303576 [42:02<56:54, 69.11it/s] 22%|       | 67636/303576 [42:03<56:15, 69.89it/s] 22%|       | 67644/303576 [42:03<55:57, 70.27it/s] 22%|       | 67652/303576 [42:03<55:50, 70.42it/s] 22%|       | 67660/303576 [42:03<55:48, 70.44it/s] 22%|       | 67668/303576 [42:03<55:56, 70.28it/s] 22%|       | 67676/303576 [42:03<55:44, 70.54it/s] 22%|       | 67684/303576 [42:03<55:32, 70.79it/s] 22%|       | 67692/303576 [42:03<55:22, 71.00it/s] 22%|       | 67700/303576 [42:03<55:18, 71.08it/s]                                                       22%|       | 67700/303576 [42:03<55:18, 71.08it/s] 22%|       | 67708/303576 [42:04<55:25, 70.94it/s] 22%|       | 67716/303576 [42:04<55:15, 71.14it/s] 22%|       | 67724/303576 [42:04<55:15, 71.14it/s] 22%|       | 67732/303576 [42:04<55:15, 71.12it/s] 22%|       | 67740/303576 [42:04<55:21, 71.01it/s] 22%|       | 67748/303576 [42:04<55:24, 70.94it/s] 22%|       | 67756/303576 [42:04<55:28, 70.85it/s] 22%|       | 67764/303576 [42:04<55:39, 70.62it/s] 22%|       | 67772/303576 [42:04<55:48, 70.42it/s] 22%|       | 67780/303576 [42:05<55:53, 70.32it/s] 22%|       | 67788/303576 [42:05<55:45, 70.47it/s] 22%|       | 67796/303576 [42:05<55:42, 70.53it/s]                                                       22%|       | 67800/303576 [42:05<55:42, 70.53it/s] 22%|       | 67804/303576 [42:05<55:33, 70.72it/s] 22%|       | 67812/303576 [42:05<55:25, 70.89it/s] 22%|       | 67820/303576 [42:05<55:30, 70.78it/s] 22%|       | 67828/303576 [42:05<55:37, 70.65it/s] 22%|       | 67836/303576 [42:05<55:43, 70.51it/s] 22%|       | 67844/303576 [42:05<55:48, 70.39it/s] 22%|       | 67852/303576 [42:06<55:51, 70.34it/s] 22%|       | 67860/303576 [42:06<55:35, 70.67it/s] 22%|       | 67868/303576 [42:06<55:41, 70.55it/s] 22%|       | 67876/303576 [42:06<55:04, 71.33it/s] 22%|       | 67884/303576 [42:06<54:41, 71.83it/s] 22%|       | 67892/303576 [42:06<54:49, 71.65it/s] 22%|       | 67900/303576 [42:06<54:55, 71.50it/s]                                                       22%|       | 67900/303576 [42:06<54:55, 71.50it/s] 22%|       | 67908/303576 [42:06<55:18, 71.01it/s] 22%|       | 67916/303576 [42:06<55:07, 71.24it/s] 22%|       | 67924/303576 [42:07<55:12, 71.15it/s] 22%|       | 67932/303576 [42:07<55:44, 70.45it/s] 22%|       | 67940/303576 [42:07<55:48, 70.37it/s] 22%|       | 67948/303576 [42:07<56:15, 69.82it/s] 22%|       | 67956/303576 [42:07<56:18, 69.74it/s] 22%|       | 67964/303576 [42:07<56:31, 69.47it/s] 22%|       | 67972/303576 [42:07<56:40, 69.28it/s] 22%|       | 67980/303576 [42:07<56:42, 69.24it/s] 22%|       | 67989/303576 [42:08<53:49, 72.96it/s] 22%|       | 67998/303576 [42:08<51:38, 76.03it/s]                                                       22%|       | 68000/303576 [42:08<51:38, 76.03it/s]
***** Running Evaluation *****
  Num examples = 226
  Batch size = 128
{'eval_loss': 0.7366549968719482, 'eval_custom_error': 'Cannot extract labels from complex structure', 'eval_runtime': 22.8295, 'eval_samples_per_second': 9.899, 'eval_steps_per_second': 0.088, 'epoch': 0.66, 'timestamp': 1762967047.2283754, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7689, 'grad_norm': 0.2521502375602722, 'learning_rate': 1.2211827747828137e-06, 'epoch': 0.66, 'timestamp': 1762967048.8778787, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7906, 'grad_norm': 0.2457597404718399, 'learning_rate': 1.2090311985950195e-06, 'epoch': 0.66, 'timestamp': 1762967050.42115, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.755, 'grad_norm': 0.22247201204299927, 'learning_rate': 1.1970005386262368e-06, 'epoch': 0.67, 'timestamp': 1762967051.7167418, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7652, 'grad_norm': 0.2133980542421341, 'learning_rate': 1.1850895916801223e-06, 'epoch': 0.67, 'timestamp': 1762967053.1118424, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7746, 'grad_norm': 0.2507883906364441, 'learning_rate': 1.1732971665329334e-06, 'epoch': 0.67, 'timestamp': 1762967054.533781, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7718, 'grad_norm': 0.21569004654884338, 'learning_rate': 1.1616220838143902e-06, 'epoch': 0.67, 'timestamp': 1762967055.9634957, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7731, 'grad_norm': 0.2599870562553406, 'learning_rate': 1.1500631758897303e-06, 'epoch': 0.67, 'timestamp': 1762967057.3835485, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7635, 'grad_norm': 0.2437932789325714, 'learning_rate': 1.1386192867429263e-06, 'epoch': 0.67, 'timestamp': 1762967058.797614, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7668, 'grad_norm': 0.301931232213974, 'learning_rate': 1.1272892718610758e-06, 'epoch': 0.67, 'timestamp': 1762967060.2048717, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.7732, 'grad_norm': 0.214051753282547, 'learning_rate': 1.1160719981199374e-06, 'epoch': 0.67, 'timestamp': 1762967061.594648, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
2025-11-12 17:04:24.978804: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-12 17:04:24.989867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762967065.003433 1765831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1762967065.007552 1765831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1762967065.018176 1765831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967065.018192 1765831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967065.018194 1765831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1762967065.018196 1765831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-12 17:04:25.021586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12T17:04:26 - TensorFlow version 2.19.1 available.
