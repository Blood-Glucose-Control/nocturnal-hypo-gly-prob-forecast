=== Environment Check ===
/u6/cjrisi/nocturnal/.noctprob-venv/bin/python
Python 3.11.4
Python path: /u6/cjrisi/nocturnal/.noctprob-venv/bin/python
==========================
-------------------- Preparing data... -------------------- 

Found 9 processed CSV files in /u6/cjrisi/nocturnal/cache/data/kaggle_brisT1D/processed
Loaded p10_full: 25803 rows
Loaded p11_full: 25559 rows
Loaded p01_full: 8711 rows
Loaded p06_full: 8791 rows
Loaded p05_full: 8808 rows
Loaded p12_full: 26371 rows
Loaded p02_full: 26423 rows
Loaded p04_full: 24983 rows
Loaded p03_full: 26423 rows
Successfully loaded 9 patients
Processing patient p10_full...
Processing patient p11_full...
Processing patient p12_full...
Processing patient p02_full...
Processing patient p04_full...
Processing patient p03_full...
Data length: 155562
Split config: Train 85.0%, Test 10.0%
Data ids: ['p10_full' 'p11_full' 'p12_full' 'p02_full' 'p04_full' 'p03_full']
Data processing complete
-------------------- Preparing model... -------------------- 

Model path: ibm-granite/granite-timeseries-ttm-r2
-------------------- Running few-shot 100% -------------------- 

Number of params before freezing backbone 805280
Number of params after freezing the backbone 289696
Using learning rate = 0.001
Training for 5 epochs
-------------------- Fine-tuning... -------------------- 

Starting new training run in output directory: /u6/cjrisi/nocturnal/models/ttm/kaggle_brisT1D/2025-10-01_16-35-03
{'loss': 0.804, 'grad_norm': 0.8206503987312317, 'learning_rate': 0.001, 'epoch': 0.0, 'timestamp': 1759336568.5885406, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8532, 'grad_norm': 0.19209247827529907, 'learning_rate': 0.0009901483535267252, 'epoch': 0.1, 'timestamp': 1759336570.2177413, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8463, 'grad_norm': 0.20077277719974518, 'learning_rate': 0.0009802957226154841, 'epoch': 0.2, 'timestamp': 1759336571.9531655, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8436, 'grad_norm': 0.26811039447784424, 'learning_rate': 0.0009705411318974409, 'epoch': 0.3, 'timestamp': 1759336573.7147162, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8424, 'grad_norm': 0.20180025696754456, 'learning_rate': 0.0009608836058078363, 'epoch': 0.4, 'timestamp': 1759336575.4613414, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
{'loss': 0.8371, 'grad_norm': 0.22279097139835358, 'learning_rate': 0.0009513221784894295, 'epoch': 0.5, 'timestamp': 1759336577.2046049, 'custom_batch_size': 128, 'custom_learning_rate': 0.001}
DEBUG: eval_pred type: <class 'transformers.trainer_utils.EvalPrediction'>
DEBUG: eval_pred length: N/A
DEBUG: predictions type: <class 'tuple'>, shape: No shape attr
DEBUG: labels type: <class 'tuple'>, shape: No shape attr
